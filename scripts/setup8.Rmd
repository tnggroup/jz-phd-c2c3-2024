---
title: "JZ_GED_PHD_C1 Analysis Setup 8"
author: "Johan Zvrskovec"
date: "03/05/2022"
output:
  html_document:
    fig_height: 6
    fig_width: 9
  pdf_document: default
  word_document:
    fig_height: 6
    fig_width: 9
---

```{r clean, include=FALSE, purl=FALSE}
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
#gc() #free up memory and report the memory usage.
```

# Title
**The joint phenotypic and molecular genetic architecture of Major Depressive Disorder (MDD) and anxiety disorders**

This analysis script is meant to contain most of the analysis steps performed in the project. It is run either as Rmd chunks in order, or as an R-script produced by the knitr::purl command further down. Run from the command line it takes command line arguments as seen in the command line setup below. It can be instructed (through command line arguments) to run in two run modes configured for running either locally on my laptop or on the HPC cluster. Some parts of the script can be run separately as a specific task (controlled by the command line arguments). So far is the Multivariate LD block recommended to be run on a HPC cluster and this block is also subdivided into different tasks intended to be run separately. The results of these separate tasks are to be loaded by a general run of the script to be included in the later analysis. When this has been done once, the final LD results will be saved to a file for subsequent runs of the script to rely on without having to run the LD step again. Remove (or rename) the LD results for the procedure to start anew.

# Packages

```{r package setup, echo=FALSE, warning=F}
#install.packages("disk.frame")  
#install.packages("skimr")
#install.packages("psych")
#install.packages("Matrix")
#install.packages("tidyverse")
#install.packages("ggrepel")
#install.packages("gt")
#install.packages("kableExtra")
#remove.packages("corrplot")
#devtools::install_github("taiyun/corrplot", build_vignettes = TRUE)
#install.packages("corrplot")
#remove.packages("GenomicSEM")
#devtools::install_github("MichelNivard/GenomicSEM",ref = 'v2.1') #specify branch for better stability
#devtools::install_github("MichelNivard/GenomicSEM") #master branch as default
#remove.packages("GenomicSEM")
#devtools::install_github("johanzvrskovec/GenomicSEM",ref = 'mod-jz') #specify branch
#remove.packages("HDL")
#devtools::install_github("zhenin/HDL/HDL")
#devtools::install_github("zhenin/HDL/HDL@77cb9d0984d1302e40bfd871491e292f8f09f49d") #specify exact commit
#remove.packages("BiocManager")
#install.packages("BiocManager")
#remove.packages("MungeSumstats")
#devtools::install_github("neurogenomics/MungeSumstats")
#remove.packages("SNPlocs.Hsapiens.dbSNP144.GRCh38")
#BiocManager::install("SNPlocs.Hsapiens.dbSNP144.GRCh38")
#remove.packages("BSgenome.Hsapiens.NCBI.GRCh38")
#BiocManager::install("BSgenome.Hsapiens.NCBI.GRCh38")
#install.packages("optparse")
#install.packages("stats")
#remove.packages("shru")
#devtools::install_github("johanzvrskovec/shru")
#remotes::install_github("johanzvrskovec/shru") #install without devtools and without compiling c++ parts
#install.packages("reticulate")
#install.packages("readr")  

#for testing supermunge
library(R.utils)
#library(disk.frame)
library(data.table)
library(optparse)
library(skimr)
library(ggrepel)
library(gt)
library(psych)
library(Matrix)
library(stats)
library(tidyverse)
#library(HDL)
#library(MungeSumstats)
library(shru)
library(GenomicSEM)

#library(reticulate)

```

```{r command line setup}
clParser <- OptionParser()
clParser <- add_option(clParser, c("-t", "--task"), type="character", default="0",
                help="Index of the explicit task to run separately:\n0: No task\nmvLD.mvLDSC:multivariate LDSC\nmvLD.HDL.piecewise:HDL Piecewise\nmvLD.HDL.jackknife:HDL Jackknife\nmvLD.origHDL:original HDL(jackknife)\nmvLD.origHDL.liabilityScale:original HDL with applied liability scale [default %default]")
clParser <- add_option(clParser, c("-l", "--location"), type="character", default="local",
                help="The place where the code is run [local,cluster] [default %default]")

clParser <- add_option(clParser, c("-a", "--task_argument"), type="character", default=NA,
                help="General purpose argument for tasks [default %default]")

```

# Script settings
```{r settings}
p<-c() #create project metadata object
p$clOptions<-parse_args(clParser)
p$date.run<-Sys.Date()
p$setup.version<-8
p$setup.code<-paste0("setup",p$setup.version)
p$setup.code.date<-paste0(p$setup.code,"_",p$date.run)
p$filename.rmd<-paste0(p$setup.code,".Rmd")
p$filename.r<-paste0(p$setup.code,".R")
p$functions<-c()


p$host<-p$clOptions$location #this is the place where the code is run [local,cluster] read from command line - default local
p$seting.refreshPrepareSummaryStatistics<-FALSE
p$setting.refreshLatentFactorGWAS<-FALSE

#color theme settings
theme.color<-c()
theme.color$contrastDark1<-"#2D2D2D"
theme.color$contrastDark2<-"#CC99CC"
theme.color$contrastDark3<-"#6699CC"
theme.color$contrastDark4<-"#99CC99"
theme.color$contrastLight1<-"#66CCCC"
theme.color$contrastLight2<-"#FFCC66"
theme.color$contrastLight3<-"#F99157"
theme.color$contrastLight4<-"#F2777A"

#file path settings
##set project shared working directory **change if you have other settings**
if(p$host=="local") {
p$folderpath<-normalizePath("/Users/jakz/project/JZ_GED_PHD_C1")
} else if (p$host=="cluster") {
p$folderpath<-normalizePath("/scratch/users/k19049801/project/JZ_GED_PHD_C1")
}
##project working directory subfolders
p$folderpath.workingDirectory<-normalizePath(file.path(p$folderpath,"working_directory"))

p$folderpath.scripts<-normalizePath(file.path(p$folderpath,"scripts"))
#p$folderpath.includedSoftware<-normalizePath(file.path(p$folderpath,"included_software"))
p$folderpath.plots<-normalizePath(file.path(p$folderpath,"plots"))

#general data folder
p$folderpath.data<-normalizePath(file.path(p$folderpath,"data"))

##cleaned sumstats folder
p$folderpath.data.sumstats.cleaned<-normalizePath(file.path(p$folderpath.data,"gwas_sumstats","cleaned"))

##munged sumstats folder
p$folderpath.data.sumstats.munged<-normalizePath(file.path(p$folderpath.data,"gwas_sumstats","munged_1kg_eur_supermunge"))
p$folderpath.data.sumstats.imputed<-normalizePath(file.path(p$folderpath.data,"gwas_sumstats","imputed_1kg_eur_supermunge"))
#p$folderpath.data.sumstats.munged<-normalizePath(file.path(p$folderpath.data,"gwas_sumstats","munged_1kg_eur_supermunge"))
#p$folderpath.data.sumstats.munged<-normalizePath(file.path(p$folderpath.data,"gwas_sumstats","munged_1kg_eur_gSEM"))

##imputed sumstats folder
#p$folderpath.data.sumstats.imputed<-normalizePath(file.path(p$folderpath.data,"gwas_sumstat","imputed"))

##export sumstats folder - for corrected associations for secondary analyses
p$folderpath.data.sumstats.export<-normalizePath(file.path(p$folderpath.data,"gwas_sumstats","export"))


#python virtual environment folder
if(p$host=="local") {
  p$folderpath.pythonVenv<-normalizePath("~/Documents/local_db/JZ_GED_PHD_C1/python-venv")
} else if (p$host=="cluster") {
  p$folderpath.pythonVenv<-normalizePath(file.path(p$folderpath,"python-venv"))
}

##Reference SNP-list (HapMap3 SNPs for example). Used for munging sumstat SNP data.
p$filepath.SNPReference.hm3<-normalizePath(file.path(p$folderpath.data,"w_hm3.noMHC.snplist")) #HapMap3 SNPs
## Used in the preparation step for performing latent factor GWAS as reference for calculating SNP variance across traits.
#p$filepath.SNPReference<-normalizePath(paste0(p$folderpath.data,"/","reference.1000G.maf.0.005.txt")) #1000 genomes phase 3
p$filepath.SNPReference.1kg<-normalizePath(file.path(p$folderpath.data,"combined.hm3_1kg.snplist.vanilla.jz2020.txt")) #custom hm3 + 1kg SNPs, based on individual level data in /users/k1204688/brc_scratch/Public/1KG_Phase3
#N.B GRCh38/hg38 assembly used

p$filename.suffix.data.sumstats.munged<-".gz"
#p$filename.suffix.data.sumstats.munged<-"_noMHC.sumstats.gz"

##Reference panel folder containing individual level data reference panel. Used for GWAS sumstat imputation tasks.
#roject$folderpath.data.sumstatImp.genomeReference<-"/users/k1204688/brc_scratch/Public/1KG_Phase3/All"
p$folderpath.data.sumstatImp.genomeReference<-"/users/k19049801/project/JZ_GED_PHD_ADMIN_GENERAL/data/reference.panel.1KG_Phase3.CLEANED.EUR.cM" #source /users/k1204688/brc_scratch/Public/1KG_Phase3

##LD scores datasets folders (these strings need to have a trailing slash for the GSEM LDSC to work)
p$folderpath.data.mvLDSC.ld.1kg <- file.path(p$folderpath.data,"ld_scores","eur_w_ld_chr.1KG_Phase3")
p$folderpath.data.mvLDSC.ld.hm3 <- file.path(p$folderpath.data,"ld_scores","eur_w_ld_chr")
#Weights, if different from LD-scores
#Set weights to the same folder as ldscores
p$folderpath.data.mvLDSC.wld.1kg <- p$folderpath.data.mvLDSC.ld.1kg
p$folderpath.data.mvLDSC.wld.hm3 <- p$folderpath.data.mvLDSC.ld.hm3

##HDL LD scores reference - needs the trailing slashes!!!
if(p$host=="local") {
  #use the smallest LD reference as default for local tests
  p$folderpath.data.HDL.ld<-paste0(p$folderpath.data,"/UKB_array_SVD_eigen90_extraction/")
} else if (p$host=="cluster") {
  p$folderpath.data.HDL.ld<-paste0(p$folderpath.data,"/UKB_imputed_hm3_SVD_eigen99_extraction/")
}

##Gene mapping
p$filepath.geneMapping<-file.path(p$folderpath.data,"gene_mapping","NCBI37.3.gene.loc")

##Transcription target maps
p$filepath.transcriptionTargetMap.mirdb <- file.path(p$folderpath.data,"gene_set","miRDB_v6.0_prediction_result.txt.gz")

##Gene sets folder
p$folderpath.geneSet<-file.path(p$folderpath.data,"gene_set")
  
##full script file paths
p$filepath.rmd<-normalizePath(file.path(p$folderpath.scripts,p$filename.rmd))
p$filepath.r<-normalizePath(file.path(p$folderpath.scripts,p$filename.r))

##CFA settings
p$CFA<-c()
p$CFA$correlation<-c("COR","ORT") #ORT, OBL, and COR
p$CFA$estimator=c("ML")
p$CFA$nFactors=c(6)


##latent factor GWAS filter settings
p$lfGWAS$info.filter=.6
p$lfGWAS$maf.filter=0.01

#working directory in case of running as an R-script
setwd(dir = normalizePath(p$folderpath.workingDirectory))

#inactivated python environment until it is used
#use_virtualenv(p$folderpath.pythonVenv)

print("Setup done!")

```

# Functions
```{r plot functions}

library(corrplot) #do not run on cluster, does not work?

#c(theme.color$contrastDark3,theme.color$contrastLight3)
p$printCorr <- function(corr, SE=NULL, filename, addrect = 4, is.corr = T, number.cex = 1, number.digits=2){
  # corr <- p$mvLD$covstruct.mvLDSC.1kg$S_Stand.forPlot
  # SE <- p$mvLD$covstruct.mvLDSC.1kg$S_Stand.SE[p$sumstats.sel$code,p$sumstats.sel$code]
  # filename <- file.path(p$folderpath.plots,"rg.1kg_ld.png")
  # is.corr <- T
  
  # if(absScale){
  #   palette<-colorRampPalette(c("#FFFFFF",theme.color$contrastLight3))
  # } else {
    palette<-colorRampPalette(c(theme.color$contrastDark3,"#FFFFFF",theme.color$contrastLight3))
  
 # }
  
  
  
  if(is.null(SE)){
    corr.uppCI <- NULL
    corr.lowCI <- NULL
  } else {
    corr.uppCI<-clipValues(corr + 1.96 * SE, -1,1)
    corr.lowCI<-clipValues(corr - 1.96 * SE, -1,1)
  }
  
  png(filename = filename, width = 1200, height = 1000)
corrplot(
  corr = corr,
  uppCI.mat = corr.uppCI,
  lowCI.mat = corr.lowCI,
  plotCI = ifelse(is.null(SE),c("n"),"circle"),
  order = "hclust",
  hclust.method = "ward.D",
  method = "square",
  type="full",
  addCoef.col = theme.color$contrastDark1,
  addgrid.col = theme.color$contrastDark1,
  col = palette(200),
  is.corr = is.corr,
  outline = T,
  addrect = addrect,
  rect.col = theme.color$contrastLight1,
  rect.lwd = 6,
  tl.cex = 1.7,
  tl.col = theme.color$contrastDark2,
  tl.srt = 75,
  cl.cex = 2,
  cl.ratio = 0.2,
  cl.pos = "n",
  number.cex = number.cex,
  number.digits = number.digits
  )
dev.off()
  
}

p$printCorrSimplified <- function(corr, SE=NULL, filename, is.corr = T, number.cex = 1.5, number.digits=2, absScale=F){
  
  if(absScale){
    palette<-colorRampPalette(c("#000000",theme.color$contrastLight3))
  } else {
    palette<-colorRampPalette(c(theme.color$contrastDark3,"#000000",theme.color$contrastLight3))
  }
  
  if(is.null(SE)){
    corr.uppCI <- NULL
    corr.lowCI <- NULL
  } else {
    corr.uppCI<-corr + 1.96 * SE
    corr.lowCI<-corr - 1.96 * SE
  }
  
  png(filename = filename, width = 1200, height = 1000)
corrplot(
  corr = corr,
  #uppCI.mat = corr.uppCI,
  #lowCI.mat = corr.lowCI,
  #plotCI = ifelse(is.null(SE),c("n"),"circle"),
  order = "hclust",
  hclust.method = "ward.D",
  method = "color",
  type="full",
  #addCoef.col = theme.color$contrastDark1,
  addgrid.col = theme.color$contrastDark1,
  col = palette(200),
  is.corr = is.corr,
  outline = T,
  #addrect = addrect,
  #rect.col = theme.color$contrastLight1,
  #rect.lwd = 6,
  tl.cex = 1.7,
  tl.col = theme.color$contrastDark2,
  tl.srt = 35,
  cl.cex = 2,
  cl.ratio = 0.2,
  #number.cex = number.cex,
  #number.digits = number.digits
  )
dev.off()
  
}

```


```{r knitr setup, include=FALSE, purl=FALSE}
knitr::opts_chunk$set(echo = TRUE,comment=NA,prompt=FALSE,cache=FALSE)
knitr::opts_knit$set(root.dir=normalizePath(p$folderpath.workingDirectory))

```

# R script export

```{r purl export, include=FALSE, purl=FALSE, eval=FALSE}
#running this will produce an R-script with the same name as the Rmd-file. Used for running the program on computational clusters (Rosalind), when the code just has to be run rather than creating a knitted output.
knitr::purl(p$filename.rmd)
  
```


```{r additional source setup, echo=FALSE, warning=F}

#source(normalizePath(file.path(p$folderpath.scripts,"sumstats.mod-jz.R")))
#source(file.path(p$folderpath.scripts,"include","fastman.R"))
#source(file.path(p$folderpath.scripts,"include","fastqq.R"))

```


```{r old anxi rg analysis of gwas sumstats, purl=FALSE, eval=FALSE}
p$rg_anxi<-read.table(file.path(p$folderpath.data,"ANXI03_gc.txt"), header=T, quote="", sep = "") %>%
extract(col = p2, into = "code", regex = "_noMHC/(.*)_noMHC.sumstats.", remove = F, )

p$rg_anxi<- p$rg_anxi[which(p$rg_anxi$p<.00001),]
p$rg_anxi$rg.abs<-abs(p$rg_anxi$rg)

#View(p$rg_anxi)

```

# Metadata setup

## Database connection to fetch trait and GWAS metadata - run from Rstudio .rmd
```{r sumstat metadata database load}
p$filepath.sumstats<-file.path(p$folderpath.workingDirectory,paste0("sumstats.",p$setup.code,".Rds"))
if (file.exists(p$filepath.sumstats)) {
  print("Loading summary statistics metadata from previously stored file.")
  p$sumstats<-readRDS(file=p$filepath.sumstats)
} else {

#install.packages('RPostgres')
library(RPostgres)
library(DBI)

p$phenodbcon <- dbConnect(RPostgres::Postgres(),
                 dbname = 'phenodb', 
                 host = '10.200.105.5', 
                 port = 5432,
                 user = 'johan',
                 password = rstudioapi::askForPassword(prompt = "Enter database password for specified user."))

p$phenodbres <- dbSendQuery(p$phenodbcon, "SELECT \"GWAS\".*, category_id, category.name AS category_name, phenotype.name AS phenotype, phenotype.type AS phenotype_type, pmid, year FROM sumstat_old.\"GWAS\", sumstat_old.reference, sumstat_old.phenotype, sumstat_old.category 
WHERE \"GWAS\".reference_id=reference.id AND \"GWAS\".phenotype_id=phenotype.id AND phenotype.category_id = category.id
ORDER BY code,\"GWAS\".id")
p$sumstats<-dbFetch(p$phenodbres)
dbClearResult(p$phenodbres)

#fallback
#p$sumstats<-read.table(file.path(p$folderpath.data,"ukbb_sumstats_download202005.csv"), header=T, quote="\"", sep = ",", fill=T, blank.lines.skip=T,as.is = c(2), strip.white = T)

saveRDS(p$sumstats,file = p$filepath.sumstats)
write.table(p$sumstats, file = file.path(p$folderpath.workingDirectory,paste0(p$setup.code,".sumstats.tsv")), quote = F, sep = "\t", row.names = FALSE, col.names = TRUE)
}



```



## Trait setup
```{r trait setup}
#,echo=FALSE
p$trait<-data.frame(phenotype_id=c())

#ADHD
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-139
p$trait[nrow(p$trait),c("populationPrevalence")]<-.00529 #Worldwide-pooled
p$trait[nrow(p$trait),c("referenceDOI")]<-"https://doi.org/10.1176/ajp.2007.164.6.942"

#ALCD
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-141
p$trait[nrow(p$trait),c("populationPrevalence")]<-.125 #US total measurement
p$trait[nrow(p$trait),c("referenceDOI")]<-"https://doi.org/10.1001/archpsyc.64.7.830"

#ANOR
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-142
p$trait[nrow(p$trait),c("populationPrevalence")]<-.0245 #European average (3 secondary refs)
p$trait[nrow(p$trait),c("referenceDOI")]<-"https://doi.org/10.1038/S41588-019-0439-2"

#ANXI
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-144
p$trait[nrow(p$trait),c("populationPrevalence")]<-.16 #Any type of anxiety disorder, Via https://doi.org/10.1038/s41380-019-0559-1 (2019), originally from https://doi.org/10.1017/S1121189X00001421 (2009)
p$trait[nrow(p$trait),c("referenceDOI")]<-"https://doi.org/10.1017/S1121189X00001421"

#AUTI
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-145
p$trait[nrow(p$trait),c("populationPrevalence")]<-.0122
p$trait[nrow(p$trait),c("referenceDOI")]<-"https://doi.org/10.1186/s12874-016-0280-6"

#BIPO
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-146
p$trait[nrow(p$trait),c("populationPrevalence")]<- .007 #mean of male and female global prevalence rate (2013) from https://doi.org/10.1111/bdi.12423 (2016)
p$trait[nrow(p$trait),c("referenceDOI")]<-"https://doi.org/10.1111/bdi.12423"

#DEPR
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-149
p$trait[nrow(p$trait),c("populationPrevalence")]<-.146 #MDD, .15 from the LD-calculations in https://doi.org/10.1038/s41588-018-0090-3 (2018), but with a possible reference to https://doi.org/10.1146/annurev-publhealth-031912-114409 (2013) which states 14.6% lifetime prevalence of MDE in high-income countries.
p$trait[nrow(p$trait),c("referenceDOI")]<-"https://doi.org/10.1146/annurev-publhealth-031912-114409"

#INSO
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-171
p$trait[nrow(p$trait),c("populationPrevalence")]<-.69 #using the 'prevalence', the higher estimate of persistent symptoms after 1y follow up.
p$trait[nrow(p$trait),c("referenceDOI")]<-"https://doi.org/10.1093/sleep/30.3.274"

#PTSD
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-140
p$trait[nrow(p$trait),c("populationPrevalence")]<-.3 #using the moderate estimate of lifetime prevalence after trauma as used in ref
p$trait[nrow(p$trait),c("referenceDOI")]<-"10.1038/s41467-019-12576-w"

#SCHI
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-151
p$trait[nrow(p$trait),c("populationPrevalence")]<-.0072 #using the lifetime morbid risk estimate, slightly more suitable for the CLOZUK sample as described in the GWAS but not using the lower point estimate of 0.4%
p$trait[nrow(p$trait),c("referenceDOI")]<-"https://doi.org/10.1093/epirev/mxn001"

p$trait

```


## Setup GWAS summary statistics datasets
```{r setup GWAS sumstat dataset}
#, echo=FALSE


#View(p$sumstats)

#rename and add columns
names(p$sumstats)[names(p$sumstats)=="n_cases"]<-"n_case"
names(p$sumstats)[names(p$sumstats)=="n_controls"]<-"n_control"
p$sumstats$gwas_name.nice<-NA_character_
p$sumstats$code.trait<-NA_character_
p$sumstats$reference_doi<-NA_character_
p$sumstats$effect.logit<-as.logical(NA)
p$sumstats$dependent_variable.linprob<-as.logical(NA)
p$sumstats$se.logit<-as.logical(NA)
p$sumstats$dependent_variable.OLS<-as.logical(NA)
p$sumstats$age.min<-NA_integer_
p$sumstats$age.max<-NA_integer_
p$sumstats$age.mean<-NA_real_
p$sumstats$age.sd<-NA_real_

#add missing datasets and data
p$sumstats[nrow(p$sumstats)+1,c("code","n_case","n_control","n_total","phenotype_id","reference_id","reference_doi")]=list(
  code="DEPR05",
  n_case=16823,
  n_control=25632,
  n_total=42455,
  phenotype_id=149,
  reference_id=127,
  reference_doi=c("https://doi.org/10.1038/s41588-018-0090-3")
  )

#add missing datasets and data
p$sumstats[nrow(p$sumstats)+1,c("code","n_case","n_control","n_total","phenotype_id","reference_id","reference_doi")]=list(
  code="ANXI04",
  n_case=19012,
  n_control=58113,
  n_total=77125,
  phenotype_id=144,
  reference_id=158
  )

p$sumstats[nrow(p$sumstats)+1,c("code","name", "n_case","n_control","n_total","phenotype_id","reference_id","reference_doi")]=list(
  code="NEUR02",
  name="Neuroticism",
  n_case=449484,
  n_control=NA_integer_,
  n_total=449484,
  phenotype_id=176,
  reference_id=NA_integer_,
  reference_doi=c("https://doi.org/10.1038/s41588-018-0151-7")
  )

#add missing datasets and data
p$sumstats[nrow(p$sumstats)+1,c("code","name","n_total","phenotype_id")]=list(
  code="NOIS01",
  name="Noise 1",
  n_total=766345,
  phenotype_id=197
  )

p$sumstats[nrow(p$sumstats)+1,c("code","name","n_total","phenotype_id")]=list(
  code="NOIS02",
  name="Noise 2",
  n_total=766345,
  phenotype_id=197
  )



#reformat columns
p$sumstats$name<-as.character(p$sumstats$name)

##Add comprehensive names as in the Google sheet
p$sumstats$name[which(p$sumstats$code=="DEPR05")]="Major depressive disorder (PGC2 29) - only clinical ascertainment"

##Add trait/disorder information
p$sumstats <- p$sumstats %>%
mutate(
  code.trait=substr(x = code, start = 1, stop = 4)
       ) %>%
  left_join(p$trait[,c("phenotype_id","populationPrevalence")], by = c("phenotype_id" = "phenotype_id"))


#set code as rowname
rownames(p$sumstats)<-p$sumstats$code

##Add sumstat cleaned and munged file paths
p$sumstats$cleanedpath<-file.path(p$folderpath.data.sumstats.cleaned,paste0(p$sumstats$code,p$filename.suffix.data.sumstats.munged))

p$sumstats$mungedpath<-file.path(p$folderpath.data.sumstats.munged,paste0(p$sumstats$code,p$filename.suffix.data.sumstats.munged))

p$sumstats$imputedpath<-file.path(p$folderpath.data.sumstats.imputed,paste0(p$sumstats$code,p$filename.suffix.data.sumstats.munged))


#special modification for special datasets for munging locally or at rosalind
if(p$host=="local"){
  p$sumstats["ANXI04",]$cleanedpath<-"/Users/jakz/Documents/local_db/JZ_GED_PHD_ADMIN_GENERAL/data/gwas_sumstats/raw/GAD7_BGENIE_SexRegressed_For_LDSC.gz"
} else {
  p$sumstats["ANXI04",]$cleanedpath<-"/users/k19049801/project/JZ_GED_PHD_C1/data/gwas_sumstats/raw/GAD7_BGENIE_SexRegressed_For_LDSC.gz"
    }

if(p$host=="local"){
  p$sumstats["NEUR02",]$cleanedpath<-"/Users/jakz/Documents/local_db/JZ_GED_PHD_ADMIN_GENERAL/data/gwas_sumstats/raw/sumstats_neuroticism_ctg_format.txt.gz"
} else {
  p$sumstats["NEUR02",]$cleanedpath<-"/users/k19049801/project/JZ_GED_PHD_C1/data/gwas_sumstats/raw/sumstats_neuroticism_ctg_format.txt.gz"
    }




##add reference year
p$sumstats["ANXI03",]$year=2019
p$sumstats["ANXI04",]$year=2019
p$sumstats["DEPR05",]$year=2018
p$sumstats["NEUR02",]$year=2018

##Add doi links for easy access to dataset publication
p$sumstats["ALCD03",]$reference_doi="https://doi.org/10.1038/s41593-018-0275-1"
p$sumstats["ANXI03",]$reference_doi="https://doi.org/10.1038/s41380-019-0559-1"
p$sumstats["ANXI04",]$reference_doi="https://doi.org/10.1038/s41380-019-0559-1"
p$sumstats["AUTI07",]$reference_doi="https://doi.org/10.1038/s41588-019-0344-8"
p$sumstats["DEPR08",]$reference_doi="https://doi.org/10.1038/s41588-018-0090-3"
p$sumstats["EDUC03",]$reference_doi="https://doi.org/10.1038/s41588-018-0147-3"
p$sumstats["HEAL01",]$reference_doi="https://doi.org/10.1093/ije/dyw219"
p$sumstats["NEUR01",]$reference_doi="https://doi.org/10.1038/ng.3552"
p$sumstats["SUBJ01",]$reference_doi="https://doi.org/10.1038/ng.3552"
p$sumstats["TIRE01",]$reference_doi="https://doi.org/10.1038/mp.2017.5"


##Add PMID
p$sumstats["ANXI03",]$pmid="31748690"
p$sumstats["ANXI04",]$pmid="31748690"
p$sumstats["DEPR05",]$pmid="29700475"

##add dependent variable type
p$sumstats$dependent_variable[which(p$sumstats$code=="DEPR05")]="binary"

##add participant numbers
p$sumstats$n_total[which(p$sumstats$code=="NEUR01")]=170911

##add ancestry details
p$sumstats$ancestry[which(p$sumstats$code=="NEUR01")]="EUR"
p$sumstats$ancestry[which(p$sumstats$code=="DEPR05")]="EUR"

##add sex details
p$sumstats$sex[which(p$sumstats$code=="ANXI04")]="both"
p$sumstats$sex[which(p$sumstats$code=="NEUR01")]="both"
p$sumstats$sex[which(p$sumstats$code=="DEPR05")]="both"

##add age range
p$sumstats$age.min[which(p$sumstats$code=="SUBJ01")]=40
p$sumstats$age.max[which(p$sumstats$code=="SUBJ01")]=73
p$sumstats$age.mean[which(p$sumstats$code=="SUBJ01")]=56.91
p$sumstats$age.sd[which(p$sumstats$code=="SUBJ01")]=7.93
p$sumstats$age.min[which(p$sumstats$code=="TIRE01")]=40
p$sumstats$age.max[which(p$sumstats$code=="TIRE01")]=73
p$sumstats$age.mean[which(p$sumstats$code=="TIRE01")]=56.91
p$sumstats$age.sd[which(p$sumstats$code=="TIRE01")]=7.93


##add sample prevalence for all datasets
p$sumstats$samplePrevalence<-p$sumstats$n_case/p$sumstats$n_total

##add number of cases or total column
p$sumstats$n_case_total<-ifelse(is.na(p$sumstats$n_case),p$sumstats$n_total,p$sumstats$n_case)

##Add nice trait names to be used in the report
p$sumstats$name.nice<-p$sumstats$name
#p$sumstats$name.nice[which(p$sumstats$code=="ADHD05")]="ADHD"
p$sumstats$name.nice[which(p$sumstats$code=="ALCD03")]="Alcohol dependence"
p$sumstats$name.nice[which(p$sumstats$code=="ANOR02")]="Anorexia nervosa"
p$sumstats$name.nice[which(p$sumstats$code=="ANXI03")]="Anxiety disorder"
p$sumstats$name.nice[which(p$sumstats$code=="ANXI04")]="Generalised anxiety symptoms"
p$sumstats$name.nice[which(p$sumstats$code=="AUTI07")]="Autism spectrum disorder"
p$sumstats$name.nice[which(p$sumstats$code=="DEPR05")]="MDD, narrow"
p$sumstats$name.nice[which(p$sumstats$code=="DEPR08")]="MDD"
p$sumstats$name.nice[which(p$sumstats$code=="EDUC03")]="Educational attainment"
p$sumstats$name.nice[which(p$sumstats$code=="EXTR01")]="Extraversion"
p$sumstats$name.nice[which(p$sumstats$code=="INCO03")]="Social deprivation"
p$sumstats$name.nice[which(p$sumstats$code=="INSO02")]="Insomnia"
p$sumstats$name.nice[which(p$sumstats$code=="INTE03")]="Cognitive ability"
p$sumstats$name.nice[which(p$sumstats$code=="LONG07")]="Longevity"
p$sumstats[c("NEUR01","NEUR02"),]$name.nice<-"Neuroticism"
p$sumstats$name.nice[which(p$sumstats$code=="RISK01")]="General risk tolerance"
p$sumstats$name.nice[which(p$sumstats$code=="RISK02")]="Risktaking, automobile"
p$sumstats$name.nice[which(p$sumstats$code=="RISK03")]="Risktaking, sex"
p$sumstats$name.nice[which(p$sumstats$code=="SCHI04")]="Schizophrenia"
p$sumstats$name.nice[which(p$sumstats$code=="SUBJ01")]="Subjective well-being"
p$sumstats$name.nice[which(p$sumstats$code=="TIRE01")]="Self-reported tiredness"

##Add a combined nice name plus code label
p$sumstats$name.nice.and_code<-paste0(p$sumstats$name.nice," (",p$sumstats$code,")")

##Add nice dataset citation
p$sumstats$reference.nice<-NA_character_
p$sumstats["ADHD05",]$reference.nice <- "Demontis et al"
p$sumstats["ALCD03",]$reference.nice <- "Walters et al"
p$sumstats["ANOR02",]$reference.nice <- "Watson et al"
p$sumstats["ANXI03",]$reference.nice <- "Purves et al"
p$sumstats["ANXI04",]$reference.nice <- "Purves et al"
p$sumstats["AUTI07",]$reference.nice <- "Grove et al"
p$sumstats["BIPO02",]$reference.nice <- "Stahl et al"
p$sumstats["DEPR05",]$reference.nice <- "Wray et al"
p$sumstats["DEPR08",]$reference.nice <- "Wray et al"
p$sumstats["EDUC03",]$reference.nice <- "Lee et al"
p$sumstats["HEAL01",]$reference.nice <- "Harris et al"
p$sumstats["INCO03",]$reference.nice <- "Hill et al"
p$sumstats["INSO02",]$reference.nice <- "Jansen et al"
p$sumstats["NEUR02",]$reference.nice <- "Nagel et al"
p$sumstats["PTSD04",]$reference.nice <- "Nievergelt et al"
p$sumstats["RISK02",]$reference.nice <- "Karlsson Linnér et al"
p$sumstats["RISK03",]$reference.nice <- "Karlsson Linnér et al"
p$sumstats["SCHI04",]$reference.nice <- "Pardiñas et al"
p$sumstats["SUBJ01",]$reference.nice <- "Okbay et al"
p$sumstats["TIRE01",]$reference.nice <- "Deary et al"

#test
# tSumstats <- read.table(p$sumstats["NEUR01",]$cleanedpath,header=T, quote="\"",fill=T,na.string=c(".",NA,"NA",""))
# tSumstats$ptest<- 2*pnorm(abs(log(tSumstats$OR))/tSumstats$SE, lower.tail = F)
# tSumstats$ptest<- 2*pnorm(abs(tSumstats$OR)/tSumstats$SE, lower.tail = F)

##add information on wether a continous dependent variable was analysed using an OLS (linear) estimator. Used for the latent factor GWAS preparation step.
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="ADHD05")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="ALCD03")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="ANOR02")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="ANXI03")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="ANXI04")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="AUTI07")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="BIPO02")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="DEPR05")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="DEPR08")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="EDUC03")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="EXTR01")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="HEAL01")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="INCO03")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="INSO02")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="INTE03")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="LONG07")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="MIGR01")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="NEUR01")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="NEUR02")]=T #meta analysis
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="PTSD04")]=T #meta analysis
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="RISK01")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="RISK02")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="RISK03")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="SCHI04")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="SUBJ01")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="TIRE01")]=T

##add data on whether the effects were estimated with a linear regression rather than a logistic regression
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="ADHD05")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="ALCD03")]=T #from test
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="ANOR02")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="ANXI03")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="ANXI04")]=T #bgenie uses a linear estimator
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="AUTI07")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="BIPO02")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="DEPR05")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="DEPR08")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="EDUC03")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="EXTR01")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="HEAL01")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="INCO03")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="INSO02")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="INTE03")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="LONG07")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="MIGR01")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="NEUR01")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="NEUR02")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="PTSD04")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="RISK01")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="RISK02")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="RISK03")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="SCHI04")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="SUBJ01")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="TIRE01")]=F


##add data on whether the SEs are on a logistic scale or not
p$sumstats$se.logit[which(p$sumstats$code=="ADHD05")]=T #Tested
p$sumstats$se.logit[which(p$sumstats$code=="ALCD03")]=F #Tested
p$sumstats$se.logit[which(p$sumstats$code=="ANOR02")]=T #Tested
p$sumstats$se.logit[which(p$sumstats$code=="ANXI03")]=T #Tested
p$sumstats$se.logit[which(p$sumstats$code=="ANXI04")]=F #Tested
p$sumstats$se.logit[which(p$sumstats$code=="AUTI07")]=T #Tested
p$sumstats$se.logit[which(p$sumstats$code=="BIPO02")]=T #Tested
p$sumstats$se.logit[which(p$sumstats$code=="DEPR05")]=T #Tested
p$sumstats$se.logit[which(p$sumstats$code=="DEPR08")]=T #Tested
p$sumstats$se.logit[which(p$sumstats$code=="EDUC03")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="EXTR01")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="HEAL01")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="INCO03")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="INSO02")]=T #Tested
p$sumstats$se.logit[which(p$sumstats$code=="INTE03")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="LONG07")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="MIGR01")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="NEUR01")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="NEUR02")]=F #Meta analysis
p$sumstats$se.logit[which(p$sumstats$code=="PTSD04")]=F #Meta analysis
p$sumstats$se.logit[which(p$sumstats$code=="RISK01")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="RISK02")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="RISK03")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="SCHI04")]=T #Tested
p$sumstats$se.logit[which(p$sumstats$code=="SUBJ01")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="TIRE01")]=F #Continuous


#p$sumstats[which(p$sumstats$code=="ANXI04"),]$populationPrevalence<-0.2 #set this to larger than for ANXI03 as this phenotype is broader
#p$sumstats[which(p$sumstats$code=="DEPR08"),]$populationPrevalence<-0.2 #set this to larger than for DEPR05 as this phenotype is broader

#set order of datasets to sorted by code
p$sumstats<-p$sumstats[order(p$sumstats$code),]

#save the project data
#saveRDS(project,file = file.path(p$folderpath.workingDirectory,paste0("project.",p$setup.code,".Rds")))

#View(p$sumstats)

```

## Setup gene sets
```{r Setup gene sets}
p$genesets<-data.frame(matrix(data=NA,nrow = 0,ncol = 0))

p$genesets["gtex8_rnaseq_median",c("name","filepath.raw")]<-c("GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_median_tpm.gct",file.path(p$folderpath.geneSet,"GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_median_tpm.gct.gz"))

p$genesets["brainspan_rnaseq_mean",c("name","filepath.raw")]<-c("BRAINSPAN_RNA-Seq_Gencode_v10_summarized_to_genes_genes_matrix_csv",file.path(p$folderpath.geneSet,"BRAINSPAN_RNA-Seq_Gencode_v10_summarized_to_genes_genes_matrix_csv","expression_matrix.csv"))


#p$genesets["msigdb.v7.5.1",c("name","filepath.raw")]<-c("All MSigDB",file.path(p$folderpath.geneSet,"msigdb.v7.5.1.symbols.gmt"))
p$genesets["msigdb.h.all.v7.5.1",c("name","filepath.raw")]<-c("MSigDB Hallmark",file.path(p$folderpath.geneSet,"msigdb.h.all.v7.5.1.symbols.gmt"))
p$genesets["msigdb.c2.cp.biocarta.v7.5.1",c("name","filepath.raw")]<-c("MSigDB Canonical pathways Biocarta",file.path(p$folderpath.geneSet,"msigdb.c2.cp.biocarta.v7.5.1.symbols.gmt"))
p$genesets["msigdb.c2.cp.kegg.v7.5.1",c("name","filepath.raw")]<-c("MSigDB Canonical pathways KEGG",file.path(p$folderpath.geneSet,"msigdb.c2.cp.kegg.v7.5.1.symbols.gmt"))
p$genesets["msigdb.c3.mir.mirdb.v7.5.1",c("name","filepath.raw")]<-c("MSigDB Regulatory target miRDB",file.path(p$folderpath.geneSet,"msigdb.c3.mir.mirdb.v7.5.1.symbols.gmt"))
p$genesets["msigdb.c3.tft.gtrd.v7.5.1",c("name","filepath.raw")]<-c("MSigDB Regulatory target GTRD",file.path(p$folderpath.geneSet,"msigdb.c3.tft.gtrd.v7.5.1.symbols.gmt"))
p$genesets["msigdb.c5.all.v7.5.1",c("name","filepath.raw")]<-c("MSigDB Ontology",file.path(p$folderpath.geneSet,"msigdb.c5.all.v7.5.1.symbols.gmt"))
p$genesets["msigdb.c7.all.v7.5.1",c("name","filepath.raw")]<-c("MSigDB Immunologic signature",file.path(p$folderpath.geneSet,"msigdb.c7.all.v7.5.1.symbols.gmt"))
p$genesets["msigdb.c8.all.v7.5.1",c("name","filepath.raw")]<-c("MSigDB Cell type",file.path(p$folderpath.geneSet,"msigdb.c8.all.v7.5.1.symbols.gmt"))

```

# Variable selection and project configuration
```{r GWAS sumstat dataset variable selection}

#selection based on specific traits
#p$sumstats.sel.code<-c("ANXI04")
#p$sumstats.sel.code<-c("ADHD05","ANXI04")
#p$sumstats.sel.code<-c("RISK02","RISK03","SCHI04","SUBJ01","TIRE01")
#p$sumstats.sel.code<-c("TIRE01")
p$sumstats.sel.code<-c("ADHD05","ALCD03","ANOR02","ANXI03","ANXI04","AUTI07","BIPO02", "DEPR05","DEPR08","EDUC03","HEAL01","INCO03","INSO02","NEUR02", "PTSD04","RISK02","RISK03","SCHI04","SUBJ01","TIRE01")
p$sumstats.sel<-p$sumstats[which(p$sumstats$code %in% p$sumstats.sel.code),]

#p$sumstats.sel$code_orig<-p$sumstats.sel$code
#p$sumstats.sel$code<-p$sumstats.sel$code.trait
p$sumstats.sel[,c("code","name","name.nice","name.nice.and_code", "year","n_case","n_control","n_total","pmid","reference_doi","samplePrevalence","populationPrevalence","dependent_variable.OLS","dependent_variable.linprob","se.logit","mungedpath")]
p$k.sel<-nrow(p$sumstats.sel)
#View(p$sumstats.sel[,c("code","n_total","pmid","reference_doi","samplePrevalence","populationPrevalence","mungedpath")])

write.table(p$sumstats.sel[,c("code", "name.nice","year", "n_case","n_control","n_total","samplePrevalence","populationPrevalence", "reference_doi")], file = file.path(p$folderpath.workingDirectory,paste0(p$setup.code,".sumstatinfo.tsv")), quote = TRUE, sep = "\t", row.names = FALSE, col.names = TRUE)

#View(p$sumstats.sel)

```

# Raw data preparatory steps

## Create df with high-LD regions for GRCh37
```{r High-LD regions}
#From 10.1016/j.ajhg.2008.06.005
#via 10.1101/211821
p$highld_b37<-data.frame(matrix(data=NA,ncol=0,nrow=0))

p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(1,48287980,52287979)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(2,86088342,101041482)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(2,134666268,138166268)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(2,183174494,190174494)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(3,47524996,50024996)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(3,83417310,96017310)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(5,44464243,50464243)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(5,97972100,100472101)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(5,128972101,131972101)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(5,135472101,138472101)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(6,25392021,33392022)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(6,56892041,63942041)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(6,139958307,142458307)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(7,55225791,66555850)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(8,7962590,11962591)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(8,42880843,49837447)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(8,111930824,114930824)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(10,36959994,43679994)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(11,46043424,57243424)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(11,87860352,90860352)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(12,33108733,41713733)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(12,111037280,113537280)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(17,31799963,33389579)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(17,40928985,42139672)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(20,32536339,35066586)

setDT(p$highld_b37)
setkeyv(p$highld_b37, cols = c("CHR","BP","BP2"))

p$filepath.highld_b38<-file.path(p$folderpath.data,"gene_mapping","highld_b38.gz")
if(file.exists(p$filepath.highld_b38)){
  p$highld_b38 <- fread(file = p$filepath.highld_b38, header = T)
} else {

  #create lift-over build 38- move to data/gene_mapping
  res <- supermunge(
    list_df = list(highld_b38=p$highld_b37),
    chainFilePath = "../data/alignment_chains/hg19ToHg38.over.chain.gz",
    pathDirOutput = p$folderpath.workingDirectory,
    lossless = T,
    process = F
    )
  p$highld_b38<-res
}
#View(res$last[order(res$last$CHR,res$last$BP),])

#p$highld_b37<-NULL

```


## GWAS summary statistics munge - if needed
Munging of GWAS sumstat datasets. The summary statistics is also prepared for latent factor GWAS (previously, the sumstats()-function of the GSEM package). Here reference alleles are standardised across all datasets, and SNP effects and their s.e. are scaled to match unit-variance phenotypes.
```{r GWAS sumstat munge}
#test
#p$clOptions$task<-"munge"

p$filepath.lfgwas.sumstats<-file.path(p$folderpath.workingDirectory,paste0("lfGWAS.sumstats.",p$setup.code,".Rds"))
p$filepath.lfgwas.sumstats_full<-file.path(p$folderpath.workingDirectory,paste0("lfGWAS.sumstats_full.",p$setup.code,".Rds"))
p$filepath.munge.meta<-file.path(p$folderpath.workingDirectory,paste0("munge.meta.",p$setup.code,".Rds"))
p$munge<-c()

#source("../scripts/supermunge.R") #TEST OF NEW VERSION!

if(p$clOptions$task=="munge" & !all(file.exists(p$sumstats.sel$mungedpath))){
  
  #test
  #p$clOptions$task_argument<-"INSO02"
  if(!is.na(p$clOptions$task_argument)){
    #task argument sets the specific dataset to munge
    
    cat("\nSet to munge with arg",p$clOptions$task_argument,"\n")
    p$munge$filesToUse<-p$sumstats.sel$cleanedpath[which(p$sumstats.sel$code==p$clOptions$task_argument)]
    p$munge$traitNamesToUse<-p$sumstats.sel$code[which(p$sumstats.sel$code==p$clOptions$task_argument)]
    p$munge$NToUse<-p$sumstats.sel$n_total[which(p$sumstats.sel$code==p$clOptions$task_argument)]
    p$munge$OLSToUse<-p$sumstats.sel$dependent_variable.OLS[which(p$sumstats.sel$code==p$clOptions$task_argument)]
    p$munge$linprobToUse<-p$sumstats.sel$dependent_variable.linprob[which(p$sumstats.sel$code==p$clOptions$task_argument)]
    p$munge$se.logitToUse<-p$sumstats.sel$se.logit[which(p$sumstats.sel$code==p$clOptions$task_argument)]
    p$munge$propToUse<-(p$sumstats.sel$n_case/p$sumstats.sel$n_total)[which(p$sumstats.sel$code==p$clOptions$task_argument)]
    
  } else {
    #defaults
    p$munge$filesToUse<-p$sumstats.sel$cleanedpath
    p$munge$traitNamesToUse<-p$sumstats.sel$code
    p$munge$NToUse<-p$sumstats.sel$n_total
    p$munge$OLSToUse<-p$sumstats.sel$dependent_variable.OLS
    p$munge$linprobToUse<-p$sumstats.sel$dependent_variable.linprob
    p$munge$se.logitToUse<-p$sumstats.sel$se.logit
    p$munge$propToUse<-(p$sumstats.sel$n_case/p$sumstats.sel$n_total)
  }
  
  # cat("\nMunging with:\n")
  # print(p$munge$filesToUse)
  # print(p$filepath.SNPReference.1kg)
  # print(p$folderpath.data.mvLDSC.ld.1kg)
  # print(p$munge$traitNamesToUse)
  # print(p$munge$NToUse)
  # print(p$munge$OLSToUse)
  # print(p$munge$se.logitToUse)
  # print(p$munge$propToUse)
  # print(p$folderpath.data.sumstats.munged)
  
  #mask<-c(F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,T,T,T,T,T)
  #munging with no filters applied - only munge without imputation!
  p$munge$results <- supermunge(
            filePaths = p$munge$filesToUse,
            refFilePath = p$filepath.SNPReference.1kg,
            #refFilePath = p$filepath.SNPReference.hm3,
            #mask = mask,
            #ldDirPath=p$folderpath.data.mvLDSC.ld.1kg,
            traitNames = p$munge$traitNamesToUse,
            #imputeFromLD=T,
            #region.imputation.filter_df=p$highld, #provide the high-ld regions to not use for imputation
            #produceVariantTable = T,
            N = p$munge$NToUse,
            OLS = p$munge$OLSToUse,
            linprob=p$munge$linprobToUse,
            se.logit = p$munge$se.logitToUse,
            prop=p$munge$propToUse,
            pathDirOutput = p$folderpath.data.sumstats.munged,
            invertEffectDirectionOn = c("ANXI04") #ANXI4 has an inverted effect direction for some reason
              ) 
    
  # #Munge with imputation
  # p$munge$results <- supermunge(
  #           filePaths = p$munge$filesToUse,
  #           refFilePath = p$filepath.SNPReference.1kg,
  #           #refFilePath = p$filepath.SNPReference.hm3,
  #           #mask = mask,
  #           ldDirPath=p$folderpath.data.mvLDSC.ld.1kg,
  #           traitNames = p$munge$traitNamesToUse,
  #           imputeFromLD=T,
  #           region.imputation.filter_df=p$highld, #provide the high-ld regions to not use for imputation
  #           #produceVariantTable = T,
  #           N = p$munge$NToUse,
  #           OLS = p$munge$OLSToUse,
  #           linprob=p$munge$linprobToUse,
  #           se.logit = p$munge$se.logitToUse,
  #           prop=p$munge$propToUse,
  #           pathDirOutput = p$folderpath.data.sumstats.imputed,
  #           invertEffectDirectionOn = c("ANXI04") #ANXI4 has an inverted effect direction for some reason
  #             )

  
  p$munge$results$meta %>% gt()
  gtsave(data = (p$munge$results$meta %>% gt()), filename = file.path(p$folderpath.workingDirectory,"munge.meta.rtf"))
  saveRDS(object = p$munge$results$meta, file = p$filepath.munge.meta)
  
  
  
} else if(file.exists(p$filepath.munge.meta)){
  p$munge$results$meta<-readRDS(file=p$filepath.munge.meta)
  print("Read munging results metadata from previous munge result file.")
}

print(p$munge$results$meta)

if(file.exists(p$filepath.lfgwas.sumstats)) {
  # p$lfGWAS$sumstats<-readRDS(file=p$filepath.lfgwas.sumstats)
  # print("Read summary statistics for latent factor GWAS from file.")
  
  #compare with genomic SEM produced sumstats 
  # p$filepath.lfgwas.sumstats2<-file.path(p$folderpath.workingDirectory,paste0("lfGWAS.sumstats.setup4.Rds"))
  # p$lfGWAS$sumstats2<-readRDS(file=p$filepath.lfgwas.sumstats2)
  # 
  # View(p$lfGWAS$sumstats[which(p$lfGWAS$sumstats$SNP==c("rs1000000","rs10000013"))])
  
  # colBeta<-colnames(p$lfGWAS$sumstats)[grep("^BETA\\.", ignore.case = TRUE,colnames(p$lfGWAS$sumstats))]
  # colSE<-colnames(p$lfGWAS$sumstats)[grep("^SE\\.", ignore.case = TRUE,colnames(p$lfGWAS$sumstats))]
  # colBeta2<-colnames(p$lfGWAS$sumstats2)[grep("^BETA\\.", ignore.case = TRUE,colnames(p$lfGWAS$sumstats2))]
  # colSE2<-colnames(p$lfGWAS$sumstats2)[grep("^SE\\.", ignore.case = TRUE,colnames(p$lfGWAS$sumstats2))]
  # p$lfGWAS$sumstats<-as.data.frame(p$lfGWAS$sumstats)
  # for(iCol in 1:length(colBeta)){
  #   #iCol<-1
  #   print(colBeta[iCol])
  #   cBeta<-p$lfGWAS$sumstats[,colBeta[iCol]]
  #   cSE<-p$lfGWAS$sumstats[,colSE[iCol]]
  #   cBeta2<-p$lfGWAS$sumstats2[,colBeta2[iCol]]
  #   cSE2<-p$lfGWAS$sumstats2[,colSE2[iCol]]
  #   
  #   cat(mean(cBeta2,na.rm=T),"(",median(cSE2,na.rm=T),")\n")
  #   cat(mean(cBeta,na.rm=T),"(",median(cSE,na.rm=T),")\n")
  #   
  #   cat(max(abs(cBeta2),na.rm=T),"(",max(cSE2,na.rm=T),")\n")
  #   cat(max(abs(cBeta),na.rm=T),"(",max(cSE,na.rm=T),")\n")
  #   
  #   cat(min(abs(cBeta2),na.rm=T),"(",min(cSE2,na.rm=T),")\n")
  #   cat(min(abs(cBeta),na.rm=T),"(",min(cSE,na.rm=T),")\n")
  #   
  # }
  
  
  #Compare with old munged ANXI04
  #ssANXI04_old <- read.table(file.path(p$folderpath.data.sumstats.munged,"ANXI04_old.gz"),header=T, quote="\"",fill=T,na.string=c(".",NA,"NA",""))
  #setDT(ssANXI04_old)
  #setkeyv(ssANXI04_old, cols = c("SNP","BP","CHR"))
  #
  # ssANXI04 <- read.table(file.path(p$folderpath.data.sumstats.munged,"ANXI04.gz"),header=T, quote="\"",fill=T,na.string=c(".",NA,"NA",""))
  # setDT(ssANXI04)
  # setkeyv(ssANXI04, cols = c("SNP","BP","CHR"))
  #
  # ssANXI04.merged.snp<-ssANXI04[ssANXI04_old, on=c(SNP='SNP'), nomatch=0]
  # View(ssANXI04.merged.snp[1:100000,c("SNP","BP","CHR","A1","A2","i.A1","i.A2")])
  # sum(!(ssANXI04.merged.snp$A1==ssANXI04.merged.snp$i.A1 & ssANXI04.merged.snp$A2==ssANXI04.merged.snp$i.A2))
  # View(ssANXI04.merged.snp[1:100000,c("SNP","BP","CHR","EFFECT","i.EFFECT","Z","i.Z","P","i.P")])
  # View(ssANXI04.merged.snp[1:100000,c("SNP","BP","CHR","N","i.N")])

  # head(p$lfGWAS$sumstats)
  
} else if(p$clOptions$task=="munge2"){
  p$munge$results<-supermunge(
    filePaths = p$sumstats.sel$mungedpath,
    refFilePath = p$filepath.SNPReference.1kg,
    traitNames = p$sumstats.sel$code,
    produceCompositeTable = T,
    process = F,
    standardiseEffectsToExposure = T,
    writeOutput = F,
    N = p$sumstats.sel$n_total,
    OLS=p$sumstats.sel$dependent_variable.OLS,
    linprob=p$sumstats.sel$dependent_variable.linprob,
    se.logit = p$sumstats.sel$se.logit,
    prop=(p$sumstats.sel$n_case/p$sumstats.sel$n_total),
    info.filter = 0.55
#    maf.filter = 0.001
    
    ) #remove rare variants only
    
  p$lfGWAS$sumstats<-p$munge$results$composite

  saveRDS(object = p$lfGWAS$sumstats, file = p$filepath.lfgwas.sumstats)
  print("Done preparing summary statistics for latent factor GWAS. The result should have been saved to a file.")
}

if(p$clOptions$task=="munge" || p$clOptions$task=="munge2") quit(save = "no")

```


## Harmonise gene sets to gene map and MAGMA format
```{r Harmonise gene sets to gene map and MAGMA format}
if(p$clOptions$task=="genesets"){
  
  p$geneMap<-fread(file = p$filepath.geneMapping, na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, data.table = T,showProgress = F, nThread=5)
  setkeyv(p$geneMap,cols = c("V6"))
  rownames(p$geneMap)<-p$geneMap$V6
  geneCodesByName<-p$geneMap$V1
  names(geneCodesByName)<-p$geneMap$V6
  
  #gtex
  cCode<-"gtex8_rnaseq_median"
  cGeneSet<-read.table(p$genesets[cCode,]$filepath.raw, header=T, quote="\"",fill=T,na.string=c(".",NA,"NA",""), sep="\t", skip = 2)
  setDT(cGeneSet,key = "Description")
  cGeneSet[p$geneMap, on=c(Description='V6'), c("KEY"):=list(i.V1)]
  ncolnames<-c("KEY",colnames(cGeneSet)[3:(length(colnames(cGeneSet))-1)]) #columns from after description
  cGeneSet <- cGeneSet[,..ncolnames][!is.na(KEY),]
  cGeneSet <- aggregate(x = cGeneSet, by = list(cGeneSet$KEY), FUN = head, 1) #DO I NEED THIS?
  cGeneSet <- cGeneSet[,2:length(colnames(cGeneSet))]
  fwrite(x = cGeneSet, file = file.path(p$folderpath.workingDirectory,paste0("geneset.",cCode,".magma")), append = F, quote = F, sep = "\t",na = "NA", col.names = T,nThread=5)
  
  #brainspan
  cCode<-"brainspan_rnaseq_mean"
  cGeneSet<-read.table(p$genesets[cCode,]$filepath.raw, header=F, quote="\"",fill=T,na.string=c(".",NA,"NA",""), sep=",")
  cGenes<-read.table(file.path(p$folderpath.geneSet,"BRAINSPAN_RNA-Seq_Gencode_v10_summarized_to_genes_genes_matrix_csv","rows_metadata.csv"), header=T, quote="\"",fill=T,na.string=c(".",NA,"NA",""), sep=",")
  cSets<-read.table(file.path(p$folderpath.geneSet,"BRAINSPAN_RNA-Seq_Gencode_v10_summarized_to_genes_genes_matrix_csv","columns_metadata.csv"), header=T, quote="\"",fill=T,na.string=c(".",NA,"NA",""), sep=",")
  
  cGeneSet<-cGeneSet[,2:ncol(cGeneSet)]
  colnames(cGeneSet)<-cSets$structure_name
  cGeneSet$gene_symbol<-cGenes$gene_symbol
  
  ncolnames<-c("gene_symbol",colnames(cGeneSet)[1:(ncol(cGeneSet)-1)])
  cGeneSet<-cGeneSet[,ncolnames]
  
  setDT(cGeneSet,key = "gene_symbol") 
  
  cGeneSet[p$geneMap, on=c(gene_symbol='V6'), c("KEY"):=list(i.V1)]
  ncolnames<-c("KEY",colnames(cGeneSet)[2:(length(colnames(cGeneSet))-1)]) #columns after rearrangement
  cGeneSet <- cGeneSet[,..ncolnames][!is.na(KEY),]
  cGeneSet <- aggregate(x = cGeneSet, by = list(cGeneSet$KEY), FUN = head, 1) #DO I NEED THIS?
  cGeneSet <- cGeneSet[,2:ncol(cGeneSet)]
  colnames(cGeneSet)<-gsub(pattern = " ", replacement = "_", x = colnames(cGeneSet))
  fwrite(x = cGeneSet, file = file.path(p$folderpath.workingDirectory,paste0("geneset.",cCode,".magma")), append = F, quote = F, sep = "\t",na = "NA", col.names = T,nThread=5)
  
  #MSigDB
  chosenSet<-c("msigdb.h.all.v7.5.1","msigdb.c2.cp.biocarta.v7.5.1","msigdb.c2.cp.kegg.v7.5.1", "msigdb.c3.mir.mirdb.v7.5.1","msigdb.c3.tft.gtrd.v7.5.1", "msigdb.c5.all.v7.5.1","msigdb.c7.all.v7.5.1","msigdb.c8.all.v7.5.1")
  for(cCode in chosenSet){
    #cCode<-"msigdb.c2.cp.biocarta.v7.5.1"
    cGeneSet<-read.table(p$genesets[cCode,]$filepath.raw, header=F, quote="\"",fill=T,na.string=c(".",NA,"NA",""), sep="\t")
    incols<-c(1,3:ncol(cGeneSet))
    cGeneSet<-cGeneSet[,incols]
    setDT(cGeneSet,key = "V1")
    for(iCol in 2:ncol(cGeneSet)){
      #iCol<-2
      col<-colnames(cGeneSet)[iCol]
      cGeneSet[, (col):=geneCodesByName[get(col)]]
    }
    rcount <- aggregate(V3 ~ V1,cGeneSet,length)
    rcount <- rcount[rcount$V3>1,]
    cGeneSet2 <- aggregate(x = cGeneSet, by = list(cGeneSet$V1), FUN = head, 1) #remove duplicate sets
    cGeneSet2 <- cGeneSet2[,2:ncol(cGeneSet2)]
    rownames(cGeneSet2)<-cGeneSet2$V1
    
    if(nrow(rcount)>0){
      cGeneSet2[,(ncol(cGeneSet2)+1):(2*(ncol(cGeneSet2)+1))]<-NA #add more columns to make room for new data
      
      #collect genes from duplicate set rows
      for(i in 1:nrow(rcount)){
        #i<-2
        cGeneSet2[rcount$V1[i],2:ncol(cGeneSet2)] <- padList(unique(unlist(cGeneSet[V1==rcount$V1[i],2:ncol(cGeneSet)])),NA,ncol(cGeneSet2))
      }
    }
    
    fwrite(x = cGeneSet2, file = file.path(p$folderpath.workingDirectory,paste0("geneset.",cCode,".magma")), append = F, quote = F, sep = "\t",na = "NA", col.names = F,nThread=5)
  }
  quit(save = "no")
}

```




# Multivariate LD
The multivariate LDSC and HDL procedure calculates genetic correlations between the different traits and estimates of correlation standard errors, producing S (variances and covariances = heritabilities and coheritabilities) and V (diagonal: squared standard errors of elements in S. Off-diagonal: Covariances of elements in S - "dependencies between estimation errors used to model dependencies due to sample overlap") matrices used later in the Genomic SEM model fitting.

HDL is an improved method to account for linkage disequilibrium while estimating genetic effects from GWAS.

```{r multivariate LD}
print("***multivariate LD***")

p$filepath.mvLD<-file.path(p$folderpath.workingDirectory,paste0("mvLD.",p$setup.code,".Rds"))

if (file.exists(p$filepath.mvLD)) {
  print("Using existing covariance structures from previous LD computations.")
  p$mvLD<-readRDS(file=p$filepath.mvLD)
} else {
  print("Running (multivariate) LD regression with different methods. This might take a while. If the procedure runs for too long you may want to abort the process.")
  
  cat("The current task is specified as:",p$clOptions$task,"\n")
  p$mvLD<-c()
  
  if(p$clOptions$task=="mvLD" || (!file.exists(p$filepath.mvLD) & p$clOptions$task=="0")){
    #run mvLDSC
    p$mvLD$covstruct.mvLDSC.hm3<-ldsc.mod(
      traits = p$sumstats.sel$mungedpath,
      sample.prev =  p$sumstats.sel$samplePrevalence,
      population.prev = p$sumstats.sel$populationPrevalence,
      trait.names = p$sumstats.sel$code,
      ld = p$folderpath.data.mvLDSC.ld.hm3,
      wld = p$folderpath.data.mvLDSC.ld.hm3,
      n.blocks = 200, #this was standard for the hm3 set of snps
      #info.limp.filter = 0.5,
      info.filter = 0.6,
      maf.filter = 0.01,
      region.filter_df = p$highld,
      #mhc.filter = 37,
      N = p$sumstats.sel$n_total,
      #forceN = , p$sumstats.sel$forceN, # Consider this when some of the original N's may be untrustworthy (ANXI04!) - TODO - fix in supermunge
      ldsc.log = p$setup.code.date
      )

    p$mvLD$covstruct.mvLDSC.1kg<-ldsc.mod(
      traits = p$sumstats.sel$mungedpath,
      sample.prev =  p$sumstats.sel$samplePrevalence,
      population.prev = p$sumstats.sel$populationPrevalence,
      trait.names = p$sumstats.sel$code,
      ld = p$folderpath.data.mvLDSC.ld.1kg,
      wld = p$folderpath.data.mvLDSC.ld.1kg,
      n.blocks = 600, #a bit more here if it can support the larger reference panel used
      #info.limp.filter = 0.5,
      info.filter = 0.6,
      maf.filter = 0.01,
      region.filter_df = p$highld,
      #mhc.filter = 37,
      N = p$sumstats.sel$n_total,
      #forceN = T, # Consider this when some of the original N's may be untrustworthy (ANXI04!) - TODO - fix in supermunge
      ldsc.log = p$setup.code.date
      )
    
    p$mvLD$covstruct.mvLDSC.1kg_limpfilter<-ldsc.mod(
      traits = p$sumstats.sel$mungedpath,
      sample.prev =  p$sumstats.sel$samplePrevalence,
      population.prev = p$sumstats.sel$populationPrevalence,
      trait.names = p$sumstats.sel$code,
      ld = p$folderpath.data.mvLDSC.ld.1kg,
      wld = p$folderpath.data.mvLDSC.ld.1kg,
      n.blocks = 600, #a bit more here if it can support the larger reference panel used
      info.limp.filter = 0.5,
      info.filter = 0.6,
      maf.filter = 0.01,
      region.filter_df = p$highld,
      #mhc.filter = 37,
      N = p$sumstats.sel$n_total,
      ldsc.log = paste0(p$setup.code,"_temp")
      )
    
    #pairwise ldsc - genomic SEM mvldsc - imputed! - DOES NOT WORK YET!!! WIP!
    p$mvLD$covstruct.mvLDSC.1kg.pairwise <- list()
    p$mvLD$covstruct.mvLDSC.1kg.pairwise$S<-matrix(data=NA,nrow = nrow(p$sumstats.sel),ncol = nrow(p$sumstats.sel))
    colnames(p$mvLD$covstruct.mvLDSC.1kg.pairwise$S)<-p$sumstats.sel$code
    rownames(p$mvLD$covstruct.mvLDSC.1kg.pairwise$S)<-p$sumstats.sel$code
     p$mvLD$covstruct.mvLDSC.1kg.pairwise$S.SE<-matrix(data=NA,nrow = nrow(p$sumstats.sel),ncol = nrow(p$sumstats.sel))
    colnames(p$mvLD$covstruct.mvLDSC.1kg.pairwise$S.SE)<-p$sumstats.sel$code
    rownames(p$mvLD$covstruct.mvLDSC.1kg.pairwise$S.SE)<-p$sumstats.sel$code
    p$mvLD$covstruct.mvLDSC.1kg.pairwise$S_Stand<-matrix(data=NA,nrow = nrow(p$sumstats.sel),ncol = nrow(p$sumstats.sel))
    colnames(p$mvLD$covstruct.mvLDSC.1kg.pairwise$S_Stand)<-p$sumstats.sel$code
    rownames(p$mvLD$covstruct.mvLDSC.1kg.pairwise$S_Stand)<-p$sumstats.sel$code
     p$mvLD$covstruct.mvLDSC.1kg.pairwise$S_Stand.SE<-matrix(data=NA,nrow = nrow(p$sumstats.sel),ncol = nrow(p$sumstats.sel))
    colnames(p$mvLD$covstruct.mvLDSC.1kg.pairwise$S_Stand.SE)<-p$sumstats.sel$code
    rownames(p$mvLD$covstruct.mvLDSC.1kg.pairwise$S_Stand.SE)<-p$sumstats.sel$code
    
    p$mvLD$covstruct.mvLDSC.1kg.pairwise$mgc<-list()
    
    for(iTrait in 1:length(p$sumstats.sel$code)){
      #iTrait<-1
      for(jTrait in (iTrait+1):length(p$sumstats.sel$code)){
        #jTrait<-2
        if(jTrait>length(p$sumstats.sel$code)) break
        cldsc <- ldsc.mod(
          traits = p$sumstats.sel$mungedpath[c(iTrait,jTrait)],
          sample.prev =  p$sumstats.sel$samplePrevalence[c(iTrait,jTrait)],
          population.prev = p$sumstats.sel$populationPrevalence[c(iTrait,jTrait)],
          trait.names = p$sumstats.sel$code[c(iTrait,jTrait)],
          ld = p$folderpath.data.mvLDSC.ld.1kg,
          wld = p$folderpath.data.mvLDSC.ld.1kg,
          n.blocks = 600, #a bit more here if it can support the larger reference panel used
          info.filter = 0.6,
          maf.filter = 0.01,
          region.filter_df = p$highld,
          #mhc.filter = 37,
          N = p$sumstats.sel$n_total[c(iTrait,jTrait)],
          ldsc.log = paste0(p$setup.code,"_temp")
          )
        p$mvLD$covstruct.mvLDSC.1kg.pairwise$S[[iTrait,iTrait]]<-cldsc$S[1,1]
        p$mvLD$covstruct.mvLDSC.1kg.pairwise$S[[iTrait,jTrait]]<-cldsc$S[1,2]
        p$mvLD$covstruct.mvLDSC.1kg.pairwise$S[[jTrait,iTrait]]<-cldsc$S[1,2]
        
        p$mvLD$covstruct.mvLDSC.1kg.pairwise$S.SE[[iTrait,iTrait]]<-cldsc$S.SE[1,1]
        p$mvLD$covstruct.mvLDSC.1kg.pairwise$S.SE[[iTrait,jTrait]]<-cldsc$S.SE[1,2]
        p$mvLD$covstruct.mvLDSC.1kg.pairwise$S.SE[[jTrait,iTrait]]<-cldsc$S.SE[1,2]
        
        p$mvLD$covstruct.mvLDSC.1kg.pairwise$S_Stand[[iTrait,iTrait]]<-cldsc$S_Stand[1,1]
        p$mvLD$covstruct.mvLDSC.1kg.pairwise$S_Stand[[iTrait,jTrait]]<-cldsc$S_Stand[1,2]
        p$mvLD$covstruct.mvLDSC.1kg.pairwise$S_Stand[[jTrait,iTrait]]<-cldsc$S_Stand[1,2]
        
        p$mvLD$covstruct.mvLDSC.1kg.pairwise$S_Stand.SE[[iTrait,iTrait]]<-cldsc$S_Stand.SE[1,1]
        p$mvLD$covstruct.mvLDSC.1kg.pairwise$S_Stand.SE[[iTrait,jTrait]]<-cldsc$S_Stand.SE[1,2]
        p$mvLD$covstruct.mvLDSC.1kg.pairwise$S_Stand.SE[[jTrait,iTrait]]<-cldsc$S_Stand.SE[1,2]
        
        p$mvLD$covstruct.mvLDSC.1kg.pairwise$mgc[[iTrait]]<-cldsc$mgc
        
      }
    
    }
    
    
    #pairwise ldsc - genomic SEM mvldsc - non-imputed!
    p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp <- list()
    p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S<-matrix(data=NA,nrow = nrow(p$sumstats.sel),ncol = nrow(p$sumstats.sel))
    colnames(p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S)<-p$sumstats.sel$code
    rownames(p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S)<-p$sumstats.sel$code
     p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S.SE<-matrix(data=NA,nrow = nrow(p$sumstats.sel),ncol = nrow(p$sumstats.sel))
    colnames(p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S.SE)<-p$sumstats.sel$code
    rownames(p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S.SE)<-p$sumstats.sel$code
    p$mvLD$covstruct.mvLDSC.1kg.pairwise.unim$S_Stand<-matrix(data=NA,nrow = nrow(p$sumstats.sel),ncol = nrow(p$sumstats.sel))
    colnames(p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S_Stand)<-p$sumstats.sel$code
    rownames(p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S_Stand)<-p$sumstats.sel$code
     p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S_Stand.SE<-matrix(data=NA,nrow = nrow(p$sumstats.sel),ncol = nrow(p$sumstats.sel))
    colnames(p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S_Stand.SE)<-p$sumstats.sel$code
    rownames(p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S_Stand.SE)<-p$sumstats.sel$code
    
    p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$mgc<-list()
    
    for(iTrait in 1:length(p$sumstats.sel$code)){
      #iTrait<-1
      for(jTrait in (iTrait+1):length(p$sumstats.sel$code)){
        #jTrait<-2
        if(jTrait>length(p$sumstats.sel$code)) break
        cldsc <- ldsc.mod(
          traits = p$sumstats.sel$mungedpath[c(iTrait,jTrait)],
          sample.prev =  p$sumstats.sel$samplePrevalence[c(iTrait,jTrait)],
          population.prev = p$sumstats.sel$populationPrevalence[c(iTrait,jTrait)],
          trait.names = p$sumstats.sel$code[c(iTrait,jTrait)],
          ld = p$folderpath.data.mvLDSC.ld.1kg,
          wld = p$folderpath.data.mvLDSC.ld.1kg,
          n.blocks = 600, #a bit more here if it can support the larger reference panel used
          info.limp.filter = 10000, #large value to filter away all imputed variants
          info.filter = 0.6,
          maf.filter = 0.01,
          region.filter_df = p$highld,
          #mhc.filter = 37,
          N = p$sumstats.sel$n_total[c(iTrait,jTrait)],
          ldsc.log = paste0(p$setup.code,"_temp")
          )
        p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S[[iTrait,iTrait]]<-cldsc$S[1,1]
        p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S[[iTrait,jTrait]]<-cldsc$S[1,2]
        p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S[[jTrait,iTrait]]<-cldsc$S[1,2]
        
        p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S.SE[[iTrait,iTrait]]<-cldsc$S.SE[1,1]
        p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S.SE[[iTrait,jTrait]]<-cldsc$S.SE[1,2]
        p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S.SE[[jTrait,iTrait]]<-cldsc$S.SE[1,2]
        
        p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S_Stand[[iTrait,iTrait]]<-cldsc$S_Stand[1,1]
        p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S_Stand[[iTrait,jTrait]]<-cldsc$S_Stand[1,2]
        p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S_Stand[[jTrait,iTrait]]<-cldsc$S_Stand[1,2]
        
        p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S_Stand.SE[[iTrait,iTrait]]<-cldsc$S_Stand.SE[1,1]
        p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S_Stand.SE[[iTrait,jTrait]]<-cldsc$S_Stand.SE[1,2]
        p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$S_Stand.SE[[jTrait,iTrait]]<-cldsc$S_Stand.SE[1,2]
        
        p$mvLD$covstruct.mvLDSC.1kg.pairwise.unimp$mgc[[iTrait]]<-cldsc$mgc
        
      }
    
    }
    

  }
    
  # #Sys.sleep(time = 5)
  # #flip effect direction of trait
  # SModifier<-matrix(nrow = nrow(p$mvLD$covstruct.mvLDSC.1kg$S), ncol = ncol(p$mvLD$covstruct.mvLDSC.1kg$S), dimnames = list(
  #   colnames(p$mvLD$covstruct.mvLDSC.1kg$S),
  #   colnames(p$mvLD$covstruct.mvLDSC.1kg$S)
  #   )
  #   )
  # 
  # SModifier["ANXI04",]<--1
  # SModifier[,"ANXI04"]<--1
  # SModifier["ANXI04","ANXI04"]<-NA
  # # View(SModifier)
  # 
  # p$mvLD$covstruct.mvLDSC.1kg$S[!is.na(SModifier)]<-p$mvLD$covstruct.mvLDSC.1kg$S[!is.na(SModifier)]*SModifier[!is.na(SModifier)]
  
  #set the default mvLDSC object to use
  p$mvLD$covstruct.mvLDSC<-p$mvLD$covstruct.mvLDSC.1kg
  
  #Additional computations
  #saving the original S in case of smoothing experiments later stored in S
  p$mvLD$covstruct.mvLDSC$S.orig<-p$mvLD$covstruct.mvLDSC$S
  p$mvLD$covstruct.mvLDSC$S.smooth<-as.matrix((nearPD(p$mvLD$covstruct.mvLDSC$S, corr = FALSE))$mat)
  
  #save the mvLD output
  saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  print("Multivariate LD correction is done now and the resulting covariance structure should have been saved to a file.")
  
}


if(p$clOptions$task=="mvLD"){
      quit(save = "no")
    }

#adding standard errors from the V matrices, unstandardised and standardised. I added these calculations to the modified ldsc.

#retrieve the standard errors of S (variances and covariances) from the diagonal of V (contains both).

# p$mvLD$covstruct.mvLDSC$S.SE<-matrix(0, p$k.sel, p$k.sel)
# rownames(p$mvLD$covstruct.mvLDSC$S.SE)<-colnames(p$mvLD$covstruct.mvLDSC$S)
# colnames(p$mvLD$covstruct.mvLDSC$S.SE)<-colnames(p$mvLD$covstruct.mvLDSC$S)
# p$mvLD$covstruct.mvLDSC$S_Stand.SE<-matrix(0, p$k.sel, p$k.sel)
# rownames(p$mvLD$covstruct.mvLDSC$S_Stand.SE)<-colnames(p$mvLD$covstruct.mvLDSC$S)
# colnames(p$mvLD$covstruct.mvLDSC$S_Stand.SE)<-colnames(p$mvLD$covstruct.mvLDSC$S)
# 
# p$mvLD$covstruct.mvLDSC$S.SE[lower.tri(p$mvLD$covstruct.mvLDSC$S.SE,diag=TRUE)] <-sqrt(diag(p$mvLD$covstruct.mvLDSC$V))
# p$mvLD$covstruct.mvLDSC$S.SE[upper.tri(p$mvLD$covstruct.mvLDSC$S.SE)]<-t(p$mvLD$covstruct.mvLDSC$S.SE)[upper.tri(p$mvLD$covstruct.mvLDSC$S.SE)]
# p$mvLD$covstruct.mvLDSC$S_Stand.SE[lower.tri(p$mvLD$covstruct.mvLDSC$S_Stand.SE,diag=TRUE)] <-sqrt(diag(p$mvLD$covstruct.mvLDSC$V_Stand))
# p$mvLD$covstruct.mvLDSC$S_Stand.SE[upper.tri(p$mvLD$covstruct.mvLDSC$S_Stand.SE)]<-t(p$mvLD$covstruct.mvLDSC$S_Stand.SE)[upper.tri(p$mvLD$covstruct.mvLDSC$S_Stand.SE)]


  
#add newly computed heritabilities to the selected summary statistics table
p$sumstats.sel$h2.liability_mvLDSC.1kg<-diag(p$mvLD$covstruct.mvLDSC.1kg$S[p$sumstats.sel$code,p$sumstats.sel$code])
p$sumstats.sel$h2.se.liability_mvLDSC.1kg<-diag(p$mvLD$covstruct.mvLDSC.1kg$S.SE[p$sumstats.sel$code,p$sumstats.sel$code])
p$sumstats.sel$h2.liability_mvLDSC.hm3<-diag(p$mvLD$covstruct.mvLDSC.hm3$S[p$sumstats.sel$code,p$sumstats.sel$code])
p$sumstats.sel$h2.se.liability_mvLDSC.hm3<-diag(p$mvLD$covstruct.mvLDSC.hm3$S.SE[p$sumstats.sel$code,p$sumstats.sel$code])


#View(p$sumstats.sel)

  
```

# Overview of rg between selected traits
```{r overview pairwise rg, fig.width=9, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}

p$mvLD$covstruct.mvLDSC.1kg$S_Stand.forPlot<-p$mvLD$covstruct.mvLDSC.1kg$S_Stand[p$sumstats.sel$code,p$sumstats.sel$code]
rownames(p$mvLD$covstruct.mvLDSC.1kg$S_Stand.forPlot)<-p$sumstats.sel$name.nice.and_code
colnames(p$mvLD$covstruct.mvLDSC.1kg$S_Stand.forPlot)<-p$sumstats.sel$code

p$mvLD$covstruct.mvLDSC.1kg$S_Stand_diff.forPlot<-p$mvLD$covstruct.mvLDSC.1kg$S_Stand - p$mvLD$covstruct.mvLDSC.hm3$S_Stand

p$mvLD$covstruct.mvLDSC.1kg$S_Stand.SE_diff.forPlot<-p$mvLD$covstruct.mvLDSC.1kg$S_Stand.SE - p$mvLD$covstruct.mvLDSC.hm3$S_Stand.SE

p$mvLD$covstruct.mvLDSC.1kg$S_Stand_diff2.forPlot<-p$mvLD$covstruct.mvLDSC.1kg$S_Stand - p$mvLD$covstruct.mvLDSC.1kg_limpfilter$S_Stand

p$mvLD$covstruct.mvLDSC.1kg$S_Stand.SE_diff2.forPlot<-p$mvLD$covstruct.mvLDSC.1kg$S_Stand.SE - p$mvLD$covstruct.mvLDSC.1kg_limpfilter$S_Stand.SE


library(heatmaply)
#ggheatmap() #static version
#heatmaply()
heatmaply(
    clipValues(p$mvLD$covstruct.mvLDSC.1kg$S_Stand.forPlot,-1,1),
    cellnote = round(clipValues(p$mvLD$covstruct.mvLDSC.1kg$S_Stand,-1,1),digits = 2),
    cellnote_size = 9,
    cellnote_textposition = "middle center",
    show_dendrogram = c(T,F),
    xlab = "Trait GWAS",
    ylab = "Trait GWAS",
    main = "r<sub>g</sub>",
    scale_fill_gradient_fun = ggplot2::scale_fill_gradient2(
        low = theme.color$contrastDark3, 
        mid = "black",
        high = theme.color$contrastLight3,
        breaks = c(-1,0,1)
      ),
    file=file.path(p$folderpath.plots,paste0("rg_cluster.indicator.1kg.png")),
    width = 1200, height = 1200,
    hclust_method = "ward.D2"
    #scale = "row"
  )


p$printCorrSimplified(
  corr = clipValues(p$mvLD$covstruct.mvLDSC.1kg$S_Stand.forPlot,-1,1),
  #SE = p$mvLD$covstruct.mvLDSC.1kg$S_Stand.SE,
  filename = file.path(p$folderpath.plots,"rg_simple.indicator.1kg.png"),
  is.corr = T
  )

p$printCorrSimplified(
  corr = clipValues(abs(p$mvLD$covstruct.mvLDSC.1kg$S_Stand.forPlot),-1,1),
  #SE = p$mvLD$covstruct.mvLDSC.1kg$S_Stand.SE,
  filename = file.path(p$folderpath.plots,"rg_abs_simple.indicator.1kg.png"),
  is.corr = F,
  absScale=T
  )

p$printCorr(
  corr = clipValues(p$mvLD$covstruct.mvLDSC.1kg$S_Stand.forPlot,-1,1),
  SE = p$mvLD$covstruct.mvLDSC.1kg$S_Stand.SE[p$sumstats.sel$code,p$sumstats.sel$code],
  filename = file.path(p$folderpath.plots,"rg.indicator.1kg.png"),
  is.corr = T,
  addrect = NULL
  )

p$printCorr(
  corr = p$mvLD$covstruct.mvLDSC.1kg$S_Stand_diff.forPlot,
  SE = NULL,
  filename = file.path(p$folderpath.plots,"rg_diff_ld.indicator.1kg_hm3.png"),
  addrect =NULL,
  is.corr = F,
  number.cex = 1.1,
  number.digits = 3
  )
# 
p$printCorr(
  corr = p$mvLD$covstruct.mvLDSC.1kg$S_Stand.SE_diff.forPlot,
  SE = NULL,
  filename = file.path(p$folderpath.plots,"rg_diff_ld_se.indicator.1kg_hm3.png"),
  addrect =NULL,
  is.corr = F,
  number.cex = 1.1,
  number.digits = 3
  )

p$printCorr(
  corr = p$mvLD$covstruct.mvLDSC.1kg$S_Stand_diff2.forPlot,
  SE = NULL,
  filename = file.path(p$folderpath.plots,"rg_diff_impf.indicator.1kg.png"),
  addrect =NULL,
  is.corr = F,
  number.cex = 1.1,
  number.digits = 3
  )
# 
p$printCorr(
  corr = p$mvLD$covstruct.mvLDSC.1kg$S_Stand.SE_diff2.forPlot,
  SE = NULL,
  filename = file.path(p$folderpath.plots,"rg_diff_impf_se.indicator.1kg.png"),
  addrect =NULL,
  is.corr = F,
  number.cex = 1.1,
  number.digits = 3
  )

cat("\nrg (LD)\n")
mean(abs(p$mvLD$covstruct.mvLDSC.1kg$S_Stand_diff.forPlot))
median(abs(p$mvLD$covstruct.mvLDSC.1kg$S_Stand_diff.forPlot))
max(abs(p$mvLD$covstruct.mvLDSC.1kg$S_Stand_diff.forPlot))
min(abs(p$mvLD$covstruct.mvLDSC.1kg$S_Stand_diff.forPlot))

cat("\nrg.SE (LD)\n")
mean(p$mvLD$covstruct.mvLDSC.1kg$S_Stand.SE_diff.forPlot)
median(p$mvLD$covstruct.mvLDSC.1kg$S_Stand.SE_diff.forPlot)
max(p$mvLD$covstruct.mvLDSC.1kg$S_Stand.SE_diff.forPlot)
min(p$mvLD$covstruct.mvLDSC.1kg$S_Stand.SE_diff.forPlot)

cat("\nrg (imputation filter)\n")
mean(abs(p$mvLD$covstruct.mvLDSC.1kg$S_Stand_diff2.forPlot))
median(abs(p$mvLD$covstruct.mvLDSC.1kg$S_Stand_diff2.forPlot))
max(abs(p$mvLD$covstruct.mvLDSC.1kg$S_Stand_diff2.forPlot))
min(abs(p$mvLD$covstruct.mvLDSC.1kg$S_Stand_diff2.forPlot))

cat("\nrg.SE (imputation filter)\n")
mean(p$mvLD$covstruct.mvLDSC.1kg$S_Stand.SE_diff2.forPlot)
median(p$mvLD$covstruct.mvLDSC.1kg$S_Stand.SE_diff2.forPlot)
max(p$mvLD$covstruct.mvLDSC.1kg$S_Stand.SE_diff2.forPlot)
min(p$mvLD$covstruct.mvLDSC.1kg$S_Stand.SE_diff2.forPlot)

```


# Improved annotation of chosen datasets

```{r improved annotation of chosen datasets, fig.width=10, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}
#View(p$sumstats.sel)

p$sumstats.sel.table<-p$sumstats.sel[,c("name.nice","code","year","n_case_total","n_control", "samplePrevalence","populationPrevalence","h2.liability_mvLDSC.1kg","h2.se.liability_mvLDSC.1kg","h2.liability_mvLDSC.hm3","h2.se.liability_mvLDSC.hm3")]

p$sumstats.sel.table$h2.liability_mvLDSC.1kg.table<-paste0(round( p$sumstats.sel.table$h2.liability_mvLDSC.1kg,digits = 3)," (",round(p$sumstats.sel.table$h2.se.liability_mvLDSC.1kg,digits = 4),")")
p$sumstats.sel.table$h2.liability_mvLDSC.hm3.table<-paste0(round( p$sumstats.sel.table$h2.liability_mvLDSC.hm3,digits = 3)," (",round(p$sumstats.sel.table$h2.se.liability_mvLDSC.hm3,digits = 4),")")

p$sumstats.sel.table<-p$sumstats.sel.table[,c("name.nice","code","year","n_case_total","n_control", "samplePrevalence","populationPrevalence","h2.liability_mvLDSC.1kg.table","h2.liability_mvLDSC.hm3.table")]
#View(p$sumstats.sel.table)
#p$sumstats.sel.table

p$plots.sumstats.sel.table<-p$sumstats.sel.table %>% 
  gt() %>% 
  fmt_number(columns = vars(samplePrevalence), decimals = 3) %>%
  fmt_number(columns = vars(populationPrevalence), decimals = 4) %>%
  fmt_number(columns = vars(n_case_total,n_control), decimals = 0) %>%
  tab_header(
    title = "Selected GWAS summary statistics datasets"
  ) %>% cols_label(
    name.nice  = "Trait",
    code = "Code",
    #ancestry = "Ancestry",
    #sex = "Sex",
    n_case_total = "N case or total",
    n_control = "N control",
    year = "Year",
    samplePrevalence = html("Prev<sub>sample</sub>"),
    populationPrevalence = html("Prev<sub>population</sub>"),
    h2.liability_mvLDSC.1kg.table = html("h<sup>2</sup><sub>mvLDSC,1kg</sub> (S.E.)"),
    h2.liability_mvLDSC.hm3.table = html("h<sup>2</sup><sub>mvLDSC,hm3</sub> (S.E.)")
  ) %>%
  tab_style(
    style = cell_text(size = px(12)),
    locations = cells_column_labels(everything())       
  ) %>%
  tab_style(
    style = cell_text(size = px(12),weight = "bold"),
    locations = cells_body(everything())        
  )

p$plots.sumstats.sel.table

gtsave(data = p$plots.sumstats.sel.table, filename = paste0(p$folderpath.plots,"/sumstats.sel.table.rtf"))


```


# Exploratory Factor Analysis
I am using EFA, clustering and  PCA as a compliment to the previous genetic correlation matrix to visualise possible cluster patterns. EFA and other techniques are used to inform CFA models later.

```{r EFA }
print("***EFA***")
#saving efa results between runs as to always use the same randomised start for clustering for example
p$filepath.efa<-file.path(p$folderpath.workingDirectory,paste0("efa.",p$setup.code,".Rds"))
if (file.exists(p$filepath.efa)) {
  print("Using existing EFA results from previous run.")
  p$EFA<-readRDS(file=p$filepath.efa)
} else {

  #visualisation of up to max factors EFA models with varimax
  # for(iefa in 1:max(p$CFA$nFactors)){
  #   res <- psych::fa(r = abs(p$mvLD$covstruct.mvLDSC$S.smooth),nfactors = iefa, rotate = 'varimax', symmetric = T, warnings = T, fm='ols', max.iter = 1000)
  #   #print(res)
  #   print(res$loadings)
  #   print(res$fit)
  #   #print(kmeans(x = p$mvLD$covstruct.mvLDSC$S_Stand, centers = iefa, iter.max = 1000, nstart = 30))
  # }
  
  #visualise factors in a scree plot
  if(!p$clOptions$location=="cluster"){
      p$plots.efa.plot.scree<-fa.parallel(abs(p$mvLD$covstruct.mvLDSC$S.smooth), fa = "fa")
      png(filename = file.path(p$folderpath.plots,"efa.plot.scree.png"), width = 800, height = 500)
      fa.parallel(abs(p$mvLD$covstruct.mvLDSC$S.smooth), fa = "fa")
      dev.off()
  }
  
  
  #fit EFA models for each nFactor configuration
  print("Setting upp and computing new EFA results.")
  p$EFA<-c()
  p$EFA$PCA<-c()
  #iFactorConfiguration<-1
  for(iFactorConfiguration in 1:length(p$CFA$nFactors)) {
    cNFactors<-p$CFA$nFactors[iFactorConfiguration]
    p$EFA$PCA[[iFactorConfiguration]]<-eigen(x = abs(p$mvLD$covstruct.mvLDSC$S_Stand), symmetric = TRUE)
    rownames(p$EFA$PCA[[iFactorConfiguration]]$vectors)<-p$sumstats.sel.code
    p$EFA$PCA[[iFactorConfiguration]]$vector_values<-t(p$EFA$PCA[[iFactorConfiguration]]$vectors*p$EFA$PCA[[iFactorConfiguration]]$values)[,1:cNFactors] #has to be transposed as well!(?)
  
    p$EFA$fa.result.ORT[[iFactorConfiguration]] <- psych::fa(r = abs(p$mvLD$covstruct.mvLDSC$S.smooth),nfactors = cNFactors, rotate = 'varimax', symmetric = T, warnings = T, fm='ols', max.iter = 1000)
    
    p$EFA$fa.result.OBL[[iFactorConfiguration]] <- psych::fa(r = abs(p$mvLD$covstruct.mvLDSC$S.smooth),nfactors = cNFactors, rotate = 'oblimin', symmetric = T, warnings = T, fm='ols', max.iter = 1000)
    
    p$EFA$kmeans.result[[iFactorConfiguration]]<- kmeans(x = abs(p$mvLD$covstruct.mvLDSC$S_Stand), centers = cNFactors, iter.max = 1000, nstart = 30)
    #View(p$clustering$centers)
    #View(fitted(p$clustering))
    #View(abs(p$mvLD$covstruct.mvLDSC$S_Stand))
    #resid<-abs(p$mvLD$covstruct.mvLDSC$S_Stand)-fitted(p$clustering)
    #View(resid)
    p$EFA$kmeans.centerDistance[[iFactorConfiguration]]<-apply(X = abs(p$mvLD$covstruct.mvLDSC$S_Stand), MARGIN = 1, FUN = function(x){
      #test
      #x<-abs(p$mvLD$covstruct.mvLDSC$S_Stand)[1,]
      #cat("\nOBS:",x)
      ss<-apply(X=(abs(x)-p$EFA$kmeans.result[[iFactorConfiguration]]$centers)^2, FUN = sum, MARGIN = 1)
      #cat("\nSS:",ss)
      s<-sum(abs(x))
      #cat("\nS:",s)
      return (ss/s)
    })
    #transpose this to conform with indicator loading data frames
    p$EFA$kmeans.centerDistance[[iFactorConfiguration]]<-t(p$EFA$kmeans.centerDistance[[iFactorConfiguration]])
    rownames(p$EFA$kmeans.centerDistance[[iFactorConfiguration]])<-p$sumstats.sel.code
    
    
  cat("\nPCA vector values\n")
  print(p$EFA$PCA[[iFactorConfiguration]]$vector_values)
  cat("\nFA fa result, ORTHOGONAL rotation\n")
  print(p$EFA$fa.result.ORT[[iFactorConfiguration]])
  cat("\nFA fa result, OBLIQUE rotation\n")
  print(p$EFA$fa.result.OBL[[iFactorConfiguration]])
  #cat("\nFA factanal result\n")
  #print(p$EFA$factanal.result)
  cat("\nKmeans clustering centers\n")
  print(t(p$EFA$kmeans.result[[iFactorConfiguration]]$centers))
  cat("\nKmeans clustering residuals\n")
  print(p$EFA$kmeans.centerDistance[[iFactorConfiguration]])
    
  }
  
  
  
  saveRDS(object = p$EFA,file = p$filepath.efa)
}



```


# Confirmatory Factor Analysis

CFA.

## Create CFA indicator loading patterns

```{r CFA indicator loading pattern creation}
print("***CFA indicator loading pattern creation***")

## CFA aditional settings
p$sumstats.sel$residualSizeLimitMax<-NA_real_
#p$sumstats.sel$residualSizeLimitMax[which(p$sumstats.sel$code=="ANXI03" | p$sumstats.sel$code=="DEPR05")]<-0.10
#(1/p$sumstats.sel$h2.se.liability_mvLDSC^2)/sum(1/p$sumstats.sel$h2.se.liability_mvLDSC^2)+0.01
p$CFA$nIndicators=length(p$sumstats.sel$code)

p$filepath.cfa<-file.path(p$folderpath.workingDirectory,paste0("cfa.",p$setup.code,".Rds"))
#p$filepath.cfa_converged_results<-file.path(p$folderpath.workingDirectory,paste0("cfa.",p$setup.code,".converged.txt"))
p$filepath.cfa.FactorConfiguration<-c()

if(!file.exists(p$filepath.cfa)){
  
  p$CFA$indicatorLoadingPatterns.PCA<-c()
  p$CFA$indicatorLoadingPatterns.fa.ORT<-c()
  p$CFA$indicatorLoadingPatterns.fa.OBL<-c()
  p$CFA$indicatorLoadingPatterns.kmeans<-c()
  #iFactorConfiguration<-1
  for(iFactorConfiguration in 1:length(p$CFA$nFactors)) {
  ##kmeans clustering based models
  p$CFA$indicatorLoadingPatterns.kmeans[[iFactorConfiguration]]<-semplate$generateIndicatorLoadingPatternsFromFactorLoadings(factorLoadings = t(p$EFA$kmeans.result[[iFactorConfiguration]]$centers), increment = 0.0005,forceOneIndicatorLoading = T)
  
  ##fa, orthogonal based models
  p$CFA$indicatorLoadingPatterns.fa.ORT[[iFactorConfiguration]]<-semplate$generateIndicatorLoadingPatternsFromFactorLoadings(factorLoadings = p$EFA$fa.result.ORT[[iFactorConfiguration]]$loadings, increment = 0.0005,forceOneIndicatorLoading = T)
  
  ##fa, oblique based models
  p$CFA$indicatorLoadingPatterns.fa.OBL[[iFactorConfiguration]]<-semplate$generateIndicatorLoadingPatternsFromFactorLoadings(factorLoadings = p$EFA$fa.result.OBL[[iFactorConfiguration]]$loadings, increment = 0.0005,forceOneIndicatorLoading = T)
    
  #PCA based models
  p$CFA$indicatorLoadingPatterns.PCA[[iFactorConfiguration]]<-semplate$generateIndicatorLoadingPatternsFromFactorLoadings(factorLoadings = p$EFA$PCA[[iFactorConfiguration]]$vector_values, increment = 0.0005,forceOneIndicatorLoading = T)
    
  p$CFA$sessionIndicatorLoadingPatterns[[iFactorConfiguration]]<-unique(rbind(p$CFA$indicatorLoadingPatterns.kmeans[[iFactorConfiguration]],p$CFA$indicatorLoadingPatterns.fa.ORT[[iFactorConfiguration]],p$CFA$indicatorLoadingPatterns.fa.OBL[[iFactorConfiguration]],p$CFA$indicatorLoadingPatterns.PCA[[iFactorConfiguration]]))
  
  }
  
  

}

```


## Evaluate CFA models

```{r CFA model evaluation}
print("***CFA model evaluation***")

#test
#p$clOptions$task<-"cfa"
#p$clOptions$task_argument<-"1"

match.row<-function(row_v,tomatch_df){
  #row_v<-lp
  #tomatch_df<-lplib
  toreturn<-vector()
  for(nTomatch in 1:nrow(tomatch_df)){
    #nTomatch<-2
    toreturn[nTomatch]<-all(row_v==tomatch_df[nTomatch,])
  }
  return(toreturn)
}

p$CFA$models<-data.frame(nModel=c(),code=c(),nFactors=c(),correlation=c(),estimator=c(), lModel=c(),lResults=c())

p$CFA$resultColumnNames<-c("chisq","df","p_chisq","AIC","CFI","SRMR")

if (file.exists(p$filepath.cfa)) {
  print("Using existing CFA results from previous run and appending to these if needed.")
  p$CFA<-readRDS(file=p$filepath.cfa)
} else {
  
  nModel<-0
  nFittingModelsFound<-0
  #compute total number of models across factor configurations
  totalNumberOfModels<-0
  nVariables<-ncol(p$mvLD$covstruct.mvLDSC$S)
  nUniqueCovariances<-nVariables*(nVariables+1)/2
  for(iFactorConfiguration in 1:length(p$CFA$nFactors)) {
    sessionPatternLength<-nrow(p$CFA$sessionIndicatorLoadingPatterns[[iFactorConfiguration]])
    totalNumberOfModels<-totalNumberOfModels+sessionPatternLength*length(p$CFA$correlation)*length(p$CFA$estimator)
  }
  
  for(iFactorConfiguration in 1:length(p$CFA$nFactors)) {
    #test
    #iFactorConfiguration<-1
    
    if(p$clOptions$task=="cfa" & length(p$clOptions$task_argument)>0 & p$clOptions$task_argument!=iFactorConfiguration) next
    
    p$filepath.cfa.FactorConfiguration[iFactorConfiguration]<-file.path(p$folderpath.workingDirectory,paste0("cfa.",p$setup.code,"_",iFactorConfiguration,".Rds"))
    
    if(file.exists(p$filepath.cfa.FactorConfiguration[iFactorConfiguration])){
      storedFactorConfigurationModelResults <- readRDS(file=p$filepath.cfa.FactorConfiguration[iFactorConfiguration])
      p$CFA$models <- rbind(p$CFA$models,storedFactorConfigurationModelResults)
      nModel<-nrow(p$CFA$models)
      next
    }
    
    
    if(p$clOptions$task!="cfa") next #do not evaluate models if not in cfa task
    
    sessionPatternLength<-nrow(p$CFA$sessionIndicatorLoadingPatterns[[iFactorConfiguration]])
    
    cat("\nAnalysing",sessionPatternLength, "patterns for this factor configuration...\n")
    for(nSessioPattern in 1:sessionPatternLength){
      #test
      #nSessioPattern<-1
      
      for(iCorrelationConfiguration in 1:length(p$CFA$correlation)){
        #iCorrelationConfiguration<-1
        cCorrelation<-p$CFA$correlation[iCorrelationConfiguration]
        
        # #avoid correlated factors if above 8 factors
        # if(p$CFA$nFactors[iFactorConfiguration]>8 & cCorrelation=="COR") next
        # 
        # #avoid oblique factors if below 9 factors
        # if(p$CFA$nFactors[iFactorConfiguration]<9 & cCorrelation=="OBL") next
        # 
        # #avoid orthogonal factors if below 7 factors
        # if(p$CFA$nFactors[iFactorConfiguration]<7 & cCorrelation=="ORT") next
        
        for(iParameterEstimator in 1:length(p$CFA$estimator)){
          #iParameterEstimator<-1
          cEstimator<-p$CFA$estimator[iParameterEstimator]
          
          #new model row
          nModel<-nModel+1
          
          if(!is.null(p$CFA$models.selected)){
            if(!nModel %in% p$CFA$models.selected$nModel) next
          }
          
          #set specific nmodel for reevaluation
          #nModel<-35
          #nSessioPattern<-35
          
          #init columns
          p$CFA$models[nModel,]<-NA
          
          #nModel
          p$CFA$models[nModel,c("nModel")]<-nModel
          
          #record code
          p$CFA$models[nModel,c("code")]<-paste0("M",p$CFA$nIndicators,"_",p$CFA$nFactors[iFactorConfiguration],
          "_",nSessioPattern,
          ".",cCorrelation,
          ".",cEstimator
          )
          
          #record nFactors
          p$CFA$models[nModel,c("nFactors")]<-p$CFA$nFactors[iFactorConfiguration]
          
          #record correlation
          p$CFA$models[nModel,c("correlation")]<-cCorrelation
          
          #record estimator
          p$CFA$models[nModel,c("estimator")]<-cEstimator
          
          #p$CFA$models$totalBitValue[nModel]<-NA #because otherwise the later assignment will crash
          p$CFA$models[nModel,c("loading_pattern","loading_pattern_pca","loading_pattern_fa","loading_pattern_kmeans")]<-NA
          p$CFA$models[nModel,c("lModel")]<-NA_character_
          p$CFA$models[nModel,c("gsemResults")]<-NA
          p$CFA$models[nModel,p$CFA$resultColumnNames]<-NA
          
          #loading pattern
          lp<-p$CFA$sessionIndicatorLoadingPatterns[[iFactorConfiguration]][nSessioPattern,]
          p$CFA$models[[nModel,c("loading_pattern")]]<-list(lp)
          cIndicatorLoadings<-matrix(data = lp, nrow = p$CFA$nIndicators, ncol = p$CFA$nFactors[iFactorConfiguration]) 
          row.names(cIndicatorLoadings)<-p$sumstats.sel$code
          
          p$CFA$models[nModel,c("loading_pattern_pca")]<-any(match.row(lp,p$CFA$indicatorLoadingPatterns.PCA[[iFactorConfiguration]]))
          p$CFA$models[nModel,c("loading_pattern_fa.ORT")]<-any(match.row(lp,p$CFA$indicatorLoadingPatterns.fa.ORT[[iFactorConfiguration]]))
          p$CFA$models[nModel,c("loading_pattern_fa.OBL")]<-any(match.row(lp,p$CFA$indicatorLoadingPatterns.fa.OBL[[iFactorConfiguration]]))
          p$CFA$models[nModel,c("loading_pattern_kmeans")]<-any(match.row(lp,p$CFA$indicatorLoadingPatterns.kmeans[[iFactorConfiguration]]))
          
          #further filter rules
          indicatorsLoadedOnFactors <- apply(cIndicatorLoadings, 1, FUN = any)
          factorsHasIndicatorsLoaded <- apply(cIndicatorLoadings, 2, FUN = any)
          ##check factor configuration is of an identified model
          if(cCorrelation!="ORT"){
            isIdentified <- (nVariables + sum(cIndicatorLoadings) + factorial(nVariables)/(factorial(2)*factorial(nVariables-2))) <= nUniqueCovariances #real condition
            p$CFA$models[nModel,c("identified")]<-isIdentified
             isIdentified <- (nVariables + sum(cIndicatorLoadings) + (factorial(nVariables)/(factorial(2)*factorial(nVariables-2)))/2) <= nUniqueCovariances #relax this condition in case my calculation is wrong
          } else { #ORT
            isIdentified<-nVariables + sum(cIndicatorLoadings) <= nUniqueCovariances
          }
          
          #allow evaluation if filter rules are met
          if(all(indicatorsLoadedOnFactors) & all(factorsHasIndicatorsLoaded)){ #& isIdentified
            
            #generate lavaan model
            p$CFA$models[nModel,c("lModel")]<- semplate$generateLavaanCFAModel(
              allow_loading.table.indicator_factor = cIndicatorLoadings,
              #indicatorArgs = p$sumstats.sel[,c("code","residualSizeLimitMax")],
              #universalResidualLimitMin = 0.0001,
              orthogonal = (cCorrelation=="ORT"),
              universalCorrelationLimitMax = ifelse((cCorrelation=="OBL"),0.3,NA)
              )
            
            #evaluate lavaan model in GenomicSEM
            cat("\n\n#Found fitting=",nFittingModelsFound,",\tevaluating new model:\t",nModel,"/",totalNumberOfModels,"\n", p$CFA$models[nModel,c("code")],"\n")
            cModelResults = tryCatch(
              usermodel.mod(covstruc = p$mvLD$covstruct.mvLDSC,
                model = p$CFA$models[nModel,c("lModel")],
                estimation = cEstimator,
                fix_resid = F,
                CFIcalc = F #ifelse(is.null(p$CFA$models.selected),F,T) #set this to true for CFI evaluation
                ), error= function(e) e
              )
            
            if(!inherits(cModelResults, "try-error") & !is.null(cModelResults$modelfit)){
              if(nrow(cModelResults$modelfit)>0 && any(p$CFA$resultColumnNames %in% colnames(cModelResults$modelfit))) {
                print(cModelResults$modelfit)
                #record results even though not fitting
                p$CFA$models[nModel,c("gsemResults")]<-NA
                p$CFA$models[[nModel,c("gsemResults")]]<-list(cModelResults)
                cRescolnames<-intersect(p$CFA$resultColumnNames,colnames(cModelResults$modelfit))
                p$CFA$models[nModel,cRescolnames]<-cModelResults$modelfit[1,cRescolnames]
                if(is.numeric(cModelResults$modelfit$chisq)){
                  #This is considered a fitting model
                  nFittingModelsFound<-nFittingModelsFound+1
                  cat("\nFITTING!:",p$CFA$models[nModel,c("code")],"\n")
                }
              } else {
                cat("\nThe model did not yield correct results.")
              }
            } else {
              cat("\nThe model did not converge.")
            }
            
          } else {warning("\nThe pattern configuration was deemed to yield an non-identified or otherwise not plausible model!")} #evaluation block
        } #for(iParameterEstimator in 1:length(p$CFA$estimator))
      } #for(iCorrelationConfiguration in 1:length(p$CFA$correlation))
    } #for(nSessioPattern in 1:sessionPatternLength)
  
    
    saveRDS(object = p$CFA$models,file = p$filepath.cfa.FactorConfiguration[iFactorConfiguration])
  print("Intermediate CFA results for this factor configuration are now done and the result should have been saved into a file.")
  
  if(p$clOptions$task=="cfa" & p$clOptions$task_argument==iFactorConfiguration){quit(save = "no")}
  
  }
  
  rownames(p$CFA$models)<-p$CFA$models$code
    
  saveRDS(object = p$CFA,file = p$filepath.cfa)
  print("CFA for this session is now done and the result should have been saved into a file.")
}



#View(p$CFA$models)
#p$CFA$models$lModel[which(p$CFA$models$nModel==57 & p$CFA$models$code=="M3-17.ML._-1107563521_389110_0_0_0_0_0_0_")]
if(p$clOptions$task=="cfa"){quit(save = "no")}

```

## Select CFA results

```{r CFA select}
print("***CFA select***")
#View(p$CFA$models[which(p$CFA$models$AIC<10000 & p$CFA$models$correlation=="ORT"),c("code","nModel","identified", "loading_pattern","loading_pattern_pca","loading_pattern_fa.ORT","loading_pattern_fa.OBL","loading_pattern_kmeans",p$CFA$resultColumnNames)])


p$CFA$models.selected<-p$CFA$models[c("M20_6_172.COR.ML","M20_6_30.ORT.ML"),] #this is a manual setting after choosing the best fitting models from the previous results
#View(p$CFA$models.selected)


```


# Pre-analysis

This is a complete alternate analysis containing a smaller set of traits

```{r pre-analysis}

print("***Pre-analysis***")

if(p$clOptions$task=="pre"){
  p$sumstats.sel.pre.code<-c("EDUC03","NEUR02","RISK02","RISK03","SCHI04")
  p$sumstats.sel.pre<-p$sumstats[which(p$sumstats$code %in% p$sumstats.sel.pre.code),]
  
  #export modified munged files
  
  p$pre<-c()
  p$pre$filepath.mvLD<-file.path(p$folderpath.workingDirectory,paste0("mvLD.pre.",p$setup.code,".Rds"))
  p$pre$filepath.models<-file.path(p$folderpath.workingDirectory,paste0("cfa.pre.",p$setup.code,".Rds"))
  
  if (file.exists(p$pre$filepath.mvLD)) {
    print("Using existing covariance structures from previous LD computations.")
    p$pre$mvLD<-readRDS(file=p$pre$filepath.mvLD)
  } else {
      
    p$pre$mvLD<-c()
    p$pre$mvLD$covstructs<-c()
    
    p$pre$mvLD$covstructs[[1]]<-ldsc.mod(
        traits = p$sumstats.sel.pre$mungedpath,
        sample.prev =  p$sumstats.sel.pre$samplePrevalence,
        population.prev = p$sumstats.sel.pre$populationPrevalence,
        trait.names = p$sumstats.sel.pre$code,
        ld = p$folderpath.data.mvLDSC.ld.1kg,
        wld = p$folderpath.data.mvLDSC.ld.1kg,
        n.blocks = 600, #a bit more here if it can support the larger reference panel used
        info.filter = 0.6,
        maf.filter = 0.01,
        mhc.filter = 37,
        N = p$sumstats.sel.pre$n_total,
        #forceN = T, # Consider this when some of the original N's may be untrustworthy (ANXI04!) - TODO - fix in supermunge
        ldsc.log = p$setup.code.date
        )
    
    for(iChr in 1:11){
      p$pre$mvLD$covstructs[[iChr+1]]<-ldsc.mod(
        traits = p$sumstats.sel.pre$mungedpath,
        sample.prev =  p$sumstats.sel.pre$samplePrevalence,
        population.prev = p$sumstats.sel.pre$populationPrevalence,
        trait.names = p$sumstats.sel.pre$code,
        ld = p$folderpath.data.mvLDSC.ld.1kg,
        wld = p$folderpath.data.mvLDSC.ld.1kg,
        n.blocks = 600, #a bit more here if it can support the larger reference panel used
        info.filter = 0.6,
        maf.filter = 0.01,
        mhc.filter = 37,
        N = p$sumstats.sel.pre$n_total,
        #forceN = T, # Consider this when some of the original N's may be untrustworthy (ANXI04!) - TODO - fix in supermunge
        ldsc.log = p$setup.code.date,
        leave.chr=c(2*iChr-1,2*iChr)
        )
    
    }
      
    #save the mvLD output
    saveRDS(object = p$pre$mvLD,file = p$pre$filepath.mvLD)
    print("Multivariate LD correction is done now and the resulting covariance structure should have been saved to a file.")
      
  }
  
  
  #analyse the differences in genetic correlation matrices
  p$pre$mvLD$covstructs.leaveoneout<-p$pre$mvLD$covstructs[2:11]
  length(p$pre$mvLD$covstructs.leaveoneout)
  p$pre$mvLD$covstructs[[1]]$S
  p$pre$mvLD$covstructs[[1]]$S.SE
  
  p$pre$mvLD$covstructs[[2]]$S
  p$pre$mvLD$covstructs[[2]]$S.SE
  
  p$pre$mvLD$covstructs.leaveoneout.S<-matrix(NA,nrow = nrow(p$pre$mvLD$covstructs[[1]]$S), ncol = ncol(p$pre$mvLD$covstructs[[1]]$S))
  
  length(p$pre$mvLD$covstructs.leaveoneout.S)
  for(i in 1:length(p$pre$mvLD$covstructs.leaveoneout.S)){
    #i<-1
    p$pre$mvLD$covstructs.leaveoneout.S[[i]]<-mean(unlist(lapply(p$pre$mvLD$covstructs.leaveoneout,function(x){x$S[i]})))
  }
  p$pre$mvLD$covstructs.leaveoneout.S<-matrix(as.numeric(p$pre$mvLD$covstructs.leaveoneout.S),nrow = nrow(p$pre$mvLD$covstructs[[1]]$S), ncol = ncol(p$pre$mvLD$covstructs[[1]]$S))
  p$pre$mvLD$covstructs.leaveoneout.S
  p$pre$mvLD$covstructs[[1]]$S
  
  as.matrix( p$pre$mvLD$covstructs.leaveoneout.S) - as.matrix(p$pre$mvLD$covstructs[[1]]$S)
  mean(as.matrix( p$pre$mvLD$covstructs.leaveoneout.S) - as.matrix(p$pre$mvLD$covstructs[[1]]$S))
  
  #EFA
  p$pre$fa.result.OBL <- psych::fa(r = abs(p$pre$mvLD$covstructs[[1]]$S),nfactors = 2, rotate = 'oblimin', symmetric = T, warnings = T, fm='ols', max.iter = 1000)
  print(p$pre$fa.result.OBL)
  p$pre$PCA<-eigen(x = abs(p$pre$mvLD$covstructs[[1]]$S), symmetric = TRUE)
  print(p$pre$PCA)
  p$pre$PCA$vector_values<-t(p$pre$PCA$vectors*p$pre$PCA$values)[,1:2]
  
  #CFA
  p$pre$resultColumnNames<-c("chisq","df","p_chisq","AIC","CFI","SRMR")
  p$pre$indicatorLoadingPatterns<-semplate$generateIndicatorLoadingPatternsFromFactorLoadings(factorLoadings = p$pre$fa.result.OBL$loadings, increment = 0.0005,forceOneIndicatorLoading = T)
  #p$pre$indicatorLoadingPatterns<-semplate$generateIndicatorLoadingPatternsFromFactorLoadings(factorLoadings = p$pre$PCA$vector_values, increment = 0.0005,forceOneIndicatorLoading = T)
  p$pre$models<-data.frame(nModel=c(),code=c(),nFactors=c(),correlation=c(),estimator=c(), lModel=c(),lResults=c(),gsemResults=c())
  
  
  if(file.exists(p$pre$filepath.models)) {
    print("Using existing models.")
    p$pre$models<-readRDS(file=p$pre$filepath.models)
  } else {
    for(iPat in 1:nrow(p$pre$indicatorLoadingPatterns)){
      #iPat<-1
      p$pre$models[iPat,]<-NA
      p$pre$models[iPat,c("nModel")]<-iPat
      
      #record code
      p$pre$models[iPat,c("code")]<-paste0("MPRE_2",
      "_",iPat,
      ".COR",
      ".ML"
      )
      
      p$pre$models[iPat,c("nFactors")]<-2
      p$pre$models[iPat,c("correlation")]<-"COR"
      p$pre$models[iPat,c("estimator")]<-"ML"
            
      lp<-p$pre$indicatorLoadingPatterns[iPat,]
      p$pre$models[iPat,c("loading_pattern")]<-NA
      p$pre$models[[iPat,c("loading_pattern")]]<-list(lp)
      cIndicatorLoadings<-matrix(data = lp, nrow = nrow(p$pre$mvLD$covstructs[[1]]$S), ncol = 2) 
      row.names(cIndicatorLoadings)<-row.names(p$pre$mvLD$covstructs[[1]]$S)
      p$pre$models[iPat,c("lModel")]<-semplate$generateLavaanCFAModel(allow_loading.table.indicator_factor = cIndicatorLoadings)
      
      cModelResults = tryCatch(
        usermodel.mod(covstruc = p$pre$mvLD$covstructs[[1]],
          model = p$pre$models[iPat,c("lModel")],
          estimation = "ML",
          fix_resid = F,
          CFIcalc = F #ifelse(is.null(p$CFA$models.selected),F,T) #set this to true for CFI evaluation
          ), error= function(e) e
        )
      
      if(!inherits(cModelResults, "try-error") & !is.null(cModelResults$modelfit)){
                if(nrow(cModelResults$modelfit)>0 && any(p$pre$resultColumnNames %in% colnames(cModelResults$modelfit))) {
                  print(cModelResults$modelfit)
                  #record results even though not fitting
                  p$pre$models[iPat,c("gsemResults")]<-NA
                  p$pre$models[[iPat,c("gsemResults")]]<-list(cModelResults)
                  cRescolnames<-intersect(p$pre$resultColumnNames,colnames(cModelResults$modelfit))
                  p$pre$models[iPat,cRescolnames]<-cModelResults$modelfit[1,cRescolnames]
                  if(is.numeric(cModelResults$modelfit$chisq)){
                    #This is considered a fitting model
                    cat("\nFITTING!:",p$pre$models[iPat,c("code")],"\n")
                  }
                } else {
                  cat("\nThe model did not yield correct results.")
                }
              } else {
                cat("\nThe model did not converge.")
              }
      
    } #for
    
    rownames(p$pre$models)<-p$pre$models$code
    saveRDS(object = p$pre$models,file = p$pre$filepath.models)
    print("PRE CFA is done now and the resultins should have been saved to a file.")
  }
  
  #setup results to be run in the later part of the script as if they were coming out of the standard script analysis
  p$sumstats.sel<-p$sumstats.sel.pre
  p$mvLD<-c()
  p$mvLD$covstruct.mvLDSC<-p$pre$mvLD$covstructs[[1]]
  
  #Additional computations
  #saving the original S in case of smoothing experiments later stored in S
  p$mvLD$covstruct.mvLDSC$S.orig<-p$mvLD$covstruct.mvLDSC$S
  p$mvLD$covstruct.mvLDSC$S.smooth<-as.matrix((nearPD(p$mvLD$covstruct.mvLDSC$S, corr = FALSE))$mat)
  
  
  p$CFA$models.selected<-p$pre$models[c("MPRE_2_1.COR.ML"),]
  
}

if(p$clOptions$task=="pre"){
  p$clOptions$task<-"lfgwas"
  }


```

# Process CFA result models and prepare them for latent factor GWAS

```{r Process CFA results}

p$CFA$models.selected$parsedGsemResults<-NA
p$CFA$models.selected$lModel.fixed<-NA
for(iSelected in 1:nrow(p$CFA$models.selected)){
  #test
  #iSelected<-1
  p$CFA$models.selected[[iSelected,c("parsedGsemResults")]]<-list(semplate$parseGenomicSEMResultAsMatrices(p$CFA$models.selected[iSelected,]$gsemResults[[1]][[1]]$results))
  
  # model explained variance is calculated by the parse function from the standardised residuals
  # vars<-vector()
  # for(iManifest in 1:nrow(p$mvLD$covstruct.mvLDSC$S)){
  #   vars[iManifest]<-p$mvLD$covstruct.mvLDSC$S[iManifest,iManifest]
  # }
  # 1-(p$CFA$models.selected[[iSelected,c("parsedGsemResults")]][[1]]$residualVaraiances.matrix/vars)
  
  
  #using the standardised pattern coefficients to fix the model
  #summary(p$CFA$model.bestFitting$gsemResults[[1]]$lresults, standardized=T)
  p$CFA$models.selected[[iSelected,c("parsedGsemResults")]][[1]]$patternCoefficientsSTDGenotype.matrix
  
  #prepare fixed lavaan model
      
  cIndicatorLoadings.loadingPattern<-matrix(
    data = p$CFA$models.selected[iSelected,]$loading_pattern[[1]][[1]],
    ncol = ncol(p$CFA$models.selected[iSelected,]$parsedGsemResults[[1]][[1]]$patternCoefficientsSTDGenotype.matrix),
    nrow = nrow(p$CFA$models.selected[iSelected,]$parsedGsemResults[[1]][[1]]$patternCoefficientsSTDGenotype.matrix)) 
  row.names(cIndicatorLoadings.loadingPattern)<-p$sumstats.sel$code
  cIndicatorLoadings.result<-!is.na(p$CFA$models.selected[iSelected,]$parsedGsemResults[[1]][[1]]$patternCoefficientsSTDGenotype.matrix)
  
  if(!all(cIndicatorLoadings.loadingPattern==cIndicatorLoadings.result)) stop("Difference in provided and result loading patterns detected!")
  
  cIndicatorLoadings<-cIndicatorLoadings.loadingPattern
  
  #test of free SEM parameters rather than fixed (pretend it is the fixed model)
  # p$CFA$models.selected[[iSelected,c("lModel.fixed")]]<-semplate$generateLavaanCFAModel(
  #   allow_loading.table.indicator_factor = cIndicatorLoadings,
  #   universalResidualLimitMin = NA,
  #   orthogonal = (p$CFA$models.selected[iSelected,]$correlation[[1]][[1]]=="ORT"))

  #original fixed setup
  p$CFA$models.selected[[iSelected,c("lModel.fixed")]]<-semplate$generateLavaanCFAModel(
    allow_loading.table.indicator_factor = cIndicatorLoadings,
    fix_loading.table.indicator_factor = p$CFA$models.selected[iSelected,]$parsedGsemResults[[1]][[1]]$patternCoefficientsSTDGenotype.matrix, fixResidualVariance_v = p$CFA$models.selected[iSelected,]$parsedGsemResults[[1]][[1]]$residualVaraiancesSTDGenotype.matrix,
    fix_correlation.table.factor_factor = p$CFA$models.selected[iSelected,]$parsedGsemResults[[1]][[1]]$covariancesSTDGenotype.matrix,
    orthogonal = (p$CFA$models.selected[iSelected,]$correlation[[1]][[1]]=="ORT"))

}

```

# Visualise CFA results

This will not work if the model does not converge.

```{r CFA visualise, fig.width=9, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}
#devtools::install_github("cjvanlissa/tidySEM")
library(tidySEM)
library(DiagrammeR)

for(iSelected in 1:nrow(p$CFA$models.selected)){

  #test
  #iSelected<-1
  
  #plot full model
  cModel<-p$CFA$models.selected[iSelected,]
  
  dir.create(path = file.path(p$folderpath.plots,cModel$code))
  
  p$CFA$semGraphLayout <- get_layout(
    "F1","","F2","","F3","","F4","","F5","","F6","","F7","","F8","","F9","","F10","","","","","","",
            "ADHD05","ALCD03","ANOR02","ANXI03","ANXI04","AUTI07","BIPO02", "DEPR05","DEPR08","EDUC03","EXTR01","HEAL01","INCO03","INSO02","INTE03","LONG07", "MIGR01","NEUR02","PTSD04","RISK01","RISK02","RISK03","SCHI04","SUBJ01","TIRE01",
            "","","","","","","","","","","","","","","","","","","","","","","","","",
            rows = 3)
  
  #this does not work anymore after package updates
  # graph_sem(
  #   #model = cModelResults$lresults,
  # model=cModel$gsemResults[[1]][[1]]$lresults,
  # layout = p$CFA$semGraphLayout,
  # spacing_y=8,
  # spacing_x=4,
  # ellipses_width=5,
  # rect_width=3,
  # variance_diameter=0.5,
  # angle=180
  # )
  
  #ggsave(filename=file.path(p$folderpath.plots,cModel$code,paste0("cfa.png")), plot = last_plot(), width = 1200, height = 600, units = "mm")
  
  
  #https://rpubs.com/danmirman/plotting_factor_analysis
  df<-as.data.frame(cModel$parsedGsemResults[[1]][[1]]$patternCoefficientsSTDGenotype.matrix)
  #df<-as.data.frame(sign(cModel$parsedGsemResults[[1]][[1]]$patternCoefficientsSTDGenotype.matrix)*cModel$parsedGsemResults[[1]][[1]]$relativeVarianceExplainedPerFactor) #plotting variance explained rather than factor loadings - only works for orthogonal factors!
  #add proportion of explained variance
  colnames(df)<-paste0(colnames(df),"(mExp=",round(cModel$parsedGsemResults[[1]][[1]]$meanRelativeVarianceExplainedPerFactor,digits = 2),")")
  df[,c(paste0("~disturbance(mExp=",round(cModel$parsedGsemResults[[1]][[1]]$meanTotalRelativeVarianceExplained,digits = 2),")"))]<-cModel$parsedGsemResults[[1]][[1]]$residualVariancesSTDGenotype.matrix #add disturbances
  df<-rownames_to_column(df,var = "var")
  
  #set nice rownames
  df$var <- p$sumstats.sel[df$var, ]$name.nice
  #df<-df[order(df$var, decreasing = T,method = "radix"),]
  df$var <- as.factor(df$var)
  
  df.l <- pivot_longer(data = df,  -var)
  
  ggplot(df.l, aes(x = abs(value), y = var, fill=value)) + 
  facet_wrap(~ name, nrow=1) + #place the factors in separate facets #scales = "free_x"
  geom_bar(stat="identity") + #make the bars
  #coord_flip() + #flip the axes so the test names can be horizontal  
  #define the fill color gradient: blue=positive, red=negative
  scale_fill_gradient2(name = "Loading", 
                       high = theme.color$contrastLight3, mid = "grey90", low = theme.color$contrastDark3, 
                       midpoint=0, guide=F) +
  xlab("Std. factor loading") + #improve y-axis label
  #xlab("Variance explained in indicator * sign(loading)") + #improve y-axis label
  ylab("Indicator") +
  theme_bw(base_size=22) #use a black-and white theme with set font size
  
  ggsave(filename=file.path(p$folderpath.plots,cModel$code, paste0("ipc.png")), plot = last_plot(), width = 800, height = 400, units = "mm")
  
  if(!all(is.na(cModel$parsedGsemResults[[1]][[1]]$covariances.SE.matrix))){
    #p$printCorr(corr = as.numeric(cModel$parsedGsemResults[[1]][[1]]$covariancesSTDGenotype.matrix),SE = as.numeric(cModel$parsedGsemResults[[1]][[1]]$covariances.SE.matrix),filename = file.path(p$folderpath.plots,cModel$code, paste0("factorCorrelations.png")),is.corr = F,addrect = NULL)
    
    
    png(filename = file.path(p$folderpath.plots,cModel$code, paste0("factorCorrelations.png")), width = 1200, height = 1000)
    palette<-colorRampPalette(c(theme.color$contrastDark3,"#FFFFFF",theme.color$contrastLight3))
    corrplot(
      corr = cModel$parsedGsemResults[[1]][[1]]$covariancesSTDGenotype.matrix,
      #uppCI.mat = corr.uppCI,
      #lowCI.mat = corr.lowCI,
      #plotCI = ifelse(is.null(SE),c("n"),"circle"),
      order = "hclust",
      hclust.method = "ward.D",
      method = "square",
      type="full",
      addCoef.col = theme.color$contrastDark1,
      addgrid.col = theme.color$contrastDark1,
      is.corr = T,
      outline = T,
      col = palette(200),
      rect.col = theme.color$contrastLight1,
      rect.lwd = 6,
      tl.cex = 1.7,
      tl.col = theme.color$contrastDark2,
      tl.srt = 75,
      cl.cex = 2,
      cl.ratio = 0.2,
      cl.pos = "n",
      number.cex = 1,
      number.digits = 2
      )
    dev.off()
    
  }
  
  #cModelResults$modelfit
  #nFactor<-1
  for(nFactor in 1:ncol(cModel$parsedGsemResults[[1]][[1]]$patternCoefficientsSTDGenotype.matrix)){
    p$CFA$semGraphLayout <- get_layout("","","","","","","","","","","",paste0("F",nFactor),"","","","","","","","","","","","","",
            "ADHD05","ALCD03","ANOR02","ANXI03","ANXI04","AUTI07","BIPO02", "DEPR05","DEPR08","EDUC03","EXTR01","HEAL01","INCO03","INSO02","INTE03","LONG07", "MIGR01","NEUR01","PTSD04","RISK01","RISK02","RISK03","SCHI04","SUBJ01","TIRE01",
            "","","","","","","","","","","","","","","","","","","","","","","","","",
            rows = 3)
  
    
    # graph_sem(
    #   #model = cModelResults$lresults,
    # model=p$CFA$model.bestFitting$gsemResults[[1]]$lresults,
    # layout = p$CFA$semGraphLayout,
    # spacing_y=8,
    # spacing_x=4,
    # ellipses_width=7,
    # rect_width=3,
    # variance_diameter=0.5,
    # angle=180
    # )
    #ggsave(filename=file.path(p$folderpath.plots,paste0("cfa.plot.bestfitting.F",nFactor,".png")), plot = last_plot(), width = 500, height = 300, units = "mm")
    #dev.off()
    
    # dftoplot<-data.frame(
    #   indicator=p$sumstats.sel$name.nice,
    #   #indicator=rownames(p$CFA$model.bestFitting$parsedGenomicSEMResult[[1]]$patternCoefficients),
    #   pattern=cModel$parsedGsemResults[[1]][[1]]$patternCoefficients[,nFactor]
    #   )
    # dftoplot$bar_aes <- ifelse(dftoplot$pattern < 0, "-1", "1")
    # ggplot(
    #   data = dftoplot,
    #   aes(x=indicator, y=pattern)) + 
    #   geom_bar(stat = "identity", aes(fill=bar_aes), width = 0.5) +
    #   scale_fill_manual(name="Indicator pattern loading", 
    #                   labels = c("Negative", "Positive"), 
    #                   values = c("-1"=theme.color$contrastDark3, "1"=theme.color$contrastLight3)) +
    #   geom_text(aes(label=paste(indicator,round(pattern,digits = 3),sep = "\n")), size=4.5) +
    #   #geom_text(aes(label=paste(indicator,round(pattern,digits = 3),sep = "\n")), vjust=-0.3, size=5) +
    #   labs(title=paste0("Factor",nFactor),
    #        y="Std. indicator loading",
    #        x="Indicator"
    #      ) +
    #   theme_minimal()
    
    #ggsave(filename=file.path(p$folderpath.plots,cModel$code, paste0("cfa.F",nFactor,".png")), plot = last_plot(), width = 500, height = 300, units = "mm")
      #coord_flip()
    
    #semplate plotting does not work now for some reason
    #dot<-semplate$parseGenomicSEMResultAsDOTDataframes(resultDf = cModel$gsemResults[[1]][[1]]$results)
    #semplate$parseAndPrintGenomicSEMResult(resultDf = cModel$gsemResults[[1]][[1]]$results)
  }
  
  
  # p$CFA$semGraphLayout <- get_layout("F1","","F2","","F3","","F4","","F5","","F6","","F7","","F8","","F9",
  #           "ADHD05","ALCD03","ANXI03","AUTI07","BIPO02", "DEPR05","DEPR08","HEAL01","INCO03","INSO02", "MIGR01","NEUR01","RISK02","RISK03","SCHI04","SUBJ01","TIRE01",
  #           "","","","","","","","","","","","","","","","","",
  #           rows = 3)
  
  
  
  
  # graph_sem(model=cModelResults$lresults)
  # parsedSEMResult<-semplate$parseGenomicSEMResult(cModel$gsemResults[[1]][[1]]$results)
  # dot<-semplate$generateDOT(nodeDf=parsedSEMResult$variable, edgeDf=parsedSEMResult$loading)
  # grViz(dot)
  #grViz(semplate$parseAndPrintGenomicSEMResult(resultDf = cModelResults$results))

}

```


# Latent factor GWAS

## Naive variant effect meta-analysis
```{r naive variant effect meta-analysis }
#test
#p$clOptions$task<-"nmeta"
#p$clOptions$task_argument<-"M20_6_172.COR.ML:1"

cat("\n***Naive variant effect meta-analysis***\n")

if(p$clOptions$task=="nmeta"){
  
  p$nmeta<-c()
  
  p$lfGWAS$sumstats<-readRDS(file=p$filepath.lfgwas.sumstats)
  setDT(p$lfGWAS$sumstats)
  print("Read summary statistics for latent factor GWAS from file.")
  head(p$lfGWAS$sumstats)
  
  colBeta<-colnames(p$lfGWAS$sumstats)[grep("^BETA\\.", ignore.case = TRUE,colnames(p$lfGWAS$sumstats))]
  colSE<-colnames(p$lfGWAS$sumstats)[grep("^SE\\.", ignore.case = TRUE,colnames(p$lfGWAS$sumstats))]
  
  #sumstats QC
  ## effects
  rsum<-rowSums(abs(p$lfGWAS$sumstats[,..colBeta]),na.rm = T)
  rem<-rsum<(length(colBeta)*1e-19)
  p$lfGWAS$sumstats<-p$lfGWAS$sumstats[!rem,]
  rm("rsum")
  cat("\nRemoved ",sum(rem), " variants as part of QC before nmeta.\n")
  
  SESNP<-p$lfGWAS$sumstats[,..colSE]
  for(i in colSE)
    SESNP[is.na(get(i)), (i):=1] #assign the value 1 to NA SNP SE
  POPVARSNP<-2*p$lfGWAS$sumstats$MAF*(1-p$lfGWAS$sumstats$MAF) #2pq according to the genomic SEM publication
  
  #S<-as.matrix(p$mvLD$covstruct.mvLDSC$S)
  #V<-as.matrix(p$mvLD$covstruct.mvLDSC$V)
  I<-as.matrix(p$mvLD$covstruct.mvLDSC$I)
  #diag(I)<-ifelse(diag(I)<= 1, 1, diag(I)) #as in genomic SEM implementation. removed this because we sum all intercepts rather than only using the diagonal.
  I_diag<-diag(I)
  mI<-diag(nrow(I))
  for (x in 1:ncol(SESNP)) {
    for (y in 1:ncol(SESNP)) {
            mI[[x,y]]<-I[[x,y]]*I[[x,x]]*I[[y,y]]
        }
  }
  
  mI.sum<-colSums(mI,na.rm = T)
  
  BETASNP<-p$lfGWAS$sumstats[,..colBeta]
  #BETAVECTORS<-data.table()
  #adjust with the full ldsc intercept
  for (iCol in 1:ncol(BETASNP)){
    #iCol<-3
    col<-colnames(BETASNP)[iCol]
    set(x = BETASNP, j = col, value = BETASNP[[col]]/ifelse(mI.sum[iCol]<1,1,mI.sum[iCol]))
    #exprimental
    # if(iCol==1)
    #   set(x = BETAVECTORS, j = beta, value = BETASNP[[col]])
    # else
    #   set(x = BETAVECTORS, j = beta, value = c(BETAVECTORS[[,"beta"]],BETASNP[[col]]))
    #BETASNP[, (col):=(..col)]
    #BETASNP[, (col):=(col)(I_diag[[iCol]])]
  }
  
  #k<-apply(X = BETASNP,MARGIN = 1,FUN = function(x){sum(!is.na(x))})
  
  if(length(grep(pattern = "\\:",x = p$clOptions$task_argument))>0){
    p$nmeta$cModel<-strsplit(x = p$clOptions$task_argument, split = ':')[[1]][1]
    p$nmeta$cFactor<-strsplit(x = p$clOptions$task_argument, split = ':')[[1]][2]
    } else {
      p$nmeta$cModel<-p$clOptions$task_argument
      p$nmeta$cFactor<-NULL
    }
  
  for(iModel in 1:nrow(p$CFA$models.selected)){
    #test
    #iModel<-1
    
    cModel<-p$CFA$models.selected[iModel,]
    if(!is.null(p$nmeta$cModel) & !is.na(p$nmeta$cModel) & p$nmeta$cModel!=cModel$code) next
    cat("\nModel:  ",cModel$code)
    
    for(iFactor in 1:cModel$nFactors){
      #test
      #iFactor<-1
      if(is.null(p$nmeta$cFactor)){} else if(p$nmeta$cFactor!=iFactor) next
      factorFilepath<-file.path(p$folderpath.workingDirectory,paste0("nmeta.",cModel$code,".F",iFactor,".",p$setup.code,".Rds"))
      if(file.exists(factorFilepath)){
        modelGWAS<-readRDS(factorFilepath)
        iSNPStart<-nrow(modelGWAS[!is.na(BETA)])+1 #THIS DOES NOT DETECT THE RIGHT START POSITION!
        cat("\nContinuing nmeta from variant with index ",iSNPStart,"\n")
      } else {
        modelGWAS<-p$lfGWAS$sumstats[,c("SNP","CHR","BP","MAF","A1","A2")]
        iSNPStart<-1
      }
      cat("\nFactor:  ",iFactor,"\n")
      W<-cModel$parsedGsemResults[[1]][[1]]$relativeVarianceExplainedPerFactor[,iFactor]*sign(cModel$parsedGsemResults[[1]][[1]]$patternCoefficients.matrix[,iFactor]) #only weighted by the factor loadings here, rather than on the dataset variances
      W2<-W^2
      sqrt.W<-sqrt(abs(W))
      signed.sqrt.W<-sign(W)*sqrt.W
      k_W<-sum(!is.na(W))
      k_tot<-ncol(SESNP)
      #W0<-W
      #W0[is.na(W0)]<-0
      nSNP<-nrow(BETASNP)
      
      #mCovarTemplate<-setDT(as.data.frame(diag(k_tot)))
      #C_old<-sum(W,na.rm = T)-sum(W2,na.rm = T)/sum(W,na.rm = T)
      
      
      for(iSNP in iSNPStart:nSNP){
        #test
        #iSNP<-1L
        #iSNP<-8952400L
        #if(!iSNP %% 10 == 0) next  #for testing
        if(iSNP %% 100000 == 0){
          cat("#SNP ",iSNP, p$lfGWAS$sumstats[[iSNP,c("SNP")]],"\n")

          saveRDS(object = modelGWAS,file = factorFilepath)
          #cat("\nSaved intermediate results!\n")
          }
        
        mCovar<-diag(k_tot)
        #mI<-diag(nrow(I))
        #set snp variances adjusted for ldsc intercepts and sample overlap (through the ldsc intercepts - see genomic sem publication)
        for (x in 1:k_tot) {
          for (y in 1:k_tot) {
            #mCovar[x,y]<-(SESNP[[iSNP,y]]*SESNP[[iSNP,x]]*mI[[x,y]]*POPVARSNP[[iSNP]]^2)
            #mCovar[[x,y]]<-(SESNP[[iSNP,y]]*SESNP[[iSNP,x]]*mI[[x,y]]*POPVARSNP[[iSNP]]^2)
            mCovar[[x,y]]<-(signed.sqrt.W[x]*signed.sqrt.W[y]*SESNP[[iSNP,y]]*SESNP[[iSNP,x]]*mI[[x,y]]*POPVARSNP[[iSNP]]^2)
          }
        }
        
        abs.mCovar.sum<-abs(colSums(mCovar,na.rm = T)) #The individual variance components of each separate dataset

        #BETASNP.wmean<-weighted.mean(x = BETASNP[iSNP,], w = W0, na.rm = T)
        #BETASNP.wmean<-weighted.mean(x = BETASNP[iSNP,], w = W0/sqrt(abs.mCovar.sum), na.rm = T) #slightly corrected by the covariances
        # C<-sum(W/abs.mCovar.sum,na.rm = T)-sum(W2/(abs.mCovar.sum^2),na.rm = T)/sum(W/abs.mCovar.sum,na.rm = T)
        # Q_part<-((BETASNP[iSNP,]-BETASNP.wmean)^2)/abs.mCovar.sum
        # Q_part[is.na(Q_part)]<-0
        #Q<-sum(Q_part)
        #Q<-sum(((BETASNP[iSNP,]-BETASNP.wmean)^2)/abs.mCovar.sum, na.rm = T)
        #k<-sum(!is.na(W*BETASNP[iSNP,]))
        # T2<-max( c(
        #   (W0*Q - (k_W-1))/C,
        #   0
        #   ))
        # T2_part<-(W*Q_part - 1 + 1/k_W)/C
        # T2_part[T2_part<0]<-0

        #W_FULL<-W/(abs.mCovar.sum+T2) #as in a standard random effects meta-analysis
        #W_FULL<-W/(abs.mCovar.sum+T2_part)
        #W_FULL<-W/abs.mCovar.sum #fixed-effect meta-analysis
        #W_FULL<-W/(1+abs.mCovar.sum) #fixed-effect meta-analysis
        W_FULL<-W/(abs.mCovar.sum) #fixed-effect meta-analysis
        
        set(x = modelGWAS,i =iSNP, j = "BETA",
            #value = sum(W_FULL*BETASNP[iSNP,],na.rm = T)/sum(abs(W_FULL), na.rm = T)
            value = sum(W_FULL*BETASNP[iSNP,],na.rm = T)/sum(abs(W_FULL[!is.na(BETASNP[iSNP,])]), na.rm = T)
            )
        set(x = modelGWAS,i =iSNP, j = "SE",
            value = sqrt(sum(abs.mCovar.sum))
            #value = sqrt(sum(abs.mCovar.sum)/sqrt(k_tot)) #reduced SE correction, /k_tot sends the effects through the roof!
            )
        # set(x = modelGWAS,i =iSNP, j = "k",
        #     value = k[iSNP]
        #     )
        # set(x = modelGWAS,i =iSNP, j = "Q",
        #     value = sum(Q_part)
        #     )
        
      } #for iSNP
      
      #this is probably wrong
      #modelGWAS[, NEF:=(SE^2)/POPVARSNP] #Calculate Effective Sample Size for Factor 1 - from the Genomic SEM Wiki, citation: https://www.biorxiv.org/content/10.1101/603134v3
      modelGWAS[, P:=2*pnorm(q = abs((BETA/SE)),mean = 0, sd = 1, lower.tail = F)] #two sided!
      
      #just to conform to the use of FRQ rather than MAF when possible
      if(any(colnames(modelGWAS)=="MAF") && !any(colnames(modelGWAS)=="FRQ")) colnames(modelGWAS)[colnames(modelGWAS)=="MAF"]<-"FRQ"
      saveRDS(object = modelGWAS,file = factorFilepath) #compress = "bzip2"
      factorCode<-paste0("nmeta.",cModel$code,".F",iFactor,".",p$setup.code)
      
     
      #fwrite(x = modelGWAS, file = factorFilepath, append = F, quote = F, sep = "\t", nThread=5)
      supermunge.result<-supermunge(list_df = list(modelGWAS),traitNames = factorCode, pathDirOutput = p$folderpath.data.sumstats.munged)
      print("Naive metaanalysis of this model factor is done and the result has been exported to a file.")
    }
  } #for iModel
  
  rm("p$lfGWAS$sumstats") #to avoid oom problems 
  
}

if(p$clOptions$task=="nmeta"){quit(save = "no")}


```


## Launch Genomic SEM latent factor GWAS
If using HDL - do not use GC:
https://rpubs.com/MichelNivard/640145
"... Note that with out of sample LD hdl() may esitmate somewhat lower heritability, and a higher intercept, this means you should NOT use the intercept to shrink effect sizes if you run a GWAS in GenomicSEM."

```{r latent factor GWAS}

print("***Genomic SEM latent factor GWAS***")
#library(lavaan)
#library(gdata)
#library(parallel)
#library(doParallel)

#on implicit multithreading  
#https://hpc.nih.gov/apps/R.html#threading
# p$numCores<-parallel::detectCores()
# cat("\nNumber of cores detected to be ",p$numCores)
# .Internal(setMaxNumMathThreads(p$numCores-1)) 
# .Internal(setNumMathThreads(p$numCores-1))

#test
#p$clOptions$task<-"lfgwas"
#p$clOptions$task_argument<-"M20_6_172.COR.ML:1"
#p$clOptions$task_argument<-"M20_6_198.COR.ML:1"
#p$clOptions$task_argument<-"M20_6_198.COR.ML:22:1"


 #load intermediate results
# do not remove !p$clOptions$task=="lfgwas" as this will cause any lfgwas job to generate the composite results
if(!p$clOptions$task=="lfgwas" & !file.exists(file.path(p$folderpath.workingDirectory,paste0("lfGWAS.gwas.",p$setup.code,".Rds")))){
  print("Reading in latent factor gwas intermediate results.")
  p$lfGWAS$gwas<-list()
  
  for(iModel in 1:nrow(p$CFA$models.selected)){
    #test
    #iModel<-1
    cModel<-p$CFA$models.selected[iModel,]
    
    
    p$lfGWAS$intermediateResultFiles<-list.files(path = p$folderpath.workingDirectory, pattern = paste0("^lfGWAS\\.gwas\\.",p$setup.code,"\\.",cModel$code,"\\.F.+\\..+\\.Rds"), full.names = T, ignore.case=T)
    #p$lfGWAS$intermediateResultFiles<-list.files(path = p$folderpath.workingDirectory, pattern = paste0("^lfGWAS\\.gwas\\.",p$setup.code,"\\.M.+-.+\\..+\\..+\\.F.+\\..+\\.Rds"), full.names = T, ignore.case=T)
    #lfGWAS.gwas.setup4.M25-4.74.ML.F_ALL.chr8.Rds
    nIntermediateFactors<-NULL
    if(length(p$lfGWAS$intermediateResultFiles)>0){
      p$lfGWAS$gwas[[cModel$code]]<-list()
      for(nIntermediateResultFile in 1:length(p$lfGWAS$intermediateResultFiles)){
        #nIntermediateResultFile<-1
        intermediateResult<-readRDS(file=p$lfGWAS$intermediateResultFiles[nIntermediateResultFile])
        #initialise storage
        if(is.null(nIntermediateFactors)){
          #p$lfGWAS$gwas<-list()
          nIntermediateFactors<-length(intermediateResult)
          if(nIntermediateFactors!=p$CFA$nFactors) warning(paste0("\nNumber of read lfGWAS factors (",nIntermediateFactors,") do not match settings!\n"))
          for(nFactor in 1:nIntermediateFactors){
            p$lfGWAS$gwas[[cModel$code]][[nFactor]]<-intermediateResult[[nFactor]]
          }
        } else {
          for(nFactor in 1:nIntermediateFactors){
            p$lfGWAS$gwas[[cModel$code]][[nFactor]]<-rbind(p$lfGWAS$gwas[[cModel$code]][[nFactor]],intermediateResult[[nFactor]]) 
          }
        }
      }
    }
    
  }
  
  if(length(p$lfGWAS$gwas)>0){
    saveRDS(object = p$lfGWAS$gwas,file = file.path(p$folderpath.workingDirectory,paste0("lfGWAS.gwas.",p$setup.code,".Rds")))
    print("Read latent factor gwas results and saved latent factor summary file.")
    if(p$clOptions$task=="lfgwas"){quit(save = "no")}
    
  }
  
}

if(p$clOptions$task=="lfgwas" & !file.exists(file.path(p$folderpath.workingDirectory,paste0("lfGWAS.gwas.",p$setup.code,".Rds")))) 
{
  
  p$lfGWAS$sumstats<-readRDS(file=p$filepath.lfgwas.sumstats)
  setDT(p$lfGWAS$sumstats)
  setkeyv(p$lfGWAS$sumstats, cols = c("SNP","CHR","BP"))
  print("Read summary statistics for latent factor GWAS from file.")
  
  #Filter columns of chosen traits only
  #chromosomes<- sort(as.integer(unique(p$lfGWAS$sumstats$CHR)))
  colBeta<-c()
  colSE<-c()
  colFRQ<-c()
  colINFO.LIMP<-c()
  colK<-c()
  for(iTrait in 1:nrow(p$sumstats.sel)){
    #iTrait<-1
    colBeta<-c(colBeta,colnames(p$lfGWAS$sumstats)[grep(paste0("^BETA\\.",p$sumstats.sel[iTrait,c("code")],"$"), ignore.case = TRUE,colnames(p$lfGWAS$sumstats))])
    colSE<-c(colSE,colnames(p$lfGWAS$sumstats)[grep(paste0("^SE\\.",p$sumstats.sel[iTrait,c("code")],"$"), ignore.case = TRUE,colnames(p$lfGWAS$sumstats))])
    colFRQ<-c(colFRQ,colnames(p$lfGWAS$sumstats)[grep(paste0("^FRQ\\.",p$sumstats.sel[iTrait,c("code")],"$"), ignore.case = TRUE,colnames(p$lfGWAS$sumstats))])
    colINFO.LIMP<-c(colINFO.LIMP,colnames(p$lfGWAS$sumstats)[grep(paste0("^INFO.LIMP\\.",p$sumstats.sel[iTrait,c("code")],"$"), ignore.case = TRUE,colnames(p$lfGWAS$sumstats))])
    colK<-c(colK,colnames(p$lfGWAS$sumstats)[grep(paste0("^K\\.",p$sumstats.sel[iTrait,c("code")],"$"), ignore.case = TRUE,colnames(p$lfGWAS$sumstats))])
    # colBeta<-colnames(p$lfGWAS$sumstats)[grep("^BETA\\.", ignore.case = TRUE,colnames(p$lfGWAS$sumstats))]
    # colSE<-colnames(p$lfGWAS$sumstats)[grep("^SE\\.", ignore.case = TRUE,colnames(p$lfGWAS$sumstats))]
  }
  
  colAll<-c("SNP","CHR","BP","MAF","A1","A2",colBeta,colSE,colFRQ,colINFO.LIMP,colK)
  
  
  #full
  #nrow(p$lfGWAS$sumstats)
  #nrow(na.omit(p$lfGWAS$sumstats))
  
  #selected subset
  p$lfGWAS$sumstats<-p$lfGWAS$sumstats[,..colAll]
  #nrow(p$lfGWAS$sumstats)
  #nrow(na.omit(p$lfGWAS$sumstats))
  
  print("Processing summary statistics for latent factor GWAS - NA values")
  #fill NA values - should be replaced with proper imputation
  
  setDT(p$lfGWAS$sumstats)
  setkeyv(x = p$lfGWAS$sumstats, cols = "SNP")
  colIsRaw<-c()
  for(iTrait in 1:nrow(p$sumstats.sel)){
    cColBeta<-colBeta[iTrait]
    cColK<-colK[iTrait]
    cColIsRaw<-paste0("is.raw.",p$sumstats.sel[iTrait,c("code")])
    p$lfGWAS$sumstats[,(cColIsRaw):=!is.na(get(cColBeta)) & is.na(get(cColK))]
    colIsRaw<-c(colIsRaw,cColIsRaw)
  }
  p$lfGWAS$sumstats[,K:=apply(.SD,MARGIN = 1,FUN = function(x){sum(x)}), .SDcols=colIsRaw]
  p$lfGWAS$sumstats[,K.IMP:=apply(.SD,MARGIN = 1,FUN = function(x){sum(!is.na(x))}), .SDcols=colBeta]
  p$lfGWAS$sumstats[,sumK:=rowSums(.SD,na.rm = T), .SDcols=colK]
  p$lfGWAS$sumstats[,sumINFO.LIMP:=rowSums(.SD,na.rm = T), .SDcols=colINFO.LIMP]
  p$lfGWAS$sumstats[,sumBETA:=rowSums(.SD,na.rm = T), .SDcols=colBeta]
  p$lfGWAS$sumstats[,sumSE:=rowSums(.SD,na.rm = T), .SDcols=colSE]
  p$lfGWAS$sumstats[,meanBETA:=sumBETA/K.IMP][,meanSE:=sumSE/K.IMP]
  
  #process still missing values
  for(iTrait in 1:nrow(p$sumstats.sel)){
    #iTrait<-19
    cColBeta<-colBeta[iTrait]
    cColSE<-colSE[iTrait]
    #nrow(p$lfGWAS$sumstats[is.na(get(cColBeta)),])
    #p$lfGWAS$sumstats[is.na(get(cColBeta)) & K.IMP>0.5*length(colBeta) & K>0.2*length(colBeta),] 
    p$lfGWAS$sumstats[is.na(get(cColBeta)) & K.IMP>0.5*length(colBeta) & K>0.2*length(colBeta), (cColBeta):=meanBETA] 
    p$lfGWAS$sumstats[is.na(get(cColSE)) & K.IMP>0.5*length(colBeta) & K>0.2*length(colBeta), (cColSE):=meanSE] 
    #nrow(p$lfGWAS$sumstats[is.na(get(cColBeta)),])
    #nrow(p$lfGWAS$sumstats[is.na(get(cColSE)),])
    #p$lfGWAS$sumstats[is.na(get(cColBeta)), (cColBeta):=(1e-20)]
    #p$lfGWAS$sumstats[is.na(get(cColSE)), (cColSE):=1]
  }
  
  cat("\nA total of ",nrow(p$lfGWAS$sumstats), " variants before QC.\n")
  
  #nrow(na.omit(p$lfGWAS$sumstats[,..colBeta]))
  #filter columns to those required for lfGWAS
  colLfGWAS<-c("SNP","CHR","BP","MAF","A1","A2",colBeta,colSE)
  #QC - remove variants with NA effects or SE
  p$lfGWAS$sumstats<-na.omit(p$lfGWAS$sumstats[,..colLfGWAS])
  
  cat("\nA total of ",nrow(p$lfGWAS$sumstats), " variants after QC.\n")

  
  #to data frame to conform with userGWAS below
  p$lfGWAS$sumstats<-as.data.frame(p$lfGWAS$sumstats)
  
  p$lfGWAS$cModel<-NULL
  p$lfGWAS$cFn<-NULL
  p$lfGWAS$cChr<-NULL
  #test #p$lfGWAS$cChr<-22
  
  if(length(grep(pattern = "\\:",x = p$clOptions$task_argument))>0){
    p$lfGWAS$cModel<-strsplit(x = p$clOptions$task_argument, split = ':')[[1]][1]
    p$lfGWAS$cChr<-strsplit(x = p$clOptions$task_argument, split = ':')[[1]][2]
    #p$lfGWAS$cFn<-strsplit(x = p$clOptions$task_argument, split = ':')[[1]][3]
  } else if(exists(p$clOptions$task_argument)){
    p$lfGWAS$cModel<-p$clOptions$task_argument
  } else {
    p$lfGWAS$cModel<-p$CFA$models.selected[1,]$code
  }
  
  
  #if(is.null(p$lfGWAS$cFn)) p$lfGWAS$cFn<-"1"
  #if(is.null(p$lfGWAS$cChr)) p$lfGWAS$cChr<-"1"
  
  
  cat("\nPerforming latent factor GWAS")
  cat("\nSelected model:",p$lfGWAS$cModel)
  cat("\nSelected factor ",ifelse(is.null(p$lfGWAS$cFn),"ALL",paste0(p$lfGWAS$cFn))," and chromosome ",ifelse(is.null(p$lfGWAS$cChr),"ALL",paste0(p$lfGWAS$cChr)),". This will take a while!\n")
  
  #select model from code
  cModel<-p$CFA$models.selected[p$lfGWAS$cModel,]
  
  if(is.null(p$lfGWAS$cFn)){
    p$lfGWAS$lmodel<-paste0(cModel$lModel.fixed,paste0("\nF",(1:cModel$nFactors),"~SNP", collapse = ""))
  } else {
    p$lfGWAS$lmodel<-paste0(cModel$lModel.fixed,paste0("\nF",p$lfGWAS$cFn,"~SNP"))
  }
  
  cat("\nExpanded CFA model with SNP effects:")
  print(p$lfGWAS$lmodel)
  
  if(length(p$lfGWAS$cChr)>0){
    cat("\nAnalysing only the specified chromosome: ",paste0(p$lfGWAS$cChr))
    #TEST
    #p$lfGWAS$sumstats.selected<-head(p$lfGWAS$sumstats[which(as.character(p$lfGWAS$sumstats$CHR)==p$lfGWAS$cChr),])
    p$lfGWAS$sumstats<-p$lfGWAS$sumstats[which(as.character(p$lfGWAS$sumstats$CHR)==p$lfGWAS$cChr),]
  }
  
  #TEST settings - restrict to a subset of variants
  #p$lfGWAS$sumstats<-head(p$lfGWAS$sumstats, n = 100)
  
  print("Head of processed sumstats table selection")
  print(head(p$lfGWAS$sumstats))
    
  p$lfGWAS$gwas<-userGWAS.mod(
    covstruc = p$mvLD$covstruct.mvLDSC,
    SNPs = p$lfGWAS$sumstats,
    estimation = "ML",
    model = p$lfGWAS$lmodel,
    modelchi = FALSE,
    printwarn = TRUE,
    sub=paste0("F",(1:cModel$nFactors),"~SNP"),
    parallel=T,
    GC="conserv",
    smooth_check = T,
    TWAS = F,
    #parallel_outfile = file.path(p$folderpath.workingDirectory,"lfgwas.progress.txt"),
    cores = 10 #set cores as standard
    #turbo=T
    )
  
  cat("\nuser GWAS done returning results for ",length(p$lfGWAS$gwas),"factors and ",nrow(p$lfGWAS$gwas[[1]])," SNPs.")
  
  saveRDS(object = p$lfGWAS$gwas,file = file.path(p$folderpath.workingDirectory,paste0("lfGWAS.gwas.",p$setup.code,".",p$lfGWAS$cModel,
                                                                                                   ".F",ifelse(length(p$lfGWAS$cFn)>0,p$lfGWAS$cFn,"ALL"),
                                                                                                   ".",ifelse(length(p$lfGWAS$cChr)>0,paste0("chr",p$lfGWAS$cChr),"ALL"),".Rds")))
  
  print("DONE performing latent factor GWAS. The results should have been saved to a file.")

}


if(p$clOptions$task=="lfgwas"){quit(save = "no")}

```

## Process latent factor GWAS results
Both effects and standard errors are adjusted by the GC-function in the userGWAS funcion, where they are either divided by or multiplied with variants of the ldsc-intecept (square-root of or plain).
```{r process latent factor GWAS results}
cat("\n***Process latent factor GWAS results***\n")
#check the first model and first factor file
if(!file.exists(file.path(p$folderpath.data.sumstats.munged,paste0(p$CFA$models.selected[1,]$code,".F",1,".gz")))){
  
  cat("\nProcessing latent factor GWAS results...\n")
  NTot<-sum(p$sumstats.sel$n_total)
  
  p$lfGWAS$gwas<-readRDS(file=file.path(p$folderpath.workingDirectory,paste0("lfGWAS.gwas.",p$setup.code,".Rds")))
    print("Read previously stored latent factor GWAS results from file.")
  
  for(iModel in 1:nrow(p$CFA$models.selected)){
    #test
    #iModel<-1
    cModel<-p$CFA$models.selected[iModel,] 
    
    inflationFactorTotal<-1/cModel$parsedGsemResults[[1]][[1]]$meanTotalRelativeVarianceExplained
    
    if(length(p$lfGWAS$gwas[[cModel$code]])>0){
      
      patCoef<-cModel$parsedGsemResults[[1]][[1]]$patternCoefficientsSTDGenotype.matrix
      patCoefSq<-patCoef^2
      disVars<-cModel$parsedGsemResults[[1]][[1]]$residualVariances.matrix
      #factorSpecificWeight<-colMeans(patCoefSq[,1:ncol(patCoefSq)]*rep((1-disVars),times=ncol(patCoefSq)),na.rm=T)
      #factorSpecificWeight<-colMeans(patCoefSq[,1:ncol(patCoefSq)],na.rm=T)
      factorSpecificWeight<-colSums(patCoefSq[,1:ncol(patCoefSq)]*rep((1-disVars),times=ncol(patCoefSq)),na.rm=T)
      
      #explainedVariance <- patCoef #TODO
      factorWeightSum<-nrow(patCoefSq)
      #factorWeightSum<-sum(factorSpecificWeight)
      effectiveN<-vector()
      
      #loop for calculating the effective N
      #inflating effect sizes - if needed - and saving factor GWAS output files
      for(iFactor in 1:cModel$nFactors){
        #test
        #iFactor<-1
        factorCode<-paste0(cModel$code,".F",iFactor)
        #factorFilepath<-file.path(p$folderpath.workingDirectory,paste0("lfGWAS.",factorCode,".",p$setup.code,".Rds"))
        
         #adjust variant effect size
        #inflationFactorFactor<-inflationFactorTotal*factorSpecificWeight[iFactor]
        #head(p$lfGWAS$gwas[[cModel$code]][[iFactor]])
        #NTot/effectiveN[iFactor]
        p$lfGWAS$gwas[[cModel$code]][[iFactor]]$Z_adj<-p$lfGWAS$gwas[[cModel$code]][[iFactor]]$Z_Estimate
        
        #adjust variant p estimate
        #p$lfGWAS$gwas[[cModel$code]][[iFactor]]$p_adj<-2*pnorm(q = p$lfGWAS$gwas[[cModel$code]][[iFactor]]$Z_Estimate, sd = (1/sqrt(nrow(p$sumstats.sel))), lower.tail = F)
        p$lfGWAS$gwas[[cModel$code]][[iFactor]]$p_adj<-2*pnorm(q = p$lfGWAS$gwas[[cModel$code]][[iFactor]]$Z_Estimate, lower.tail = F)
        #head(p$lfGWAS$gwas[[cModel$code]][[iFactor]])[,c("SNP","Z_Estimate","Z_smooth","Z_adj", "Pval_Estimate","p_adj")]
      
      
        #set which values to use for output
        #p$lfGWAS$gwas[[cModel$code]][[iFactor]]$p<-p$lfGWAS$gwas[[cModel$code]][[iFactor]]$p_adj
        p$lfGWAS$gwas[[cModel$code]][[iFactor]]$P<-p$lfGWAS$gwas[[cModel$code]][[iFactor]]$Pval_Estimate
        p$lfGWAS$gwas[[cModel$code]][[iFactor]]$BETA<-p$lfGWAS$gwas[[cModel$code]][[iFactor]]$est
        p$lfGWAS$gwas[[cModel$code]][[iFactor]]$Z<-p$lfGWAS$gwas[[cModel$code]][[iFactor]]$Z_Estimate
        p$lfGWAS$gwas[[cModel$code]][[iFactor]]$CHISQ<-p$lfGWAS$gwas[[cModel$code]][[iFactor]]$chisq
        p$lfGWAS$gwas[[cModel$code]][[iFactor]]$DF<-p$lfGWAS$gwas[[cModel$code]][[iFactor]]$chisq_df
        
        
        #save the factor GWAS to file
        #saveRDS(object = (p$lfGWAS$gwas[[cModel$code]][[iFactor]])[,c("SNP","CHR","BP","MAF","A1","A2","BETA","SE","Z","CHISQ","DF","P","NEF")],file = factorFilepath)
        supermunge(
          list_df = list((p$lfGWAS$gwas[[cModel$code]][[iFactor]])[,c("SNP","CHR","BP","MAF","A1","A2","BETA","SE","Z","CHISQ","DF","P")]),traitNames = factorCode, pathDirOutput = p$folderpath.data.sumstats.munged
          )
        }
    }
    
  }
}
```


## Setup additional latent traits for later analysis

```{r setup additional traits}

p$sumstats$code.file<-p$sumstats$code #default as code

#GSEM pre-analysis (simple, no NA effects)
factorCode<-"PRE.F1"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"MPRE_2_1.COR.ML.F1","Risk F1",294363)
factorCode<-"PRE.F2"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"MPRE_2_1.COR.ML.F2","Risk F2",364476)


#GSEM latent factor GWAS
factorCode<-"GSEM.F1"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"M20_6_172.COR.ML.F1","Factor neuroticism",364979)
factorCode<-"GSEM.F2"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"M20_6_172.COR.ML.F2","Factor psychoticism",159862)
factorCode<-"GSEM.F3"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"M20_6_172.COR.ML.F3","Factor depression",448644)
factorCode<-"GSEM.F4"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"M20_6_172.COR.ML.F4","Factor risktaking",46293)
factorCode<-"GSEM.F5"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"M20_6_172.COR.ML.F5","Factor deprivation",271911)
factorCode<-"GSEM.F6"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"M20_6_172.COR.ML.F6","Factor neuropsyche",91409)


#nmeta latent factor GWAS
factorCode<-"nmeta.CF1"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_172.COR.ML.F1.setup7","Anxiety CF",237392)
factorCode<-"nmeta.CF2"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_172.COR.ML.F2.setup7","Thought CF",1406685)
factorCode<-"nmeta.CF3"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_172.COR.ML.F3.setup7","Depression CF",1051408)
factorCode<-"nmeta.CF4"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_172.COR.ML.F4.setup7","Externalising CF",1131595)
factorCode<-"nmeta.CF5"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_172.COR.ML.F5.setup7","SE deprivation CF",865415)
factorCode<-"nmeta.CF6"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_172.COR.ML.F6.setup7","Neuropsychiatric CF",2091884)

factorCode<-"nmeta.OF1"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_30.ORT.ML.F1.setup7","Externalising(inv) OF",2379693)
factorCode<-"nmeta.OF2"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_30.ORT.ML.F2.setup7","Neuropsychiatric OF",1957237)
factorCode<-"nmeta.OF3"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_30.ORT.ML.F3.setup7","Fear OF",282511)
factorCode<-"nmeta.OF4"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_30.ORT.ML.F4.setup7","Depression OF",360436)
factorCode<-"nmeta.OF5"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_30.ORT.ML.F5.setup7","Distress(inv) OF",572446)
factorCode<-"nmeta.OF6"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_30.ORT.ML.F6.setup7","Thought OF",1096993)


p$sumstats.sel.code<-c("PRE.F1","PRE.F2","GSEM.F1","GSEM.F2","GSEM.F3","GSEM.F4","GSEM.F5","GSEM.F6","nmeta.CF1","nmeta.CF2","nmeta.CF3","nmeta.CF4","nmeta.CF5","nmeta.CF6","nmeta.OF1","nmeta.OF2","nmeta.OF3","nmeta.OF4","nmeta.OF5","nmeta.OF6")

# set nice name for selected traits
p$sumstats[p$sumstats.sel.code,]$name.nice<-p$sumstats[p$sumstats.sel.code,]$name

##Add sumstat cleaned and munged file paths
p$sumstats[p$sumstats.sel.code,c("cleanedpath")]<-file.path(p$folderpath.data.sumstats.cleaned,paste0(p$sumstats[p$sumstats.sel.code,c("code.file")],p$filename.suffix.data.sumstats.munged))

p$sumstats[p$sumstats.sel.code,c("mungedpath")]<-file.path(p$folderpath.data.sumstats.munged,paste0(p$sumstats[p$sumstats.sel.code,c("code.file")],p$filename.suffix.data.sumstats.munged))

##Add a combined nice name plus code label
p$sumstats$name.nice.and_code<-paste0(p$sumstats$name.nice," (",p$sumstats$code,")")

#set order of datasets to sorted by code
p$sumstats<-p$sumstats[order(p$sumstats$name.nice),]

#re-calculate effective N from file information - perform manually as needed
if(F){
        factorCode<-"nmeta.OF6"
        gwasForEffectiveN<-fread(file = file.path(p$folderpath.data.sumstats.munged,paste0( p$sumstats[factorCode,]$code.file,".gz")), na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, key = c("SNP","CHR","BP"), data.table = T,showProgress = F, nThread=6)
  ##Calculate Effective Sample Size for Factor 1 - from the Genomic SEM Wiki
        #citation: https://www.biorxiv.org/content/10.1101/603134v3
        #restrict to MAF of 40% and 10%
        #change to use adjusted Z if this has been set above
        #added to supermunge also
        gwasForEffectiveN[,MAF:=ifelse(FRQ>0.5,1-FRQ,FRQ)][,VSNP:=2*FRQ*(1-FRQ)]
        gwasForEffectiveN<-gwasForEffectiveN[MAF>=.1 & MAF<=.4,]
        setDT(gwasForEffectiveN)
        #gwasForEffectiveN[,NEF:=round(((Z/EFFECT)^2)/VSNP,digits = 0)]
        effectiveN<-mean(gwasForEffectiveN$NEF,na.rm=T)
        round(effectiveN,digits = 0)
        
}
```


## Variable selection and project configuration, second iteration
```{r GWAS sumstat dataset variable selection 2}

#selection based on specific traits
#p$sumstats.sel.code<-c("ANXI04")
#p$sumstats.sel.code<-c("ADHD05","ANXI04")
#p$sumstats.sel.code<-c("RISK02","RISK03","SCHI04","SUBJ01","TIRE01")
#p$sumstats.sel.code<-c("TIRE01")
#p$sumstats.sel.uv.code<-c("EDUC03","NEUR02","RISK02","RISK03","SCHI04")
p$sumstats.sel.uv.code<-c("ADHD05","ALCD03","ANOR02","ANXI03","ANXI04","AUTI07","BIPO02", "DEPR05","DEPR08","EDUC03","HEAL01","INCO03","INSO02","NEUR02", "PTSD04","RISK02","RISK03","SCHI04","SUBJ01","TIRE01")
#p$sumstats.sel.lfgwas.code<-c("PRE.F1","PRE.F2")
p$sumstats.sel.set1_spec.code<-c("GSEM.F1","GSEM.F2","GSEM.F3","GSEM.F4","GSEM.F5","GSEM.F6")
p$sumstats.sel.set2_spec.code<-c("nmeta.CF1","nmeta.CF2","nmeta.CF3","nmeta.CF4","nmeta.CF5","nmeta.CF6")
p$sumstats.sel.set3_spec.code<-c("nmeta.OF1","nmeta.OF2","nmeta.OF3","nmeta.OF4","nmeta.OF5","nmeta.OF6")
p$sumstats.sel.set1.code<-c(p$sumstats.sel.uv.code,p$sumstats.sel.set1_spec.code)
p$sumstats.sel.set2.code<-c(p$sumstats.sel.uv.code,p$sumstats.sel.set2_spec.code)
p$sumstats.sel.set3.code<-c(p$sumstats.sel.uv.code,p$sumstats.sel.set3_spec.code)
p$sumstats.sel.code<-c(p$sumstats.sel.uv.code,p$sumstats.sel.set1_spec.code,p$sumstats.sel.set2_spec.code,p$sumstats.sel.set3_spec.code)
p$sumstats.sel<-p$sumstats[which(p$sumstats$code %in% p$sumstats.sel.code),]

p$sumstats.sel[,c("code","name","name.nice","name.nice.and_code", "year","n_case","n_control","n_total","n_effective", "pmid","reference_doi","samplePrevalence","populationPrevalence","dependent_variable.OLS","dependent_variable.linprob","se.logit","mungedpath")]
p$k.sel<-nrow(p$sumstats.sel)
#View(p$sumstats.sel[,c("code","n_total","pmid","reference_doi","samplePrevalence","populationPrevalence","mungedpath")])
#set order of datasets to sorted by code
p$sumstats.sel[is.na(p$sumstats.sel$name.nice),c("name.nice")]<-p$sumstats.sel[is.na(p$sumstats.sel$name.nice),c("name")]
p$sumstats.sel[,c("n_consensus")] <- as.numeric(
                                        ifelse(is.na(p$sumstats.sel$n_total),
                                               p$sumstats.sel$n_effective,
                                               p$sumstats.sel$n_total)
                                              )

p$sumstats.sel<-p$sumstats.sel[order(p$sumstats.sel$name.nice),]

write.table(p$sumstats.sel[,c("code", "name.nice","year", "n_case","n_control","n_total","n_effective","samplePrevalence","populationPrevalence", "reference_doi")], file = file.path(p$folderpath.workingDirectory,paste0(p$setup.code,".sumstatinfo.tsv")), quote = TRUE, sep = "\t", row.names = FALSE, col.names = TRUE)

#this should not be needed as the SNP's already have their NEF
#set n-total for new latent traits from efective n
# cond<-is.na(p$sumstats.sel$n_total)&!is.na(p$sumstats.sel$n_effective)
# p$sumstats.sel[cond,c("n_total")]<-p$sumstats.sel[cond,c("n_effective")]

#View(p$sumstats.sel)

```


# Multivariate LD-score regression including latent factors, second iteration

```{r mvLD 2, including latent factors}
print("***Multivariate LD 2***")
p$filepath.mvLD2.set1<-file.path(p$folderpath.workingDirectory,paste0("mvLD2.set1.",p$setup.code,".Rds"))
p$filepath.mvLD2.set2<-file.path(p$folderpath.workingDirectory,paste0("mvLD2.set2.",p$setup.code,".Rds"))
p$filepath.mvLD2.set3<-file.path(p$folderpath.workingDirectory,paste0("mvLD2.set3.",p$setup.code,".Rds"))

#set1 - GSEM
if (file.exists(p$filepath.mvLD2.set1)) {
  print("Using existing covariance structures from previous LD computations.")
  p$mvLD2.set1<-readRDS(file=p$filepath.mvLD2.set1)
} else {
  
  print("Running multivariate LD regression with different methods. This might take a while. If the procedure runs for too long you may want to abort the process.")
  
  cat("The current task is specified as:",p$clOptions$task)
  p$mvLD2.set1<-c()
  
  if(p$clOptions$task=="mvLD2"){
    #run mvLDSC

    p$mvLD2.set1$covstruct.mvLDSC.1kg<-ldsc.mod(
      traits = p$sumstats.sel[p$sumstats.sel.set1.code,]$mungedpath,
      sample.prev =  p$sumstats.sel[p$sumstats.sel.set1.code,]$samplePrevalence,
      population.prev = p$sumstats.sel[p$sumstats.sel.set1.code,]$populationPrevalence,
      trait.names = p$sumstats.sel[p$sumstats.sel.set1.code,]$code,
      ld = p$folderpath.data.mvLDSC.ld.1kg,
      wld = p$folderpath.data.mvLDSC.ld.1kg,
      n.blocks = 600, #a bit more here if it can support the larger reference panel used
      info.filter = 0.6,
      maf.filter = 0.01,
      mhc.filter = 37,
      #chisq.min = 1e-3,
      N = p$sumstats.sel[p$sumstats.sel.set1.code,]$n_total,
      #forceN = T, # Consider this when some of the original N's may be untrustworthy (ANXI04!) - TODO - fix in supermunge
      ldsc.log = p$setup.code.date
      )

    
    saveRDS(object = p$mvLD2.set1,file = p$filepath.mvLD2.set1)
    print("Multivariate LD correction is done now and the resulting covariance structure should have been saved to a file.")
  
  } 
}

#set2 - nmeta, best correlated factor model
if (file.exists(p$filepath.mvLD2.set2)) {
  print("Using existing covariance structures from previous LD computations.")
  p$mvLD2.set2<-readRDS(file=p$filepath.mvLD2.set2)
} else if (F){
  
  print("Running multivariate LD regression with different methods. This might take a while. If the procedure runs for too long you may want to abort the process.")
  
  cat("The current task is specified as:",p$clOptions$task)
  p$mvLD2.set2<-c()
  
  if(p$clOptions$task=="mvLD2"){
    #run mvLDSC

    p$mvLD2.set2$covstruct.mvLDSC.1kg<-ldsc.mod(
      traits = p$sumstats.sel[p$sumstats.sel.set2.code,]$mungedpath,
      sample.prev =  p$sumstats.sel[p$sumstats.sel.set2.code,]$samplePrevalence,
      population.prev = p$sumstats.sel[p$sumstats.sel.set2.code,]$populationPrevalence,
      trait.names = p$sumstats.sel[p$sumstats.sel.set2.code,]$code,
      ld = p$folderpath.data.mvLDSC.ld.1kg,
      wld = p$folderpath.data.mvLDSC.ld.1kg,
      n.blocks = 600, #a bit more here if it can support the larger reference panel used
      info.filter = 0.6,
      maf.filter = 0.01,
      mhc.filter = 37,
      #chisq.min = 1e-3,
      N = p$sumstats.sel[p$sumstats.sel.set2.code,]$n_total,
      #forceN = T, # Consider this when some of the original N's may be untrustworthy (ANXI04!) - TODO - fix in supermunge
      ldsc.log = p$setup.code.date
      )

    
    saveRDS(object = p$mvLD2.set2,file = p$filepath.mvLD2.set2)
    print("Multivariate LD correction is done now and the resulting covariance structure should have been saved to a file.")
  
  } 
}

#set3 - nmeta, best orthogonal factor model
if (file.exists(p$filepath.mvLD2.set3)) {
  print("Using existing covariance structures from previous LD computations.")
  p$mvLD2.set3<-readRDS(file=p$filepath.mvLD2.set3)
} else if(F){
  
  print("Running multivariate LD regression with different methods. This might take a while. If the procedure runs for too long you may want to abort the process.")
  
  cat("The current task is specified as:",p$clOptions$task)
  p$mvLD2.set3<-c()
  
  if(p$clOptions$task=="mvLD2"){
    #run mvLDSC

    p$mvLD2.set3$covstruct.mvLDSC.1kg<-ldsc.mod(
      traits = p$sumstats.sel[p$sumstats.sel.set3.code,]$mungedpath,
      sample.prev =  p$sumstats.sel[p$sumstats.sel.set3.code,]$samplePrevalence,
      population.prev = p$sumstats.sel[p$sumstats.sel.set3.code,]$populationPrevalence,
      trait.names = p$sumstats.sel[p$sumstats.sel.set3.code,]$code,
      ld = p$folderpath.data.mvLDSC.ld.1kg,
      wld = p$folderpath.data.mvLDSC.ld.1kg,
      n.blocks = 600, #a bit more here if it can support the larger reference panel used
      info.filter = 0.6,
      maf.filter = 0.01,
      mhc.filter = 37,
      #chisq.min = 1e-3,
      N = p$sumstats.sel[p$sumstats.sel.set3.code,]$n_total,
      #forceN = T, # Consider this when some of the original N's may be untrustworthy (ANXI04!) - TODO - fix in supermunge
      ldsc.log = p$setup.code.date
      )

    
    saveRDS(object = p$mvLD2.set3,file = p$filepath.mvLD2.set3)
    print("Multivariate LD correction is done now and the resulting covariance structure should have been saved to a file.")
  
  } 
}


if(p$clOptions$task=="mvLD2"){
      quit(save = "no")
}


#add newly computed heritabilities and LDSC intercepts to the selected summary statistics table
p$sumstats.sel[p$sumstats.sel.set1.code,c("h2.liability_mvLDSC")]<-diag(p$mvLD2.set1$covstruct.mvLDSC.1kg$S[p$sumstats.sel.set1.code,p$sumstats.sel.set1.code])
p$sumstats.sel[p$sumstats.sel.set1.code,c("h2.se.liability_mvLDSC")]<-diag(p$mvLD2.set1$covstruct.mvLDSC.1kg$S.SE[p$sumstats.sel.set1.code,p$sumstats.sel.set1.code])

if(F){
  p$sumstats.sel[p$sumstats.sel.set2_spec.code,c("h2.se.liability_mvLDSC")]<-diag(p$mvLD2.set2$covstruct.mvLDSC.1kg$S[p$sumstats.sel.set2_spec.code,p$sumstats.sel.set2_spec.code])
  p$sumstats.sel[p$sumstats.sel.set2_spec.code,c("h2.se.liability_mvLDSC")]<-diag(p$mvLD2.set2$covstruct.mvLDSC.1kg$S.SE[p$sumstats.sel.set2_spec.code,p$sumstats.sel.set2_spec.code])
  
  p$sumstats.sel[p$sumstats.sel.set3_spec.code,c("h2.se.liability_mvLDSC")]<-diag(p$mvLD2.set3$covstruct.mvLDSC.1kg$S[p$sumstats.sel.set3_spec.code,p$sumstats.sel.set3_spec.code])
  p$sumstats.sel[p$sumstats.sel.set3_spec.code,c("h2.se.liability_mvLDSC")]<-diag(p$mvLD2.set3$covstruct.mvLDSC.1kg$S.SE[p$sumstats.sel.set3_spec.code,p$sumstats.sel.set3_spec.code])
}

colnames(p$mvLD2.set1$covstruct.mvLDSC.1kg$I)<-colnames(p$mvLD2.set1$covstruct.mvLDSC.1kg$S)
rownames(p$mvLD2.set1$covstruct.mvLDSC.1kg$I)<-rownames(p$mvLD2.set1$covstruct.mvLDSC.1kg$S)
p$sumstats.sel[p$sumstats.sel.set1.code,c("lambda_ldsc")]<-diag(p$mvLD2.set1$covstruct.mvLDSC.1kg$I[p$sumstats.sel.set1.code,p$sumstats.sel.set1.code])


#compute scaling factor relative to sample size and overall trait heritability
p$sumstats.sel[,c("power_scale_factor")]<-p$sumstats.sel$h2.liability_mvLDSC*p$sumstats.sel$n_consensus


```

# Overview of rg between selected traits, including latent factors
```{r overview pairwise rg 2, fig.width=9, fig.height=6, out.width="1600px", out.height="1000px", purl=FALSE}

cMvLDset<-p$mvLD2.set1
cMvLDset.names<-colnames(cMvLDset$covstruct.mvLDSC.1kg$S)
#edit the selection of traits here for the plot
cMvLDset$covstruct.mvLDSC.1kg$S_Stand.forPlot<-cMvLDset$covstruct.mvLDSC.1kg$S_Stand

rownames(cMvLDset$covstruct.mvLDSC.1kg$S_Stand.forPlot)<-p$sumstats.sel[cMvLDset.names,]$name.nice.and_code
colnames(cMvLDset$covstruct.mvLDSC.1kg$S_Stand.forPlot)<-cMvLDset.names

p$printCorrSimplified(
  corr = clipValues(cMvLDset$covstruct.mvLDSC.1kg$S_Stand.forPlot,-1,1),
  #SE = cMvLDset$covstruct.mvLDSC$S_Stand.SE,
  filename = file.path(p$folderpath.plots,"rg.full.simple.png"),
  is.corr = T
  )

p$printCorrSimplified(
  corr = clipValues(abs(cMvLDset$covstruct.mvLDSC.1kg$S_Stand.forPlot),-1,1),
  #SE = cMvLDset$covstruct.mvLDSC$S_Stand.SE,
  filename = file.path(p$folderpath.plots,"absrg.full.simple.png"),
  is.corr = F,
  absScale=T
  )

p$printCorr(
  corr = clipValues(cMvLDset$covstruct.mvLDSC.1kg$S_Stand.forPlot,-1,1),
  SE = cMvLDset$covstruct.mvLDSC.1kg$S_Stand.SE,
  filename = file.path(p$folderpath.plots,"rg.full.png"),
  is.corr = T,
  addrect = NULL
  )

library(heatmaply)
#ggheatmap() #static version
#heatmaply()
heatmaply(
    clipValues(cMvLDset$covstruct.mvLDSC.1kg$S_Stand.forPlot,-1,1),
    cellnote = round(clipValues(cMvLDset$covstruct.mvLDSC.1kg$S_Stand.forPlot,-1,1),digits = 2),
    cellnote_size = 9,
    cellnote_textposition = "middle center",
    show_dendrogram = c(T,F),
    xlab = "Trait GWAS",
    ylab = "Trait GWAS",
    main = "r<sub>g</sub>",
    scale_fill_gradient_fun = ggplot2::scale_fill_gradient2(
        low = theme.color$contrastDark3, 
        mid = "black",
        high = theme.color$contrastLight3,
        breaks = c(-1,0,1)
      ),
    file=file.path(p$folderpath.plots,paste0("rg.full2.png")),
    width = 1200, height = 1200,
    hclust_method = "ward.D2"
    #scale = "row"
  )


print("Heritabilities")
p$plots.heritabilities<-data.frame(
  trait=colnames(cMvLDset$covstruct.mvLDSC.1kg$S),
  heritability=diag(cMvLDset$covstruct.mvLDSC.1kg$S),
  se=diag(cMvLDset$covstruct.mvLDSC.1kg$S.SE),
  heritability_se=paste0(format(diag(cMvLDset$covstruct.mvLDSC.1kg$S),digits=1)," (",format(diag(cMvLDset$covstruct.mvLDSC.1kg$S.SE),digits=1),")")
  )

p$plots.heritabilities


```




# Process, export, visualise corrected GWAS results

```{r process latent factor GWAS, purl=FALSE, eval=FALSE}

#install.packages("qqman")

settingLIMPFilter<-T
if(settingLIMPFilter){
    #p$lfGWAS$sumstats<-copy(readRDS(file=p$filepath.lfgwas.sumstats))
    cSumstatsAll<-readRDS(file=p$filepath.lfgwas.sumstats)
    setDT(cSumstatsAll)
    
    colBeta<-c()
    colSE<-c()
    colFRQ<-c()
    colINFO.LIMP<-c()
    colK<-c()
    for(iTrait in 1:nrow(p$sumstats.sel)){
      #iTrait<-1
      colBeta<-c(colBeta,colnames(cSumstatsAll)[grep(paste0("^BETA\\.",p$sumstats.sel[iTrait,c("code")],"$"), ignore.case = TRUE,colnames(cSumstatsAll))])
    colSE<-c(colSE,colnames(cSumstatsAll)[grep(paste0("^SE\\.",p$sumstats.sel[iTrait,c("code")],"$"), ignore.case = TRUE,colnames(cSumstatsAll))])
    colFRQ<-c(colFRQ,colnames(cSumstatsAll)[grep(paste0("^FRQ\\.",p$sumstats.sel[iTrait,c("code")],"$"), ignore.case = TRUE,colnames(cSumstatsAll))])
      colINFO.LIMP<-c(colINFO.LIMP,colnames(cSumstatsAll)[grep(paste0("^INFO.LIMP\\.",p$sumstats.sel[iTrait,c("code")],"$"), ignore.case = TRUE,colnames(cSumstatsAll))])
      colK<-c(colK,colnames(cSumstatsAll)[grep(paste0("^K\\.",p$sumstats.sel[iTrait,c("code")],"$"), ignore.case = TRUE,colnames(cSumstatsAll))])
    }
    
    colIsRaw<-c()
    for(iTrait in 1:length(colBeta)){
      #iTrait<-1
      cColBeta<-colBeta[iTrait]
      cColK<-colK[iTrait]
      cColIsRaw<-paste0("is.raw.",p$sumstats.sel[iTrait,c("code")])
      cSumstatsAll[,(cColIsRaw):=!is.na(get(cColBeta)) & is.na(get(cColK))]
      colIsRaw<-c(colIsRaw,cColIsRaw)
    }
    cSumstatsAll[,KRAW:=apply(.SD,MARGIN = 1,FUN = function(x){sum(x)}), .SDcols=colIsRaw]
    cSumstatsAll[,KIMP:=apply(.SD,MARGIN = 1,FUN = function(x){sum(!is.na(x))}), .SDcols=colBeta]
    cSumstatsAll[,sumK:=rowSums(.SD,na.rm = T), .SDcols=colK]
    cSumstatsAll[,sumINFO.LIMP:=rowSums(.SD,na.rm = T), .SDcols=colINFO.LIMP]
    cSumstatsAll[,sumBETA:=rowSums(.SD,na.rm = T), .SDcols=colBeta]
    cSumstatsAll[,sumSE:=rowSums(.SD,na.rm = T), .SDcols=colSE]
    cSumstatsAll[,meanBETA:=sumBETA/KIMP][,meanSE:=sumSE/KIMP]
    cSumstatsAll[,KREL:=(1-(KIMP-KRAW)/KIMP)][,sumINFO.LIMP.REL:=ifelse(sumK>0,sumINFO.LIMP/(KIMP-KRAW),NA_real_)][,sumK.REL:=ifelse(sumK>0,sumK/(KIMP-KRAW),NA_real_)]
    
    cSumstatsAll<-cSumstatsAll[,c("SNP","CHR","BP","MAF","KRAW","KIMP","sumK","sumINFO.LIMP","sumBETA","sumSE","meanBETA","meanSE","sumINFO.LIMP.REL","sumK.REL","KREL")]
    
}

#p$sumstats.sel.set1.code
#p$sumstats.sel.set1_spec.code

#Export trait codes for selected sets
write.table(x = p$sumstats.sel[p$sumstats.sel.set1.code,c("code")],file = file.path(p$folderpath.workingDirectory, "sumstats.sel.set1.code.txt"),sep="\t", quote = FALSE, row.names = F, col.names = F, append = F)
write.table(x = p$sumstats.sel[p$sumstats.sel.uv.code,c("code")],file = file.path(p$folderpath.workingDirectory, "sumstats.sel.uv.code.txt"),sep="\t", quote = FALSE, row.names = F, col.names = F, append = F)
write.table(x = p$sumstats.sel[p$sumstats.sel.set1_spec.code,c("code")],file = file.path(p$folderpath.workingDirectory, "sumstats.sel.set1_spec.code.txt"),sep="\t", quote = FALSE, row.names = F, col.names = F, append = F)


chosenSet<-p$sumstats.sel[p$sumstats.sel.set1_spec.code,] #SET SELECTED SUMSTATS HERE


for(iTrait in 1:nrow(chosenSet)){
  #test
  #iTrait<-10
  
  p$lfGWAS$gwas.for.display.info<-chosenSet[iTrait,]
  p$lfGWAS$gwas.for.display.info$code
  
  is.latent<-!is.na(p$lfGWAS$gwas.for.display.info$n_effective)
  # cColname.INFO.LIMP <- colnames(cSumstatsAll)[grep(paste0("^INFO.LIMP\\.",p$lfGWAS$gwas.for.display.info$code,"$"), ignore.case = TRUE,colnames(cSumstatsAll))]
  # cColname.K <- colnames(cSumstatsAll)[grep(paste0("^K\\.",p$lfGWAS$gwas.for.display.info$code,"$"), ignore.case = TRUE,colnames(cSumstatsAll))]
  
                                                                    
  if(!file.exists(p$lfGWAS$gwas.for.display.info$mungedpath) #| #is.na(p$lfGWAS$gwas.for.display.info$n_effective) #only latent factors
     ) next 
  #p$lfGWAS$gwas.for.display <- read.table(p$lfGWAS$gwas.for.display.info$mungedpath,header=T, quote="\"",fill=T,na.string=c(".",NA,"NA",""))
  cSumstats<-fread(file = p$lfGWAS$gwas.for.display.info$mungedpath, na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, key = c("SNP","CHR","BP"), data.table = T,showProgress = F, nThread=5)
  
  #setDT(cSumstats) - not needed because of fread arg
  if(any(colnames(cSumstats)=="MAF") & !any(colnames(cSumstats)=="FRQ")) cSumstats[,FRQ:=MAF]
  if(any(colnames(cSumstats)=="NEF") & !any(colnames(cSumstats)=="N")) cSumstats[,N:=round(NEF,digits = 0)] #special - also fix NEF format to integer
  if(!any(colnames(cSumstats)=="Z")) cSumstats <- cSumstats[,Z:=EFFECT/SE]
  if(!any(colnames(cSumstats)=="SE")) cSumstats[,c("SE")]<-1
  
  #imputation quality filter
  if(settingLIMPFilter){
    setkeyv(cSumstats,cols = "SNP")
    setkeyv(cSumstatsAll,cols = "SNP")
    cSumstats[cSumstatsAll,c("KRAW","KIMP","sumK","sumINFO.LIMP","sumBETA","sumSE","meanBETA","meanSE","sumINFO.LIMP.REL","sumK.REL","KREL") :=list(i.KRAW,i.KIMP,i.sumK,i.sumINFO.LIMP,i.sumBETA,i.sumSE,i.meanBETA,i.meanSE,i.sumINFO.LIMP.REL,i.sumK.REL,i.KREL)]
  }
  
  # update sumstat metadata with genomic inflation factors
  medianChisq<-median(cSumstats$Z^2)
  meanChisq<-mean(x = cSumstats$Z^2)
  p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambdaGC_median")]<-medianChisq/qchisq(0.5,1)
  p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambdaGC_mean")]<-meanChisq/qchisq(0.5,1)
  #lambda 1000 is the inflation factor scaled relative to 1000 cases and 1000 controls
  if(!is.na(p$lfGWAS$gwas.for.display.info$n_case) || !is.na(p$lfGWAS$gwas.for.display.info)){
    p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambda1000")]<-1+(p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambdaGC_median")]-1)*(1/as.numeric( p$lfGWAS$gwas.for.display.info$n_case) + 1/as.numeric(p$lfGWAS$gwas.for.display.info$n_control))/(2/1000)
  } else if (!is.na(p$lfGWAS$gwas.for.display.info$n_total)){
     p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambda1000")]<-1+(p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambdaGC_median")]-1)*(1/as.numeric(p$lfGWAS$gwas.for.display.info$n_total))/(1/1000)
  } else if (!is.na(p$lfGWAS$gwas.for.display.info$n_effective)){
     p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambda1000")]<-1+(p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambdaGC_median")]-1)*(1/as.numeric(p$lfGWAS$gwas.for.display.info$n_effective))/(1/1000)
  }
  cat("\n",p$lfGWAS$gwas.for.display.info$code,", lambda(using median,mean)=", p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambdaGC_median")],p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambdaGC_mean")])
  
  cat("\n",p$lfGWAS$gwas.for.display.info$code,", lambda1000=", p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambda1000")])
  
  cat("\n",p$lfGWAS$gwas.for.display.info$code,", LDSC intercept (uv)=", p$lfGWAS$gwas.for.display.info$lambda_ldsc)
  
  #FILTERS
  cSumstats.n<-nrow(cSumstats)
  cat("\nRows before filtering:",nrow(cSumstats),"\n")
  #FRQ
  if(any(colnames(cSumstats)=="FRQ")) cSumstats <- cSumstats[FRQ>=0.001 & 1-FRQ>=0.001,]
  cat("\nRows filtered by FRQ:",cSumstats.n-nrow(cSumstats),"\n")
  cSumstats.n<-nrow(cSumstats)
  
  if(any(colnames(cSumstats)=="INFO")) cSumstats <- cSumstats[INFO>=0.6,]
  cat("\nRows filtered by INFO:",cSumstats.n-nrow(cSumstats),"\n")
  cSumstats.n<-nrow(cSumstats)
  
  if(is.latent){
    #use well informed latent factor variants, includes imputed information 
    cSumstats <- cSumstats[KREL>0.75 | is.na(sumINFO.LIMP.REL) | (KREL>0.5 & sumINFO.LIMP.REL>0.5),]
  } else {
    #do not use imputed SNPs for trait GWAS
    cSumstats <- cSumstats[is.na(INFO.LIMP),]
  }
  cat("\nRows filtered by LD-imputation quality:",cSumstats.n-nrow(cSumstats),"\n")
  cat("\nRows after filtering:",nrow(cSumstats),"\n")
 
  #export ALL
  fwrite(x = na.omit(cSumstats[,c("SNP","CHR","A1","A2","BP","P","N")]), file = file.path(p$folderpath.data.sumstats.export,paste0(p$lfGWAS$gwas.for.display.info$code,".gz")), append = F, quote = F, sep = "\t", nThread=5)

  #export SNPLOC
  fwrite(x = na.omit(cSumstats[,c("SNP","CHR","BP")]), file = file.path(p$folderpath.data.sumstats.export,paste0(p$lfGWAS$gwas.for.display.info$code,".SNPLOC")), append = F, quote = F, sep = "\t", nThread=5)

  #export PVAL_FILE
  fwrite(x = na.omit(cSumstats[,c("SNP","P","N")]), file = file.path(p$folderpath.data.sumstats.export,paste0(p$lfGWAS$gwas.for.display.info$code,".PVAL")), append = F, quote = F, sep = "\t", nThread=5)
  
  #head(p$lfGWAS$gwas.for.display)
  
  
  # restore chr info if missing
  # ref <- read.table(p$filepath.SNPReference.1kg,header=T, quote="\"",fill=T,na.string=c(".",NA,"NA",""))
  # 
  # ref <- setDT(ref)
  # # Column harmonisation
  # ref.keys<-c('SNP')
  # ref$SNP <- tolower(as.character(ref$SNP))
  # ref$A1 <- toupper(as.character(ref$A1))
  # ref$A2 <- toupper(as.character(ref$A2))
  # ref$CHR <- toupper(as.character(ref$CHR))
  # ref.keys<-c(ref.keys,'CHR')
  # ref$BP <- as.integer(ref$BP)
  # ref.keys<-c(ref.keys,'BP')
  # 
  # names(ref)<-paste0(names(ref),"_REF")
  # setkeyv(ref, cols = paste0(ref.keys,"_REF"))
  # 
  # p$lfGWAS$gwas.for.display2<-ref[p$lfGWAS$gwas.for.display, on=c(SNP_REF='SNP'), nomatch=0]
  # p$lfGWAS$gwas.for.display2[,SNP:=SNP_REF][,BP:=BP_REF][,CHR:=CHR_REF][,MAF:=MAF_REF][,A1:=A1_REF][,A2:=A2_REF]
  # p$lfGWAS$gwas.for.display<-p$lfGWAS$gwas.for.display2[,c("SNP","BP","CHR","MAF","A1","A2","BETA","SE","P")]
  # 
  # saveRDS(object = p$lfGWAS$gwas.for.display,file =p$lfGWAS$gwas.for.display.filename)
  #View(p$lfGWAS$gwas.for.display)
  
  
  #top SNPs
  #View(p$lfGWAS$gwas.for.display[order(p$lfGWAS$gwas.for.display$P),c("SNP","CHR","MAF","P")])
  
  cTable <- cSumstats[P<5e-8,][order(-Z,decreasing = T),] %>% 
    slice_head(n = 50) %>%
    mutate(i=row_number()) %>%
    select(i,SNP,CHR,FRQ,sumINFO.LIMP.REL,sumK.REL,KREL,Z,P) %>%
  gt() %>% 
  fmt_scientific(columns = vars(P), decimals = 4) %>%
  fmt_number(columns = vars(FRQ,Z,sumINFO.LIMP.REL,sumK.REL,KREL), decimals = 4) %>%
  #fmt_number(columns = vars(K,K.IMP,sumK), decimals = 0) %>%
  tab_header(
    title = paste0("Top-50 highly associated COMMON variants for\n",p$lfGWAS$gwas.for.display.info$name.nice.and_code)
  ) %>%
  tab_style(
    style = cell_text(size = px(12)),
    locations = cells_column_labels(everything())       
  ) %>%
  tab_style(
    style = cell_text(size = px(12),weight = "bold"),
    locations = cells_body(everything())        
  )

  cTable

  #dir.create(path = file.path(p$folderpath.plots,p$lfGWAS$gwas.for.display.info$code))
  gtsave(data = cTable, filename = file.path(p$folderpath.plots,paste0("top.",p$lfGWAS$gwas.for.display.info$code,".rtf")))
  
  #manhattan plots
  #cPlot <- manhattan.custom(df = p$lfGWAS$gwas.for.display)
  #cPlot
  #ggsave(filename=file.path(p$folderpath.plots,cModel$code,paste0("gwas.F",iGwas,".png")), plot = last_plot(), width = 500, height = 300, units = "mm")
  
  #qqman adaptations
  qqmanGwas<-cSumstats
  qqmanGwas$P<- shru::clipValues(qqmanGwas$P,min = 10^(-24), max = NULL)
  qqmanGwas<-qqmanGwas[which(!is.na(qqmanGwas$P)),]
  qqmanGwas<-qqmanGwas[,c("SNP","BP","CHR","P")]
  qqmanGwas$CHR<-as.integer(qqmanGwas$CHR)
  
  #manhattan plot, fastman
  png(filename = file.path(p$folderpath.plots,paste0("man.",p$lfGWAS$gwas.for.display.info$code,".png")), width = 1200, height = 600)
  fastman(
    m = as.data.frame(qqmanGwas),
    speedup = T, 
    #col = 
    maxP = 24,
    annotatePval = 1e-8,
    annotationWinMb = 4,
    annotationCol = theme.color$contrastDark2,
    cex.text = 0.7
    #annotateTop = T,
    #annotateN = 3
      )
  dev.off()
  
  png(filename = file.path(p$folderpath.plots,paste0("qq.",p$lfGWAS$gwas.for.display.info$code,".png")), width = 600, height = 600)
  fastqq(
    p = qqmanGwas$P,
    speedup = T,
    lambda = T,
    fix_zero = F
         )
  dev.off()
  
  #manhattan plot, qqman
  # png(filename = file.path(p$folderpath.plots,paste0("man.",p$lfGWAS$gwas.for.display.info$code,".png")), width = 1200, height = 600)
  # qqman::manhattan(x = qqmanGwas)
  # dev.off()
  
  #qqman::qq(p$lfGWAS$gwas.for.display$Pval_Estimate)
  
  #qq plot, qqman
  # png(filename = file.path(p$folderpath.plots,paste0("qq.",p$lfGWAS$gwas.for.display.info$code,".png")), width = 600, height = 600)
  # qqman::qq(qqmanGwas$P)
  # dev.off()
  
}

```

# Visualise exported latent factor GWAS results in manhattan and qq plots
```{r visualise composite manhattan and qq plots, purl=FALSE, eval=FALSE}

chosenSet<-p$sumstats.sel[p$sumstats.sel.set1_spec.code,] #SET SELECTED SUMSTATS HERE

manhattanPlots<-c()
qqPlots<-c()

for(iTrait in 1:nrow(chosenSet)){
  #test
  #iTrait<-1
  
  p$lfGWAS$gwas.for.display.info<-chosenSet[iTrait,]
  p$lfGWAS$gwas.for.display.info$code
  
  cSumstats <- fread(file = file.path(p$folderpath.data.sumstats.export,paste0(p$lfGWAS$gwas.for.display.info$code,".gz")), na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, key = c("SNP","CHR","BP"), data.table = T,showProgress = F, nThread=5)
  
  
  
  # manhattanPlots[iTrait] <- fastman(
  #   m = as.data.frame(cSumstats),
  #   speedup = T, 
  #   #col = 
  #   maxP = 16,
  #   annotatePval = 1e-7,
  #   annotationWinMb = 4,
  #   annotationCol = theme.color$contrastDark2,
  #   cex.text = 0.7
  #   #annotateTop = T,
  #   #annotateN = 3
  #     )
  
  manhattanPlots[[iTrait]] <- plot.manhattan.custom(cSumstats,y_limits = c(0,24),maxNLogP = 24)
  
  #test save
  #ggsave(filename=file.path(p$folderpath.plots, paste0("man_test.png")), plot = manhattanPlots[[iTrait]], width = 800, height = 400, units = "mm")

  qqPlots[[iTrait]] <- plot.qq.custom(cSumstats$P)
  #test save
  #ggsave(filename=file.path(p$folderpath.plots, paste0("qq_test.png")), plot = qqPlots[[iTrait]], width = 400, height = 400, units = "mm")
  
  
}

full <- cowplot::plot_grid(plotlist = c(manhattanPlots,qqPlots),labels = "AUTO",ncol = 2, nrow = 6,byrow=F)

ggsave(filename=file.path(p$folderpath.plots, paste0("manqq.factors.png")), plot = full, width = 210, height = 297, units = "mm", dpi = 320, scale = 3)
#A4 is 210 x 297 mm


```

# Genome-wide genetic association results

## Read genome-wide genetic associations per dataset

```{r read genetic associations}
cat("\n***READ GENETIC ASSOCIATIONS***")

p$filepath.results.gwa<-file.path(p$folderpath.workingDirectory,paste0("results.gwa.",p$setup.code,".Rds"))

if (file.exists(p$filepath.results.gwa)) {
  print("Using existing GWA results from previous run.")
  p$results.gwa<-readRDS(file=p$filepath.results.gwa)
} else {

  chosenSet<-p$sumstats.sel[p$sumstats.sel.set1.code,] #configure selected trait set here!
  
  p$results.gwa<-c()
  p$results.gwa$topHits<-c()
  
  for(iTrait in 1:nrow(chosenSet)){
    #iTrait<-1
    cSumstats<-fread(file = chosenSet[iTrait,]$mungedpath, na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, key = c("SNP","CHR","BP"), data.table = T,showProgress = F, nThread=5)
    cSumstats<-cSumstats[P<5e-8,]
    p$results.gwa$topHits[[chosenSet[iTrait,]$code]]<-cSumstats$SNP
    
  }
  
  saveRDS(object = p$results.gwa,file = p$filepath.results.gwa)
}


p$results.gwa$unique<-c()

p$results.gwa$unique.uv<-unique(unlist(p$results.gwa$topHits[p$sumstats.sel.uv.code]))

#GSEM.F1 - Factor Neuroticism
# p$results.gwa$unique[["GSEM.F1"]]<-list(unlist(p$results.gwa$topHits["GSEM.F1"])[
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["ANXI03"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["ANXI04"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["DEPR05"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["DEPR08"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["NEUR02"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["HEAL01"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["TIRE01"]))])

p$results.gwa$unique[["GSEM.F1"]]<-list(unlist(p$results.gwa$topHits["GSEM.F1"])[!(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% p$results.gwa$unique.uv)])
length(p$results.gwa$unique[["GSEM.F1"]][[1]])

#GSEM.F2 - Factor Psychoticism
p$results.gwa$unique[["GSEM.F2"]]<-list(unlist(p$results.gwa$topHits["GSEM.F2"])[!(unlist(p$results.gwa$topHits["GSEM.F2"]) %in% p$results.gwa$unique.uv)])
length(p$results.gwa$unique[["GSEM.F2"]][[1]])

#GSEM.F3 - Factor Depression
p$results.gwa$unique[["GSEM.F3"]]<-list(unlist(p$results.gwa$topHits["GSEM.F3"])[!(unlist(p$results.gwa$topHits["GSEM.F3"]) %in% p$results.gwa$unique.uv)])
length(p$results.gwa$unique[["GSEM.F3"]][[1]])

#GSEM.F4 - Factor Risktaking
p$results.gwa$unique[["GSEM.F4"]]<-list(unlist(p$results.gwa$topHits["GSEM.F4"])[!(unlist(p$results.gwa$topHits["GSEM.F4"]) %in% p$results.gwa$unique.uv)])
length(p$results.gwa$unique[["GSEM.F4"]][[1]])

#GSEM.F5 - Factor Deprivation
p$results.gwa$unique[["GSEM.F5"]]<-list(unlist(p$results.gwa$topHits["GSEM.F5"])[!(unlist(p$results.gwa$topHits["GSEM.F5"]) %in% p$results.gwa$unique.uv)])
length(p$results.gwa$unique[["GSEM.F5"]][[1]])

#GSEM.F6 - Factor Neuropsyche
p$results.gwa$unique[["GSEM.F6"]]<-list(unlist(p$results.gwa$topHits["GSEM.F6"])[!(unlist(p$results.gwa$topHits["GSEM.F6"]) %in% p$results.gwa$unique.uv)])
length(p$results.gwa$unique[["GSEM.F6"]][[1]])


```


## Read gene associations per dataset, output top gene lists
Added gene and gene level analysis results read

```{r read gene associations}
cat("\n***READ GENE, GENE LEVEL ASSOCIATIONS***")
p$filepath.results.ga<-file.path(p$folderpath.workingDirectory,paste0("results.ga.",p$setup.code,".Rds")) #gene analysis
p$filepath.results.gs<-file.path(p$folderpath.workingDirectory,paste0("results.gs.",p$setup.code,".Rds")) #gene level analysis

if (file.exists(p$filepath.results.ga)) {
  print("Using existing GA results from previous run.")
  p$results.ga<-readRDS(file=p$filepath.results.ga)
} else {

  chosenSet<-p$sumstats.sel[p$sumstats.sel.set1.code,] #configure selected trait set here!
  
  p$results.ga<-c()
  p$results.ga$geneAssociation<-c()
  
  p$geneMap<-fread(file = p$filepath.geneMapping, na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, data.table = T,showProgress = F, nThread=5)
  
  #TODO - Get map for transcript codes to gene codes!
  #p$transcriptionTargetMap.mirdb<-fread(file = p$filepath.transcriptionTargetMap.mirdb, na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, data.table = T,showProgress = F, nThread=5)
  
  for(iTrait in 1:nrow(chosenSet)){
    #iTrait<-1
    cat("\nProcessing ",chosenSet[iTrait,]$code)
    cGeneAssoc<-fread(file = file.path(p$folderpath.workingDirectory,paste0(p$setup.code,".geneanalysis.",chosenSet[iTrait,]$code,".genes.out")), na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, key = c("GENE","CHR","START","STOP"), data.table = T,showProgress = F, nThread=5)
    cGeneAssoc[p$geneMap, on=c(GENE='V1'), c("CODE"):=list(i.V6)]
    #cSigLevel<-(0.05/nrow(cGeneAssoc))
    cGeneAssoc$P.FDR<-p.adjust(p = cGeneAssoc$P,method = "fdr")
    #cat("Adj. sig. lev. ",chosenSet[iTrait,]$code,": ",cSigLevel)
    p$results.ga$geneAssociation[[chosenSet[iTrait,]$code]]<-list(cGeneAssoc)
    #topGenes <- cGeneAssoc[P<cSigLevel & P<0.01,]
    topGenes <- cGeneAssoc[P.FDR<0.05,]
    cat(", n sig. genes ",chosenSet[iTrait,]$code,":",nrow(topGenes))
    write.table(x = topGenes[,c("CODE")],file = file.path(p$folderpath.workingDirectory, paste0(chosenSet[iTrait,]$code,".top.genes.txt")),sep="\t", quote = FALSE, row.names = F, col.names = F, append = F)
    
  }
  
  saveRDS(object = p$results.ga,file = p$filepath.results.ga)
}


if (file.exists(p$filepath.results.gs)) {
  print("Using existing GS results from previous run.")
  p$results.gs<-readRDS(file=p$filepath.results.gs)
} else {

  chosenSet<-p$sumstats.sel[p$sumstats.sel.set1.code,] #configure selected trait set here!
  
  p$results.gs<-c()
  
  for(cCode in chosenSet$code){
    #cCode<-"ADHD05"
    p$results.gs[[cCode]]<-c()
    
    #gene sets, standard, and or gene property sets
    toprocess<-c("gtex8_rnaseq_median","brainspan_rnaseq_mean","msigdb.h.all.v7.5.1","msigdb.c2.cp.biocarta.v7.5.1","msigdb.c2.cp.kegg.v7.5.1", "msigdb.c3.mir.mirdb.v7.5.1","msigdb.c3.tft.gtrd.v7.5.1", "msigdb.c5.all.v7.5.1","msigdb.c7.all.v7.5.1","msigdb.c8.all.v7.5.1") #sets to process
    for(igeneset in 1:length(toprocess)){
      #igeneset<-1
      cat("\nProcessing ",cCode, " and ",toprocess[igeneset])
      cGeneSet.filepath <- file.path(p$folderpath.workingDirectory,paste0(p$setup.code, ".geneset.",toprocess[igeneset],".",cCode,".gsa.out"))
      cGeneSet<-read.table(cGeneSet.filepath, header=T, quote="\"",fill=T,na.string=c(".",NA,"NA",""), comment.char = "#")
      #cGeneSet$P.FDR<-p.adjust(p = cGeneSet$P,method = "fdr") #moved until later to calculate per subset rather than the full set (i.e. for msigdb c5)
      p$results.gs[[cCode]][[toprocess[igeneset]]]<-cGeneSet
    }
  }
 
  
  
  saveRDS(object = p$results.gs,file = p$filepath.results.gs)
}



p$results.ga$unique<-c()

p$results.ga$unique.uv<-unique(unlist(lapply(p$results.ga$geneAssociation[p$sumstats.sel.uv.code], function(x){x[[1]] [P.FDR<0.05,c("CODE")]})))

#GSEM.F1 - Factor Neuroticism
# p$results.gwa$unique[["GSEM.F1"]]<-list(unlist(p$results.gwa$topHits["GSEM.F1"])[
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["ANXI03"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["ANXI04"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["DEPR05"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["DEPR08"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["NEUR02"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["HEAL01"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["TIRE01"]))])

cGeneAssoc<-unlist(p$results.ga$geneAssociation["GSEM.F1"][[1]][[1]][P.FDR<0.05,c("CODE")],use.names = F)
p$results.ga$unique[["GSEM.F1"]]<-list(cGeneAssoc[!(cGeneAssoc %in% p$results.ga$unique.uv)])
length(p$results.ga$unique[["GSEM.F1"]][[1]])

#GSEM.F2 - Factor Psychoticism
cGeneAssoc<-unlist(p$results.ga$geneAssociation["GSEM.F2"][[1]][[1]][P.FDR<0.05,c("CODE")],use.names = F)
p$results.ga$unique[["GSEM.F2"]]<-list(cGeneAssoc[!(cGeneAssoc %in% p$results.ga$unique.uv)])
length(p$results.ga$unique[["GSEM.F2"]][[1]])

#GSEM.F3 - Factor Depression
cGeneAssoc<-unlist(p$results.ga$geneAssociation["GSEM.F3"][[1]][[1]][P.FDR<0.05,c("CODE")],use.names = F)
p$results.ga$unique[["GSEM.F3"]]<-list(cGeneAssoc[!(cGeneAssoc %in% p$results.ga$unique.uv)])
length(p$results.ga$unique[["GSEM.F3"]][[1]])

#GSEM.F4 - Factor Risktaking
cGeneAssoc<-unlist(p$results.ga$geneAssociation["GSEM.F4"][[1]][[1]][P.FDR<0.05,c("CODE")],use.names = F)
p$results.ga$unique[["GSEM.F4"]]<-list(cGeneAssoc[!(cGeneAssoc %in% p$results.ga$unique.uv)])
length(p$results.ga$unique[["GSEM.F4"]][[1]])

#GSEM.F5 - Factor Deprivation
cGeneAssoc<-unlist(p$results.ga$geneAssociation["GSEM.F5"][[1]][[1]][P.FDR<0.05,c("CODE")],use.names = F)
p$results.ga$unique[["GSEM.F5"]]<-list(cGeneAssoc[!(cGeneAssoc %in% p$results.ga$unique.uv)])
length(p$results.ga$unique[["GSEM.F5"]][[1]])

#GSEM.F6 - Factor Neuropsyche
cGeneAssoc<-unlist(p$results.ga$geneAssociation["GSEM.F6"][[1]][[1]][P.FDR<0.05,c("CODE")],use.names = F)
p$results.ga$unique[["GSEM.F6"]]<-list(cGeneAssoc[!(cGeneAssoc %in% p$results.ga$unique.uv)])
length(p$results.ga$unique[["GSEM.F6"]][[1]])

```

## Process gene-set analysis results
```{r Process gene-set analysis results}
cat("\n***Process gene-set analysis results***")

chosenSet<-p$sumstats.sel[p$sumstats.sel.set1.code,] #configure selected trait set here!
toprocess<-c("gtex8_rnaseq_median","brainspan_rnaseq_mean","msigdb.h.all.v7.5.1","msigdb.c2.cp.biocarta.v7.5.1","msigdb.c2.cp.kegg.v7.5.1","msigdb.c3.mir.mirdb.v7.5.1","msigdb.c3.tft.gtrd.v7.5.1","msigdb.c5.gobp.v7.5.1","msigdb.c5.gocc.v7.5.1","msigdb.c5.gomf.v7.5.1","msigdb.c5.hpo.v7.5.1","msigdb.c5.other.v7.5.1","msigdb.c7.all.v7.5.1","msigdb.c8.all.v7.5.1") #sets to process
#toprocess<-c("gtex8_rnaseq_median","brainspan_rnaseq_mean","msigdb.h.all.v7.5.1","msigdb.c3.all.v7.5.1","msigdb.c5.all.v7.5.1","msigdb.c7.all.v7.5.1","msigdb.c8.all.v7.5.1") #sets to process

p$mGeneLevelBeta <-c()
p$mGeneLevelSE <-c()
p$mGeneLevelBetaSTD <-c()
p$mGeneLevelP <-c()
p$mGeneLevelP.FDR <-c()
p$geneSetVariables <-c()

for(igeneset in 1:length(toprocess)){
  #igeneset<-3
  cCodes <- c()
  cNames <- c()
  
  cGeneSetDataCode <- toprocess[igeneset]
  if(toprocess[igeneset] %in% c("msigdb.c5.gobp.v7.5.1","msigdb.c5.gocc.v7.5.1","msigdb.c5.gomf.v7.5.1","msigdb.c5.hpo.v7.5.1","msigdb.c5.other.v7.5.1")) cGeneSetDataCode <- "msigdb.c5.all.v7.5.1" #these share the same dataset
  #if(toprocess[igeneset] %in% c("msigdb.c3.mir.v7.5.1","msigdb.c3.tft.v7.5.1")) cGeneSetDataCode <- "msigdb.c3.all.v7.5.1" #these share the same dataset
  
  
  #assess the full set of set variables across GWAS datasets
  for(cCode in chosenSet$code){
    cCodes <- c(cCodes, p$results.gs[[cCode]][[cGeneSetDataCode]]$VARIABLE)
    cNames <- c(cNames, p$results.gs[[cCode]][[cGeneSetDataCode]]$FULL_NAME)
  }
  
  cGeneSetVariables <- data.frame(code=cCodes, name=cNames)
  cGeneSetVariables <- unique(cGeneSetVariables)
  #rownames(cGeneSetVariables)<-cGeneSetVariables$code #fails at duplicates
  
  #special treatment of some sets, subsets etc
  if(toprocess[igeneset]=="brainspan_rnaseq_mean"){
    cGeneSetVariables <- cGeneSetVariables[cGeneSetVariables$code %in% c("amygdaloid_complex","anterior_(rostral)_cingulate...1","caudal_ganglionic_eminence","	
cerebellar_cortex","cerebellum","dorsal_thalamus","dorsolateral_prefrontal_cort...1","hippocampus_(hippocampal_for...1","inferolateral_temporal_corte...1","lateral_ganglionic_eminence","medial_ganglionic_eminence","occipital_neocortex","orbital_frontal_cortex","parietal_neocortex","posterior_(caudal)_superior_...1","posteroventral_(inferior)_pa...1","primary_auditory_cortex_(cor...1","primary_motor_cortex_(area_M...1","	
primary_motor-sensory_cortex...1","primary_somatosensory_cortex...1","primary_visual_cortex_(stria...1","striatum","temporal_neocortex","upper_(rostral)_rhombic_lip","ventrolateral_prefrontal_cor...1"),]
  } else if(toprocess[igeneset] == "msigdb.c5.gobp.v7.5.1"){
    cGeneSetVariables <- cGeneSetVariables[cGeneSetVariables$code %in% grep("^gobp\\_", ignore.case = T, cGeneSetVariables$code, value = T),]
  } else if(toprocess[igeneset] == "msigdb.c5.gocc.v7.5.1"){
    cGeneSetVariables <- cGeneSetVariables[cGeneSetVariables$code %in% grep("^gocc\\_", ignore.case = T, cGeneSetVariables$code, value = T),]
  } else if(toprocess[igeneset] == "msigdb.c5.gomf.v7.5.1"){
    cGeneSetVariables <- cGeneSetVariables[cGeneSetVariables$code %in% grep("^gomf\\_", ignore.case = T, cGeneSetVariables$code, value = T),]
  } else if(toprocess[igeneset] == "msigdb.c5.hpo.v7.5.1"){
    cGeneSetVariables <- cGeneSetVariables[cGeneSetVariables$code %in% grep("^hp\\_", ignore.case = T, cGeneSetVariables$code, value = T),]
  } else if(toprocess[igeneset] == "msigdb.c5.other.v7.5.1"){
    cGeneSetVariables <- cGeneSetVariables[cGeneSetVariables$code %in% grep("^[^gobp\\_|gocc\\_|gomf\\_|hpo\\_]", ignore.case = T, cGeneSetVariables$code, value = T),]
  }
    
  
  p$mGeneLevelBeta[toprocess[igeneset]] <- list(matrix(NA,ncol = nrow(chosenSet), nrow = nrow(cGeneSetVariables)))
  colnames(p$mGeneLevelBeta[toprocess[igeneset]][[1]]) <- chosenSet$code
  rownames(p$mGeneLevelBeta[toprocess[igeneset]][[1]]) <- cGeneSetVariables$name
  p$mGeneLevelBetaSTD[toprocess[igeneset]] <- p$mGeneLevelBeta[toprocess[igeneset]]
  p$mGeneLevelSE[toprocess[igeneset]] <- p$mGeneLevelBeta[toprocess[igeneset]]
  p$mGeneLevelP[toprocess[igeneset]] <- p$mGeneLevelBeta[toprocess[igeneset]]
  p$mGeneLevelP.FDR[toprocess[igeneset]] <- p$mGeneLevelBeta[toprocess[igeneset]]
  p$geneSetVariables[toprocess[igeneset]] <-list(cGeneSetVariables)
  
  for(cCode in chosenSet$code){
    #cCode<-"ALCD03"
    cGeneSetResult <- p$results.gs[[cCode]][[cGeneSetDataCode]]
    rownames(cGeneSetResult)<-cGeneSetResult$FULL_NAME #changed to full name
    
    p$mGeneLevelP[toprocess[igeneset]][[1]][,cCode] <- cGeneSetResult[cGeneSetVariables$name,]$P
    p$mGeneLevelP.FDR[toprocess[igeneset]][[1]][,cCode] <- p.adjust(p =  cGeneSetResult[cGeneSetVariables$name,]$P, method = "fdr") #FDR adjustment
    p$mGeneLevelBeta[toprocess[igeneset]][[1]][,cCode] <- cGeneSetResult[cGeneSetVariables$name,]$BETA
    p$mGeneLevelBetaSTD[toprocess[igeneset]][[1]][,cCode] <- cGeneSetResult[cGeneSetVariables$name,]$BETA_STD
    p$mGeneLevelSE[toprocess[igeneset]][[1]][,cCode] <- cGeneSetResult[cGeneSetVariables$name,]$SE
    # #effects are scaled to trait dataset power (heritability x sample size)
    # p$mGeneLevelBeta[toprocess[igeneset]][[1]][,cCode] <- cGeneSetResult[cGeneSetVariables$code,]$BETA/p$sumstats.sel[cCode,]$power_scale_factor
    # p$mGeneLevelBetaSTD[toprocess[igeneset]][[1]][,cCode] <- cGeneSetResult[cGeneSetVariables$code,]$BETA_STD/p$sumstats.sel[cCode,]$power_scale_factor
   
  }
} 


```

# Plots, tables, and diagrams

## Improved annotation of all traits, including latent factor traits

```{r improved annotation, fig.width=10, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}
#View(p$sumstats.sel)

p$sumstats.sel.table<-p$sumstats.sel[p$sumstats.sel.set1.code,c("name.nice","code","reference.nice","year","n_consensus","h2.liability_mvLDSC","h2.se.liability_mvLDSC","lambda_ldsc")] #full trait list
#p$sumstats.sel.table<-p$sumstats.sel[p$sumstats.sel.l.code,c("name.nice","code","n_effective","h2.liability_mvLDSC","h2.se.liability_mvLDSC","lambda_ldsc")]

p$sumstats.sel.table$h2.liability_mvLDSC.table<-paste0(round( p$sumstats.sel.table$h2.liability_mvLDSC,digits = 3)," (",round(p$sumstats.sel.table$h2.se.liability_mvLDSC,digits = 3),")")

p$sumstats.sel.table<-p$sumstats.sel.table[,c("name.nice","code","year","reference.nice","n_consensus","h2.liability_mvLDSC.table","lambda_ldsc")] #"lambda1000"
#View(p$sumstats.sel.table)
#p$sumstats.sel.table

p$plots.factors.sel.table<-p$sumstats.sel.table %>% 
  gt() %>% 
  fmt_number(columns = c("n_consensus"), decimals = 0) %>%
  fmt_number(columns = c("lambda_ldsc"), decimals = 2) %>%
  tab_header(
    title = "Selected GWAS summary statistics datasets, including latent factors"
  ) %>% cols_label(
    name.nice  = "Trait",
    code = "Code",
    reference.nice = "Study",
    year = "Year",
    n_consensus = "N",
    h2.liability_mvLDSC.table = html("h<sup>2</sup><sub>mvLDSC</sub> (S.E.)"),
    lambda_ldsc = "LDSC intercept"
    #lambda1000 = "lambda1000"
  ) %>%
  tab_style(
    style = cell_text(size = px(12)),
    locations = cells_column_labels(everything())       
  ) %>%
  tab_style(
    style = cell_text(size = px(12),weight = "bold"),
    locations = cells_body(everything())        
  )

p$plots.factors.sel.table

gtsave(data = p$plots.factors.sel.table, filename = paste0(p$folderpath.plots,"/factors.sel.table.rtf"))


```

## Gene association analyses, multivariate
```{r Plots gene association analyses - multivariate, fig.width=10, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}
library(UpSetR)
#https://upset.app/
#Don't forget to cite!
chosenSet<-p$sumstats.sel[p$sumstats.sel.set1.code,] #configure selected trait set here!

codesAllSets <- list()

for(iTrait in 1:nrow(chosenSet)){
  #iTrait<-3
  cCode <- chosenSet$code[iTrait]
  cAssociation <- p$results.ga$geneAssociation[cCode][[1]][[1]]
  cAssociation <- cAssociation[cAssociation$P.FDR<0.05,]
  codesAllSets[[cCode]] <- c(cAssociation$CODE)
}

#set nice names
names(codesAllSets) <- p$sumstats.sel[names(codesAllSets), ]$name.nice

#png(filename = file.path(p$folderpath.plots,paste0("ga.png")), width = 800, height = 600, units = "px")
pdf(file = file.path(p$folderpath.plots,paste0("ga.pdf")))
upset(
  fromList(codesAllSets),
  nsets = 12,
  nintersects = 50,
  order.by = "freq",
  matrix.color = theme.color$contrastDark1,
  main.bar.color = theme.color$contrastLight3,
  sets.bar.color = theme.color$contrastLight3,
  text.scale = c(1, 0.7, 1, 1, 1, 0.6) #c(intersection size title, intersection size tick labels, set size title, set size tick labels, set names, numbers above bars)
  )
#upset(fromList(codesAllSets),order.by = "freq", nintersects=20)
#upset(fromList(codesAllSets), group.by = "sets", order.by = "freq")
dev.off()

#Get gene publications - also needs a gene - id map
#publishedGenes.df<-read_tsv("ftp://ftp.ncbi.nlm.nih.gov/gene/DATA/gene2pubmed.gz",col_names=T)

```

## Gene level analyses, multivariate

```{r Plots gene level analyses - multivariate, fig.width=10, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}
#install.packages("heatmaply")
library(heatmaply)

toprocess<-c("gtex8_rnaseq_median","brainspan_rnaseq_mean","msigdb.h.all.v7.5.1") #sets to process


for(igeneset in 1:length(toprocess)){
  #igeneset<-2
  cGeneSetVariables <-  p$geneSetVariables[[toprocess[igeneset]]]
  if(nrow(cGeneSetVariables)>100) next #safety not to run large sets
  cGeneLevelBeta <- p$mGeneLevelBeta[toprocess[igeneset]][[1]]
  cGeneLevelBetaSTD <- p$mGeneLevelBetaSTD[toprocess[igeneset]][[1]]
  cGeneLevelSE <- p$mGeneLevelSE[toprocess[igeneset]][[1]]
  cGeneLevelP <- p$mGeneLevelP[toprocess[igeneset]][[1]]
  cGeneLevelP.FDR <- p$mGeneLevelP.FDR[toprocess[igeneset]][[1]]
  
  rownames(cGeneLevelBeta) <- cGeneSetVariables$name
  rownames(cGeneLevelBetaSTD) <- cGeneSetVariables$name
  
  cGeneLevelNlog10P<-(-log10(cGeneLevelP.FDR))
  cGeneLevelNlog10P[is.na(cGeneLevelNlog10P)]<-0 #replace na with 0
  
  heatmaply(
    cGeneLevelNlog10P,
    #cGeneLevelBetaSTD,
            xlab = "Traits",
            ylab = "Feature",
            main = paste("-log10(p), p-value of t(set/property regression coefficient), ",toprocess[igeneset]),
             #main = paste("Gene level effect sizes (raw beta), ",toprocess[igeneset]),
            #main = paste("Gene level effect sizes (semi-standardised), ",toprocess[igeneset]),
            scale_fill_gradient_fun = ggplot2::scale_fill_gradient2(
                low = theme.color$contrastDark3, 
                mid = "black",
                high = theme.color$contrastLight3
              ),
            file=file.path(p$folderpath.plots,paste0("genelevel.heatcluster.", toprocess[igeneset],".png")),
            width = 1200, height = 1600,
            hclust_method = "ward.D2"
            #scale = "row"
            )
  
}



```

## Gene level analyses, single datasets

```{r Plots - gene level analyses - single datasets, fig.width=10, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}
#p$sumstats.sel.set1.code
chosenSet<-p$sumstats.sel[c("EDUC03","SCHI04","NEUR02","RISK03","GSEM.F1","RISK02","GSEM.F5","BIPO02","GSEM.F3","GSEM.F2","INSO02","ANOR02"),] #configure selected trait set here!
toprocess<-c("gtex8_rnaseq_median","brainspan_rnaseq_mean","msigdb.h.all.v7.5.1","msigdb.c2.cp.biocarta.v7.5.1","msigdb.c2.cp.kegg.v7.5.1","msigdb.c3.mir.mirdb.v7.5.1","msigdb.c3.tft.gtrd.v7.5.1","msigdb.c5.gobp.v7.5.1","msigdb.c5.gocc.v7.5.1","msigdb.c5.gomf.v7.5.1","msigdb.c5.hpo.v7.5.1","msigdb.c5.other.v7.5.1","msigdb.c7.all.v7.5.1","msigdb.c8.all.v7.5.1") #sets to process

for(igeneset in 1:length(toprocess)){
  #igeneset<-13
  cGeneSetVariables <-  p$geneSetVariables[[toprocess[igeneset]]]
  cGeneLevelBeta <- p$mGeneLevelBeta[toprocess[igeneset]][[1]]
  cGeneLevelBetaSTD <- p$mGeneLevelBetaSTD[toprocess[igeneset]][[1]]
  cGeneLevelSE <- p$mGeneLevelSE[toprocess[igeneset]][[1]]
  cGeneLevelP <- p$mGeneLevelP[toprocess[igeneset]][[1]]
  cGeneLevelP.FDR <- p$mGeneLevelP.FDR[toprocess[igeneset]][[1]]
  
  cGeneLevelNlog10P<-(-log10(cGeneLevelP.FDR))
  
  cGeneLevelZ<-cGeneLevelBeta/cGeneLevelSE
  
  for(iTrait in 1:nrow(chosenSet)){
    #iTrait<-1
    cTraitVal.df <- data.frame(val=cGeneLevelBetaSTD[,chosenSet$code[iTrait]],feature=cGeneSetVariables$name, p=cGeneLevelP.FDR[,chosenSet$code[iTrait]])
    #cTraitVal.df <- data.frame(val=cGeneLevelBetaSTD[,chosenSet$code[iTrait]],feature=cGeneSetVariables$name, p=cGeneLevelP[,chosenSet$code[iTrait]])
    #cTraitVal.df <- cTraitVal.df[cTraitVal.df$p<0.1,]
    cTraitVal.df <- head(cTraitVal.df[order(cTraitVal.df$val,decreasing = T),],60)
    cTraitVal.df$sig<-ifelse(cTraitVal.df$p<0.05 & cTraitVal.df$val>0,"s","n")
    if(nrow(cTraitVal.df)>1){
      cplot<-ggplot(cTraitVal.df, aes(x = reorder(feature,val), y = val, fill=sig)) + 
      scale_fill_manual(name = "stat. significance",
                     values = c("s" = theme.color$contrastLight3,
                                "n" = theme.color$contrastDark1),
                     labels = c("*", "")) +
      # scale_fill_gradient2(name = "p-value",
      #                      mid = theme.color$contrastLight3,
      #                      low = theme.color$contrastDark3,
      #                      midpoint=0,
      #                      limits=c(0,1)) +
      geom_bar(position="dodge", stat="identity") +
      theme_bw(base_size=22) +
      theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5)) + 
      coord_flip()
     # theme_bw(base_size=22) #use a black-and white theme with set font size
      #dir.create(path = file.path(p$folderpath.plots,chosenSet$code[iTrait]))
      ggsave(filename=file.path(p$folderpath.plots, paste0("genelevel.",toprocess[igeneset],".",chosenSet$code[iTrait],".png")), plot = cplot, width = 700, height = 500, units = "mm")
    }
  }
}



```


## Gene level analyses, selected differences

```{r Plots - gene level analyses - selected differences, fig.width=10, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}
library(cowplot)

chosenSet <- p$sumstats.sel[c("GSEM.F1"),] #configure selected trait set here!
#comparisonSet <- p$sumstats.sel["EDUC03","NEUR02","INSO02","RISK02","RISK03","SUBJ01","TIRE01","ANXI03","DEPR05",GSEM.F1","GSEM.F2","GSEM.F3","GSEM.F5"] #comparison traits, apart from general mean
#comparisonSet <- p$sumstats.sel[p$sumstats.sel.set1.code,] #comparison traits, apart from general mean
comparisonSet <- p$sumstats.sel[c("NEUR02","GSEM.F1"),] #comparison traits, place main trait towards end if to include in combination plot
#comparisonSet <- p$sumstats.sel[c("EDUC03","NEUR02","GSEM.F1"),] #comparison traits, place main trait towards end if to include in combination plot
#comparisonSet <- p$sumstats.sel[c("SCHI04","BIPO02","GSEM.F1","GSEM.F3"),] #comparison traits, place main trait towards end if to include in combination plot
#Old well powered
# toprocess <- c(
#   #"gtex8_rnaseq_median",
#   "brainspan_rnaseq_mean",
#   "msigdb.h.all.v7.5.1",
#   #"msigdb.c2.cp.biocarta.v7.5.1",
#   #"msigdb.c2.cp.kegg.v7.5.1",
#   #"msigdb.c3.mir.mirdb.v7.5.1",
#   #"msigdb.c3.tft.gtrd.v7.5.1",
#   "msigdb.c5.gobp.v7.5.1",
#   "msigdb.c5.gocc.v7.5.1",
#   "msigdb.c5.gomf.v7.5.1",
#   #"msigdb.c5.hpo.v7.5.1",
#   #"msigdb.c5.other.v7.5.1",
#   "msigdb.c7.all.v7.5.1",
#   "msigdb.c8.all.v7.5.1"
#   ) #sets to process

toprocess <- c(
  "msigdb.c5.gobp.v7.5.1",
  "msigdb.c5.gomf.v7.5.1"
  ) #sets to process

df.traits<-list()


for(igeneset in 1:length(toprocess)){
  #igeneset<-3
  cGeneSetVariables <-  p$geneSetVariables[[toprocess[igeneset]]]
  cGeneLevelBeta <- p$mGeneLevelBeta[toprocess[igeneset]][[1]]
  cGeneLevelBetaSTD <- p$mGeneLevelBetaSTD[toprocess[igeneset]][[1]]
  cGeneLevelSE <- p$mGeneLevelSE[toprocess[igeneset]][[1]]
  cGeneLevelP <- p$mGeneLevelP[toprocess[igeneset]][[1]]
  cGeneLevelP.FDR <- p$mGeneLevelP.FDR[toprocess[igeneset]][[1]]
  
  cGeneLevelNlog10P<-(-log10(cGeneLevelP.FDR))
  
  cGeneLevelZ<-cGeneLevelBeta/cGeneLevelSE
  
  cGeneLevelBetaSTD.scaled<-scale(cGeneLevelBetaSTD)
  #cGeneLevelBetaSTD.scaled<-ifelse(cGeneLevelP<0.05,cGeneLevelBetaSTD.scaled,NA_real_)
  cGeneLevelBetaSTD.scaled.rmean<-rowMeans(cGeneLevelBetaSTD.scaled,na.rm = T)
  cGeneLevelBetaSTD.rmean<-rowMeans(cGeneLevelBetaSTD,na.rm = T)
  
  for(iTrait in 1:nrow(chosenSet)){
    #iTrait<-1
    
    dir.create(path = file.path(p$folderpath.plots,chosenSet$code[iTrait]))
    
    #run comparison traits per main trait
    for(iComparison in 1:nrow(comparisonSet)){
      #iComparison<-1
      
      #comparison plot, main trait vs comparison trait
      cTraitVal.df <- data.frame(val=cGeneLevelBetaSTD[,chosenSet$code[iTrait]]-cGeneLevelBetaSTD[,comparisonSet$code[iComparison]],feature=cGeneSetVariables$name, p=cGeneLevelP.FDR[,chosenSet$code[iTrait]])
      #cTraitVal.df <- cTraitVal.df[cTraitVal.df$p<0.1,]
      cTraitVal.df<-cTraitVal.df[which(cTraitVal.df$p<0.05),] #only select differences from main significant associations.
      cTraitVal.df <- head(cTraitVal.df[order(cTraitVal.df$val,decreasing = T),],30)
      cTraitVal.df$sig<-ifelse(cTraitVal.df$p<0.05,"s","n")
      if(nrow(cTraitVal.df)>1 & chosenSet$code[iTrait]!=comparisonSet$code[iComparison]){ #inactivated with F!!!
        cplot<-ggplot(cTraitVal.df, aes(x = reorder(feature,val), y = val, fill=sig)) + 
        scale_fill_manual(name = "stat. significance",
                       values = c("s" = theme.color$contrastLight3,
                                  "n" = theme.color$contrastDark1),
                       labels = c("*", "")) +
        # scale_fill_gradient2(name = "p-value",
        #                      mid = theme.color$contrastLight3,
        #                      low = theme.color$contrastDark3,
        #                      midpoint=0,
        #                      limits=c(0,1)) +
        geom_bar(position="dodge", stat="identity") +
        theme_bw(base_size=22) +
        theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5)) +
        coord_flip()
       # theme_bw(base_size=22) #use a black-and white theme with set font size
        ggsave(filename=file.path(p$folderpath.plots,chosenSet$code[iTrait], paste0("genelevel.diff.",toprocess[igeneset],".",chosenSet$code[iTrait],"-",comparisonSet$code[iComparison],".png")), plot = cplot, width = 700, height = 500, units = "mm")
      }
      
      
      #multi-plot, main trait
      cTraitVal.df1 <- data.frame(
        trait=chosenSet$code[iTrait],
        var=cGeneSetVariables$name,
        val0=cGeneLevelBetaSTD[,chosenSet$code[iTrait]],
        se0=cGeneLevelSE[,chosenSet$code[iTrait]],
        #high=cGeneLevelBeta[,chosenSet$code[iTrait]]+qnorm(0.05,lower.tail = F)*cGeneLevelSE[,chosenSet$code[iTrait]],
        #low=cGeneLevelBeta[,chosenSet$code[iTrait]]-qnorm(0.05,lower.tail = F)*cGeneLevelSE[,chosenSet$code[iTrait]],
        p=abs(cGeneLevelP.FDR[,chosenSet$code[iTrait]])
        )
      cTraitVal.df1$zCorrected <- qnorm(cTraitVal.df1$p/2,lower.tail = F)
      cTraitVal.df1$val <- cTraitVal.df1$val0
      cTraitVal.df1$se <- abs(cTraitVal.df1$val/cTraitVal.df1$zCorrected)
      
      #pair-plot, comparison trait
      cTraitVal.df2 <- data.frame(
        trait=comparisonSet$code[iComparison],
        var=cGeneSetVariables$name,
        val0=cGeneLevelBetaSTD[,comparisonSet$code[iComparison]],
        se0=cGeneLevelSE[,comparisonSet$code[iComparison]],
        #high=cGeneLevelBeta[,comparisonSet$code[iComparison]]+qnorm(0.05,lower.tail = F)*cGeneLevelSE[,comparisonSet$code[iComparison]],
        #low=cGeneLevelBeta[,comparisonSet$code[iComparison]]-qnorm(0.05,lower.tail = F)*cGeneLevelSE[,comparisonSet$code[iComparison]],
        p=abs(cGeneLevelP.FDR[,comparisonSet$code[iComparison]])
        )
      cTraitVal.df2$zCorrected <- qnorm(cTraitVal.df2$p/2,lower.tail = F)
      cTraitVal.df2$val <- cTraitVal.df2$val0
      cTraitVal.df2$se <- abs(cTraitVal.df2$val/cTraitVal.df2$zCorrected)
      
      cTraitVal.df1$p2<-cTraitVal.df2$p
      cTraitVal.df2$p2<-cTraitVal.df1$p
      cTraitVal.df1 <- cTraitVal.df1[(cTraitVal.df1$p<0.05) & !is.nan(cTraitVal.df1$se) & cTraitVal.df1$val>0,] #|cTraitVal.df1$p2<0.05 #only select results significant in main trait
      if(chosenSet$code[iTrait]==comparisonSet$code[iComparison]){
        #comparison trait is the main trait
        cTraitVal.df2 <- cTraitVal.df2[cTraitVal.df2$var %in% df.traits[iTrait][[1]]$var,] #& cTraitVal.df2$val>0
        # cTraitVal.df2$z <- cTraitVal.df2$val/cTraitVal.df2$se
        # dfOrder <- head(na.omit(cTraitVal.df2[order(-cTraitVal.df2$val,na.last = T),]),30)
      } else {
        #comparison trait as standard
        cTraitVal.df2 <- cTraitVal.df2[cTraitVal.df2$var %in% cTraitVal.df1$var & cTraitVal.df2$val>0 & cTraitVal.df1$val>0,]
       
      }
      
      cTraitVal.df1$z <- cTraitVal.df1$val/cTraitVal.df1$se
      dfOrder <- head(na.omit(cTraitVal.df1[order(-cTraitVal.df1$val,na.last = T),]),30)
      
      #df <- rbind(cTraitVal.df1,cTraitVal.df2)
      df <- cTraitVal.df2
      varOrder<-rev(unique(dfOrder$var))
      
      #df <- df[df$p<0.05,]
      df <- na.omit(df)
      df <- df[df$var %in% varOrder,]
      
      
      df$trait <- factor(df$trait)
      df$var <- factor(df$var,levels = varOrder)
      df$val <- as.numeric(df$val)
      df$high <- df$val + qnorm(0.05,lower.tail = F)*df$se
      df$low <- df$val - qnorm(0.05,lower.tail = F)*df$se
      
      if(nrow(df)>1) {
        df$set <- toprocess[igeneset]
        df.traits[iTrait] <- list(rbindlist(l = list(df.traits[iTrait][[1]],df),use.names = T,fill = T,idcol = F))
      }
      # if(nrow(df)>1){
      #    cplot  <- ggplot(df, aes(x=var, y=val, ymin=low, ymax=high,col=trait,fill=trait)) +
      #       #geom_errorbar(aes(xmin = low, xmax = high)) +
      #       geom_linerange(size=2,position=position_dodge(width = 0.5)) +
      #       geom_hline(yintercept=0, lty=2) +
      #       geom_point(size=3, shape=21, colour="white", stroke = 0.5,position=position_dodge(width = 0.5)) +
      #       scale_fill_manual(values=c(theme.color$contrastDark1,theme.color$contrastDark1)) +
      #       scale_color_manual(values=c(theme.color$contrastLight3,theme.color$contrastDark3)) +
      #       scale_x_discrete(name="Set") +
      #       scale_y_continuous(name="Regression beta", limits = c(min(df$low)-0.1*max(abs(df$val)), max(df$high)+0.1*max(abs(df$val)))) +
      #       coord_flip() +
      #       theme_bw() +
      #       ggtitle(label = paste0("Gene-level MAGMA regression betas and standard errors: ",toprocess[igeneset]))
      #    
      #    glplotsgrid[iTrait] <- append(glplotsgrid[iTrait],list(cplot))
      #     
      #     #ggsave(filename=file.path(p$folderpath.plots,chosenSet$code[iTrait], paste0("genelevel.pair.",toprocess[igeneset],".",chosenSet$code[iTrait],"-",comparisonSet$code[iComparison],".png")), plot = cplot, width = 700, height = 500, units = "mm")
      # }
  
    }
  }
}

#plot all subplots in grid for selected trait
#https://stackoverflow.com/questions/58657802/forest-plot-with-subgroups-in-ggplot2
for(iTrait in 1:nrow(chosenSet)){
  #iTrait<-1
  df <- df.traits[iTrait][[1]]
  df <- df[which(df$set!="gtex8_rnaseq_median" & df$set!="brainspan_rnaseq_mean"),]
  df$set <- as.factor(df$set)
  
  #df.l <- pivot_longer(data = df,cols = set)
  
  
  if(nrow(df)>0){
       cplot  <- ggplot(df, aes(x=var, y=val, ymin=low, ymax=high,col=trait,fill=trait)) +
          geom_hline(yintercept=0, lty=2) + 
          #geom_boxplot() +
          geom_linerange(size=0.3, position=position_dodge(width = 0.8)) +
          
          geom_point(size=0.8, shape=21, colour="white", stroke = 0.2,position=position_dodge(width = 0.8)) +
          
          scale_fill_manual(values=c(theme.color$contrastDark3,theme.color$contrastLight3)) +
          scale_color_manual(values=c(theme.color$contrastDark3,theme.color$contrastLight3)) +
          scale_x_discrete(name="Set") +
          scale_y_continuous(name="Regression beta") +
          #scale_y_continuous(name="Regression beta", limits = c(min(df$low)-0.1*max(abs(df$val)), max(df$high)+0.1*max(abs(df$val)))) +
          coord_flip() +
          facet_wrap(~ set, ncol = 1, shrink = T, drop = T, scales = "free") +
          theme_bw(base_size = 8) +
          theme(axis.text.y =element_text(size=7)) +
          ggtitle(label = paste0("Gene-level MAGMA std. regression betas and standard errors"))

        ggsave(filename=file.path(p$folderpath.plots,chosenSet$code[iTrait], paste0("genelevel.multi.",chosenSet$code[iTrait],".png")), plot = cplot, width = 210, height = 297, units = "mm")
        #A4 is 210 x 297 mm
  }
  
}


```




#Scratch area
```{r gSEM TEST scratch area - working model, include=FALSE, eval=FALSE, purl=FALSE}
p$CFA$test<-c()

max(p$mvLD$covstruct.mvLDSC$S.smooth-p$mvLD$covstruct.mvLDSC$S.orig)

#p$mvLD$covstruct.mvLDSC$S<-p$mvLD$covstruct.mvLDSC$S.smooth
#p$mvLD$covstruct.mvLDSC$S<-p$mvLD$covstruct.mvLDSC$S.orig

cModel <- p$CFA$models.selected["M18_4_14.C.DWLS",]


#p$lfGWAS$sumstats.test<-p$lfGWAS$sumstats[which(p$lfGWAS$sumstats$CHR=='22'),]
  
p$test$gwasResults<-usermodel.mod(
  covstruc = p$mvLD$covstruct.mvLDSC,
  model = cModel$lModel,
  #model = p$efaSEM$lmodel,
  estimation = p$CFA$estimator[1],
  fix_resid = F,
  CFIcalc = T,
  imp_cov = T
  )

p$test$gwasResults$modelfit
p$test$gwasResults$results

p$test$gwasResults.matrix<-semplate$parseGenomicSEMResultAsMatrices(resultDf = p$test$gwasResults$results)

p$test$gwasResults.matrix$relativeVarianceExplainedPerFactor


```


```{r gSEM TEST scratch area, include=FALSE, eval=FALSE, purl=FALSE}
p$CFA$test<-c()

max(p$mvLD$covstruct.mvLDSC$S.smooth-p$mvLD$covstruct.mvLDSC$S.orig)

#p$mvLD$covstruct.mvLDSC$S<-p$mvLD$covstruct.mvLDSC$S.smooth
#p$mvLD$covstruct.mvLDSC$S<-p$mvLD$covstruct.mvLDSC$S.orig


p$CFA$test$lmodel<-"
F1 =~ 0.539641264951842*ADHD05+0.301549201476588*ANXI03+0.254983357523383*DEPR05+0.516478144100956*DEPR08+(-0.913884414704993)*HEAL01+0.550680494996066*INCO03+0.496387381827906*INSO02+0.294766753034134*MIGR01+(-0.211404258261124)*RISK02+(-0.361814282182997)*SUBJ01+0.773443804538135*TIRE01
F2 =~ 0.358713644817655*ALCD03+0.608742286980208*ANXI03+0.659101734283354*DEPR05+0.48894150805209*DEPR08+0.345469173361549*INSO02+0.933173107768295*NEUR01+(-0.283942826541694)*RISK02+(-0.692978677882566)*SUBJ01+0.334430724866043*TIRE01
F3 =~ 0.217320562834197*ADHD05+0.362548259169021*ALCD03+0.392626636082975*ANXI03+0.209526495296818*AUTI07+0.719358812724766*BIPO02+0.601432867622906*DEPR05+0.322194158145306*DEPR08+0.471966530358034*SCHI04+(-0.2086147893327*SUBJ01)+0.22790907391054*TIRE01
F4 =~ 0.834026681568278*ALCD03+0.338368216706376*DEPR05+0.298883066770123*DEPR08+0.517986168598069*INCO03+0.52623652437116*RISK03
F5 =~ 0.496871917208472*ANXI03+0.500470483364792*AUTI07+0.544236896104398*DEPR08+0.282647157511683*NEUR01+0.20837509707694*SCHI04+0.278253900439062*TIRE01
ADHD05~~ADHD05
ALCD03~~ALCD03
ANXI03~~ANXI03
AUTI07~~AUTI07
BIPO02~~BIPO02
DEPR05~~DEPR05
DEPR08~~DEPR08
HEAL01~~HEAL01
INCO03~~INCO03
INSO02~~INSO02
MIGR01~~MIGR01
NEUR01~~NEUR01
RISK02~~RISK02
RISK03~~RISK03
SCHI04~~SCHI04
SUBJ01~~SUBJ01
TIRE01~~TIRE01
F1~~1*F1
F2~~1*F2
F3~~1*F3
F4~~1*F4
F5~~1*F5
F1~~1*F2
F1~~1*F3
F1~~1*F4
F1~~1*F5
F2~~1*F3
F2~~1*F4
F2~~1*F5
F3~~1*F4
F3~~1*F5
F4~~1*F5
"

#p$lfGWAS$sumstats.test<-p$lfGWAS$sumstats[which(p$lfGWAS$sumstats$CHR=='22'),]
  
p$test$gwasResults<-usermodel.mod(
  covstruc = p$mvLD$covstruct.mvLDSC,
  model = p$CFA$test$lmodel,
  #model = p$efaSEM$lmodel,
  estimation = p$CFA$estimator,
  fix_resid = FALSE,
  CFIcalc = T,
  imp_cov = T
  )

p$test$gwasResults$modelfit
p$test$gwasResults$results

```
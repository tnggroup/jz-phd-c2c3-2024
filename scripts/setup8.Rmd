---
title: "JZ_GED_PHD_C1 Analysis Setup 8"
author: "Johan Zvrskovec"
date: "03/05/2022"
output:
  html_document:
    fig_height: 6
    fig_width: 9
  pdf_document: default
  word_document:
    fig_height: 6
    fig_width: 9
---

```{r clean, include=FALSE, purl=FALSE}
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
#gc() #free up memory and report the memory usage.
```

# Title
**The joint phenotypic and molecular genetic architecture of Major Depressive Disorder (MDD) and anxiety disorders**

This analysis script is meant to contain most of the analysis steps performed in the project. It is run either as Rmd chunks in order, or as an R-script produced by the knitr::purl command further down. Run from the command line it takes command line arguments as seen in the command line setup below. It can be instructed (through command line arguments) to run in two run modes configured for running either locally on my laptop or on the HPC cluster. Some parts of the script can be run separately as a specific task (controlled by the command line arguments). So far is the Multivariate LD block recommended to be run on a HPC cluster and this block is also subdivided into different tasks intended to be run separately. The results of these separate tasks are to be loaded by a general run of the script to be included in the later analysis. When this has been done once, the final LD results will be saved to a file for subsequent runs of the script to rely on without having to run the LD step again. Remove (or rename) the LD results for the procedure to start anew.

# Packages

```{r package setup, echo=FALSE, warning=F}
#install.packages("disk.frame")  
#install.packages("skimr")
#install.packages("psych")
#install.packages("Matrix")
#install.packages("tidyverse")
#install.packages("ggrepel")
#install.packages("gt")
#install.packages("kableExtra")
#remove.packages("corrplot")
#devtools::install_github("taiyun/corrplot", build_vignettes = TRUE) #this is the most updated
#devtools::install_github("mkanai/corrplot")
#install.packages("corrplot")
#devtools::install_github("caijun/ggcorrplot2")
#remove.packages("GenomicSEM")
#devtools::install_github("MichelNivard/GenomicSEM",ref = 'v2.1') #specify branch for better stability
#devtools::install_github("MichelNivard/GenomicSEM") #master branch as default
#remove.packages("GenomicSEM")
#devtools::install_github("johanzvrskovec/GenomicSEM",ref = 'mod-jz') #specify branch
#remove.packages("HDL")
#devtools::install_github("zhenin/HDL/HDL")
#devtools::install_github("zhenin/HDL/HDL@77cb9d0984d1302e40bfd871491e292f8f09f49d") #specify exact commit
#remove.packages("BiocManager")
#install.packages("BiocManager")
#remove.packages("MungeSumstats")
#devtools::install_github("neurogenomics/MungeSumstats")
#remove.packages("SNPlocs.Hsapiens.dbSNP144.GRCh38")
#BiocManager::install("SNPlocs.Hsapiens.dbSNP144.GRCh38")
#remove.packages("BSgenome.Hsapiens.NCBI.GRCh38")
#BiocManager::install("BSgenome.Hsapiens.NCBI.GRCh38")
#install.packages("optparse")
#remove.packages("shru")
#devtools::install_github("johanzvrskovec/shru")
#remotes::install_github("johanzvrskovec/shru") #install without devtools and without compiling c++ parts
#install.packages("reticulate")
#install.packages("readr")  
#install.packages("GGally")
#install.packages("FDRestimation")

#for testing supermunge
library(R.utils)
library(corrplot) #do not run on cluster, does not work?
#library(ggcorrplot2) #this does not print coefficients on the boxes
#library(disk.frame)
#library(GGally)
library(data.table)
library(optparse)
library(skimr)
library(ggrepel)
library(gt)
library(psych)
library(Matrix)
library(stats)
#library(tidyverse)
#library(HDL)
#library(MungeSumstats)
library(shru)
library(GenomicSEM)
require(msm) #for the deltamethod function used for GWIS
#require(FDRestimation)

#library(reticulate)

```

```{r command line setup}
clParser <- OptionParser()
clParser <- add_option(clParser, c("-t", "--task"), type="character", default="0",
                help="Index of the explicit task to run separately:\n0: No task\nmvLD.mvLDSC:multivariate LDSC\nmvLD.HDL.piecewise:HDL Piecewise\nmvLD.HDL.jackknife:HDL Jackknife\nmvLD.origHDL:original HDL(jackknife)\nmvLD.origHDL.liabilityScale:original HDL with applied liability scale [default %default]")
clParser <- add_option(clParser, c("-l", "--location"), type="character", default="local",
                help="The place where the code is run [local,cluster] [default %default]")

clParser <- add_option(clParser, c("-a", "--task_argument"), type="character", default=NA,
                help="General purpose argument for tasks [default %default]")

```

# Script settings
```{r settings}
p<-c() #create project metadata object
p$clOptions<-parse_args(clParser)
p$date.run<-Sys.Date()
p$setup.version<-8
p$setup.code<-paste0("setup",p$setup.version)
p$setup.code.date<-paste0(p$setup.code,"_",p$date.run)
p$filename.rmd<-paste0(p$setup.code,".Rmd")
p$filename.r<-paste0(p$setup.code,".R")
p$functions<-c()
p$nThread=6
setDTthreads(p$nThreads) #configure DT threads accordingly


p$host<-p$clOptions$location #this is the place where the code is run [local,cluster] read from command line - default local
p$seting.refreshPrepareSummaryStatistics<-FALSE
p$setting.refreshLatentFactorGWAS<-FALSE

#color theme settings
theme.color<-c()
theme.color$contrastDark1<-"#2D2D2D"
theme.color$contrastDark2<-"#CC99CC"
theme.color$contrastDark3<-"#6699CC"
theme.color$contrastDark4<-"#99CC99"
theme.color$contrastLight1<-"#66CCCC"
theme.color$contrastLight2<-"#FFCC66"
theme.color$contrastLight3<-"#F99157"
theme.color$contrastLight4<-"#F2777A"

#file path settings
##set project shared working directory **change if you have other settings**
if(p$host=="local") {
p$folderpath<-normalizePath("/Users/jakz/project/JZ_GED_PHD_C1")
} else if (p$host=="cluster") {
p$folderpath<-normalizePath("/scratch/users/k19049801/project/JZ_GED_PHD_C1")
}
##project working directory subfolders
p$folderpath.workingDirectory<-normalizePath(file.path(p$folderpath,"working_directory"))

p$folderpath.scripts<-normalizePath(file.path(p$folderpath,"scripts"))
#p$folderpath.includedSoftware<-normalizePath(file.path(p$folderpath,"included_software"))
p$folderpath.plots<-normalizePath(file.path(p$folderpath,"plots"))

#general data folder
p$folderpath.data<-normalizePath(file.path(p$folderpath,"data"))

##cleaned sumstats folder
p$folderpath.data.sumstats.cleaned<-normalizePath(file.path(p$folderpath.data,"gwas_sumstats","cleaned"))

##munged sumstats folder
p$folderpath.data.sumstats.munged<-normalizePath(file.path(p$folderpath.data,"gwas_sumstats","munged_1kg_eur_supermunge"))

##munged sumstats folder
p$folderpath.data.sumstats.munged.4ssimp<-normalizePath(file.path(p$folderpath.data,"gwas_sumstats","munged_1kg_eur_supermunge.4ssimp"))

##imputed sumstats folder
#p$folderpath.data.sumstats.imputed<-normalizePath(file.path(p$folderpath.data,"gwas_sumstats","imputed_1kg_eur_supermunge"))
p$folderpath.data.sumstats.imputed<-normalizePath(file.path(p$folderpath.data,"gwas_sumstats","imputed_1kg_eur_supermunge.500Kbwin"))

p$folderpath.data.sumstats.imputed.05cm<-normalizePath(file.path(p$folderpath.data,"gwas_sumstats","imputed_1kg_eur_supermunge.0.5cMwin"))

# p$folderpath.data.sumstats.imputed.10<-normalizePath(file.path(p$folderpath.data,"gwas_sumstats","imputed_1kg_eur_supermunge.10Kwin"))
# 
# p$folderpath.data.sumstats.imputed.500<-normalizePath(file.path(p$folderpath.data,"gwas_sumstats","imputed_1kg_eur_supermunge.500Kwin.validated"))

##imputed sumstats folder, SSIMP
p$folderpath.data.sumstats.imputed.ssimp<-normalizePath(file.path(p$folderpath.data,"gwas_sumstats","imputed_1kg_eur_ssimp"))



p$filename.suffix.data.sumstats.munged<-".gz"
#p$filename.suffix.data.sumstats.munged<-"_noMHC.sumstats.gz"


##imputed sumstats folder
#p$folderpath.data.sumstats.imputed<-normalizePath(file.path(p$folderpath.data,"gwas_sumstat","imputed"))

##export sumstats folders
p$folderpath.data.sumstats.export<-normalizePath(file.path(p$folderpath.data,"export","gwas"))
p$folderpath.data.sumstats.export.cleaned.nohighld<-normalizePath(file.path(p$folderpath.data,"export","gwas.cleaned.nohighld"))
p$folderpath.data.sumstats.export.500.cleaned.nohighld<-normalizePath(file.path(p$folderpath.data,"export","gwas.500.cleaned.nohighld"))
p$folderpath.data.sumstats.export.ssimp.cleaned.nohighld<-normalizePath(file.path(p$folderpath.data,"export","gwas.ssimp.cleaned.nohighld"))


#python virtual environment folder
if(p$host=="local") {
  p$folderpath.pythonVenv<-normalizePath("~/Documents/local_db/JZ_GED_PHD_C1/python-venv")
} else if (p$host=="cluster") {
  p$folderpath.pythonVenv<-normalizePath(file.path(p$folderpath,"python-venv"))
}

#variant lists folder
p$folderpath.data.variantLists<-normalizePath(file.path(p$folderpath.data,"variant_lists"))


##Reference SNP-list (HapMap3 SNPs for example). Used for munging sumstat SNP data.
p$filepath.SNPReference.hm3<-normalizePath(file.path(p$folderpath.data.variantLists,"w_hm3.snplist.flaskapp2018")) #HapMap3 SNPs
## Used in the preparation step for performing latent factor GWAS as reference for calculating SNP variance across traits.
#p$filepath.SNPReference<-normalizePath(paste0(p$folderpath.data,"/","reference.1000G.maf.0.005.txt")) #1000 genomes phase 3
#hard coded, only works on CREATE
p$filepath.SNPReference.1kg<-normalizePath(file.path("/scratch/prj/gwas_sumstats/1kg_bed","1KG_Phase3.WG.CLEANED.EUR_MAF001.CM23.bim"))

p$filepath.SNPReference.hc1kg<-normalizePath(file.path(p$folderpath.data.variantLists,"hc1kgp3.b38.eur.l2.jz2023.gz")) #Based on the high coverage 1kgp3 panel in b38

#p$filepath.SNPReference.hc1kg<-normalizePath(file.path(p$folderpath.data.variantLists,"combined.hm3_1kg.snplist.vanilla.jz2020.txt")) #custom hm3 + 1kg SNPs, based on individual level data in /users/k1204688/brc_scratch/Public/1KG_Phase3


p$filepath.rsSynonyms.dbSNP151<-normalizePath(file.path(p$folderpath.data.variantLists,"dbsnp151.synonyms.gz"))

#reference panels
p$folderpath.data.referencePanels<-normalizePath(file.path(p$folderpath.data,"reference_panel"))

##Reference panel folder containing individual level data reference panel. Used for GWAS sumstat imputation tasks.
p$folderpath.data.sumstatImp.genomeReference<-file.path(p$folderpath.data.referencePanels,"hc1kgp3.b38.plink")

#p$folderpath.data.sumstatImp.genomeReference<-"/users/k19049801/project/JZ_GED_PHD_ADMIN_GENERAL/data/reference.panel.1KG_Phase3.CLEANED.EUR.cM" #source /users/k1204688/brc_scratch/Public/1KG_Phase3

##LD scores datasets folders (these strings need to have a trailing slash for the GSEM LDSC to work)
p$folderpath.data.mvLDSC.ld.hc1kg <- file.path(p$folderpath.data,"ld_scores","hc1kgp3.b38.eur.l2.jz2023")
p$folderpath.data.mvLDSC.ld.hm3 <- file.path(p$folderpath.data,"ld_scores","eur_w_ld_chr")
p$folderpath.data.mvLDSC.ld.1kg <- file.path(p$folderpath.data,"ld_scores","1KG_Phase3.WG.CLEANED.EUR_MAF001.1cm.250blocks")
#Weights, if different from LD-scores
#Set weights to the same folder as ldscores
p$folderpath.data.mvLDSC.wld.hc1kg <- p$folderpath.data.mvLDSC.ld.hc1kg
p$folderpath.data.mvLDSC.wld.1kg <- p$folderpath.data.mvLDSC.ld.1kg
p$folderpath.data.mvLDSC.wld.hm3 <- p$folderpath.data.mvLDSC.ld.hm3

##HDL LD scores reference - needs the trailing slashes!!!
if(p$host=="local") {
  #use the smallest LD reference as default for local tests
  p$folderpath.data.HDL.ld<-paste0(p$folderpath.data,"/UKB_array_SVD_eigen90_extraction/")
} else if (p$host=="cluster") {
  p$folderpath.data.HDL.ld<-paste0(p$folderpath.data,"/UKB_imputed_hm3_SVD_eigen99_extraction/")
}

##Gene mapping
p$filepath.geneMapping<-file.path(p$folderpath.data,"gene_mapping","NCBI37.3.gene.locUPDATETHISTOBUILD38")

##Transcription target maps
p$filepath.transcriptionTargetMap.mirdb <- file.path(p$folderpath.data,"gene_set","miRDB_v6.0_prediction_result.txt.gz")

##Gene sets folder
p$folderpath.geneSet<-file.path(p$folderpath.data,"gene_set")
  
##full script file paths
p$filepath.rmd<-normalizePath(file.path(p$folderpath.scripts,p$filename.rmd))
p$filepath.r<-normalizePath(file.path(p$folderpath.scripts,p$filename.r))

##CFA settings
p$CFA<-c()
p$CFA$correlation<-c("COR","ORT") #ORT, OBL, and COR
p$CFA$estimator=c("ML")
p$CFA$nFactors=c(6)


##latent factor GWAS filter settings
p$lfGWAS$info.filter=.6
p$lfGWAS$maf.filter=0.01

#working directory in case of running as an R-script
setwd(dir = normalizePath(p$folderpath.workingDirectory))

#inactivated python environment until it is used
#use_virtualenv(p$folderpath.pythonVenv)

print("Setup done!")

```

# Functions
```{r plot functions}

#c(theme.color$contrastDark3,theme.color$contrastLight3)
p$printCorr <- function(corr, pmat=NULL, SE=NULL, filename, addrect = NULL, is.corr = T, number.cex = 1.0, number.digits=2, newnames=NULL, title=NULL, sig.level=c(0.05)){
  # corr = p$mvLD$S.SE.deltaimpnoimp.500
  # pmat = p$mvLD$covstruct.mvLDSC.1kg.500$cov.p
  # filename = file.path(p$folderpath.plots,"covse.deltaimpnoimp.500.png")
  # is.corr = F
  # number.digits = 4
  # newnames = p$sumstats.sel$code.nice
  
  
  #palette<-colorRampPalette(c(theme.color$contrastDark3,"#FFFFFF",theme.color$contrastLight3))
    
  if(!is.null(newnames)){
    rownames(corr)<-newnames
    colnames(corr)<-newnames
    if(!is.null(pmat)){
      rownames(pmat)<-newnames
      colnames(pmat)<-newnames
    }
  }

  corr<-corr[order(colnames(corr)),order(colnames(corr))]
  if(!is.null(pmat)) pmat<-pmat[order(colnames(pmat)),order(colnames(pmat))]
  
  # if(is.null(SE)){
  #   corr.uppCI <- NULL
  #   corr.lowCI <- NULL
  # } else {
  #   corr.uppCI<-clipValues(corr + 1.96 * SE, -1,1)
  #   corr.lowCI<-clipValues(corr - 1.96 * SE, -1,1)
  # }
  
  par.addCoef.col <- NULL
  if(!is.corr) par.addCoef.col <- 'black'
  if(is.corr) par.col.lim <- c(-1,1)
  if(!is.corr) par.col.lim <- c(min(corr), max(corr))
  if(!is.corr & all(corr>=0)) par.col.lim <- c(-max(corr),max(corr))
  if(!is.corr & all(corr<=0)) par.col.lim <- c(min(corr),-min(corr))
  # if(!is.corr & all(corr>=0)) par.col.lim <- c(-round(max(corr),digits = 0),round(max(corr),digits = 0))
  # if(!is.corr & all(corr<=0)) par.col.lim <- c(round(min(corr)-1,digits = 0),-1*(round(min(corr)-1)))

  png(filename = filename, width = 9, height = 9, units = 'in', res = 300, family = "Helvetica")
  par(xpd=TRUE) #keep labels inside margins
  pal<-colorRampPalette(c("#FF6666","#EEEEEE","#6666FF"))
  corrplot(corr = corr, method = "circle", insig='blank', order = "original", p.mat = pmat, sig.level = sig.level, pch.cex = 1.5, full_col=!is.corr, na.label = "square", na.label.col = "grey30", diag=T, addrect = addrect, is.corr = is.corr, number.cex = number.cex, number.digits = number.digits, addCoef.col = par.addCoef.col, col = pal(200), col.lim = par.col.lim, mar=c(0,0,4,0), title = title)$corrPos -> p1  #COL2('RdBu')
  
  #p1$corr <- ifelse(0==-p1$y + ncol(corr)-p1$x + 1, NA_real_, p1$corr)
  if(is.corr) text(p1$x, p1$y, round(p1$corr, number.digits)) #only full coeficients for correlation plots

  dev.off()
  
}

p$printCorrSimplified <- function(corr, SE=NULL, filename, is.corr = T, number.cex = 1.5, number.digits=2, absScale=F){
  
  if(absScale){
    palette<-colorRampPalette(c("#000000",theme.color$contrastLight3))
  } else {
    palette<-colorRampPalette(c(theme.color$contrastDark3,"#000000",theme.color$contrastLight3))
  }
  
  if(is.null(SE)){
    corr.uppCI <- NULL
    corr.lowCI <- NULL
  } else {
    corr.uppCI<-corr + 1.96 * SE
    corr.lowCI<-corr - 1.96 * SE
  }
  
  png(filename = filename, width = 1200, height = 1000)
corrplot(
  corr = corr,
  #uppCI.mat = corr.uppCI,
  #lowCI.mat = corr.lowCI,
  #plotCI = ifelse(is.null(SE),c("n"),"circle"),
  order = "original",#"hclust",
  #hclust.method = "ward.D",
  method = "color",
  type="full",
  #addCoef.col = theme.color$contrastDark1,
  addgrid.col = theme.color$contrastDark1,
  col = palette(200),
  is.corr = is.corr,
  outline = T,
  #addrect = addrect,
  #rect.col = theme.color$contrastLight1,
  #rect.lwd = 6,
  tl.cex = 1.7,
  tl.col = theme.color$contrastDark2,
  tl.srt = 35,
  cl.cex = 2,
  cl.ratio = 0.2,
  #number.cex = number.cex,
  #number.digits = number.digits
  )
dev.off()
  
}

p.adjust2 <- function (p, method = p.adjust.methods, n = length(p)) 
{
    method <- match.arg(method)
    if (method == "fdr") 
        method <- "BH"
    nm <- names(p)
    p <- as.numeric(p)
    p0 <- setNames(p, nm)
    if (all(nna <- !is.na(p))) 
        nna <- TRUE
    else p <- p[nna]
    lp <- length(p)
    #stopifnot(n >= lp) #+++JZ: Now we can run with n < lp !!!! Thank you Stack Overflow!
    if (n <= 1) 
        return(p0)
    if (n == 2 && method == "hommel") 
        method <- "hochberg"
    p0[nna] <- switch(method, bonferroni = pmin(1, n * p), holm = {
        i <- seq_len(lp)
        o <- order(p)
        ro <- order(o)
        pmin(1, cummax((n + 1L - i) * p[o]))[ro]
    }, hommel = {
        if (n > lp) p <- c(p, rep.int(1, n - lp))
        i <- seq_len(n)
        o <- order(p)
        p <- p[o]
        ro <- order(o)
        q <- pa <- rep.int(min(n * p/i), n)
        for (j in (n - 1L):2L) {
            ij <- seq_len(n - j + 1L)
            i2 <- (n - j + 2L):n
            q1 <- min(j * p[i2]/(2L:j))
            q[ij] <- pmin(j * p[ij], q1)
            q[i2] <- q[n - j + 1L]
            pa <- pmax(pa, q)
        }
        pmax(pa, p)[if (lp < n) ro[1L:lp] else ro]
    }, hochberg = {
        i <- lp:1L
        o <- order(p, decreasing = TRUE)
        ro <- order(o)
        pmin(1, cummin((n + 1L - i) * p[o]))[ro]
    }, BH = {
        i <- lp:1L
        o <- order(p, decreasing = TRUE)
        ro <- order(o)
        pmin(1, cummin(n/i * p[o]))[ro]
    }, BY = {
        i <- lp:1L
        o <- order(p, decreasing = TRUE)
        ro <- order(o)
        q <- sum(1/(1L:n))
        pmin(1, cummin(q * n/i * p[o]))[ro]
    }, none = p)
    
    p0 <- ifelse(p0 < p, p, p0) #+++JZ: Added this to avoid any p0 < p when using small n
    
    p0
}

p$plotAndTestBatteryForMVLDSC <- function(
    mvldsc,
    code,
    titleAddition="",
    titleAdditionComparison="",
    titleTemplate="LDSC++, HC1kG reference,\nGWAS (non-imputed) + GWIS of male BMI (LD-IMP augmented height & weight),\n",
    mvldscComparison=NULL,
    testOnlyTraitNameCodes=NULL){
  
  traitCodes<-colnames(mvldsc$S)
  
  cv.S_StandLimit <- 0.05 #0.05
  
  pcaRes <- eigen(mvldsc$V_Stand,symmetric = T)
  eigenSum<-sum(abs(pcaRes$values))
  eigenSumLimit<-0.95
  for(iEV in 1:length(pcaRes$values)){
    if(sum(abs(pcaRes$values[1:iEV]))/eigenSum > eigenSumLimit) break
  }
  
   #0.9644592 
  
  #fdr tests
  #fdr.res <- p.fdr(pvalues = mvldsc$cov.p)
  #iEV <- 8
  # fdr.res <- data.frame(
  #   p.fdr = p.adjust(mvldsc$cov.p[lower.tri(mvldsc$cov.p,diag = T)], method = "fdr"),
  #   p.fdr2 = p.adjust2(mvldsc$cov.p[lower.tri(mvldsc$cov.p,diag = T)], method = "fdr",n = iEV),
  #   p.bf = iEV * unlist(as.list(mvldsc$cov.p[lower.tri(mvldsc$cov.p,diag = T)])),
  #   p = unlist(as.list(mvldsc$cov.p[lower.tri(mvldsc$cov.p,diag = T)]))
  #   )
  
  mvldsc$cov.p.fdr2<-matrix(NA,nrow = nrow(mvldsc$cov.p),ncol = ncol(mvldsc$cov.p))
  mvldsc$cov.p.fdr2[lower.tri(mvldsc$cov.p,diag = T)]<-p.adjust2(mvldsc$cov.p[lower.tri(mvldsc$cov.p,diag = T)], method = "fdr",n = iEV)
  mvldsc$cov.p.fdr2[upper.tri(mvldsc$cov.p.fdr2,diag = F)]<-t( mvldsc$cov.p.fdr2)[upper.tri(mvldsc$cov.p.fdr2,diag = F)]
  
  if(!is.null(mvldscComparison)){
    mvldscComparison$cov.p.fdr2<-matrix(NA,nrow = nrow(mvldscComparison$cov.p),ncol = ncol(mvldscComparison$cov.p))
    mvldscComparison$cov.p.fdr2[lower.tri(mvldscComparison$cov.p,diag = T)]<-p.adjust2(mvldscComparison$cov.p[lower.tri(mvldscComparison$cov.p,diag = T)], method = "fdr",n = iEV)
    mvldscComparison$cov.p.fdr2[upper.tri(mvldscComparison$cov.p.fdr2,diag = F)]<-t( mvldscComparison$cov.p.fdr2)[upper.tri(mvldscComparison$cov.p.fdr2,diag = F)]
  }
  
  
  
  p$printCorr(
  corr = clipValues(mvldsc$I,-3,3),
  pmat = mvldsc$cov.p.fdr2,
  filename = file.path(p$folderpath.plots,paste0("i.",code,".png")),
  is.corr = F,
  number.digits = 3,
  newnames = p$sumstats.sel[traitCodes,]$code.nice,
  title = paste0("Intercepts, ",titleTemplate,titleAddition)
  )

p$printCorr(
  corr = mvldsc$S,
  pmat = mvldsc$cov.p.fdr2,
  filename = file.path(p$folderpath.plots,paste0("cov.",code,".png")),
  is.corr = F,
  number.digits = 3,
  newnames = p$sumstats.sel[traitCodes,]$code.nice,
  title = paste0("Genetic covariances, ",titleTemplate,titleAddition)
  )

p$printCorr(
  corr = clipValues(mvldsc$S.SE,-1,1),
  #pmat = mvldsc$cov.p.fdr2,
  filename = file.path(p$folderpath.plots,paste0("covse.",code,".png")),
  is.corr = F,
  number.digits = 4,
  newnames = p$sumstats.sel[traitCodes,]$code.nice,
  title = paste0("Genetic covariances S.E., ",titleTemplate,titleAddition)
  )

#this is just the same as the values from the rg
# S_StandForCV<-abs(mvldsc$S)
# S_StandForCV[S_StandForCV<cv.S_StandLimit]<-cv.S_StandLimit
# p$printCorr(
#   corr = (mvldsc$S.SE/S_StandForCV),
#   #pmat = mvldsc$cov.p.fdr2,
#   filename = file.path(p$folderpath.plots,paste0("covse.std.",code,".png")),
#   is.corr = F,
#   number.digits = 4,
#   newnames = p$sumstats.sel[traitCodes,]$code.nice,
#   title = paste0("Genetic covariances Coefficient of Variation (CV), ",titleTemplate,titleAddition)
#   )

p$printCorr(
  corr = clipValues(mvldsc$S_Stand,-1,1),
  pmat = mvldsc$cov.p.fdr2,
  filename = file.path(p$folderpath.plots,paste0("rg.",code,".png")),
  is.corr = T,
  number.digits = 3,
  newnames = p$sumstats.sel[traitCodes,]$code.nice,
  title = paste0("Genetic correlations, ",titleTemplate,titleAddition)
  )

p$printCorr(
  corr = clipValues(mvldsc$S_Stand.SE,-1,1),
  #pmat = mvldsc$cov.p.fdr2,
  filename = file.path(p$folderpath.plots,paste0("rgse.",code,".png")),
  is.corr = F,
  number.digits = 4,
  newnames = p$sumstats.sel[traitCodes,]$code.nice,
  title = paste0("Genetic correlations S.E., ",titleTemplate,titleAddition)
  )


S_StandForCV<-abs(mvldsc$S_Stand)
S_StandForCV[S_StandForCV<cv.S_StandLimit]<-cv.S_StandLimit #cap at min 0.05 to avoid extreme values
p$printCorr(
  corr = (mvldsc$S_Stand.SE/S_StandForCV),
  #pmat = mvldsc$cov.p.fdr2,
  filename = file.path(p$folderpath.plots,paste0("rgse.std.",code,".png")),
  is.corr = F,
  number.digits = 4,
  newnames = p$sumstats.sel[traitCodes,]$code.nice,
  title = paste0("Genetic correlations Coefficient of Variation (CV), ",titleTemplate,titleAddition)
  )

# mvldsc<-p$mvLD$covstruct.mvLDSC.1kg.vbcs.drc.winfo
# mvldscComparison<-p$mvLD$covstruct.mvLDSC.1kg.original
# testOnlyTraitNameCodes<-infoTraits

if(is.null(testOnlyTraitNameCodes)){
  testOnlyTraitNameCodes<-colnames(mvldsc$S)
}

if(!is.null(mvldscComparison)){
  cat("\n***Tests for ",code," ***\n")
  
  #Fisher transformation of correlations to make them approximate normal.
  SCorrected<-atanh(mvldsc$S_Stand)
  SCorrected.comparison<-atanh(mvldscComparison$S_Stand)
  
  #corrections for >=1 correlations
  cond<-!is.finite(SCorrected) & mvldsc$S_Stand>=1
  SCorrected[cond]<-sign(mvldsc$S_Stand[cond])*atanh(0.9999999999999999) #set to some large std normal #atanh(0.9999999999999999)
  cond<-!is.finite(SCorrected.comparison) & mvldscComparison$S_Stand>=1
  SCorrected.comparison[cond]<-sign(mvldscComparison$S_Stand[cond])*atanh(0.9999999999999999) #set to some large std normal #atanh(0.9999999999999999)
  
  #test correlation difference
  mTest<-SCorrected-SCorrected.comparison
  varTest<-2*abs(mvldsc$S_Stand.SE^2-mvldscComparison$S_Stand.SE^2) #the intersect
  pTest<-pnorm(q = mTest,sd = sqrt(varTest), lower.tail = F)
  
  pTest.fdr2<-matrix(NA,nrow = nrow(pTest),ncol = ncol(pTest))
  pTest.fdr2[lower.tri(pTest.fdr2,diag = T)]<-p.adjust2(pTest[lower.tri(pTest,diag = T)], method = "fdr", n = iEV)
  pTest.fdr2[upper.tri(pTest.fdr2,diag = F)]<-t(pTest.fdr2)[upper.tri(pTest.fdr2,diag = F)]
  
  
  S.SECorrected<-mvldsc$cov.blocks*(mvldsc$S_Stand.SE^2) #chi-squared with df=nblocks, scaled with the mean of the sample (mvldsc$S_Stand) - they are already centered!
  S.SECorrected.comparison<-mvldscComparison$cov.blocks*(mvldscComparison$S_Stand.SE^2)
  
  #try using the #blocks as df, transform to normal - EXPERIMENTAL - NOT DONE!!
  S.SECorrected2<-(S.SECorrected-mvldsc$cov.blocks*abs(mvldsc$S_Stand))/sqrt(2*mvldsc$cov.blocks*abs(mvldsc$S_Stand))
  S.SECorrected.comparison2<-(S.SECorrected.comparison-mvldscComparison$cov.blocks)/sqrt(2*mvldscComparison$cov.blocks)
  
  #test variance difference
  mTestSE<-S.SECorrected2-S.SECorrected.comparison2
  #varTestSE<-mvldsc$cov.blocks+mvldscComparison$cov.blocks #assume these are not covarying
  #varTest<-2*abs(2*mvldsc$cov.blocks-2*mvldscComparison$cov.blocks)# this is very unpractical as they are all 0
  pTestSE<-pnorm(q = mTestSE, sd = 1, lower.tail = T)
  
  
  dS_Stand<-mvldsc$S_Stand[testOnlyTraitNameCodes,testOnlyTraitNameCodes]-mvldscComparison$S_Stand[testOnlyTraitNameCodes,testOnlyTraitNameCodes]
  dS.S_Stand.SE<-mvldsc$S_Stand.SE[testOnlyTraitNameCodes,testOnlyTraitNameCodes]-mvldscComparison$S_Stand.SE[testOnlyTraitNameCodes,testOnlyTraitNameCodes]
  bartlett.test.labels<-c(rep("mvldsc",length(mvldsc$S[testOnlyTraitNameCodes,testOnlyTraitNameCodes])),rep("comparison",length(mvldscComparison$S[testOnlyTraitNameCodes,testOnlyTraitNameCodes])))
  
  cat("Mean abs(dS_Stand)=",mean(abs(dS_Stand)),"\n")
  #pS<-pchisq(abs(dS_Stand),df = 1, lower.tail = F) #this is pretending that the dist is chi-square
  # result<-bartlett.test(x = c(unlist(mvldsc$S_Stand[testOnlyTraitNameCodes,testOnlyTraitNameCodes]),unlist(mvldscComparison$S_Stand[testOnlyTraitNameCodes,testOnlyTraitNameCodes])), g =bartlett.test.labels)
  # print(result)
  
  # cat("Mean dS.S_Stand.SE=",mean(dS.S_Stand.SE),"\n")
  # 
  # cat("\nBartlett's test of the obtained S.E.\n")
  # result<-bartlett.test(x = c(unlist(mvldsc$S_Stand.SE[testOnlyTraitNameCodes,testOnlyTraitNameCodes]),unlist(mvldscComparison$S_Stand.SE[testOnlyTraitNameCodes,testOnlyTraitNameCodes])), g = bartlett.test.labels)
  # print(result)
  # 
  # cat("\nBartlett's test of the obtained S.E. (standardised)\n")
  # result<-bartlett.test(x = c(unlist((mvldsc$S_Stand.SE/abs(mvldsc$S_Stand))[testOnlyTraitNameCodes,testOnlyTraitNameCodes]),unlist((mvldscComparison$S_Stand.SE/abs(mvldscComparison$S_Stand))[testOnlyTraitNameCodes,testOnlyTraitNameCodes])), g = bartlett.test.labels)
  # print(result)
  
  
  
  #custom pdf difference test for the difference between standard errors or CV
  # mvldsc<-p$mvLD$covstruct.mvLDSC.1kg
  # mvldscComparison<-p$mvLD$covstruct.mvLDSC.hm3
  #variance-to-mean-ratio (relative variance, index of dispersion etc)
  
  S_StandForCV<-abs(mvldsc$S_Stand)
  S_StandForCV[S_StandForCV<cv.S_StandLimit]<-cv.S_StandLimit #cap at min 0.05 to avoid extreme values
  mvldsc$CV <- mvldsc$S_Stand.SE/S_StandForCV #square of this is X2 distr, if times (n-1) and scaled by the population variance
  mvldsc$CV.n <- mvldsc$cov.blocks
  mvldsc$testVar<-(mvldsc$CV^2)*mvldsc$CV.n
  mvldsc$covse.p <- pchisq(q = mvldsc$testVar, df = (mvldsc$CV.n-1),lower.tail = F)
  
  #add in FDR correction
  mvldsc$covse.p.fdr2<-matrix(NA,nrow = nrow(mvldsc$covse.p),ncol = ncol(mvldsc$covse.p))
  mvldsc$covse.p.fdr2[lower.tri(mvldsc$covse.p.fdr2,diag = T)]<-p.adjust2(mvldsc$covse.p[lower.tri(mvldsc$covse.p,diag = T)], method = "fdr", n = iEV)
  mvldsc$covse.p.fdr2[upper.tri(mvldsc$covse.p.fdr2,diag = F)]<-t(mvldsc$covse.p.fdr2)[upper.tri(mvldsc$covse.p.fdr2,diag = F)]
  
  S_StandForCV<-abs(mvldscComparison$S_Stand)
  S_StandForCV[S_StandForCV<cv.S_StandLimit]<-cv.S_StandLimit #cap at min 0.05 to avoid extreme values
  mvldscComparison$CV <- mvldscComparison$S_Stand.SE/S_StandForCV #square of this is X2 distr, if times (n-1) and scaled by the population variance
  mvldscComparison$CV.n <- mvldscComparison$cov.blocks
  mvldscComparison$testVar<-(mvldscComparison$CV^2)*mvldscComparison$CV.n
  mvldscComparison$covse.p <- pchisq(q = mvldscComparison$testVar, df = (mvldscComparison$CV.n-1),lower.tail = F)
  
   #add in FDR correction
  mvldscComparison$covse.p.fdr2<-matrix(NA,nrow = nrow(mvldscComparison$covse.p),ncol = ncol(mvldscComparison$covse.p))
  mvldscComparison$covse.p.fdr2[lower.tri(mvldscComparison$covse.p.fdr2,diag = T)]<-p.adjust2(mvldscComparison$covse.p[lower.tri(mvldscComparison$covse.p,diag = T)], method = "fdr", n = iEV)
  mvldscComparison$covse.p.fdr2[upper.tri(mvldscComparison$covse.p.fdr2,diag = F)]<-t(mvldscComparison$covse.p.fdr2)[upper.tri(mvldscComparison$covse.p.fdr2,diag = F)]
  
  
  cat("Mean dS.S_Stand.SE=",mean(dS.S_Stand.SE),"\n")
  
  covse.testVar.diff<-abs(mvldsc$testVar-mvldscComparison$testVar)
  covse.testVar.diff.n <- abs((mvldsc$CV.n -1) - (mvldscComparison$CV.n-1))
  covse.p.diff <- pchisq(q = covse.testVar.diff, df = covse.testVar.diff.n,lower.tail = F)
  
  covse.p.diff.fdr2<-matrix(NA,nrow = nrow(covse.p.diff),ncol = ncol(covse.p.diff))
  covse.p.diff.fdr2[lower.tri(covse.p.diff.fdr2,diag = T)]<-p.adjust2(covse.p.diff[lower.tri(covse.p.diff,diag = T)], method = "fdr", n = iEV) #use the same number of tests as for the correlation difference - just an approximation as we don't assess the standard error correlations
  covse.p.diff.fdr2[upper.tri(covse.p.diff.fdr2,diag = F)]<-t( covse.p.diff.fdr2)[upper.tri(covse.p.diff.fdr2,diag = F)]
  colnames(covse.p.diff.fdr2)<-colnames(covse.p.diff)
  rownames(covse.p.diff.fdr2)<-colnames(covse.p.diff)
  
  # tdata<-data.frame(x=rnorm(100,0.7,2),y=rnorm(100,-0.2,3))
  # tdata.full<-data.frame(var=c(tdata$x,tdata$y))
  # tdata.full[1:100,c("group")]<-"a"
  # tdata.full[101:200,c("group")]<-"b"
  # tdata.full$group<-as.factor(tdata.full$group)
  
  #levene test test
  #https://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm
  #tres <- car::leveneTest(var ~ group, data=tdata.full) #HERE!!! TRY X2 DISTRIBUTIONS INSTEAD
  #mTot<-(sd(tdata$x)+sd(tdata$y))/2
  
  #((100 + 100 - 2)/(2-1)) * (100*(sd(tdata$x)-mTot)^2+100*(sd(tdata$x)-mTot)^2) / (100*var(tdata$x)  + 100*var(tdata$y)) #NO
  
  #Comparison plots
  dS_Stand<-mvldsc$S_Stand-mvldscComparison$S_Stand #re-compute as we need the full matrices here
  p$printCorr(
    corr = clipValues(dS_Stand,-1,1),
    pmat = pTest.fdr2,
    filename = file.path(p$folderpath.plots,paste0("drg.",code,".png")),
    is.corr = F,
    number.digits = 3,
    newnames = p$sumstats.sel[traitCodes,]$code.nice,
    title = paste0("Difference in genetic correlations, ",titleTemplate,titleAddition,titleAdditionComparison," [abs(mean)=",round(mean(abs(dS_Stand[testOnlyTraitNameCodes,testOnlyTraitNameCodes])),digits = 2),"]")
  )
  
  #relative, in percent
  dS_Stand<-100*(mvldsc$S_Stand-mvldscComparison$S_Stand)/abs(mvldscComparison$S_Stand) #re-compute as we need the full matrices here
  p$printCorr(
    corr = dS_Stand,
    #pmat = pTest.fdr2,
    filename = file.path(p$folderpath.plots,paste0("drg.rel.",code,".png")),
    is.corr = F,
    number.digits = 1,
    newnames = p$sumstats.sel[traitCodes,]$code.nice,
    title = paste0("Relative (%) difference in genetic correlations, ",titleTemplate,titleAddition,titleAdditionComparison," [mean=",round(mean(abs(dS_Stand[testOnlyTraitNameCodes,testOnlyTraitNameCodes])),digits = 1),"]")
  )
  
  dS.S_Stand.SE<-mvldsc$S_Stand.SE-mvldscComparison$S_Stand.SE
  p$printCorr(
    corr = dS.S_Stand.SE,
    #pmat = covse.p.diff.fdr2,
    filename = file.path(p$folderpath.plots,paste0("drgse.",code,".png")),
    is.corr = F,
    number.digits = 4,
    newnames = p$sumstats.sel[traitCodes,]$code.nice,
    title = paste0("Difference in genetic correlations S.E., ",titleTemplate,titleAddition,titleAdditionComparison," [mean=",round(mean(dS.S_Stand.SE[testOnlyTraitNameCodes,testOnlyTraitNameCodes]),digits = 4),"]")
  )
  
  #relative, in percent
  dS.S_Stand.SE<-100*(mvldsc$S_Stand.SE-mvldscComparison$S_Stand.SE)/abs(mvldscComparison$S_Stand.SE)
  p$printCorr(
    corr = dS.S_Stand.SE,
    #pmat = covse.p.diff.fdr2,
    filename = file.path(p$folderpath.plots,paste0("drgse.rel.",code,".png")),
    is.corr = F,
    number.digits = 1,
    newnames = p$sumstats.sel[traitCodes,]$code.nice,
    title = paste0("Relative (%) difference in genetic correlations S.E., ",titleTemplate,titleAddition,titleAdditionComparison," [mean=",round(mean(dS.S_Stand.SE[testOnlyTraitNameCodes,testOnlyTraitNameCodes]),digits = 1),"]")
  )
  
  #CV, standardised
  dCV<-(mvldsc$CV-mvldscComparison$CV)
  p$printCorr(
    corr = dCV,
    #pmat = covse.p.diff.fdr2,
    filename = file.path(p$folderpath.plots,paste0("drgse.std.",code,".png")),
    is.corr = F,
    number.digits = 3,
    newnames = p$sumstats.sel[traitCodes,]$code.nice,
    title = paste0("Difference in genetic correlations Coefficient of Variation (CV), ",titleTemplate,titleAddition,titleAdditionComparison," [mean=",round(mean(dCV[testOnlyTraitNameCodes,testOnlyTraitNameCodes]),digits = 3),"]")
  )
  
  #p-values for the difference
  p$printCorr(
    corr = covse.p.diff.fdr2,
    #pmat = covse.p.diff.fdr2,
    filename = file.path(p$folderpath.plots,paste0("drgse.p.",code,".png")),
    is.corr = F,
    number.digits = 3,
    newnames = p$sumstats.sel[traitCodes,]$code.nice,
    title = paste0("Significance as p-values (FDR corrected, ",iEV," effective tests)\nfor difference in genetic correlations Coefficient of Variation (CV), ",titleTemplate,titleAddition,titleAdditionComparison)
  )
  
  #this does not work bc of wrong p
  # p$printCorr(
  #   corr = dS.S_Stand.SE,
  #   pmat = pTestSE,
  #   filename = file.path(p$folderpath.plots,paste0("sdrgse.",code,".png")),
  #   is.corr = F,
  #   number.digits = 4,
  #   newnames = p$sumstats.sel[traitCodes,]$code.nice,
  #   title = paste0("Difference in LDSC++ genetic correlations S.E., ",titleTemplate,titleAdditionComparison)
  # )
  
}

  
}

```

# Knitr setup

```{r knitr setup, include=FALSE, purl=FALSE}
knitr::opts_chunk$set(echo = TRUE,comment=NA,prompt=FALSE,cache=FALSE)
knitr::opts_knit$set(root.dir=normalizePath(p$folderpath.workingDirectory))

```

# R script export

```{r purl export, include=FALSE, purl=FALSE, eval=FALSE}
#running this will produce an R-script with the same name as the Rmd-file. Used for running the program on computational clusters (Rosalind), when the code just has to be run rather than creating a knitted output.
knitr::purl(p$filepath.rmd)
  
```


```{r additional source setup, echo=FALSE, warning=F}

#source(normalizePath(file.path(p$folderpath.scripts,"include","ldsc.orig.R")))
#source(file.path(p$folderpath.scripts,"include","fastman.R"))
#source(file.path(p$folderpath.scripts,"include","fastqq.R"))

```


```{r old anxi rg analysis of gwas sumstats, purl=FALSE, eval=FALSE}
p$rg_anxi<-read.table(file.path(p$folderpath.data,"ANXI03_gc.txt"), header=T, quote="", sep = "") %>%
extract(col = p2, into = "code", regex = "_noMHC/(.*)_noMHC.sumstats.", remove = F, )

p$rg_anxi<- p$rg_anxi[which(p$rg_anxi$p<.00001),]
p$rg_anxi$rg.abs<-abs(p$rg_anxi$rg)

#View(p$rg_anxi)

```

# Metadata setup

## Database connection to fetch trait and GWAS metadata - run from Rstudio .rmd
```{r sumstat metadata database load}
p$filepath.sumstats<-file.path(p$folderpath.workingDirectory,paste0("sumstats.",p$setup.code,".Rds"))
if (file.exists(p$filepath.sumstats)) {
  print("Loading summary statistics metadata from previously stored file.")
  p$sumstats<-readRDS(file=p$filepath.sumstats)
} else {

#install.packages('RPostgres')
library(RPostgres)
library(DBI)

p$phenodbcon <- dbConnect(RPostgres::Postgres(),
                 dbname = 'phenodb', 
                 host = '10.200.105.5', 
                 port = 5432,
                 user = 'johan',
                 password = rstudioapi::askForPassword(prompt = "Enter database password for specified user."))

p$phenodbres <- dbSendQuery(p$phenodbcon, "SELECT \"GWAS\".*, category_id, category.name AS category_name, phenotype.name AS phenotype, phenotype.type AS phenotype_type, pmid, year FROM sumstat_old.\"GWAS\", sumstat_old.reference, sumstat_old.phenotype, sumstat_old.category 
WHERE \"GWAS\".reference_id=reference.id AND \"GWAS\".phenotype_id=phenotype.id AND phenotype.category_id = category.id
ORDER BY code,\"GWAS\".id")
p$sumstats<-dbFetch(p$phenodbres)
dbClearResult(p$phenodbres)

#fallback
#p$sumstats<-read.table(file.path(p$folderpath.data,"ukbb_sumstats_download202005.csv"), header=T, quote="\"", sep = ",", fill=T, blank.lines.skip=T,as.is = c(2), strip.white = T)

saveRDS(p$sumstats,file = p$filepath.sumstats)
write.table(p$sumstats, file = file.path(p$folderpath.workingDirectory,paste0(p$setup.code,".sumstats.tsv")), quote = F, sep = "\t", row.names = FALSE, col.names = TRUE)
}



```



## Trait setup
```{r trait setup}
#,echo=FALSE
p$trait<-data.frame(phenotype_id=c())

#ADHD
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-139
p$trait[nrow(p$trait),c("populationPrevalence")]<-.00529 #Worldwide-pooled
p$trait[nrow(p$trait),c("referenceDOI")]<-"https://doi.org/10.1176/ajp.2007.164.6.942"

#ALCD
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-141
p$trait[nrow(p$trait),c("populationPrevalence")]<-.125 #US total measurement
p$trait[nrow(p$trait),c("referenceDOI")]<-"https://doi.org/10.1001/archpsyc.64.7.830"

#ANOR
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-142
p$trait[nrow(p$trait),c("populationPrevalence")]<-.0245 #European average (3 secondary refs)
p$trait[nrow(p$trait),c("referenceDOI")]<-"https://doi.org/10.1038/S41588-019-0439-2"

#ANXI
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-144
p$trait[nrow(p$trait),c("populationPrevalence")]<-.16 #Any type of anxiety disorder, Via https://doi.org/10.1038/s41380-019-0559-1 (2019), originally from https://doi.org/10.1017/S1121189X00001421 (2009)
p$trait[nrow(p$trait),c("referenceDOI")]<-"https://doi.org/10.1017/S1121189X00001421"

#AUTI
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-145
p$trait[nrow(p$trait),c("populationPrevalence")]<-.0122
p$trait[nrow(p$trait),c("referenceDOI")]<-"https://doi.org/10.1186/s12874-016-0280-6"

#BIPO
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-146
p$trait[nrow(p$trait),c("populationPrevalence")]<- .007 #mean of male and female global prevalence rate (2013) from https://doi.org/10.1111/bdi.12423 (2016)
p$trait[nrow(p$trait),c("referenceDOI")]<-"https://doi.org/10.1111/bdi.12423"

#DEPR
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-149
p$trait[nrow(p$trait),c("populationPrevalence")]<-.146 #MDD, .15 from the LD-calculations in https://doi.org/10.1038/s41588-018-0090-3 (2018), but with a possible reference to https://doi.org/10.1146/annurev-publhealth-031912-114409 (2013) which states 14.6% lifetime prevalence of MDE in high-income countries.
p$trait[nrow(p$trait),c("referenceDOI")]<-"https://doi.org/10.1146/annurev-publhealth-031912-114409"

#DEPR - broad
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-1499 #this is just an adhoc id
p$trait[nrow(p$trait),c("populationPrevalence")]<-.302 #MDD, .15 from the partitioned heritability analysis in https://doi.org/10.1038/s41593-018-0326-7
p$trait[nrow(p$trait),c("referenceDOI")]<-"https://doi.org/10.1038/s41593-018-0326-7"

#INSO
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-171
p$trait[nrow(p$trait),c("populationPrevalence")]<-.69 #using the 'prevalence', the higher estimate of persistent symptoms after 1y follow up.
p$trait[nrow(p$trait),c("referenceDOI")]<-"https://doi.org/10.1093/sleep/30.3.274"

#PTSD
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-140
p$trait[nrow(p$trait),c("populationPrevalence")]<-.3 #using the moderate estimate of lifetime prevalence after trauma as used in ref
p$trait[nrow(p$trait),c("referenceDOI")]<-"10.1038/s41467-019-12576-w"

#SCHI
p$trait[nrow(p$trait)+1,c("phenotype_id")]<-151
p$trait[nrow(p$trait),c("populationPrevalence")]<-.0072 #using the lifetime morbid risk estimate, slightly more suitable for the CLOZUK sample as described in the GWAS but not using the lower point estimate of 0.4%
p$trait[nrow(p$trait),c("referenceDOI")]<-"https://doi.org/10.1093/epirev/mxn001"

p$trait
setDT(p$trait)
setkeyv(p$trait, cols = c("phenotype_id"))

```


## Setup GWAS summary statistics datasets

```{r setup GWAS sumstat dataset}

#, echo=FALSE


#View(p$sumstats)

#rename and add columns
names(p$sumstats)[names(p$sumstats)=="n_cases"]<-"n_case"
names(p$sumstats)[names(p$sumstats)=="n_controls"]<-"n_control"
p$sumstats$gwas_name.nice<-NA_character_
p$sumstats$code.trait<-NA_character_
p$sumstats$reference_doi<-NA_character_
p$sumstats$effect.logit<-as.logical(NA)
p$sumstats$dependent_variable.linprob<-as.logical(NA)
p$sumstats$se.logit<-as.logical(NA)
p$sumstats$dependent_variable.OLS<-as.logical(NA)
p$sumstats$age.min<-NA_integer_
p$sumstats$age.max<-NA_integer_
p$sumstats$age.mean<-NA_real_
p$sumstats$age.sd<-NA_real_

#add missing datasets and data
p$sumstats[nrow(p$sumstats)+1,c("code","n_case","n_control","n_total","phenotype_id","reference_id","reference_doi")]=list(
  code="DEPR05",
  n_case=16823,
  n_control=25632,
  n_total=42455,
  phenotype_id=149,
  reference_id=127,
  reference_doi=c("https://doi.org/10.1038/s41588-018-0090-3")
  )

p$sumstats[nrow(p$sumstats)+1,c("code","n_case","n_control","n_total","phenotype_id","reference_id","reference_doi")]=list(
  code="DEPR5B",
  n_case=14260,
  n_control=15480,
  n_total=29740,
  phenotype_id=149,
  reference_id=127,
  reference_doi=c("https://doi.org/10.1038/s41588-018-0090-3")
  )

#add missing datasets and data
p$sumstats[nrow(p$sumstats)+1,c("code","n_case","n_control","n_total","phenotype_id","reference_id","reference_doi")]=list(
  code="ANXI04",
  n_case=19012,
  n_control=58113,
  n_total=77125,
  phenotype_id=144,
  reference_id=158
  )

p$sumstats[nrow(p$sumstats)+1,c("code","name", "n_case","n_control","n_total","phenotype_id","reference_id","reference_doi")]=list(
  code="NEUR02",
  name="Neuroticism",
  n_case=449484,
  n_control=NA_integer_,
  n_total=449484,
  phenotype_id=176,
  reference_id=NA_integer_,
  reference_doi=c("https://doi.org/10.1038/s41588-018-0151-7")
  )

p$sumstats[nrow(p$sumstats)+1,c("code","name", "n_case","n_control","n_total","phenotype_id","reference_id","reference_doi")]=list(
  code="INSO03",
  name="Insomnia",
  n_case=593724,
  n_control=1771286,
  n_total=2365010,
  phenotype_id=171,
  reference_id=NA_integer_,
  reference_doi=c("https://doi.org/10.1038/s41588-022-01124-w")
  )

p$sumstats[nrow(p$sumstats)+1,c("code","name", "n_case","n_control","n_total","phenotype_id","reference_id","reference_doi")]=list(
  code="BVOL01",
  name="Brain volume",
  n_case=47316,
  n_control=NA_integer_,
  n_total=47316,
  phenotype_id=NA_integer_,
  reference_id=NA_integer_,
  reference_doi=c("https://doi.org/10.1038/s41467-020-19378-5")
  )

p$sumstats[nrow(p$sumstats)+1,c("code","name", "n_case","n_control","n_total","phenotype_id","reference_id","reference_doi")]=list(
  code="HEIG09",
  name="Height",
  n_case=3612229,
  n_control=NA_integer_,
  n_total=3612229,
  phenotype_id=NA_integer_,
  reference_id=NA_integer_,
  reference_doi=c("https://doi.org/10.1038/s41586-022-05275-y")
  )

p$sumstats[nrow(p$sumstats)+1,c("code","name", "n_case","n_control","n_total","phenotype_id","reference_id","reference_doi")]=list(
  code="BODYTM",
  name="2013 BMI, male",
  n_case=60586,
  n_control=NA_integer_,
  n_total=60586,
  phenotype_id=NA_integer_,
  reference_id=NA_integer_,
  reference_doi=c("10.1371/journal.pgen.1003500")
  )

p$sumstats[nrow(p$sumstats)+1,c("code","name", "n_case","n_control","n_total","phenotype_id","reference_id","reference_doi")]=list(
  code="BODY14",
  name="2019 BMI",
  n_case=806834,
  n_control=NA_integer_,
  n_total=806834,
  phenotype_id=NA_integer_,
  reference_id=NA_integer_,
  reference_doi=c("https://doi.org/10.1093/hmg/ddy327")
  )

p$sumstats[nrow(p$sumstats)+1,c("code","name", "n_case","n_control","n_total","phenotype_id","reference_id","reference_doi")]=list(
  code="BODYTF",
  name="2013 BMI, female",
  n_case=73137,
  n_control=NA_integer_,
  n_total=73137,
  phenotype_id=NA_integer_,
  reference_id=NA_integer_,
  reference_doi=c("10.1371/journal.pgen.1003500")
  )

p$sumstats[nrow(p$sumstats)+1,c("code","name", "n_case","n_control","n_total","phenotype_id","reference_id","reference_doi")]=list(
  code="BODYT2M",
  name="GWIS of BMI, male",
  n_case=60586, #this is the N of the BMI GWAS of the same sample
  n_control=NA_integer_,
  n_total=60586,
  phenotype_id=NA_integer_,
  reference_id=NA_integer_,
  reference_doi=c("10.1016/j.ajhg.2016.07.020")
  )

p$sumstats[nrow(p$sumstats)+1,c("code","name", "n_case","n_control","n_total","phenotype_id","reference_id","reference_doi")]=list(
  code="BODYT2MI",
  name="GWIS of BMI, male, imputed H&W",
  n_case=60586, #this is the N of the BMI GWAS of the same sample
  n_control=NA_integer_,
  n_total=60586,
  phenotype_id=NA_integer_,
  reference_id=NA_integer_,
  reference_doi=c("10.1016/j.ajhg.2016.07.020")
  )

#reformat columns
p$sumstats$name<-as.character(p$sumstats$name)

#set datatable
setDT(p$sumstats)
setkeyv(p$sumstats, cols = c("code"))

##set specific trait data corrections - before join!
p$sumstats[which(p$sumstats$code=="DEPR09"),]$phenotype_id<-1499

##Add trait/disorder information
p$sumstats<-as.data.frame(p$sumstats[p$trait,on=c('phenotype_id'),c('populationPrevalence','referenceDOI') :=list(i.populationPrevalence,i.referenceDOI)]) #reset to dataframe

#set code as rowname
rownames(p$sumstats)<-p$sumstats$code


##Add comprehensive names as in the Google sheet
p$sumstats$name[which(p$sumstats$code=="DEPR05")]="Major depressive disorder (PGC2 29) - only clinical ascertainment"


##Add sumstat full file paths
p$sumstats$cleanedpath<-file.path(p$folderpath.data.sumstats.cleaned,paste0(p$sumstats$code,p$filename.suffix.data.sumstats.munged))

p$sumstats$mungedpath<-file.path(p$folderpath.data.sumstats.munged,paste0(p$sumstats$code,p$filename.suffix.data.sumstats.munged))

p$sumstats$imputedpath<-file.path(p$folderpath.data.sumstats.imputed,paste0(p$sumstats$code,p$filename.suffix.data.sumstats.munged))

p$sumstats$imputedpath.05cm<-file.path(p$folderpath.data.sumstats.imputed.05cm,paste0(p$sumstats$code,p$filename.suffix.data.sumstats.munged))

p$sumstats$imputedpath.ssimp<-file.path(p$folderpath.data.sumstats.imputed.ssimp,paste0(p$sumstats$code,p$filename.suffix.data.sumstats.munged))

p$sumstats$mungedpath2<-file.path(p$folderpath.data.sumstats.export.cleaned.nohighld,paste0(p$sumstats$code,p$filename.suffix.data.sumstats.munged))

p$sumstats$imputedpath2.500<-file.path(p$folderpath.data.sumstats.export.500.cleaned.nohighld,paste0(p$sumstats$code,p$filename.suffix.data.sumstats.munged))

p$sumstats$imputedpath2.ssimp<-file.path(p$folderpath.data.sumstats.export.ssimp.cleaned.nohighld,paste0(p$sumstats$code,p$filename.suffix.data.sumstats.munged))


#special modification for special datasets for munging locally or at rosalind
if(p$host=="local"){
  p$sumstats["ANXI04",]$cleanedpath<-"/Users/jakz/Documents/local_db/JZ_GED_PHD_ADMIN_GENERAL/data/gwas_sumstats/raw/GAD7_BGENIE_SexRegressed_For_LDSC.gz"
} else {
  p$sumstats["ANXI04",]$cleanedpath<-"/users/k19049801/project/JZ_GED_PHD_C1/data/gwas_sumstats/raw/GAD7_BGENIE_SexRegressed_For_LDSC.gz"
}

if(p$host=="local"){
  p$sumstats["BODY14",]$cleanedpath<-"/Users/jakz/Documents/local_db/JZ_GED_PHD_ADMIN_GENERAL/data/gwas_sumstats/raw/bmi.giant-ukbb.meta-analysis.combined.23May2018.txt.gz"
} else {
  p$sumstats["BODY14",]$cleanedpath<-"/users/k19049801/project/JZ_GED_PHD_C1/data/gwas_sumstats/raw/bmi.giant-ukbb.meta-analysis.combined.23May2018.txt.gz"
}

if(p$host=="local"){
  p$sumstats["BODYTM",]$cleanedpath<-"/Users/jakz/Documents/local_db/JZ_GED_PHD_ADMIN_GENERAL/data/gwas_sumstats/raw/GIANT_Randall2013PlosGenet_stage1_publicrelease_HapMapCeuFreq_BMI_MEN_N.txt.gz"
} else {
  p$sumstats["BODYTM",]$cleanedpath<-"/scratch/prj/gwas_sumstats/new/GIANT_Randall2013PlosGenet_stage1_publicrelease_HapMapCeuFreq_BMI_MEN_N.txt.gz"
}

if(p$host=="local"){
  p$sumstats["BODYTF",]$cleanedpath<-"/Users/jakz/Documents/local_db/JZ_GED_PHD_ADMIN_GENERAL/data/gwas_sumstats/raw/GIANT_Randall2013PlosGenet_stage1_publicrelease_HapMapCeuFreq_BMI_WOMEN_N.txt.gz"
} else {
  p$sumstats["BODYTF",]$cleanedpath<-"/scratch/prj/gwas_sumstats/new/GIANT_Randall2013PlosGenet_stage1_publicrelease_HapMapCeuFreq_BMI_WOMEN_N.txt.gz"
}

if(p$host=="local"){
  p$sumstats["NEUR02",]$cleanedpath<-"/Users/jakz/Documents/local_db/JZ_GED_PHD_ADMIN_GENERAL/data/gwas_sumstats/raw/sumstats_neuroticism_ctg_format.txt.gz"
} else {
  p$sumstats["NEUR02",]$cleanedpath<-"/users/k19049801/project/JZ_GED_PHD_C1/data/gwas_sumstats/raw/sumstats_neuroticism_ctg_format.txt.gz"
}

if(p$host=="local"){
  p$sumstats["INSO03",]$cleanedpath<-"/Users/jakz/Documents/local_db/JZ_GED_PHD_ADMIN_GENERAL/data/gwas_sumstats/raw/insomnia_ukb2b_EUR_sumstats_20190311_with_chrX_mac_100.txt.gz"
} else {
  p$sumstats["INSO03",]$cleanedpath<-"/users/k19049801/project/JZ_GED_PHD_C1/data/gwas_sumstats/raw/insomnia_ukb2b_EUR_sumstats_20190311_with_chrX_mac_100.txt.gz"
}

if(p$host=="local"){
  p$sumstats["BVOL01",]$cleanedpath<-"/Users/jakz/Documents/local_db/JZ_GED_PHD_ADMIN_GENERAL/data/gwas_sumstats/raw/meta_analysis_BV_Jansenetal_2020.sumstats.txt.gz"
} else {
  p$sumstats["BVOL01",]$cleanedpath<-"/users/k19049801/project/JZ_GED_PHD_C1/data/gwas_sumstats/raw/meta_analysis_BV_Jansenetal_2020.sumstats.txt.gz"
}

if(p$host=="local"){
  p$sumstats["DEPR5B",]$cleanedpath<-"/Users/jakz/Documents/local_db/JZ_GED_PHD_ADMIN_GENERAL/data/gwas_sumstats/raw/PGC2_MDD_Wray/daner_ukb_170227_aligned.assoc.gz"
} else {
  p$sumstats["DEPR5B",]$cleanedpath<-"/scratch/prj/gwas_sumstats/original/PGC2_MDD_Wray/daner_ukb_170227_aligned.assoc.gz"
}

if(p$host=="local"){
  p$sumstats["HEIG09",]$cleanedpath<-"/Users/jakz/Documents/local_db/JZ_GED_PHD_ADMIN_GENERAL/data/gwas_sumstats/raw/GIANT_HEIGHT_YENGO_2022_GWAS_SUMMARY_STATS_EUR.gz"
} else {
  p$sumstats["HEIG09",]$cleanedpath<-"/scratch/prj/gwas_sumstats/new/GIANT_HEIGHT_YENGO_2022_GWAS_SUMMARY_STATS_EUR.gz"
}

if(p$host=="local"){
  p$sumstats["HEIG04F",]$cleanedpath<-"/Users/jakz/Documents/local_db/JZ_GED_PHD_ADMIN_GENERAL/data/gwas_sumstats/raw/GIANT_Randall2013PlosGenet_stage1_publicrelease_HapMapCeuFreq_HEIGHT_WOMEN_N.txt"
} else {
  p$sumstats["HEIG04F",]$cleanedpath<-"/scratch/prj/gwas_sumstats/original/GIANT_Randall2013PlosGenet_stage1_publicrelease_HapMapCeuFreq_HEIGHT_WOMEN_N.txt"
}

if(p$host=="local"){
  p$sumstats["HEIG04M",]$cleanedpath<-"/Users/jakz/Documents/local_db/JZ_GED_PHD_ADMIN_GENERAL/data/gwas_sumstats/raw/GIANT_Randall2013PlosGenet_stage1_publicrelease_HapMapCeuFreq_HEIGHT_MEN_N.txt"
} else {
  p$sumstats["HEIG04M",]$cleanedpath<-"/scratch/prj/gwas_sumstats/original/GIANT_Randall2013PlosGenet_stage1_publicrelease_HapMapCeuFreq_HEIGHT_MEN_N.txt"
}

if(p$host=="local"){
  p$sumstats["WEIG04F",]$cleanedpath<-"/Users/jakz/Documents/local_db/JZ_GED_PHD_ADMIN_GENERAL/data/gwas_sumstats/raw/GIANT_Randall2013PlosGenet_stage1_publicrelease_HapMapCeuFreq_WEIGHT_WOMEN_N.txt"
} else {
  p$sumstats["WEIG04F",]$cleanedpath<-"/scratch/prj/gwas_sumstats/original/GIANT_Randall2013PlosGenet_stage1_publicrelease_HapMapCeuFreq_WEIGHT_WOMEN_N.txt"
}

if(p$host=="local"){
  p$sumstats["WEIG04M",]$cleanedpath<-"/Users/jakz/Documents/local_db/JZ_GED_PHD_ADMIN_GENERAL/data/gwas_sumstats/raw/GIANT_Randall2013PlosGenet_stage1_publicrelease_HapMapCeuFreq_WEIGHT_MEN_N.txt"
} else {
  p$sumstats["WEIG04M",]$cleanedpath<-"/scratch/prj/gwas_sumstats/original/GIANT_Randall2013PlosGenet_stage1_publicrelease_HapMapCeuFreq_WEIGHT_MEN_N.txt"
}




##add reference year - UPDATE THESE!!
p$sumstats["ANXI03",]$year=2019
p$sumstats["ANXI04",]$year=2019
p$sumstats["BVOL01",]$year=2020
p$sumstats["BODY14",]$year=2019
p$sumstats["BODYTM",]$year=2013
p$sumstats["DEPR05",]$year=2018
p$sumstats["DEPR5B",]$year=2018
p$sumstats["NEUR02",]$year=2018


##Add doi links for easy access to dataset publication
p$sumstats["ALCD03",]$reference_doi="https://doi.org/10.1038/s41593-018-0275-1"
p$sumstats["ANXI03",]$reference_doi="https://doi.org/10.1038/s41380-019-0559-1"
p$sumstats["ANXI04",]$reference_doi="https://doi.org/10.1038/s41380-019-0559-1"
p$sumstats["AUTI07",]$reference_doi="https://doi.org/10.1038/s41588-019-0344-8"
p$sumstats["BODY11",]$reference_doi="https://doi.org/10.1093/hmg/ddy271"
p$sumstats["DEPR08",]$reference_doi="https://doi.org/10.1038/s41588-018-0090-3"
p$sumstats["DEPR09",]$reference_doi="https://doi.org/10.1038/s41593-018-0326-7"
p$sumstats["EDUC03",]$reference_doi="https://doi.org/10.1038/s41588-018-0147-3"
p$sumstats["HEAL01",]$reference_doi="https://doi.org/10.1093/ije/dyw219"
p$sumstats["NEUR01",]$reference_doi="https://doi.org/10.1038/ng.3552"
p$sumstats["SUBJ01",]$reference_doi="https://doi.org/10.1038/ng.3552"
p$sumstats["TIRE01",]$reference_doi="https://doi.org/10.1038/mp.2017.5"


##Add PMID
p$sumstats["ANXI03",]$pmid="31748690"
p$sumstats["ANXI04",]$pmid="31748690"
p$sumstats["DEPR05",]$pmid="29700475"

##add dependent variable type
p$sumstats$dependent_variable[which(p$sumstats$code=="DEPR05")]="binary"

##add participant numbers
p$sumstats$n_total[which(p$sumstats$code=="NEUR01")]=170911
p$sumstats$n_case[which(p$sumstats$code=="HEIG04F" | p$sumstats$code=="HEIG04M" | p$sumstats$code=="WEIG04F" | p$sumstats$code=="WEIG04M")]=60586
p$sumstats$n_case[which(p$sumstats$code=="EDUC03")]=766345 #not sure why it is missing here
p$sumstats$n_total[which(p$sumstats$code=="EDUC03")]=766345

##add sex details
p$sumstats$sex[which(p$sumstats$code=="ANXI04")]="both"
p$sumstats$sex[which(p$sumstats$code=="NEUR01")]="both"
p$sumstats$sex[which(p$sumstats$code=="DEPR05")]="both"

##add age range
p$sumstats$age.min[which(p$sumstats$code=="SUBJ01")]=40
p$sumstats$age.max[which(p$sumstats$code=="SUBJ01")]=73
p$sumstats$age.mean[which(p$sumstats$code=="SUBJ01")]=56.91
p$sumstats$age.sd[which(p$sumstats$code=="SUBJ01")]=7.93
p$sumstats$age.min[which(p$sumstats$code=="TIRE01")]=40
p$sumstats$age.max[which(p$sumstats$code=="TIRE01")]=73
p$sumstats$age.mean[which(p$sumstats$code=="TIRE01")]=56.91
p$sumstats$age.sd[which(p$sumstats$code=="TIRE01")]=7.93


##add sample prevalence for all datasets
p$sumstats$samplePrevalence<-ifelse(is.na(p$sumstats$n_control),NA_real_, p$sumstats$n_case/p$sumstats$n_total)

##add number of cases or total column
p$sumstats$n_case_total<-ifelse(is.na(p$sumstats$n_control),p$sumstats$n_case,p$sumstats$n_total)

##Add nice trait names to be used in the report
p$sumstats$name.nice<-p$sumstats$name
#p$sumstats$name.nice[which(p$sumstats$code=="ADHD05")]="ADHD"
p$sumstats$name.nice[which(p$sumstats$code=="ALCD03")]="Alcohol dependence"
p$sumstats$name.nice[which(p$sumstats$code=="ANOR02")]="Anorexia nervosa"
p$sumstats$name.nice[which(p$sumstats$code=="ANXI03")]="Anxiety disorder"
p$sumstats$name.nice[which(p$sumstats$code=="ANXI04")]="Generalised anxiety symptoms"
p$sumstats$name.nice[which(p$sumstats$code=="AUTI07")]="Autism spectrum disorder"
p$sumstats$name.nice[which(p$sumstats$code=="BODY11")]="2018 BMI"
p$sumstats$name.nice[which(p$sumstats$code=="DEPR05")]="MDD"
p$sumstats$name.nice[which(p$sumstats$code=="DEPR5B")]="MDD symptoms"
p$sumstats$name.nice[which(p$sumstats$code=="DEPR08")]="MDD"
p$sumstats$name.nice[which(p$sumstats$code=="DEPR09")]="Broad depression"
p$sumstats$name.nice[which(p$sumstats$code=="EDUC03")]="Educational attainment"
p$sumstats$name.nice[which(p$sumstats$code=="EXTR01")]="Extraversion"
p$sumstats$name.nice[which(p$sumstats$code=="HEIG04F")]="2013 Height, female"
p$sumstats$name.nice[which(p$sumstats$code=="HEIG04M")]="2013 Height, male"
p$sumstats$name.nice[which(p$sumstats$code=="INCO03")]="Social deprivation"
p$sumstats$name.nice[which(p$sumstats$code=="INSO02")]="Insomnia"
p$sumstats$name.nice[which(p$sumstats$code=="INTE03")]="Cognitive ability"
p$sumstats$name.nice[which(p$sumstats$code=="LONG07")]="Longevity"
p$sumstats[c("NEUR01","NEUR02"),]$name.nice<-"Neuroticism"
p$sumstats$name.nice[which(p$sumstats$code=="RISK01")]="General risk tolerance"
p$sumstats$name.nice[which(p$sumstats$code=="RISK02")]="Risktaking, automobile"
p$sumstats$name.nice[which(p$sumstats$code=="RISK03")]="Risktaking, sex"
p$sumstats$name.nice[which(p$sumstats$code=="SCHI04")]="Schizophrenia"
p$sumstats$name.nice[which(p$sumstats$code=="SUBJ01")]="Subjective well-being"
p$sumstats$name.nice[which(p$sumstats$code=="TIRE01")]="Self-reported tiredness"
p$sumstats$name.nice[which(p$sumstats$code=="WEIG04F")]="2013 Weight, female"
p$sumstats$name.nice[which(p$sumstats$code=="WEIG04M")]="2013 Weight, male"

##Add trait codes for publication rather than internal codes
p$sumstats$code.nice<-p$sumstats$code
p$sumstats["ADHD05",]$code.nice<-"ADHD"
p$sumstats["ANOR02",]$code.nice<-"ANOR"
p$sumstats["ANXI03",]$code.nice<-"ANXD"
p$sumstats["ANXI04",]$code.nice<-"ANXS"
p$sumstats["AUTI07",]$code.nice<-"AUTI"
p$sumstats["BODY11",]$code.nice<-"BMI2018"
p$sumstats["BODY14",]$code.nice<-"BMI2019"
p$sumstats["BODYTM",]$code.nice<-"BMI2013M"
p$sumstats["BIPO02",]$code.nice<-"BIPD"
p$sumstats["DEPR05",]$code.nice<-"MDD"
p$sumstats["DEPR5B",]$code.nice<-"MDDS"
p$sumstats["DEPR09",]$code.nice<-"MDDB"
p$sumstats["EDUC03",]$code.nice<-"EDUA"
p$sumstats["EXTR01",]$code.nice<-"EXTR"
p$sumstats["HEIG04F",]$code.nice<-"H2013F"
p$sumstats["HEIG04M",]$code.nice<-"H2013M"
p$sumstats["BODYT2M",]$code.nice<-"BMIGWIS"
p$sumstats["BODYT2MI",]$code.nice<-"BMIGWISI"
p$sumstats["INCO03",]$code.nice<-"SDEP"
p$sumstats["INSO02",]$code.nice<-"INSO"
p$sumstats["INTE03",]$code.nice<-"COGA"
p$sumstats["LONG07",]$code.nice<-"LONG"
p$sumstats["NEUR01",]$code.nice<-"NEUR1"
p$sumstats["NEUR02",]$code.nice<-"NEUR"
p$sumstats["RISK01",]$code.nice<-"RISK"
p$sumstats["RISK02",]$code.nice<-"RCAR"
p$sumstats["RISK03",]$code.nice<-"RSEX"
p$sumstats["SCHI04",]$code.nice<-"SCHI"
p$sumstats["SUBJ01",]$code.nice<-"SUBJ"
p$sumstats["TIRE01",]$code.nice<-"TIRE"
p$sumstats["WEIG04F",]$code.nice<-"W2013F"
p$sumstats["WEIG04M",]$code.nice<-"W2013M"

#INFO (genotype imputation) metadata
p$sumstats$hasinfo<-NA
p$sumstats["ANXI03",]$hasinfo<-T
p$sumstats["BIPO02",]$hasinfo<-T
p$sumstats["BODY14",]$hasinfo<-T
p$sumstats["BODYTM",]$hasinfo<-F
p$sumstats["DEPR05",]$hasinfo<-T
p$sumstats["DEPR5B",]$hasinfo<-T
p$sumstats["DEPR09",]$hasinfo<-F
p$sumstats["EDUC03",]$hasinfo<-F
p$sumstats["BODYT2MI",]$hasinfo<-F
p$sumstats["INSO02",]$hasinfo<-T
p$sumstats["NEUR02",]$hasinfo<-T
p$sumstats["SCHI04",]$hasinfo<-F


##Add a combined nice name plus code label
p$sumstats$name.nice.and_code<-paste0(p$sumstats$name.nice," (",p$sumstats$code.nice,")")

##Add nice dataset citation
p$sumstats$reference.nice<-NA_character_
p$sumstats["ADHD05",]$reference.nice <- "Demontis et al."
p$sumstats["ALCD03",]$reference.nice <- "Walters et al."
p$sumstats["ANOR02",]$reference.nice <- "Watson et al."
p$sumstats["ANXI03",]$reference.nice <- "Purves et al."
p$sumstats["ANXI04",]$reference.nice <- "Purves et al."
p$sumstats["AUTI07",]$reference.nice <- "Grove et al."
p$sumstats["BODY11",]$reference.nice <- "Yengo et al."
p$sumstats["BODY14",]$reference.nice <- "Pulit et al."
p$sumstats["BODYTM",]$reference.nice <- "Randall et al."
p$sumstats["BIPO02",]$reference.nice <- "Stahl et al."
p$sumstats["BVOL01",]$reference.nice <- "Jansen et al."
p$sumstats["DEPR05",]$reference.nice <- "Wray et al."
p$sumstats["DEPR5B",]$reference.nice <- "Wray et al."
p$sumstats["DEPR08",]$reference.nice <- "Wray et al."
p$sumstats["DEPR09",]$reference.nice <- "Howard et al."
p$sumstats["EDUC03",]$reference.nice <- "Lee et al."
p$sumstats["HEAL01",]$reference.nice <- "Harris et al."
p$sumstats["HEIG04F",]$reference.nice <- "Randall et al."
p$sumstats["HEIG04M",]$reference.nice <- "Randall et al."
p$sumstats["HEIG09",]$reference.nice <- "Yengo et al."
p$sumstats["INCO03",]$reference.nice <- "Hill et al."
p$sumstats["INSO02",]$reference.nice <- "Jansen et al."
p$sumstats["INSO03",]$reference.nice <- "Watanabe et al."
p$sumstats["NEUR02",]$reference.nice <- "Nagel et al."
p$sumstats["PTSD04",]$reference.nice <- "Nievergelt et al."
p$sumstats["RISK02",]$reference.nice <- "Karlsson Linnr et al."
p$sumstats["RISK03",]$reference.nice <- "Karlsson Linnr et al."
p$sumstats["SCHI04",]$reference.nice <- "Pardias et al."
p$sumstats["SUBJ01",]$reference.nice <- "Okbay et al."
p$sumstats["TIRE01",]$reference.nice <- "Deary et al."
p$sumstats["WEIG04F",]$reference.nice <- "Randall et al."
p$sumstats["WEIG04M",]$reference.nice <- "Randall et al."


#test
# tSumstats <- read.table(p$sumstats["NEUR01",]$cleanedpath,header=T, quote="\"",fill=T,na.string=c(".",NA,"NA",""))
# tSumstats$ptest<- 2*pnorm(abs(log(tSumstats$OR))/tSumstats$SE, lower.tail = F)
# tSumstats$ptest<- 2*pnorm(abs(tSumstats$OR)/tSumstats$SE, lower.tail = F)

##add information on wether a continous dependent variable was analysed using an OLS (linear) estimator. Used for the latent factor GWAS preparation step.
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="ADHD05")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="ALCD03")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="ANOR02")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="ANXI03")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="ANXI04")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="AUTI07")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="BODY11")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="BODY14")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="BIPO02")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="DEPR05")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="DEPR5B")]=F #check this!
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="DEPR08")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="DEPR09")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="EDUC03")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="EXTR01")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="HEAL01")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="HEIG04F")]=T #meta-analysis
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="HEIG04M")]=T #meta-analysis
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="HEIG09")]=T #meta-analysis
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="INCO03")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="INSO02")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="INTE03")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="LONG07")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="MIGR01")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="NEUR01")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="NEUR02")]=T #meta analysis
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="PTSD04")]=T #meta analysis
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="RISK01")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="RISK02")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="RISK03")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="SCHI04")]=F
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="SUBJ01")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="TIRE01")]=T
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="WEIG04F")]=T #meta analysis
p$sumstats$dependent_variable.OLS[which(p$sumstats$code=="WEIG04M")]=T #meta analysis

##add data on whether the effects were estimated with a linear regression rather than a logistic regression
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="ADHD05")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="ALCD03")]=T #from test
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="ANOR02")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="ANXI03")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="ANXI04")]=T #bgenie uses a linear estimator
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="AUTI07")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="BODY11")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="BODY14")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="BIPO02")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="DEPR05")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="DEPR5B")]=F #check this!
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="DEPR08")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="DEPR09")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="EDUC03")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="EXTR01")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="HEAL01")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="HEIG04F")]=F #check this (but probably not)
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="HEIG04M")]=F #check this (but probably not)
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="HEIG09")]=F #check this (but probably not)
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="INCO03")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="INSO02")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="INTE03")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="LONG07")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="MIGR01")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="NEUR01")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="NEUR02")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="PTSD04")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="RISK01")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="RISK02")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="RISK03")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="SCHI04")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="SUBJ01")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="TIRE01")]=F
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="WEIG04F")]=F #check this (but probably not)
p$sumstats$dependent_variable.linprob[which(p$sumstats$code=="WEIG04M")]=F #check this (but probably not)


##add data on whether the SEs are on a logistic scale or not
p$sumstats$se.logit[which(p$sumstats$code=="ADHD05")]=T #Tested
p$sumstats$se.logit[which(p$sumstats$code=="ALCD03")]=F #Tested
p$sumstats$se.logit[which(p$sumstats$code=="ANOR02")]=T #Tested
p$sumstats$se.logit[which(p$sumstats$code=="ANXI03")]=T #Tested
p$sumstats$se.logit[which(p$sumstats$code=="ANXI04")]=F #Tested
p$sumstats$se.logit[which(p$sumstats$code=="AUTI07")]=T #Tested
p$sumstats$se.logit[which(p$sumstats$code=="BODY11")]=F #NOT Tested!!!!!
p$sumstats$se.logit[which(p$sumstats$code=="BODY14")]=F #NOT Tested!!!!!
p$sumstats$se.logit[which(p$sumstats$code=="BIPO02")]=T #Tested
p$sumstats$se.logit[which(p$sumstats$code=="DEPR05")]=T #Tested
p$sumstats$se.logit[which(p$sumstats$code=="DEPR5B")]=T #NOT Tested!!!!!
p$sumstats$se.logit[which(p$sumstats$code=="DEPR08")]=T #Tested
p$sumstats$se.logit[which(p$sumstats$code=="DEPR09")]=F #NOT Tested!!!!!
p$sumstats$se.logit[which(p$sumstats$code=="EDUC03")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="EXTR01")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="HEAL01")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="HEIG04F")]=F #Continuous, not tested!
p$sumstats$se.logit[which(p$sumstats$code=="HEIG04M")]=F #Continuous, not tested!
p$sumstats$se.logit[which(p$sumstats$code=="HEIG09")]=F #Continuous, not tested!
p$sumstats$se.logit[which(p$sumstats$code=="INCO03")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="INSO02")]=T #Tested
p$sumstats$se.logit[which(p$sumstats$code=="INTE03")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="LONG07")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="MIGR01")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="NEUR01")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="NEUR02")]=F #Meta analysis
p$sumstats$se.logit[which(p$sumstats$code=="PTSD04")]=F #Meta analysis
p$sumstats$se.logit[which(p$sumstats$code=="RISK01")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="RISK02")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="RISK03")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="SCHI04")]=T #Tested
p$sumstats$se.logit[which(p$sumstats$code=="SUBJ01")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="TIRE01")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="WEIG04F")]=F #Continuous
p$sumstats$se.logit[which(p$sumstats$code=="WEIG04M")]=F #Continuous


#p$sumstats[which(p$sumstats$code=="ANXI04"),]$populationPrevalence<-0.2 #set this to larger than for ANXI03 as this phenotype is broader
#p$sumstats[which(p$sumstats$code=="DEPR08"),]$populationPrevalence<-0.2 #set this to larger than for DEPR05 as this phenotype is broader

#set order of datasets to sorted by code
p$sumstats<-p$sumstats[order(p$sumstats$code),]


#read manual metadata describing imputation stats etc
p$filepath.manualmeta <- file.path(p$folderpath.data,"manualAnnotations.tsv.txt")
if(file.exists(p$filepath.manualmeta)){
  manualMeta <- as.data.frame(shru::readFile(filePath = p$filepath.manualmeta))
  rownames(manualMeta)<-manualMeta$trait
  manualMeta$trait<-NULL
  p$sumstats[rownames(manualMeta),colnames(manualMeta)]<-manualMeta[rownames(manualMeta),colnames(manualMeta)]
  rm(manualMeta)
}


# p$filepath.manualmeta.impstats <- file.path(p$folderpath.data,"impstats.tsv.txt")
# 
# if(file.exists(p$filepath.manualmeta.impstats)){
#   manualMeta <- as.data.frame(shru::readFile(filePath = p$filepath.manualmeta.impstats))
#   rownames(manualMeta)<-manualMeta$trait
#   p$sumstats[rownames(manualMeta),c("h_cpu_ldimp","h_cpu_ssimp", "variants_raw","variants_ldimp","variants_ssimp")]<-manualMeta[rownames(manualMeta),c("h_ldimp","h_ssimp","n","n_ldimp","n_ssimp")]
#   rm(manualMeta)
# }



#save the project data
#saveRDS(project,file = file.path(p$folderpath.workingDirectory,paste0("project.",p$setup.code,".Rds")))

#View(p$sumstats)

```

## Setup gene sets
```{r Setup gene sets}
p$genesets<-data.frame(matrix(data=NA,nrow = 0,ncol = 0))

p$genesets["gtex8_rnaseq_median",c("name","filepath.raw")]<-c("GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_median_tpm.gct",file.path(p$folderpath.geneSet,"GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_median_tpm.gct.gz"))

p$genesets["brainspan_rnaseq_mean",c("name","filepath.raw")]<-c("BRAINSPAN_RNA-Seq_Gencode_v10_summarized_to_genes_genes_matrix_csv",file.path(p$folderpath.geneSet,"BRAINSPAN_RNA-Seq_Gencode_v10_summarized_to_genes_genes_matrix_csv","expression_matrix.csv"))


#p$genesets["msigdb.v7.5.1",c("name","filepath.raw")]<-c("All MSigDB",file.path(p$folderpath.geneSet,"msigdb.v7.5.1.symbols.gmt"))
p$genesets["msigdb.h.all.v7.5.1",c("name","filepath.raw")]<-c("MSigDB Hallmark",file.path(p$folderpath.geneSet,"msigdb.h.all.v7.5.1.symbols.gmt"))
p$genesets["msigdb.c2.cp.biocarta.v7.5.1",c("name","filepath.raw")]<-c("MSigDB Canonical pathways Biocarta",file.path(p$folderpath.geneSet,"msigdb.c2.cp.biocarta.v7.5.1.symbols.gmt"))
p$genesets["msigdb.c2.cp.kegg.v7.5.1",c("name","filepath.raw")]<-c("MSigDB Canonical pathways KEGG",file.path(p$folderpath.geneSet,"msigdb.c2.cp.kegg.v7.5.1.symbols.gmt"))
p$genesets["msigdb.c3.mir.mirdb.v7.5.1",c("name","filepath.raw")]<-c("MSigDB Regulatory target miRDB",file.path(p$folderpath.geneSet,"msigdb.c3.mir.mirdb.v7.5.1.symbols.gmt"))
p$genesets["msigdb.c3.tft.gtrd.v7.5.1",c("name","filepath.raw")]<-c("MSigDB Regulatory target GTRD",file.path(p$folderpath.geneSet,"msigdb.c3.tft.gtrd.v7.5.1.symbols.gmt"))
p$genesets["msigdb.c5.all.v7.5.1",c("name","filepath.raw")]<-c("MSigDB Ontology",file.path(p$folderpath.geneSet,"msigdb.c5.all.v7.5.1.symbols.gmt"))
p$genesets["msigdb.c7.all.v7.5.1",c("name","filepath.raw")]<-c("MSigDB Immunologic signature",file.path(p$folderpath.geneSet,"msigdb.c7.all.v7.5.1.symbols.gmt"))
p$genesets["msigdb.c8.all.v7.5.1",c("name","filepath.raw")]<-c("MSigDB Cell type",file.path(p$folderpath.geneSet,"msigdb.c8.all.v7.5.1.symbols.gmt"))

```

# Variable selection and project configuration
```{r GWAS sumstat dataset variable selection}

#selection based on specific traits
#p$sumstats.sel.code<-c("ANXI03","DEPR09","NEUR02")
#p$sumstats.sel.code<-c("ADHD05","ANXI04")
#p$sumstats.sel.code<-c("RISK02","RISK03","SCHI04","SUBJ01","TIRE01")
#p$sumstats.sel.code<-c("TIRE01")

#tests
#p$sumstats.sel.ssimp.code <- c("SCHI04","DEPR5B") #TEST
#p$sumstats.sel.ssimp.code <- c("ANXI03","BODY11","DEPR5B","SCHI04") #TEST
#p$sumstats.sel.ssimp.code <- c("ANXI03","BODY11","BIPO02","BVOL01","DEPR05","DEPR09","EDUC03","INSO02","NEUR02","SCHI04")
#full, but excluding BVOL01 as of now
p$sumstats.sel.ssimp.code<-c("ANXI03","BODY14","BIPO02","DEPR05","DEPR5B","DEPR09","EDUC03","INSO02","NEUR02","SCHI04")

p$sumstats.sel.bmigwas.code<-c("HEIG09","WEIG04F","WEIG04M")

p$sumstats.sel.ldscSel<-c("ANXI03","DEPR09","EDUC03","INSO02","NEUR02","SCHI04")

#p$sumstats.sel.gwis.code<-c("GWISI","BODYTM","BODY11") #TESTING!
#p$sumstats.sel.gwis.code<-c("GWISM","BODY11")
p$sumstats.sel.gwis.code<-c("ANXI03","BODYTM","BODY14","BIPO02","DEPR05","DEPR5B","DEPR09","EDUC03","BODYT2MI","INSO02","NEUR02","SCHI04")

p$sumstats.sel.raw.code<-c("ANXI03","BODYTM","BODY14","HEIG04M","WEIG04M","BIPO02","DEPR05","DEPR5B","DEPR09","EDUC03","INSO02","NEUR02","SCHI04")

p$sumstats.sel.code <- p$sumstats.sel.gwis.code


#all traits
#p$sumstats.sel.code<-c("ADHD05","ALCD03","ANOR02","ANXI03","ANXI04","AUTI07","BODY14","BODYTM","BODYTF","BIPO02", "BVOL01","DEPR05","DEPR5B","DEPR09","EDUC03","HEAL01","HEIG04F","HEIG04M","HEIG09","INCO03","INSO03","INSO02","NEUR02","PTSD04","RISK02","RISK03","SCHI04","SUBJ01","TIRE01","WEIG04F","WEIG04M")


p$sumstats.sel<-p$sumstats[which(p$sumstats$code %in% p$sumstats.sel.code),]
p$sumstats.sel.raw<-p$sumstats[which(p$sumstats$code %in% p$sumstats.sel.raw.code),]
p$sumstats.sel.bmigwas<-p$sumstats[which(p$sumstats$code %in% p$sumstats.sel.bmigwas.code),]
p$sumstats.sel.ssimp<-p$sumstats[which(p$sumstats$code %in% p$sumstats.sel.ssimp.code),]

#p$sumstats.sel$code_orig<-p$sumstats.sel$code
#p$sumstats.sel$code<-p$sumstats.sel$code.trait
#p$sumstats.sel[,c("code","name","name.nice","name.nice.and_code","reference.nice", "year","n_case","n_control","n_total","pmid","reference_doi","samplePrevalence","populationPrevalence","dependent_variable.OLS","dependent_variable.linprob","se.logit","mungedpath")]
p$k.sel<-nrow(p$sumstats.sel)
#View(p$sumstats.sel[,c("code","n_total","pmid","reference_doi","samplePrevalence","populationPrevalence","mungedpath")])

write.table(p$sumstats.sel[,c("code", "name.nice","year","reference.nice", "n_case","n_control","n_total","samplePrevalence","populationPrevalence", "reference_doi")], file = file.path(p$folderpath.workingDirectory,paste0(p$setup.code,".sumstatinfo.tsv")), quote = TRUE, sep = "\t", row.names = FALSE, col.names = TRUE)

#View(p$sumstats.sel)

```



# Raw data preparatory steps

## Create df with high-LD regions for GRCh37
```{r High-LD regions}
#From 10.1016/j.ajhg.2008.06.005
#via 10.1101/211821
p$highld_b37<-data.frame(matrix(data=NA,ncol=0,nrow=0))

p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(1,48287980,52287979)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(2,86088342,101041482)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(2,134666268,138166268)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(2,183174494,190174494)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(3,47524996,50024996)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(3,83417310,96017310)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(5,44464243,50464243)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(5,97972100,100472101)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(5,128972101,131972101)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(5,135472101,138472101)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(6,25392021,33392022)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(6,56892041,63942041)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(6,139958307,142458307)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(7,55225791,66555850)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(8,7962590,11962591)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(8,42880843,49837447)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(8,111930824,114930824)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(10,36959994,43679994)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(11,46043424,57243424)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(11,87860352,90860352)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(12,33108733,41713733)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(12,111037280,113537280)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(17,31799963,33389579)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(17,40928985,42139672)
p$highld_b37[(nrow(p$highld_b37)+1),c("CHR","BP","BP2")]<-c(20,32536339,35066586)

setDT(p$highld_b37)
setkeyv(p$highld_b37, cols = c("CHR","BP","BP2"))

p$filepath.highld_b38<-file.path(p$folderpath.data,"gene_mapping","highld_b38.gz")
if(file.exists(p$filepath.highld_b38)){
  p$highld_b38 <- fread(file = p$filepath.highld_b38, header = T)
} else {

  #create lift-over build 38- move to data/gene_mapping
  res <- supermunge(
    list_df = list(highld_b38=p$highld_b37),
    chainFilePath = "../data/alignment_chains/hg19ToHg38.over.chain.gz",
    pathDirOutput = p$folderpath.workingDirectory,
    lossless = T,
    process = F
    )
  p$highld_b38<-res
}
setkeyv(p$highld_b38, cols = c("CHR","BP","BP2"))
#View(res$last[order(res$last$CHR,res$last$BP),])

#p$highld_b37<-NULL

```

## Simulate GWAS
```{r Simulate GWAS}

if(p$clOptions$task=="sim") {
  #TBC
}

if(p$clOptions$task=="sim") quit(save = "no")

```


## OLD Simulate GWAS (incativated)
```{r Simulate GWAS OLD, eval=FALSE, purl=FALSE}
# if(p$clOptions$task=="hap") { 
#   
# 
#   
# }


if(p$clOptions$task=="sim") {
#devtools::install_github("chr1swallace/simGWAS")
#install.packages('hapsim')

#simulate haplotypes test  -from https://chr1swallace.github.io/simGWAS/articles/intro.html
set.seed(42)
nsnps <- 100
nhaps <- 1000
lag <- 5 # genotypes are correlated between neighbouring variants
maf <- runif(nsnps+lag,0.05,0.5) # common SNPs
laghaps <- do.call("cbind", lapply(maf, function(f) rbinom(nhaps,1,f)))
haps <- laghaps[,1:nsnps]
for(j in 1:lag) 
    haps <- haps + laghaps[,(1:nsnps)+j]
haps <- round(haps/matrix(apply(haps,2,max),nhaps,nsnps,byrow=TRUE))

snps <- colnames(haps) <- paste0("s",1:nsnps)
freq <- as.data.frame(haps+1)
freq$Probability <- 1/nrow(freq)
sum(freq$Probability)

#specify causal vriants
##Next, we need to specify the causal variants, and their effects on disease, as odds ratios. We create a vector CV with snp names that are a subset of column names in freq and a vector of odds ratios. In our simulated data, we pick two causal variants at random, with odds ratios of 1.4 and 1.2.
nExposed <- colSums(haps) #d1+h1
nNonexposed <- nhaps-nExposed #d0+h0

CV=sample(snps[which(colMeans(haps)>0.1)],2)
g1 <- c(1.004,1.002)

#variance tests
# #variance1: Two random variables (Bernoulli) E and D - PROBABLY WRONG!
# pE<-nExposed[CV]
# pD<-0.5 #this is set to 0.5 for the comparison
# varOR1<- (pE*(1-pE)+pE^2) * (pD*(1-pD)+pD^2) - (pE^2)*(pD^2)


#variance2: variance of log(OR): X  B(n, p) and Y  B(m, q), independent; 0 < p, q < 1, while n and m are large: 1/np + 1/(n(1-p)) + 1/mq + 1/(m(1-q))
#https://www.stat.berkeley.edu/~freedman/oddsrat.pdf
#p1<-0.7 #unknown
p0<-0.1

# OR<-(p1*(1-p1))/(p0*(1-p0))
# OR*(p0*(1-p0))=p1-p1^2
# p1^2-p1+OR*(p0*(1-p0))=0

#roots 1/2 +-sqrt( (-1/2)^2 - OR*(p0*(1-p0)))
p1 <- 1/2 + sqrt( (-1/2)^2 - g1*(p0*(1-p0)))
#p1 <- 1/2 - sqrt( (-1/2)^2 - g1*(p0*(1-p0)))
varLogOR <- 1/(nExposed[CV]*p1) + 1/(nExposed[CV]*(1-p1)) + 1/(nNonexposed[CV]*p0) + 1/(nNonexposed[CV]*(1-p0))



#old
#varLogOR <- ((1/g1)+1)/nExposed[CV] + (g1+1)/nExposed[CV] + 4/nNonexposed[CV]

#heritability is
sum(varLogOR) #variance formulas for sum of random variables

#using d0/h0=1:
#OR=d1/h1, n1=d1+h1 => d1 = n1/(1/OR+1)
#OR=d1/h1, n1=d1+h1 => h1 = n1/(OR+1)
#OR=d1/h1, n0=d0+h0, d0/h0=1 => d0=h0=n0/2
#var(log(OR))=1/d1+1/h1+1/d0+1/h0 = ((1/OR)+1)/n1 + (OR+1)/n1 + 4/n0


##Now we simulate the results of a GWAS. There are two key functions, makeGenoProbList calculates genotype probabilities at each SNP conditional on genotypes at the causal variants, then est_statistic generates the vector of Z scores across all SNPs, conditional on the causal variants and their odds ratios.
FP <- simGWAS::make_GenoProbList(snps=snps,W=CV,freq=freq)
zexp <- simGWAS::expected_z_score(N0=10000, # number of controls
              N1=10000, # number of cases
              snps=snps, # column names in freq of SNPs for which Z scores should be generated
              W=CV, # causal variants, subset of snps
              gamma.W=log(g1), # odds ratios
              freq=freq, # reference haplotypes
              GenoProbList=FP) # FP above


#new routine - simulate random variant effects from a specified trait heritability measure

#p$nThread<-6
#test - generate haplotypes with hapsim
filepath.varlist <- normalizePath(file.path(p$folderpath.data.variantLists,"hc1kgp3.b38.eur.l2.jz2023.gz")) #use the new version here rather than the old
varlist<-readFile(filepath.varlist)
gwasColumns<-stdGwasColumnNames(colnames(varlist), ancestrySetting = "EUR")
gwasColumns$orig
gwasColumns$std
colnames(varlist)<-gwasColumns$std
varlist<-varlist[FRQ>0,]
randomTraitWeightsTot<-sqrt(rchisq(n=nrow(varlist), ncp = 1, df = 1))
names(randomTraitWeightsTot)<-varlist$SNP

heritabilityPopulationM <- nrow(varlist) #nrow(varlist[FRQ>0.05,]) #improve this value a bit, what is the reference value to use here? nr of non-rare variants in a reference population?

th<-0.05 #target heritability
ratioCausal <- 0.2
initialMeanOR<-1.000001
targetMeanHeritabilityPerCausalVariant <- th/(heritabilityPopulationM*ratioCausal)
targetMeanHeritabilityPerVariant <- th/(heritabilityPopulationM)
nSimCas<-500000
nSimCon<-500000
nSimTot<-nSimCas+nSimCon


#genome-wide OR-table
ORtable<-data.frame(SNP=varlist$SNP,initialMeanOR=initialMeanOR,w=randomTraitWeightsTot)
setDT(ORtable)
setkeyv(ORtable, cols = c("SNP"))
ORtable[sample(.N, ratioCausal*nrow(ORtable)),causal:=T]

filepath.individuals <- file.path(p$folderpath.data,"data","reference_panel","hc1kgp3.b38.plink","hc1kgp3.b38.eur.jz2023.vcf.gz")
filepath.test.individuals <- file.path(p$folderpath.workingDirectory,"test.individuals.Rds")  #test
individuals.all <- fread(file = filepath.individuals, na.strings =c(".",NA,"NA",""), encoding = "UTF-8", header = T, fill = T, blank.lines.skip = T, data.table = T, nThread = p$nThread, showProgress = T, skip =  31, nrows = 10000) #test
individuals.all <- readRDS(file=filepath.test.individuals) #test
rownames(individuals.all)<-individuals.all$ID #does this do anything when DT?
setkeyv(individuals.all, cols = c("ID"))

n.individuals<-ncol(individuals.all)-9
m.blockVariants<-nrow(individuals.all)

#freq <- as.data.frame(matrix(data=NA,nrow = n.individuals, ncol = m.blockVariants))
freq<-t(individuals.all[,10:ncol(individuals.all)][,ifelse(.SD=="0/0",0,ifelse(.SD=="1/1",2,1))])
colnames(freq)<-individuals.all$ID
#rownames(freq)<-colnames(individuals.all)[10:ncol(individuals.all)]
#setDT(freq)

#saveRDS(object = individuals.all, file = filepath.test.individuals)


randomTraitWeights<-randomTraitWeightsTot[colnames(freq)]
nExposed<-colSums(freq) #this is an approximation, counting the homozygous alt allele twice
nNonexposed<-n.individuals-nExposed
exposedRatio<-nExposed/n.individuals
nonexposedRatio<-nNonexposed/n.individuals
#ORtable.chunk<- ORtable[SNP %in% individuals.all$ID,]
freq.sum<-data.frame(SNP=individuals.all$ID,nExposed=colSums(freq),nNonexposed=n.individuals-nExposed,exposedRatio=nExposed/n.individuals,
nonexposedRatio=nNonexposed/n.individuals)
setDT(freq.sum)
setkeyv(freq.sum, cols = c("SNP"))


ORtable.chunk <- merge(x = ORtable, y = freq.sum, by = "SNP", all = F)
ORtable.chunk[,OR:=NA_real_]

p1<-NA #unknown
p0<-0.1 #fix setting
nSimExposedMean<-nSimTot*mean(ORtable.chunk$exposedRatio)
nSimNonexposedMean<-nSimTot-nSimExposedMean

# tVariance <- 1/(nSimExposedMean*p1) + 1/(nSimExposedMean*(1-p1)) + 1/(nSimNonexposedMean*p0) + 1/(nSimNonexposedMean*(1-p0))
# tVariance - 1/(nSimNonexposedMean*p0) - 1/(nSimNonexposedMean*(1-p0))<- 1/(nSimExposedMean*p1) + 1/(nSimExposedMean*(1-p1)) 
# (nSimExposedMean*p1)*(nSimExposedMean*(1-p1)) 
# = 2/(tVariance - 1/(nSimNonexposedMean*p0) - 1/(nSimNonexposedMean*(1-p0)))
# nSimExposedMean^2+p1*nSimExposedMean+nSimExposedMean-nSimExposedMean*p1+p1-p1^2
# = 2/(tVariance - 1/(nSimNonexposedMean*p0) - 1/(nSimNonexposedMean*(1-p0)))
# p1^2-p1-nSimExposedMean-nSimExposedMean^2+2/(tVariance - 1/(nSimNonexposedMean*p0) - 1/(nSimNonexposedMean*(1-p0)))


#p1<- 1/2 + sqrt( (-1/2)^2 - (nSimExposedMean-nSimExposedMean^2+2/(targetMeanHeritabilityPerCausalVariant - 1/(nSimNonexposedMean*p0) - 1/(nSimNonexposedMean*(1-p0)) ) ) )
#this does not work


#roots 1/2 +-sqrt( (-1/2)^2 - OR*(p0*(1-p0)))
p1 <- 1/2 + sqrt( (-1/2)^2 - initialMeanOR*(p0*(1-p0)))
#p1 <- 1/2 - sqrt( (-1/2)^2 - g1*(p0*(1-p0)))

varLogOR <- 1/(nSimExposedMean*p1) + 1/(nSimExposedMean*(1-p1)) + 1/(nSimNonexposedMean*p0) + 1/(nSimNonexposedMean*(1-p0))
# nonexposedRatio<-(1-exposedRatio)
# tVariance<-((1/initialMeanOR)+1)/(exposedRatio*nSimTot) + (initialMeanOR+1)/(exposedRatio*nSimTot) + 4/(nonexposedRatio*nSimTot)
#tVariance <- 1/(nSimTot*pE) + 1/(nSimTot*(1-pE)) + 1/(nSimTot*pD) + 1/(nSimTot*(1-pD))

ORtable.chunk[,OR:=initialMeanOR*w]


#hypothetical variance in the target simulation using the same proportions of exposed and non-exposed individuals as in the haplotype sample
#cVariance<-((1/initialMeanOR)+1)/(exposedRatio*nSimTot) + (initialMeanOR+1)/(exposedRatio*nSimTot) + 4/(nonexposedRatio*nSimTot)

ORtable.chunk[,variance:=((1/OR)+1)/(exposedRatio*eval(nSimTot)) + (OR+1)/(exposedRatio*eval(nSimTot)) + 4/(nonexposedRatio*eval(nSimTot))]

sum(cVariance[is.finite(cVariance)])
mean(cVariance[is.finite(cVariance)])


names(varLogOR)<-snps
#check obtained heritability mean
mean(varLogOR)*heritabilityPopulationM

#roots  #does not work
# a <- varLogOR[CV]
# b <-  (4*(nExposed[CV]-1)/nNonexposed[CV])-varLogOR[CV]*nExposed[CV]
# c <- nExposed[CV]
# 
# d1r1 <- abs(((-b)+sqrt(b^2-4*a*c))/(2*a))
# d1r2 <- abs(((-b)-sqrt(b^2-4*a*c))/(2*a))
# 
# g1 <- abs(d1r1/(nExposed[CV]-d1r1))
#test
#((1/g1)+1)/nExposed[CV] + (g1+1)/nExposed[CV] + 4/nNonexposed[CV] 


#run manually

# Create SNP-list for simulated GWAS - not used as the GCTA simulation does not seem to work using the list

# p$simTemplate <- shru::readFile(filePath = file.path(p$folderpath.data.sumstats.munged,"NEUR02.gz"),nThreads = p$nThread) #based on NEUR02
# 
# fwrite(x = p$simTemplate[P<1e-2,c("SNP")], file = file.path(p$folderpath.workingDirectory,"neuro02.sim.varlist.gz"), sep = "\t",append = F, na = ".",nThread = p$nThread, col.names = F)
  
}

if(p$clOptions$task=="hap" | p$clOptions$task=="sim") quit(save = "no")

```


## GWAS summary statistics munge - if needed
Munging of GWAS sumstat datasets. The summary statistics is also prepared for latent factor GWAS (previously, the sumstats()-function of the GSEM package). Here reference alleles are standardised across all datasets, and SNP effects and their s.e. are scaled to match unit-variance phenotypes.
```{r GWAS sumstat munge}
#test
#p$clOptions$task<-"munge"

p$filepath.lfgwas.sumstats<-file.path(p$folderpath.workingDirectory,paste0("lfGWAS.sumstats.",p$setup.code,".Rds"))
p$filepath.lfgwas.sumstats_full<-file.path(p$folderpath.workingDirectory,paste0("lfGWAS.sumstats_full.",p$setup.code,".Rds"))
p$filepath.munge.meta<-file.path(p$folderpath.workingDirectory,paste0("munge.meta.",p$setup.code,".Rds"))
p$munge<-c()

if(p$clOptions$task=="munge" & (!all(file.exists(p$sumstats.sel$mungedpath)) | !is.na(p$clOptions$task_argument))){
  
  #test
  #p$clOptions$task_argument<-"BIPO02"
  if(!is.na(p$clOptions$task_argument)){
    #task argument sets the specific dataset to munge
    
    cat("\nSet to munge with arg",p$clOptions$task_argument,"\n")
    p$munge$filesToUse<-p$sumstats.sel[which(p$sumstats.sel$code==p$clOptions$task_argument),]$cleanedpath
    p$munge$traitNamesToUse<-p$sumstats.sel[which(p$sumstats.sel$code==p$clOptions$task_argument),]$code
    p$munge$NToUse<-p$sumstats.sel[which(p$sumstats.sel$code==p$clOptions$task_argument),]$n_total
    
  } else {
    #defaults
    p$munge$filesToUse<-p$sumstats.sel$cleanedpath
    p$munge$traitNamesToUse<-p$sumstats.sel$code
    p$munge$NToUse<-p$sumstats.sel$n_total
  }
  
  # cat("\nMunging with:\n")
  # print(p$munge$filesToUse)
  # print(p$filepath.SNPReference.hc1kg)
  # print(p$folderpath.data.mvLDSC.ld.1kg)
  # print(p$munge$traitNamesToUse)
  # print(p$munge$NToUse)
  # print(p$munge$OLSToUse)
  # print(p$munge$se.logitToUse)
  # print(p$munge$propToUse)
  # print(p$folderpath.data.sumstats.munged)
  
  #mask<-c(F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,T,T,T,T,T)
  #munging with no filters applied - only munge without imputation!
  
  p$munge$results <- supermunge(
            filePaths = p$munge$filesToUse,
            rsSynonymsFilePath = p$filepath.rsSynonyms.dbSNP151,
            refFilePath = p$filepath.SNPReference.hc1kg,
            traitNames = p$munge$traitNamesToUse,
            chainFilePath = file.path(p$folderpath.data,"alignment_chains","hg19ToHg38.over.chain.gz"),
            N = p$munge$NToUse,
            pathDirOutput = p$folderpath.data.sumstats.munged,
            ancestrySetting = "EUR"
              )
    
  
  p$munge$results$meta %>% gt()
  gtsave(data = (p$munge$results$meta %>% gt()), filename = file.path(p$folderpath.workingDirectory,"munge.meta.rtf"))
  saveRDS(object = p$munge$results$meta, file = p$filepath.munge.meta)
  
  
  
} else if(file.exists(p$filepath.munge.meta)){
  p$munge$results$meta<-readRDS(file=p$filepath.munge.meta)
  print("Read munging results metadata from previous munge result file.")
}

print(p$munge$results$meta)


if(p$clOptions$task=="impute"
   #& !all(file.exists(p$sumstats.sel$imputedpath))
   ){
  #test
  #p$clOptions$task_argument<-"ANXI03"
  if(!is.na(p$clOptions$task_argument)){
    #task argument sets the specific dataset to munge
    
    cat("\nSet to IMPUTE with arg",p$clOptions$task_argument,"\n")
    p$munge$filesToUse<-p$sumstats.sel$mungedpath[which(p$sumstats.sel$code==p$clOptions$task_argument)]
    p$munge$traitNamesToUse<-p$sumstats.sel$code[which(p$sumstats.sel$code==p$clOptions$task_argument)]
    #p$munge$NToUse<-p$sumstats.sel$n_total[which(p$sumstats.sel$code==p$clOptions$task_argument)]
    
  } else {
    #defaults
    p$munge$filesToUse<-p$sumstats.sel$mungedpath
    p$munge$traitNamesToUse<-p$sumstats.sel$code
    p$munge$NToUse<-p$sumstats.sel$n_total
  }
  
  
  #Munge with imputation
  p$munge$results <- supermunge(
            filePaths = p$munge$filesToUse,
            refFilePath = p$filepath.SNPReference.hc1kg,
            traitNames = p$munge$traitNamesToUse,
            imputeFromLD=T,
            # imputeFrameLenBp = 500000, #use default setting of 0.5 CM
            # imputeFrameLenCM=NULL,
            filter.region.imputation.df=p$highld_b38, #provide the high-ld regions to not use for imputation
            #N = p$munge$NToUse,
            #test = T, #REMOVE THIS!
            imputeFromLD.validate.q=1.0, #validate with all of the original dataset
            pathDirOutput = p$folderpath.data.sumstats.imputed.05cm,
            ancestrySetting = "EUR"
              )
}

if(file.exists(p$filepath.lfgwas.sumstats)) {
  # p$lfGWAS$sumstats<-readRDS(file=p$filepath.lfgwas.sumstats)
  # print("Read summary statistics for latent factor GWAS from file.")
  
  #compare with genomic SEM produced sumstats 
  # p$filepath.lfgwas.sumstats2<-file.path(p$folderpath.workingDirectory,paste0("lfGWAS.sumstats.setup4.Rds"))
  # p$lfGWAS$sumstats2<-readRDS(file=p$filepath.lfgwas.sumstats2)
  # 
  # View(p$lfGWAS$sumstats[which(p$lfGWAS$sumstats$SNP==c("rs1000000","rs10000013"))])
  
  # colBeta<-colnames(p$lfGWAS$sumstats)[grep("^BETA\\.", ignore.case = TRUE,colnames(p$lfGWAS$sumstats))]
  # colSE<-colnames(p$lfGWAS$sumstats)[grep("^SE\\.", ignore.case = TRUE,colnames(p$lfGWAS$sumstats))]
  # colBeta2<-colnames(p$lfGWAS$sumstats2)[grep("^BETA\\.", ignore.case = TRUE,colnames(p$lfGWAS$sumstats2))]
  # colSE2<-colnames(p$lfGWAS$sumstats2)[grep("^SE\\.", ignore.case = TRUE,colnames(p$lfGWAS$sumstats2))]
  # p$lfGWAS$sumstats<-as.data.frame(p$lfGWAS$sumstats)
  # for(iCol in 1:length(colBeta)){
  #   #iCol<-1
  #   print(colBeta[iCol])
  #   cBeta<-p$lfGWAS$sumstats[,colBeta[iCol]]
  #   cSE<-p$lfGWAS$sumstats[,colSE[iCol]]
  #   cBeta2<-p$lfGWAS$sumstats2[,colBeta2[iCol]]
  #   cSE2<-p$lfGWAS$sumstats2[,colSE2[iCol]]
  #   
  #   cat(mean(cBeta2,na.rm=T),"(",median(cSE2,na.rm=T),")\n")
  #   cat(mean(cBeta,na.rm=T),"(",median(cSE,na.rm=T),")\n")
  #   
  #   cat(max(abs(cBeta2),na.rm=T),"(",max(cSE2,na.rm=T),")\n")
  #   cat(max(abs(cBeta),na.rm=T),"(",max(cSE,na.rm=T),")\n")
  #   
  #   cat(min(abs(cBeta2),na.rm=T),"(",min(cSE2,na.rm=T),")\n")
  #   cat(min(abs(cBeta),na.rm=T),"(",min(cSE,na.rm=T),")\n")
  #   
  # }
  
  
  #Compare with old munged ANXI04
  #ssANXI04_old <- read.table(file.path(p$folderpath.data.sumstats.munged,"ANXI04_old.gz"),header=T, quote="\"",fill=T,na.string=c(".",NA,"NA",""))
  #setDT(ssANXI04_old)
  #setkeyv(ssANXI04_old, cols = c("SNP","BP","CHR"))
  #
  # ssANXI04 <- read.table(file.path(p$folderpath.data.sumstats.munged,"ANXI04.gz"),header=T, quote="\"",fill=T,na.string=c(".",NA,"NA",""))
  # setDT(ssANXI04)
  # setkeyv(ssANXI04, cols = c("SNP","BP","CHR"))
  #
  # ssANXI04.merged.snp<-ssANXI04[ssANXI04_old, on=c(SNP='SNP'), nomatch=0]
  # View(ssANXI04.merged.snp[1:100000,c("SNP","BP","CHR","A1","A2","i.A1","i.A2")])
  # sum(!(ssANXI04.merged.snp$A1==ssANXI04.merged.snp$i.A1 & ssANXI04.merged.snp$A2==ssANXI04.merged.snp$i.A2))
  # View(ssANXI04.merged.snp[1:100000,c("SNP","BP","CHR","EFFECT","i.EFFECT","Z","i.Z","P","i.P")])
  # View(ssANXI04.merged.snp[1:100000,c("SNP","BP","CHR","N","i.N")])

  # head(p$lfGWAS$sumstats)
  
}

if(p$clOptions$task=="munge2"){
  
  p$munge$results<-supermunge(
    filePaths = p$sumstats.sel$mungedpath,
    refFilePath = p$filepath.SNPReference.hc1kg,
    traitNames = p$sumstats.sel$code,
    filter.info = 0.6,
    filter.maf = 0.01,
    N = p$sumstats.sel$n_total,
    filter.region.df = p$highld_b38,
    #filter.chr = list(1,2,6,7,9,11),
    pathDirOutput = p$folderpath.data.sumstats.export.cleaned.nohighld
    )

  p$munge$results<-supermunge(
    filePaths = p$sumstats.sel$imputedpath.500,
    refFilePath = p$filepath.SNPReference.hc1kg,
    traitNames = p$sumstats.sel$code,
    filter.info = 0.6,
    filter.maf = 0.01,
    N = p$sumstats.sel$n_total,
    filter.region.df = p$highld_b38,
    #filter.chr = list(1,2,6,7,9,11),
    pathDirOutput = p$folderpath.data.sumstats.export.500.cleaned.nohighld
    )

  p$munge$results<-supermunge(
    filePaths = p$sumstats.sel.ssimp$imputedpath.ssimp,
    refFilePath = p$filepath.SNPReference.hc1kg,
    traitNames = p$sumstats.sel.ssimp$code,
    filter.info = 0.6,
    filter.maf = 0.01,
    N = p$sumstats.sel.ssimp$n_total,
    filter.region.df = p$highld_b38,
    filter.chr = list(1,2,6,7,9,11),
    pathDirOutput = p$folderpath.data.sumstats.export.ssimp.cleaned.nohighld
    )

  print("Done exporting cleaned + munged + no high LD regions")
} else if(p$clOptions$task=="composite"){
  p$munge$results<-supermunge(
    filePaths = p$sumstats.sel$imputedpath,
    refFilePath = p$filepath.SNPReference.hc1kg,
    traitNames = p$sumstats.sel$code,
    produceCompositeTable = T,
    process = F,
    standardiseEffectsToExposure = T,
    writeOutput = F,
    N = p$sumstats.sel$n_total,
    OLS=p$sumstats.sel$dependent_variable.OLS,
    linprob=p$sumstats.sel$dependent_variable.linprob,
    se.logit = p$sumstats.sel$se.logit,
    prop=(p$sumstats.sel$n_case/p$sumstats.sel$n_total),
    info.filter = 0.55
#    maf.filter = 0.001
    
    ) #remove rare variants only
    
  p$lfGWAS$sumstats<-p$munge$results$composite

  saveRDS(object = p$lfGWAS$sumstats, file = p$filepath.lfgwas.sumstats)
  print("Done preparing summary statistics for latent factor GWAS. The result should have been saved to a file.")
}

if(p$clOptions$task=="munge" ||  p$clOptions$task=="impute" || p$clOptions$task=="munge2" || p$clOptions$task=="composite") quit(save = "no")

```

## Format SSIMP munged datasets
```{r ssimp munged format}

if(p$clOptions$task=="ssimpformat"){
  
  cat("\nFormatting SSIMP munged datasets!\n")
  
  for(cTraitCode in p$sumstats.sel.ssimp.code) {
      cSumstats <- shru::readFile(filePath = p$sumstats.sel[cTraitCode,]$mungedpath, nThreads = 5)
      cSumstats[,BP:=NULL][,CHR:=NULL]
      fwrite(x = cSumstats,file = file.path(p$folderpath.data.sumstats.munged.4ssimp,paste0(cTraitCode,".gz")),append = F,quote = F,sep = "\t",col.names = T)
  }
  if(p$clOptions$task=="ssimpformat") quit(save = "no")
}

```


## Merge SSIMP imputed datasets

Delete the previous results first or they will be merged together with the intermediate results files!!!!

```{r GWAS imputed merge}

if(p$clOptions$task=="merge"){
  
  cat("\nMerging SSIMP fractured datasets!\n")
  
  #cRef <- shru::readFile(filePath = p$filepath.SNPReference.hc1kg,nThreads = 5)
  
  for(cTraitCode in p$sumstats.sel.ssimp.code) {
    #cTraitCode <- "NEUR02"
    #cTraitCode <- "BODY11"
    files<-list.files(path = p$folderpath.data.sumstats.imputed.ssimp, pattern = paste0("^",cTraitCode,"\\..+"))
    print(files)
    fullTraitList<-lapply(files, function(x){
      shru::readFile(filePath = file.path(p$folderpath.data.sumstats.imputed.ssimp,x),nThreads = 5)
    }
    )
    
    if(length(fullTraitList)>0){
      fullTrait <- rbindlist(l = fullTraitList, use.names = T, fill = T)
      rm(fullTraitList)
      #print(colnames(fullTrait))
      #test
      # fullTrait<-shru::readFile(filePath = p$sumstats.sel[cTraitCode,]$imputedpath.ssimp,nThreads = 5)
      
      #fullTrait
      
      colnames(fullTrait)[colnames(fullTrait)=="LD_IMP"]<-"LD_IMP.old"
      colnames(fullTrait)[colnames(fullTrait)=="Z"]<-"Z.old"
      colnames(fullTrait)[colnames(fullTrait)=="N"]<-"N.old"
      colnames(fullTrait)[colnames(fullTrait)=="P"]<-"P.old"
      colnames(fullTrait)[colnames(fullTrait)=="CHR"]<-"CHR.old"
      colnames(fullTrait)[colnames(fullTrait)=="BP"]<-"BP.old"
      colnames(fullTrait)[colnames(fullTrait)=="FRQ"]<-"FRQ.old"
      
      colnames(fullTrait)[colnames(fullTrait)=="r2.pred"]<-"LD_IMP"
      colnames(fullTrait)[colnames(fullTrait)=="z_imp"]<-"Z"
      colnames(fullTrait)[colnames(fullTrait)=="N.imp"]<-"N"
      colnames(fullTrait)[colnames(fullTrait)=="P.imp"]<-"P"
      
      print(colnames(fullTrait))
      
      
      #fix faulty SSimp output 
      mungedTrait <- shru::readFile(filePath = p$sumstats.sel[cTraitCode,]$mungedpath,nThreads = 5)
      #rename mungedTrait columns
      colnames(mungedTrait) <- paste0(colnames(mungedTrait),".m")
      print(colnames(mungedTrait))
      
      
      mergedFullTrait <- merge(fullTrait,mungedTrait, by.x="SNP", by.y = "SNP.m", all = T)
      print(colnames(mergedFullTrait))
      
      mergedFullTrait[(is.na(Z)&!is.na(Z.m)) || P>P.m,c("A1","A2","Z","P","N", "LD_IMP"):=list(A1.m,A2.m,Z.m,P.m,N.m,1.0)]
      mergedFullTrait[is.na(chr),chr:=CHR.m][is.na(pos),pos:=BP.m][is.na(maf),maf:=FRQ.m]
      
      mergedFullTrait<-mergedFullTrait[,.(SNP,A1,A2,CHR=chr,BP=pos,FRQ=maf,Z=Z,N=N,P=P,LD_IMP)]
      
      print(colnames(mergedFullTrait))
      
      shru::supermunge(list_df = list(mergedFullTrait) , traitNames = cTraitCode, parse=F, process = F, nThreads = 5, pathDirOutput = p$folderpath.data.sumstats.imputed.ssimp)
      
      rm(mergedFullTrait)
      rm(fullTrait)
      rm(mungedTrait)
    }
    
    rm(fullTraitList)
  }
  
  #rm(cRef)
  
  if(p$clOptions$task=="merge") quit(save = "no")
  
}



```

## GWIS of height and weight into BMI

```{r GWIS}

if(p$clOptions$task=="gwis"){
  
  cat("\nPerforming GWIS of height and weight\n")
  
  nCode = "BODYT2MI" #what to call the new sumstat
  
  
  
  # original GWIS implementation
  
  Weight_mean <- 83.858621
  Height_mean <- 1.81942192
  
  
  Weight_SD <- 12.981540
  Height_SD <- 0.07325379
  
  HW_cor <- 0.370959

  # Approximate the SD for BMI:
  BMI_SD <- deltamethod(~x1/(x2^2) ,mean=c(Weight_mean,Height_mean),cov=diag(c(Weight_SD,Height_SD)) %*% matrix(c(1,HW_cor,HW_cor,1),2,2) %*% diag(c(Weight_SD,Height_SD )))

  GIANT_Height_Men <- as.data.frame(shru::readFile(file.path(p$folderpath.data.sumstats.imputed.05cm, "HEIG04M.gz")))
  GIANT_Weight_Men <- as.data.frame(shru::readFile(file.path(p$folderpath.data.sumstats.imputed.05cm, "WEIG04M.gz")))
  
  if(any(colnames(GIANT_Height_Men)=="SINFO") & any(colnames(GIANT_Weight_Men)=="SINFO")){
    #TODO
    
    #reset validation SINFO
    #head(GIANT_Height_Men[GIANT_Height_Men$BETA!=GIANT_Height_Men$BETA.I | GIANT_Height_Men$SE!=GIANT_Height_Men$SE.I,])
    
    #y1[,IMPUTED:=(is.finite(BETA.I) & BETA.I==BETA)] #condition used in ldscpp
    GIANT_Height_Men$IMPUTED<-is.finite(GIANT_Height_Men$BETA.I) & GIANT_Height_Men$BETA.I==GIANT_Height_Men$BETA
    GIANT_Weight_Men$IMPUTED<-is.finite(GIANT_Weight_Men$BETA.I) & GIANT_Weight_Men$BETA.I==GIANT_Weight_Men$BETA
    
    GIANT_Height_Men$SINFO<-ifelse(GIANT_Height_Men$IMPUTED==T,GIANT_Height_Men$SINFO,NA_real_)
    GIANT_Weight_Men$SINFO<-ifelse(GIANT_Weight_Men$IMPUTED==T,GIANT_Weight_Men$SINFO,NA_real_)
    
    # GIANT_Height_Men<-GIANT_Height_Men[GIANT_Height_Men$FRQ>0.01 & (GIANT_Height_Men$SINFO>0.1 | is.na(GIANT_Height_Men$SINFO)),]
    # GIANT_Weight_Men<-GIANT_Weight_Men[GIANT_Weight_Men$FRQ>0.01 & (GIANT_Weight_Men$SINFO>0.1 | is.na(GIANT_Weight_Men$SINFO)),]
  }

  # GIANT_Height_Men <- as.data.frame(shru::readFile(file.path(p$folderpath.data.sumstats.munged, "HEIG04M.gz")))
  # GIANT_Weight_Men <- as.data.frame(shru::readFile(file.path(p$folderpath.data.sumstats.munged, "WEIG04M.gz")))

  GIANT_Combined <- merge(GIANT_Weight_Men,GIANT_Height_Men,by=1)
  rm(GIANT_Height_Men)
  rm(GIANT_Weight_Men)
  # compute new beta:

    # Rewscale beta and SE:
    Bw <- Weight_SD *  GIANT_Combined$BETA.x
    Bh <- Height_SD *  GIANT_Combined$BETA.y
  
  
    SEw <- Weight_SD *  GIANT_Combined$SE.x
    SEh <- Height_SD *  GIANT_Combined$SE.y
  
    # Frequency:
    FRQ <- as.vector(GIANT_Combined$FRQ.x)
    
  
    # Compute af weighted mean of 2 aproximated beta's
    AF1 <- 2*FRQ*(1-FRQ) / (2*FRQ*(1-FRQ) + FRQ^2)
  
    B1 <- ( ((Weight_mean  + Bw )/ (Height_mean + Bh)^2) - (Weight_mean /(Height_mean^2)))
  
    AF2 <- ((FRQ^2) ) / (2*FRQ*(1-FRQ) + FRQ^2)
  
    B2 <-(((Weight_mean  + 2*Bw) / ((Height_mean + 2*Bh)^2)) - ( Weight_mean /(Height_mean^2))) / 2
  
  
    new.beta.us <-    (AF1 * B1 + AF2 * B2 )
    new.beta <- (new.beta.us / BMI_SD) 
  
  # compute new SE:
  
    N <- length(new.beta)
    cat("\nGWIS has ", N,  " rows after filters.\n\n")
    #deltamethod
    cat("\nComputing SEs with the deltamethod...")
  
    new.se <- matrix(NA,nrow=length(Bh),ncol=1)
    for(i in 1:length(new.beta)){
      if(i %% 100000 == 0) cat("*") else if(i %% 10000 == 0) cat(".")
      
      AF1_l <- AF1[i]
      AF2_l <- AF2[i] 
  
      new.se[i]<- deltamethod(~( AF1_l*(((Weight_mean+x1)/((Height_mean+x2)^2)) -(Weight_mean/Height_mean^2)) + (AF2_l*(((Weight_mean+2*x1)/((Height_mean+2*x2)^2)) -(Weight_mean/Height_mean^2)))/2)/BMI_SD, mean=c(Bw[i],Bh[i]),
                               
                               cov=cbind(rbind((SEw[i])^2,           (SEw[i])*HW_cor*(SEh[i])),
                                         rbind((SEw[i])*HW_cor*(SEh[i]),      (SEh[i])^2)))
      }
  
  
  
  # build an output file:
  
  GWIS_BMI <- as.data.frame(cbind(GIANT_Combined$SNP,GIANT_Combined$CHR.x,GIANT_Combined$BP.x,GIANT_Combined$A1.x,GIANT_Combined$A2.x,new.beta,new.se,(pchisq((new.beta/new.se)^2,1,lower.tail=F)),(GIANT_Combined$N.x+GIANT_Combined$N.y)/2))
  
  colnames(GWIS_BMI) <- c("SNP","CHR","BP","A1","A2","BETA","SE","P","N")
  
  if(any(colnames(GIANT_Combined)=="SINFO.x") | any(colnames(GIANT_Combined)=="SINFO.y")){
    GWIS_BMI$SINFO<-(GIANT_Combined$SINFO.x+GIANT_Combined$SINFO.y)/2
  }
  
  GWIS_BMI$CHR<-as.integer(GWIS_BMI$CHR)
  GWIS_BMI$BP<-as.integer(GWIS_BMI$BP)
  GWIS_BMI$P<-as.numeric(GWIS_BMI$P)
  
  supermunge(
    list_df = list(GWIS_BMI),
    refFilePath = p$filepath.SNPReference.hc1kg,
    traitNames = c(nCode),
    pathDirOutput = p$folderpath.data.sumstats.munged
      )
  
  if(p$clOptions$task=="gwis") quit(save = "no") #end gwis task - only manual stuff below
  
  
  #read previous results
  GWISM_BMI <- as.data.frame(shru::readFile(file.path(p$folderpath.data.sumstats.munged, "BODYT2M.gz")))
  GWISI_BMI <- as.data.frame(shru::readFile(file.path(p$folderpath.data.sumstats.imputed, "BODYT2MI.gz")))
  
 
  
  # PLOT GWIS Mwenahttan:
  
  
  
  #manhattan(na.omit(GWIS_BMI),chr="GIANT_Combined$chrom",bp="GIANT_Combined$pos",p="(pchisq((new.beta/new.se)^2, 1, lower.tail = F))",ylim=c(0,50))
  
  cPlot<-plot.manhattan.custom(GWISM_BMI,var = "P")
  ggsave(filename=file.path(p$folderpath.plots, paste0("manp.GWIS.GWISM.png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
  
  cPlot<-plot.manhattan.custom(GWISI_BMI,var = "P")
  ggsave(filename=file.path(p$folderpath.plots, paste0("manp.GWIS.GWISI.png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
  
  #  Read in the real BMI results:
  
  
  REFERENCE_BMI <- as.data.frame(shru::readFile(file.path(p$folderpath.data.sumstats.munged, "BODYTM.gz")))
  REFERENCE_BMI2 <- as.data.frame(shru::readFile(file.path(p$folderpath.data.sumstats.munged, "BODY11.gz")))
  
  
  # Merge to test:
  
  GWIS_GWAS <- merge(GWISI_BMI,REFERENCE_BMI,by=1)
  GWIS_GWAS.f <- GWIS_GWAS[GWIS_GWAS$N.x > 58000 & GWIS_GWAS$N.y > 58000,] # & (GWIS_GWAS$Z.x)^2>0.01579077 & (GWIS_GWAS$Z.y)^2>0.01579077
  
  
  cor(GWIS_GWAS.f$BETA.x,GWIS_GWAS.f$BETA.y,use="pairwise.co")^2
  cor(GWIS_GWAS.f$SE.x,GWIS_GWAS.f$SE.y,use="pairwise.co")^2
  cor(GWIS_GWAS.f$Z.x,GWIS_GWAS.f$Z.y,use="pairwise.co")^2
  
  
  tiff(file.path(p$folderpath.plots,"GWISI_REF1_corr.tiff"), width = 4, height = 8, units = 'in', res = 300)
  # Make plot
  
  par(mfrow=c(3,1))
  
  plot(GWIS_GWAS.f$BETA.x,GWIS_GWAS.f$BETA.y, col=rgb(0,0,1,.2),pch=19,ylab="Beta's GWAS BMI", xlab="Beta's GWIS BMI Male Height" )
  legend("topleft",expression(R^2 ~ .935))
  abline(0,1,col="red")
  
  plot(GWIS_GWAS.f$SE.x,GWIS_GWAS.f$SE.y, col=rgb(0,0,1,.2),pch=19,ylab="SE GWAS BMI", xlab="SE GWIS BMI Male Height" )
  legend("topleft",expression(R^2 ~ .996))
  abline(0,1,col="red")
  
  plot(GWIS_GWAS.f$Z.x,GWIS_GWAS.f$Z.y, col=rgb(0,0,1,.2),pch=19,ylab="Z GWAS BMI", xlab="Z GWIS BMI Male Height" )
  legend("topleft",expression(R^2 ~ .936))
  abline(0,1,col="red")
  
  dev.off()
  
  
  #`1000G_rs_ch_bp` <- read.table("C:/8. post hoc GWAS/FINAL Analysis paper/1000G_rs_ch_bp", quote="\"")
  
  
  #manhattan(na.omit(GWIS_GWAS),chr="GIANT_Combined$chrom",bp="GIANT_Combined$pos",p="P.2gc",ylim=c(0,50))
  cPlot<-plot.manhattan.custom(REFERENCE_BMI,var = "P")
  ggsave(filename=file.path(p$folderpath.plots, paste0("manp.GWIS.BODYTM.png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
  
  
  
  # Merge to test 2:
  
  GWIS_GWAS2 <- merge(GWISI_BMI,REFERENCE_BMI2,by=1)
  GWIS_GWAS2.f <- GWIS_GWAS2[GWIS_GWAS2$N.x > 58000 & GWIS_GWAS2$N.y > 58000,] #& (GWIS_GWAS2$Z.x)^2>0.1 & (GWIS_GWAS2$Z.y)^2>0.1 #0.01579077
  
  
  cor(GWIS_GWAS2.f$BETA.x,GWIS_GWAS2.f$BETA.y,use="pairwise.co")^2
  cor(GWIS_GWAS2.f$SE.x,GWIS_GWAS2.f$SE.y,use="pairwise.co")^2
  cor(GWIS_GWAS2.f$Z.x,GWIS_GWAS2.f$Z.y,use="pairwise.co")^2
  
  
  tiff(file.path(p$folderpath.plots,"GWISI_REF2_corr.tiff"), width = 4, height = 8, units = 'in', res = 300)
  # Make plot
  
  par(mfrow=c(3,1))
  
  plot(GWIS_GWAS2.f$BETA.x,GWIS_GWAS2.f$BETA.y, col=rgb(0,0,1,.2),pch=19,ylab="Beta's GWAS BMI", xlab="Beta's GWIS BMI Male Height" )
  legend("topleft",expression(R^2 ~ .156))
  abline(0,1,col="red")
  
  plot(GWIS_GWAS2.f$SE.x,GWIS_GWAS2.f$SE.y, col=rgb(0,0,1,.2),pch=19,ylab="SE GWAS BMI", xlab="SE GWIS BMI Male Height" )
  legend("topleft",expression(R^2 ~ .889))
  abline(0,1,col="red")
  
  plot(GWIS_GWAS2.f$Z.x,GWIS_GWAS2.f$Z.y, col=rgb(0,0,1,.2),pch=19,ylab="Z GWAS BMI", xlab="Z GWIS BMI Male Height" )
  legend("topleft",expression(R^2 ~ .186))
  abline(0,1,col="red")
  
  dev.off()
  
  
  #`1000G_rs_ch_bp` <- read.table("C:/8. post hoc GWAS/FINAL Analysis paper/1000G_rs_ch_bp", quote="\"")
  
  
  #manhattan(na.omit(GWIS_GWAS),chr="GIANT_Combined$chrom",bp="GIANT_Combined$pos",p="P.2gc",ylim=c(0,50))
  cPlot<-plot.manhattan.custom(REFERENCE_BMI2,var = "P")
  ggsave(filename=file.path(p$folderpath.plots, paste0("manp.GWIS.BODY11.png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
  
  
  
  
  # B B Plot
  #plot(GWIS_GWAS[,5],GWIS_GWAS[,12],col=rgb(0,0,1,.1),ylim=c(-.35,.35),pch=19,ylab="BMI GWAS Beta",xlab="BMI GWIS Beta")
  # SE SE Plot
  #plot(GWIS_GWAS[,6],GWIS_GWAS[,13],col=rgb(0,0,1,.1),ylim=c(0,.16),pch=19,ylab="BMI GWAS SE",xlab="BMI GWIS SE")
  # P P Plot
  plot(-log10(GWIS_GWAS$P.x),-log10(GWIS_GWAS$P.y),col=rgb(0,0,1,.1),ylim=c(0,16),xlim=c(0,16),pch=19,ylab="BMI GWAS -log10(P)",xlab="BMI GWIS -log10(P)")
  
  # Number of Hits GWAS:
  nrow(GWIS_GWAS[GWIS_GWAS$P.x < 5e-8,])
  
  # Numer of hits replicated:
  sum(GWIS_GWAS[GWIS_GWAS$P.x < 5e-8,]$P.y < 5e-8)
  
  # numer of false positives:
  sum(GWIS_GWAS[GWIS_GWAS$P.x < 5e-8,]$P.y > 5e-8)
  
  
  # Table the false positives for inclusion in a supplment:
  
  fp <-GWIS_GWAS[GWIS_GWAS$P.x < 5e-8 & GWIS_GWAS$P.y > 5e-8 ,]
  
  write.table(fp,"false_positive_male.txt")

  
  # Number of Hits GWAS2:
  nrow(GWIS_GWAS2[GWIS_GWAS2$P.x < 5e-8,])
  
  # Numer of hits replicated:
  sum(GWIS_GWAS2[GWIS_GWAS2$P.x < 5e-8,]$P.y < 5e-8)
  
  # numer of false positives:
  sum(GWIS_GWAS2[GWIS_GWAS2$P.x < 5e-8,]$P.y > 5e-8)
  
  
  # # nwe implementation - on pause
  # #performGWIS <- function(nCode,pathGwasH,patghGwasWM,pathGwasWF){
  #   pathGWISI = p$sumstats["GWISI",]$mungedpath
  # 
  #   
  #   pathGwasH = p$sumstats["HEIG09",]$imputedpath
  #   patghGwasWM = p$sumstats["WEIG04M",]$imputedpath
  #   pathGwasWF = p$sumstats["WEIG04F",]$imputedpath
  #   
  #   
  #   
  #   # pathGwasH = p$sumstats["HEIG09",]$mungedpath
  #   # patghGwasWM = p$sumstats["WEIG04M",]$mungedpath
  #   # pathGwasWF = p$sumstats["WEIG04F",]$mungedpath
  #   
  #   HW_cor <- 0.370959 #from GWIS example
  #   
  #   #10.1194/jlr.P041673
  #   mHeightM <- (168.85/15095+181.31/9809)/(1/15095+1/9809)/100
  #   sdHeightM <- sqrt(((6.54^2)/15095+(7.37^2)/9809)/(1/15095+1/9809))/100
  #   mBMIKgpM <- (24.290/16312+24.772/10709)/(1/16312+1/10709)
  #   sdBMIKgpM <- sqrt(((4.389^2)/16312+(4.389^2)/10709)/(1/16312+1/10709))
  #   #mWeightKg <- mBMIKgpM * mHeightM^2
  #   
  #   #10.1038/ijo.2008.11
  #   mWeightKg <- (82.0/6580+69.3/7021)/(1/6580+1/7021)
  #   sdWeightKg <- sqrt(((0.19^2)/6580+(0.20^2)/7021)/(1/6580+1/7021))
  #   
  #   #https://stats.stackexchange.com/questions/201358/distribution-of-the-square-of-a-non-standard-normal-random-variable
  #   #E[Non-central Chi-squared variable, k] = k + l
  #   #Var[Non-central Chi-squared variable, k] = 2(k +2l)
  #   # varHeight2 <-  2 + 2*((mHeightM/sdHeightM)^2)
  #   # mHeight2 <- 1 + (mHeightM/sdHeightM)^2
  #   #Find variance for BMI*Height^2=Weight
  #   #Goodman's formula. How to compute cov(X^2,Y^2) in the dependent variables formula???
  #   #Var(XY)=Cov(X^2,Y^2) + (Var(X) + [E(X)]^2) * (Var(Y) + [E(Y)]^2) - [Cov(X,Y) + E(X)*E(Y)]^2
  #   #for the reciprocal normal distribution the Var(1/X) ~= Var(X)
  #   # covH2BMI<-0.75*sqrt(varHeight2)*sdBMIKgpM #Just an arbitrary placeholder
  #   # covH22BMI2<-sqrt(covH2BMI) #Just an arbitrary placeholder
  #   # sdWeightKg <- sqrt(
  #   #   covH22BMI2 + (sdBMIKgpM^2+mBMIKgpM^2) * (varHeight2 + mHeight2^2) - (covH2BMI + mBMIKgpM*mHeight2)^2
  #   #   )
  #   
  #   gwasGWISI<-readFile(filePath = pathGWISI) #for QC
  # 
  #   gwasH<-readFile(filePath = pathGwasH)
  #   gwasWM<-readFile(filePath = patghGwasWM)
  #   gwasWF<-readFile(filePath = pathGwasWF)
  #   
  #   #The deltamethod is not fast so let's filter the data to what we will be using later anyway
  #   gwasH<-gwasH[FRQ>0.01 & (Z*Z)>0.01579077,]
  #   gwasWM<-gwasWM[FRQ>0.01 & (Z*Z)>0.01579077,]
  #   gwasWF<-gwasWF[FRQ>0.01 & (Z*Z)>0.01579077,]
  #   
  #   #this is probably not best practice
  #   # gwasH[FRQ==0,FRQ:=1/(10*N)]
  #   # gwasWM[FRQ==0,FRQ:=1/(10*N)]
  #   # gwasWF[FRQ==0,FRQ:=1/(10*N)]
  #   
  #   gwasH[,W:=1/(SE^2)] #meta-analytical weights
  #   gwasWM[,W:=1/(SE^2)] #meta-analytical weights
  #   gwasWF[,W:=1/(SE^2)] #meta-analytical weights
  #   
  #   if(!any(colnames(gwasH)=="SINFO")) { 
  #     gwasH$SINFO<-NA_real_
  #   } else {
  #     #Height has wrong SINFO for some reason
  #     gwasH[,SINFO:=as.double(SINFO)]
  #     gwasH[LDIMP.L2.SUM>0,LDIMP.Q:=LDIMP.K*L2_REF/(LDIMP.L2.SUM)][LDIMP.L2.SUM>0,c('SINFO'):=list(pnorm(q = LDIMP.Q, mean = 1, sd = 1))]
  #   }
  #   if(!any(colnames(gwasWM)=="SINFO")) gwasWM$SINFO<-NA_real_
  #   if(!any(colnames(gwasWF)=="SINFO")) gwasWF$SINFO<-NA_real_
  #   
  #   #merge male and female weight GWAS
  #   gwasW<-copy(gwasWM)
  #   gwasW[gwasWF, on="SNP", c("BETA","SE","N","FRQ","SINFO"):=list((W*BETA+i.W*i.BETA)/(W+i.W), sqrt(1/(W+i.W)), N+i.N, shru::clipValues((FRQ/N+i.FRQ/i.N)/(1/N+1/i.N),min = 1/(10*N), max = 1),ifelse(is.na(SINFO) & is.na(i.SINFO), NA_real_, (ifelse(is.na(SINFO),1,SINFO)+ifelse(is.na(i.SINFO),1,i.SINFO))/2))][,W:=1/(SE^2)]
  #   #gwasW[gwasWF, on="SNP", c("BETA","SE","N","FRQ"):=list( (BETA/(N*FRQ)+i.BETA/(i.N*i.FRQ))/(1/(N*FRQ)+1/(i.N*i.FRQ)), sqrt((SE^2/(N*FRQ)+i.SE^2/(i.N*i.FRQ))/(1/(N*FRQ)+1/(i.N*i.FRQ))), N+i.N, shru::clipValues( (FRQ/N+i.FRQ/i.N)/(1/N+1/i.N),min = 1/(10*N), max = 1))] #old, non-meta-analysis
  #   
  #   #standardisation and GWIS formulas
  #   gwasBMI <- copy(gwasH)
  #   gwasBMI[gwasW,on=c("SNP"),c("BETA.W","SE.W","BETA.H","SE.H","N","FRQ","Z.H","Z.W","N.H","N.W","SINFO"):=list(i.BETA, i.SE, BETA, SE, (N+i.N)/2, shru::clipValues( (FRQ/N+i.FRQ/i.N)/(1/N+1/i.N),min = 1/(10*N), max = 1), Z, i.Z, N, i.N,ifelse(is.na(SINFO) & is.na(i.SINFO), NA_real_, (ifelse(is.na(SINFO),1,SINFO)+ifelse(is.na(i.SINFO),1,i.SINFO))/2))]
  #   
  #   gwasBMI<-gwasBMI[is.finite(BETA.W) & is.finite(BETA.H),]
  #   
  #   #different types of Z
  #   gwasBMI[,Z.BMI:=Z.W/(Z.H^2)]
  #   gwasBMI[,Z.WEIGHTED:=(Z.W/(N.W*(FRQ-FRQ^2+1/2))+Z.H/(N.H*(FRQ-FRQ^2+1/2)))/(1/(N.W*(FRQ-FRQ^2+1/2))+1/(N.H*(FRQ-FRQ^2+1/2)))]
  #   
  #   gwasBMI[,c("I.W","I.H","I.BMI"):=list(eval(..mWeightKg),eval(..mHeightM),eval(..mWeightKg)/(eval(..mHeightM)^2))]
  #   
  #   #scaling etc
  #   gwasBMI[,c("BETA.W.S","BETA.H.S","SE.W.S","SE.H.S"):=list(
  #     BETA.W*eval(..sdWeightKg), #scaled beta
  #     BETA.H*eval(..sdHeightM), #scaled beta
  #     SE.W*eval(..sdWeightKg), #scaled standard error
  #     SE.H*eval(..sdHeightM) #scaled standard error
  #   )][,c('AF1','AF2'):=list((2*FRQ*(1-FRQ)/(2*FRQ*(1-FRQ)+FRQ^2)),(FRQ^2)/(2*FRQ*(1-FRQ)+FRQ^2))]
  #   
  #   #H2 variable estimates - HERE!!! SEE THE NEW FORMULAS ON THE PAPER!
  #   gwasBMI[,c("SE.H2.S","E.H2.S"):=list(
  #     sqrt(SE.H.S^4 * 2), # Var(aX) = a^2 * Var(X), Var(X)= 2k
  #     1 * SE.H.S^2 # k * var(H)
  #     # sqrt(2 + 2*(2*abs(BETA.H.S)/((FRQ-FRQ^2+1/2)*SE.H.S))^2), #scaled standard error, m = 2*BETA/X
  #     # 1 + 2*abs(BETA.H.S)/(FRQ-FRQ^2+1/2) #scaled estimated value - THIS IS THE MEAN OF H2!!!
  #   )]
  #  
  #   #GWIS
  #   gwasBMI[,c("BETA"):=list(
  #     (AF1*((I.W+BETA.W.S)/((I.H+BETA.H.S)^2) - I.BMI) + (1/2)*AF2*((I.W+2*BETA.W.S)/((I.H+2*BETA.H.S)^2) - I.BMI))/eval(..sdBMIKgpM) #this last denominator thing was added in the GWIS code example, but is not documented in the paper (I think). 
  #   )]
  #   
  #   
  #   #SE of BMI - a ratio of random variables - no closed form solution for the variance
  #   
  #   
  #   #The GWIS solution from the original implementation
  #   
  #   # #test
  #   # HW_cor <- 0.370959
  #   # AF1_l <- (2*0.5154780*(1-0.5154780)/(2*0.5154780*(1-0.5154780)+0.5154780^2))
  #   # AF2_l <- (1/2)*((0.5154780^2)/(2*0.5154780*(1-0.5154780)+0.5154780^2))
  #   # 
  #   # new.se <- deltamethod(~( AF1_l*(((mWeightKg+x1)/((mHeightM+x2)^2)) - mBMIKgpM) + (AF2_l*(((mWeightKg+2*x1)/((mHeightM+2*x2)^2)) - mBMIKgpM))/2)/sdBMIKgpM, mean=c(-0.008090578*sdWeightKg,0.000489998*sdHeightM),
  #   #                            
  #   #                            cov=cbind(rbind((0.004523826*sdWeightKg)^2,           (0.004523826*sdWeightKg)*HW_cor*(0.00105*sdHeightM)),
  #   #                                      rbind((0.004523826*sdWeightKg)*HW_cor*(0.00105*sdHeightM),(0.00105*sdHeightM)^2)))
  #   
  #   
  #   
  #   # https://www.stat.cmu.edu/~hseltman/files/ratio.pdf
  #   # https://math.stackexchange.com/questions/40713/calculating-the-variance-of-the-ratio-of-random-variables
  #   gwasBMI[,c("SE.DERIVED","E.BMI","SE.BMI.Z.DERIVED","SE.WEIGHTED"):=list(
  #       sqrt(
  #         1/(E.H2.S^4)*((SE.W.S^2)/1 - 2*eval(..HW_cor)*SE.W.S*SE.H2.S/((BETA.W.S)^2) + (SE.H2.S^2)/(E.H2.S^2))
  #            ), #use the HW correlation as approximation. the approximation of a ratio random variables using taylor series. Issue with E[W]=0, approximately Var(W) when E[W] -> 0 ??
  #       1/E.H2.S - eval(..HW_cor)*SE.W.S*SE.H2.S/((BETA.W.S)^2) + (SE.H2.S^2)*1/((BETA.W.S)^3), #use the HW correlation as approximation. the approximation of a ratio random variables using taylor series.
  #       abs(BETA/Z.BMI),
  #       abs(BETA/Z.WEIGHTED)
  #       
  #   )]
  #   
  #   N <- nrow(gwasBMI)
  #   cat("\nGWIS has ", N,  " rows after filters.\n\n")
  #   #deltamethod
  #   cat("\nComputing SEs with the deltamethod...")
  #   for(i in 1:N){ #nrow(gwasBMI)
  #     #i<-1
  #     if(i %% 100000 == 0) cat("*")
  #     else if(i %% 10000 == 0) cat(".")
  #     
  #     AF1_l <- gwasBMI[i,]$AF1
  #     AF2_l <- gwasBMI[i,]$AF2
  #     
  #     set(x = gwasBMI,i = i,j = "SE.DELTAMETHOD",
  #                 value = deltamethod(~( AF1_l*(((mWeightKg+x1)/((mHeightM+x2)^2)) - mBMIKgpM) + ((1/2)*AF2_l*((mWeightKg+2*x1)/((mHeightM+2*x2)^2) - mBMIKgpM)))/sdBMIKgpM,
  #                     mean=c(gwasBMI[i,]$BETA.W.S,gwasBMI[i,]$BETA.H.S),
  #                     cov=cbind(rbind(gwasBMI[i,]$SE.W.S^2,gwasBMI[i,]$SE.W.S*HW_cor*gwasBMI[i,]$SE.H.S),rbind(gwasBMI[i,]$SE.W.S*HW_cor*gwasBMI[i,]$SE.H.S,gwasBMI[i,]$SE.H.S^2)))
  #             )
  #     # gwasBMI[i,c('SE.DELTAMETHOD')] <- deltamethod(~( AF1_l*(((mWeightKg+x1)/((mHeightM+x2)^2)) - mBMIKgpM) + ((1/2)*AF2_l*((mWeightKg+2*x1)/((mHeightM+2*x2)^2) - mBMIKgpM)))/sdBMIKgpM,
  #     #                 mean=c(gwasBMI[i,]$BETA.W.S,gwasBMI[i,]$BETA.H.S),
  #     #                 cov=cbind(rbind(gwasBMI[i,]$SE.W.S^2,gwasBMI[i,]$SE.W.S*HW_cor*gwasBMI[i,]$SE.H.S),rbind(gwasBMI[i,]$SE.W.S*HW_cor*gwasBMI[i,]$SE.H.S,gwasBMI[i,]$SE.H.S^2)))
  #   }
  #   cat("done!")
  #   #SEs of squared random variables
  #   # gwasBMI[,c("SE.W.S.2","SE.H2.S.2"):=list(
  #   #   sqrt(SE.W.S^4+2*I.W^2), #approximation of these as uncorrelated
  #   #   sqrt(SE.H2.S^4+2*I.H2^2)  #approximation of these as uncorrelated
  #   #   # sqrt(SE.W.S^4+2*(SE.W.S^2)*I.W^2-2*I.W^2), #correlated
  #   #   # sqrt(SE.H2.S^4+2*(SE.H2.S^2)*I.H2^2-2*I.H2^2) #correlated
  #   # )]
  #   #test
  #   #sqrt(0.001248959^4 + 2*75.85589^2) #uncorrelated     
  #   #sqrt(0.001248959^4 + 2*(0.001248959^2)*75.85589^2-2*75.85589^2) #correlated
  #   
  #   gwasBMI[,SE:=SE.DELTAMETHOD][,c("Z"):=list(BETA/SE)][,P:=2*pnorm(q = abs(Z), mean = 0, sd = 1, lower.tail = F)]
  #   
  #   gwasBMI <- gwasBMI[is.finite(BETA.W) & is.finite(P), c("SNP","A1","A2","CHR","BP","FRQ","BETA","SE","Z","P","N","SINFO")]
  #   
  #   cat("\nNumber of rows in GWIS: ", nrow(gwasBMI))
  #   
  #   fwrite(x = gwasBMI,file = file.path(p$folderpath.data.sumstats.munged,paste0(nCode,".gz")),append = F,quote = F,sep = "\t",col.names = T,nThread=5)
  #   
  # #}
  # 
  # # performGWIS(
  # #   nCode = "GWISM",
  # #   pathGwasH = p$sumstats["HEIG09",]$mungedpath,
  # #   patghGwasWM = p$sumstats["WEIG04M",]$mungedpath,
  # #   pathGwasWF = p$sumstats["WEIG04F",]$mungedpath
  # #   )
  # # 
  # # performGWIS(
  # #   nCode = "GWISI",
  # #   pathGwasH = p$sumstats["HEIG09",]$imputedpath,
  # #   patghGwasWM = p$sumstats["WEIG04M",]$imputedpath,
  # #   pathGwasWF = p$sumstats["WEIG04F",]$imputedpath
  # #   )
  # 
  if(p$clOptions$task=="gwis") quit(save = "no")
  
}



```



## Harmonise gene sets to gene map and MAGMA format
```{r Harmonise gene sets to gene map and MAGMA format}
if(p$clOptions$task=="genesets"){
  
  p$geneMap<-fread(file = p$filepath.geneMapping, na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, data.table = T,showProgress = F, nThread=5)
  setkeyv(p$geneMap,cols = c("V6"))
  rownames(p$geneMap)<-p$geneMap$V6
  geneCodesByName<-p$geneMap$V1
  names(geneCodesByName)<-p$geneMap$V6
  
  #gtex
  cCode<-"gtex8_rnaseq_median"
  cGeneSet<-read.table(p$genesets[cCode,]$filepath.raw, header=T, quote="\"",fill=T,na.string=c(".",NA,"NA",""), sep="\t", skip = 2)
  setDT(cGeneSet,key = "Description")
  cGeneSet[p$geneMap, on=c(Description='V6'), c("KEY"):=list(i.V1)]
  ncolnames<-c("KEY",colnames(cGeneSet)[3:(length(colnames(cGeneSet))-1)]) #columns from after description
  cGeneSet <- cGeneSet[,..ncolnames][!is.na(KEY),]
  cGeneSet <- aggregate(x = cGeneSet, by = list(cGeneSet$KEY), FUN = head, 1) #DO I NEED THIS?
  cGeneSet <- cGeneSet[,2:length(colnames(cGeneSet))]
  fwrite(x = cGeneSet, file = file.path(p$folderpath.workingDirectory,paste0("geneset.",cCode,".magma")), append = F, quote = F, sep = "\t",na = "NA", col.names = T,nThread=5)
  
  #brainspan
  cCode<-"brainspan_rnaseq_mean"
  cGeneSet<-read.table(p$genesets[cCode,]$filepath.raw, header=F, quote="\"",fill=T,na.string=c(".",NA,"NA",""), sep=",")
  cGenes<-read.table(file.path(p$folderpath.geneSet,"BRAINSPAN_RNA-Seq_Gencode_v10_summarized_to_genes_genes_matrix_csv","rows_metadata.csv"), header=T, quote="\"",fill=T,na.string=c(".",NA,"NA",""), sep=",")
  cSets<-read.table(file.path(p$folderpath.geneSet,"BRAINSPAN_RNA-Seq_Gencode_v10_summarized_to_genes_genes_matrix_csv","columns_metadata.csv"), header=T, quote="\"",fill=T,na.string=c(".",NA,"NA",""), sep=",")
  
  cGeneSet<-cGeneSet[,2:ncol(cGeneSet)]
  colnames(cGeneSet)<-cSets$structure_name
  cGeneSet$gene_symbol<-cGenes$gene_symbol
  
  ncolnames<-c("gene_symbol",colnames(cGeneSet)[1:(ncol(cGeneSet)-1)])
  cGeneSet<-cGeneSet[,ncolnames]
  
  setDT(cGeneSet,key = "gene_symbol") 
  
  cGeneSet[p$geneMap, on=c(gene_symbol='V6'), c("KEY"):=list(i.V1)]
  ncolnames<-c("KEY",colnames(cGeneSet)[2:(length(colnames(cGeneSet))-1)]) #columns after rearrangement
  cGeneSet <- cGeneSet[,..ncolnames][!is.na(KEY),]
  cGeneSet <- aggregate(x = cGeneSet, by = list(cGeneSet$KEY), FUN = head, 1) #DO I NEED THIS?
  cGeneSet <- cGeneSet[,2:ncol(cGeneSet)]
  colnames(cGeneSet)<-gsub(pattern = " ", replacement = "_", x = colnames(cGeneSet))
  fwrite(x = cGeneSet, file = file.path(p$folderpath.workingDirectory,paste0("geneset.",cCode,".magma")), append = F, quote = F, sep = "\t",na = "NA", col.names = T,nThread=5)
  
  #MSigDB
  chosenSet<-c("msigdb.h.all.v7.5.1","msigdb.c2.cp.biocarta.v7.5.1","msigdb.c2.cp.kegg.v7.5.1", "msigdb.c3.mir.mirdb.v7.5.1","msigdb.c3.tft.gtrd.v7.5.1", "msigdb.c5.all.v7.5.1","msigdb.c7.all.v7.5.1","msigdb.c8.all.v7.5.1")
  for(cCode in chosenSet){
    #cCode<-"msigdb.c2.cp.biocarta.v7.5.1"
    cGeneSet<-read.table(p$genesets[cCode,]$filepath.raw, header=F, quote="\"",fill=T,na.string=c(".",NA,"NA",""), sep="\t")
    incols<-c(1,3:ncol(cGeneSet))
    cGeneSet<-cGeneSet[,incols]
    setDT(cGeneSet,key = "V1")
    for(iCol in 2:ncol(cGeneSet)){
      #iCol<-2
      col<-colnames(cGeneSet)[iCol]
      cGeneSet[, (col):=geneCodesByName[get(col)]]
    }
    rcount <- aggregate(V3 ~ V1,cGeneSet,length)
    rcount <- rcount[rcount$V3>1,]
    cGeneSet2 <- aggregate(x = cGeneSet, by = list(cGeneSet$V1), FUN = head, 1) #remove duplicate sets
    cGeneSet2 <- cGeneSet2[,2:ncol(cGeneSet2)]
    rownames(cGeneSet2)<-cGeneSet2$V1
    
    if(nrow(rcount)>0){
      cGeneSet2[,(ncol(cGeneSet2)+1):(2*(ncol(cGeneSet2)+1))]<-NA #add more columns to make room for new data
      
      #collect genes from duplicate set rows
      for(i in 1:nrow(rcount)){
        #i<-2
        cGeneSet2[rcount$V1[i],2:ncol(cGeneSet2)] <- padList(unique(unlist(cGeneSet[V1==rcount$V1[i],2:ncol(cGeneSet)])),NA,ncol(cGeneSet2))
      }
    }
    
    fwrite(x = cGeneSet2, file = file.path(p$folderpath.workingDirectory,paste0("geneset.",cCode,".magma")), append = F, quote = F, sep = "\t",na = "NA", col.names = F,nThread=5)
  }
  quit(save = "no")
}

```

# Visualise GWAS effect distributions
```{r visualise distributions, fig.width=9, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}

  #munged
  for(iTrait in 1:nrow(p$sumstats.sel)){
    cSumstats <- shru::readFile(filePath = p$sumstats.sel[iTrait,]$mungedpath, nThreads = 5)
    #cSumstats <- cSumstats[,]
    cPlot<-plot.manhattan.custom(cSumstats,var = "BETA")
    ggsave(filename=file.path(p$folderpath.plots, paste0("manbeta.munged.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
    cPlot<-plot.manhattan.custom(cSumstats,var = "SE")
    ggsave(filename=file.path(p$folderpath.plots, paste0("manse.munged.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
    cPlot<-plot.manhattan.custom(cSumstats,var = "P")
    ggsave(filename=file.path(p$folderpath.plots, paste0("manp.munged.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
  }

  #imputed ld-imp
  for(iTrait in 1:nrow(p$sumstats.sel)){
    cSumstats <- shru::readFile(filePath = p$sumstats.sel[iTrait,]$imputedpath.500, nThreads = 5)
    cPlot<-plot.manhattan.custom(cSumstats,var = "BETA")
    ggsave(filename=file.path(p$folderpath.plots, paste0("manbeta.ld-imp.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
    cPlot<-plot.manhattan.custom(cSumstats,var = "SE")
    ggsave(filename=file.path(p$folderpath.plots, paste0("manse.ld-imp.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
    cPlot<-plot.manhattan.custom(cSumstats,var = "P")
    ggsave(filename=file.path(p$folderpath.plots, paste0("manp.ld-imp.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
  }

  #imputed ssimp
  # for(iTrait in 1:nrow(p$sumstats.sel)){
  #   cSumstats <- shru::readFile(filePath = p$sumstats.sel[iTrait,]$imputedpath.ssimp, nThreads = 5)
  #   # cPlot<-plot.manhattan.custom(cSumstats,var = "BETA")
  #   # ggsave(filename=file.path(p$folderpath.plots, paste0("manbeta.ssimp.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
  #   # cPlot<-plot.manhattan.custom(cSumstats,var = "SE")
  #   # ggsave(filename=file.path(p$folderpath.plots, paste0("manse.ssimp.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
  #   cPlot<-plot.manhattan.custom(cSumstats,var = "P")
  #   ggsave(filename=file.path(p$folderpath.plots, paste0("manp.ssimp.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
  # }
  
  #munged2
  for(iTrait in 1:nrow(p$sumstats.sel)){
    cSumstats <- shru::readFile(filePath = p$sumstats.sel[iTrait,]$mungedpath2, nThreads = 5)
    cPlot<-plot.manhattan.custom(cSumstats,var = "BETA")
    ggsave(filename=file.path(p$folderpath.plots, paste0("manbeta.munged2.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
    cPlot<-plot.manhattan.custom(cSumstats,var = "SE")
    ggsave(filename=file.path(p$folderpath.plots, paste0("manse.munged2.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
    cPlot<-plot.manhattan.custom(cSumstats,var = "P")
    ggsave(filename=file.path(p$folderpath.plots, paste0("manp.munged2.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
  }
  
  #imputed ld-imp, munge2
  for(iTrait in 1:nrow(p$sumstats.sel)){
    cSumstats <- shru::readFile(filePath = p$sumstats.sel[iTrait,]$imputedpath2.500, nThreads = 5)
    cPlot<-plot.manhattan.custom(cSumstats,var = "BETA")
    ggsave(filename=file.path(p$folderpath.plots, paste0("manbeta.ld-imp2.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
    cPlot<-plot.manhattan.custom(cSumstats,var = "SE")
    ggsave(filename=file.path(p$folderpath.plots, paste0("manse.ld-imp2.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
    cPlot<-plot.manhattan.custom(cSumstats,var = "P")
    ggsave(filename=file.path(p$folderpath.plots, paste0("manp.ld-imp2.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
  }
  
  #imputed ssimp, munge2
  for(iTrait in 1:nrow(p$sumstats.sel)){
    cSumstats <- shru::readFile(filePath = p$sumstats.sel[iTrait,]$imputedpath2.ssimp, nThreads = 5)
    cPlot<-plot.manhattan.custom(cSumstats,var = "BETA")
    ggsave(filename=file.path(p$folderpath.plots, paste0("manbeta.ssimp2.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
    cPlot<-plot.manhattan.custom(cSumstats,var = "SE")
    ggsave(filename=file.path(p$folderpath.plots, paste0("manse.ssimp2.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
    cPlot<-plot.manhattan.custom(cSumstats,var = "P")
    ggsave(filename=file.path(p$folderpath.plots, paste0("manp.ssimp2.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)
  }
  
  #quit(save = "no")
  

```

# Per-dataset statistics

This takes a long time to run as we have to read all datasets.

```{r dataset statistics}

print("***Dataset statistics***")

p$filepath.dsStat<-file.path(p$folderpath.workingDirectory,paste0("dsStat.",p$setup.code,".Rds"))

if(file.exists(p$filepath.dsStat)) {
  print("Using existing dataset statistics.")
  p$dsStat<-readRDS(file=p$filepath.dsStat)
}

if(p$clOptions$task=="stat") {
  
  p$dsStat<-c()
  p$dsStat$sumstats.meta<-data.table(code=p$sumstats.sel.raw$code)
  
  for(iTrait in 1:nrow(p$sumstats.sel.raw)){
    #iTrait<-1
    if(!file.exists(p$sumstats.sel.raw[iTrait,]$imputedpath.05cm)) next
    cat("\n",p$sumstats.sel.raw[iTrait,]$code)
    cSumstats <- shru::readFile(filePath = p$sumstats.sel.raw[iTrait,]$imputedpath.05cm, nThreads = p$nThread)

    if(!any(colnames(cSumstats)=="BETA.I")) next



    #nrow(cSumstats)
    cond.invertedMAF<-cSumstats$FRQ > .5
    cSumstats$MAF<-ifelse(cond.invertedMAF,1-cSumstats$FRQ,cSumstats$FRQ)
    #cSumstats <- cSumstats[MAF>0.01,]
    #nrow(cSumstats)
    cSumstats[,ZZ:=Z*Z][,ZZ.I:=(BETA.I/SE.I)^2][,AC:=FRQ*N][,MAC:=MAF*N][,VSNP:=2*FRQ*(1-FRQ)][,NEFF:=round((((BETA.I/SE.I)/BETA.I)^2)/VSNP,digits = 0)][,IMPUTED:=(is.finite(LDIMP.L2.SUM) & BETA.I==BETA)]

    # cSumstats$SINFO<-as.double(cSumstats$SINFO)
    # cSumstats[IMPUTED==T & is.finite(L2_REF),SINFO:=pnorm(q = LDIMP.K*L2_REF/(LDIMP.L2.SUM), mean = 1, sd = 1)]

    setkeyv(cSumstats,cols = c("CHR","BP"))
    #[is.finite(BETA) & is.finite(BETA.I) & is.finite(SE.I),]
    cSumstats[,c('d.z','d.beta','d.se') :=list((BETA.I/SE.I)-(BETA/SE),BETA.I-BETA,SE.I-SE)]
    cSumstats[,d.z.abs:=abs(d.z)]


    p$dsStat$sumstats.meta[iTrait,c("medianAssocChi2.genotyped")]<-median(cSumstats[is.finite(ZZ) & IMPUTED==F,]$ZZ,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("medianAssocChi2.imputed")]<-median(cSumstats[is.finite(ZZ.I),]$ZZ.I,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("medianAssocChi2.genotyped.05_50")]<-median(cSumstats[is.finite(ZZ) & IMPUTED==F & MAF>0.05 & MAF<0.5,]$ZZ,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("medianAssocChi2.imputed.05_50")]<-median(cSumstats[is.finite(ZZ.I) & MAF>0.05 & MAF<0.5,]$ZZ.I,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("medianAssocChi2.genotyped.01_05")]<-median(cSumstats[is.finite(ZZ) & IMPUTED==F & MAF>0.01 & MAF<0.05,]$ZZ,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("medianAssocChi2.imputed.01_05")]<-median(cSumstats[is.finite(ZZ.I) & MAF>0.01 & MAF<0.05,]$ZZ.I,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("medianAssocChi2.genotyped.0_01")]<-median(cSumstats[is.finite(ZZ) & IMPUTED==F & MAF<0.01,]$ZZ,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("medianAssocChi2.imputed.0_01")]<-median(cSumstats[is.finite(ZZ.I) & MAF<0.01,]$ZZ.I,na.rm=T)

    # p$dsStat$sumstats.meta[iTrait,c("medianAssocChi2.genotyped")]<-median(cSumstats[is.finite(ZZ) & IMPUTED==F,]$ZZ,na.rm=T)
    # p$dsStat$sumstats.meta[iTrait,c("medianAssocChi2.imputed")]<-median(cSumstats[is.finite(ZZ.I),]$ZZ.I,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("l_ldimp_reinflation")]<-p$dsStat$sumstats.meta[iTrait,]$medianAssocChi2.imputed/p$dsStat$sumstats.meta[iTrait,]$medianAssocChi2.genotyped
    #p$dsStat$sumstats.meta[iTrait,c("l_ldimp_reinflation")]<-p$dsStat$sumstats.meta[iTrait,]$meanAssocChi2.imputed/p$dsStat$sumstats.meta[iTrait,]$meanAssocChi2.genotyped


    #re-inflation test
    cSumstats[,c(
      'd.z.re',
      'd.z.re2',
      'd.z.re3'
      ) :=list(
        (BETA.I/(eval(p$dsStat$sumstats.meta[iTrait,]$l_ldimp_reinflation)*SE.I))-(BETA/SE),
        (BETA.I/(eval(p$dsStat$sumstats.meta[iTrait,]$l_ldimp_reinflation^(1/2))*SE.I))-(BETA/SE),
        (BETA.I/(eval(p$dsStat$sumstats.meta[iTrait,]$l_ldimp_reinflation^(1/3))*SE.I))-(BETA/SE)
      )
      ]

    #re-inflation
    cSumstats[,ZZ.re:=(BETA.I/(eval(p$dsStat$sumstats.meta[iTrait,]$l_ldimp_reinflation)*SE.I))^2]
    cSumstats[,ZZ.re2:=(BETA.I/(eval(p$dsStat$sumstats.meta[iTrait,]$l_ldimp_reinflation^(1/2))*SE.I))^2]
    cSumstats[,ZZ.re3:=(BETA.I/(eval(p$dsStat$sumstats.meta[iTrait,]$l_ldimp_reinflation^(1/3))*SE.I))^2]

    p$dsStat$sumstats.meta[iTrait,c("meanAssocChi2.imputed.re")]<-mean(cSumstats[is.finite(ZZ.re),]$ZZ.re,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("meanAssocChi2.imputed.re2")]<-mean(cSumstats[is.finite(ZZ.re2),]$ZZ.re2,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("meanAssocChi2.imputed.re3")]<-mean(cSumstats[is.finite(ZZ.re3),]$ZZ.re3,na.rm=T)

    p$dsStat$sumstats.meta[iTrait,c("medianAssocChi2.imputed.re")]<-median(cSumstats[is.finite(ZZ.re),]$ZZ.re,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("medianAssocChi2.imputed.re2")]<-median(cSumstats[is.finite(ZZ.re2),]$ZZ.re2,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("medianAssocChi2.imputed.re3")]<-median(cSumstats[is.finite(ZZ.re3),]$ZZ.re3,na.rm=T)

    p$dsStat$sumstats.meta[iTrait,c("m")]<-nrow(cSumstats)
    p$dsStat$sumstats.meta[iTrait,c("m.genotyped")]<-nrow(cSumstats[IMPUTED==F,])
    p$dsStat$sumstats.meta[iTrait,c("m.imputed")]<-nrow(cSumstats[IMPUTED==T,])
    p$dsStat$sumstats.meta[iTrait,c("m.05_50")]<-nrow(cSumstats[MAF>0.05 & MAF<0.5,])
     p$dsStat$sumstats.meta[iTrait,c("m.genotyped.05_50")]<-nrow(cSumstats[IMPUTED==F & MAF>0.05 & MAF<0.5,])
    p$dsStat$sumstats.meta[iTrait,c("m.imputed.05_50")]<-nrow(cSumstats[IMPUTED==T & MAF>0.05 & MAF<0.5,])
    p$dsStat$sumstats.meta[iTrait,c("m.genotyped.01_05")]<-nrow(cSumstats[IMPUTED==F & MAF>0.01 & MAF<0.05,])
    p$dsStat$sumstats.meta[iTrait,c("m.imputed.01_05")]<-nrow(cSumstats[IMPUTED==T & MAF>0.01 & MAF<0.05,])
    p$dsStat$sumstats.meta[iTrait,c("m.genotyped.0_01")]<-nrow(cSumstats[IMPUTED==F & MAF<0.01,])
    p$dsStat$sumstats.meta[iTrait,c("m.imputed.0_01")]<-nrow(cSumstats[IMPUTED==T & MAF<0.01,])

    p$dsStat$sumstats.meta[iTrait,c("rmse_z")]<-sqrt(mean(cSumstats[IMPUTED==F,]$d.z^2,na.rm=T))
    p$dsStat$sumstats.meta[iTrait,c("rmse_z_re")]<-sqrt(mean(cSumstats[IMPUTED==F,]$d.z.re^2,na.rm=T))
    p$dsStat$sumstats.meta[iTrait,c("rmse_z_re2")]<-sqrt(mean(cSumstats[IMPUTED==F,]$d.z.re2^2,na.rm=T))
    p$dsStat$sumstats.meta[iTrait,c("rmse_z_re3")]<-sqrt(mean(cSumstats[IMPUTED==F,]$d.z.re3^2,na.rm=T))

    #p$dsStat$sumstats.meta[iTrait,c("rmse_beta")]<-sqrt(mean(cSumstats$d.beta^2,na.rm=T))
    #p$dsStat$sumstats.meta[iTrait,c("rmse_se")]<-sqrt(mean(cSumstats$d.se^2,na.rm=T))
    p$dsStat$sumstats.meta[iTrait,c("rmse_z.05_50")]<-sqrt(mean(cSumstats[IMPUTED==F & MAF>0.05 & MAF<0.5,]$d.z^2,na.rm=T))
    p$dsStat$sumstats.meta[iTrait,c("rmse_z.01_05")]<-sqrt(mean(cSumstats[IMPUTED==F & MAF>0.01 & MAF<0.05,]$d.z^2,na.rm=T))
    p$dsStat$sumstats.meta[iTrait,c("rmse_z.0_01")]<-sqrt(mean(cSumstats[IMPUTED==F & MAF<0.01,]$d.z^2,na.rm=T))
    p$dsStat$sumstats.meta[iTrait,c("rmse_z_re2.05_50")]<-sqrt(mean(cSumstats[IMPUTED==F & MAF>0.05 & MAF<0.5,]$d.z.re2^2,na.rm=T))
    p$dsStat$sumstats.meta[iTrait,c("rmse_z_re2.01_05")]<-sqrt(mean(cSumstats[IMPUTED==F & MAF>0.01 & MAF<0.05,]$d.z.re2^2,na.rm=T))
    p$dsStat$sumstats.meta[iTrait,c("rmse_z_re2.0_01")]<-sqrt(mean(cSumstats[IMPUTED==F & MAF<0.01,]$d.z.re2^2,na.rm=T))
    p$dsStat$sumstats.meta[iTrait,c("rmse_z_re3.05_50")]<-sqrt(mean(cSumstats[IMPUTED==F & MAF>0.05 & MAF<0.5,]$d.z.re3^2,na.rm=T))
    p$dsStat$sumstats.meta[iTrait,c("rmse_z_re3.01_05")]<-sqrt(mean(cSumstats[IMPUTED==F & MAF>0.01 & MAF<0.05,]$d.z.re3^2,na.rm=T))
    p$dsStat$sumstats.meta[iTrait,c("rmse_z_re3.0_01")]<-sqrt(mean(cSumstats[IMPUTED==F & MAF<0.01,]$d.z.re3^2,na.rm=T))

    # cQ<-quantile(sqrt(cSumstats[IMPUTED==F & MAF>0.05 & MAF<0.5,]$ZZ),0.5)
    # p$dsStat$sumstats.meta[iTrait,c("rmse_z.q_50")]<-sqrt(mean(cSumstats[IMPUTED==F & sqrt(ZZ)<eval(cQ),]$d.z^2,na.rm=T))
    # cQ2<-quantile(sqrt(cSumstats[IMPUTED==F & MAF>0.05 & MAF<0.5,]$ZZ),0.75)
    # p$dsStat$sumstats.meta[iTrait,c("rmse_z.q_50_75")]<-sqrt(mean(cSumstats[IMPUTED==F & sqrt(ZZ)<eval(cQ2) & sqrt(ZZ)>eval(cQ),]$d.z^2,na.rm=T))
    # p$dsStat$sumstats.meta[iTrait,c("rmse_z.q_75_100")]<-sqrt(mean(cSumstats[IMPUTED==F & sqrt(ZZ)>eval(cQ2),]$d.z^2,na.rm=T))


    p$dsStat$sumstats.meta[iTrait,c("bias_z")]<-mean(cSumstats[IMPUTED==F,]$d.z,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("bias_z_re")]<-mean(cSumstats[IMPUTED==F,]$d.z.re,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("bias_z_re2")]<-mean(cSumstats[IMPUTED==F,]$d.z.re2,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("bias_z_re3")]<-mean(cSumstats[IMPUTED==F,]$d.z.re3,na.rm=T)
    #p$dsStat$sumstats.meta[iTrait,c("bias_beta")]<-mean(cSumstats$d.beta,na.rm=T)
    #p$dsStat$sumstats.meta[iTrait,c("bias_se")]<-mean(cSumstats$d.se,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("bias_z.05_50")]<-mean(cSumstats[IMPUTED==F & MAF>0.05 & MAF<0.5,]$d.z,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("bias_z.01_05")]<-mean(cSumstats[IMPUTED==F & MAF>0.01 & MAF<0.05,]$d.z,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("bias_z.0_01")]<-mean(cSumstats[IMPUTED==F & MAF<0.01,]$d.z,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("bias_z_re2.05_50")]<-mean(cSumstats[IMPUTED==F & MAF>0.05 & MAF<0.5,]$d.z.re2,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("bias_z_re2.01_05")]<-mean(cSumstats[IMPUTED==F & MAF>0.01 & MAF<0.05,]$d.z.re2,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("bias_z_re2.0_01")]<-mean(cSumstats[IMPUTED==F & MAF<0.01,]$d.z.re2,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("bias_z_re3.05_50")]<-mean(cSumstats[IMPUTED==F & MAF>0.05 & MAF<0.5,]$d.z.re3,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("bias_z_re3.01_05")]<-mean(cSumstats[IMPUTED==F & MAF>0.01 & MAF<0.05,]$d.z.re3,na.rm=T)
    p$dsStat$sumstats.meta[iTrait,c("bias_z_re3.0_01")]<-mean(cSumstats[IMPUTED==F & MAF<0.01,]$d.z.re3,na.rm=T)


   # test.result <-cor.test(cSumstats[IMPUTED==F & is.finite(d.z.abs) & is.finite(SINFO),]$d.z.abs,cSumstats[IMPUTED==F & is.finite(d.z.abs) & is.finite(SINFO),]$SINFO)
    #p-values are expected to be 0 always due to large sample size.
    p$dsStat$sumstats.meta[iTrait,c("cor_sinfo_adz")]<-cor(cSumstats[IMPUTED==F & is.finite(d.z.abs) & is.finite(SINFO),]$d.z.abs,cSumstats[IMPUTED==F & is.finite(d.z.abs) & is.finite(SINFO),]$SINFO)
    p$dsStat$sumstats.meta[iTrait,c("cor_sinfo_adz.05_50")]<-cor(cSumstats[IMPUTED==F & is.finite(d.z.abs) & is.finite(SINFO) & MAF>0.05 & MAF<0.5,]$d.z.abs,cSumstats[IMPUTED==F & is.finite(d.z.abs) & is.finite(SINFO) & MAF>0.05 & MAF<0.5,]$SINFO)
    p$dsStat$sumstats.meta[iTrait,c("cor_sinfo_adz.01_05")]<-cor(cSumstats[IMPUTED==F & is.finite(d.z.abs) & is.finite(SINFO) & MAF>0.01 & MAF<0.05,]$d.z.abs,cSumstats[IMPUTED==F & is.finite(d.z.abs) & is.finite(SINFO) & MAF>0.01 & MAF<0.05,]$SINFO)
    p$dsStat$sumstats.meta[iTrait,c("cor_sinfo_adz.0_01")]<-cor(cSumstats[IMPUTED==F & is.finite(d.z.abs) & is.finite(SINFO) & MAF<0.01,]$d.z.abs,cSumstats[IMPUTED==F & is.finite(d.z.abs) & is.finite(SINFO) & MAF<0.01,]$SINFO)

    p$dsStat$sumstats.meta[iTrait,c("rmse_sinfo.0_5")]<-sqrt(mean(cSumstats[IMPUTED==F & is.finite(d.z.abs) & is.finite(SINFO) & SINFO<0.5,]$d.z^2, na.rm=T))
    p$dsStat$sumstats.meta[iTrait,c("rmse_sinfo.5_9")]<-sqrt(mean(cSumstats[IMPUTED==F & is.finite(d.z.abs) & is.finite(SINFO) & SINFO>0.5 & SINFO<0.9,]$d.z^2, na.rm=T))
    p$dsStat$sumstats.meta[iTrait,c("rmse_sinfo.9_10")]<-sqrt(mean(cSumstats[IMPUTED==F & is.finite(d.z.abs) & is.finite(SINFO) & SINFO>0.9 & SINFO<1,]$d.z^2, na.rm=T))




    saveRDS(object = p$dsStat,file = p$filepath.dsStat)
  }
  
  #paths
  
  p$dsStat$panel.meta<-as.data.table(matrix(data = NA,nrow = 0,ncol = 0))
  p$dsStat$panel.meta<- rbind(p$dsStat$panel.meta,list(code="hm3",path=eval(p$filepath.SNPReference.hm3)))
  p$dsStat$panel.meta<- rbind(p$dsStat$panel.meta,list(code="1kg",path=eval(p$filepath.SNPReference.1kg)))
  p$dsStat$panel.meta<- rbind(p$dsStat$panel.meta,list(code="hc1kg",path=eval(p$filepath.SNPReference.hc1kg)))
  
  print(p$dsStat$panel.meta)
  
  #hard coded
  cat("\n1kg")
  tgp.old <- shru::readFile(filePath = file.path("/scratch/prj/gwas_sumstats/1kg_bed","1KG_Phase3.WG.CLEANED.EUR_MAF001.CM23.bim"), nThreads = p$nThread)
  colnames(tgp.old)<-c("CHR","SNP","CM","BP","A1","A2")
  tgp.old.frq <- shru::readFile(filePath = file.path("/scratch/prj/gwas_sumstats/1kg_bed","1KG_Phase3.WG.CLEANED.EUR_MAF001.CM23.frq.frq"), nThreads = p$nThread)
  setkeyv(tgp.old,cols = c("SNP"))
  setkeyv(tgp.old.frq,cols = c("SNP"))
  tgp.old[tgp.old.frq,on=c("SNP"),c("MAF"):=i.MAF]
  
  p$dsStat$panel.meta[code=="1kg",c("m")]<-nrow(tgp.old)
  p$dsStat$panel.meta[code=="1kg",c("m.0_01")]<-nrow(tgp.old[is.finite(MAF) & MAF<0.01,])
  p$dsStat$panel.meta[code=="1kg",c("m.01_05")]<-nrow(tgp.old[is.finite(MAF) & MAF>0.01 & MAF <0.05,])
  p$dsStat$panel.meta[code=="1kg",c("m.05_50")]<-nrow(tgp.old[is.finite(MAF) & MAF>0.05 & MAF <0.5,])
  rm(tgp.old)
  
  cat("\nhm3")
  hm3 <- shru::readFile(filePath = p$dsStat$panel.meta[code=="hm3",]$path, nThreads = p$nThread)
  setkeyv(hm3,cols = c("SNP"))
  hm3[tgp.old.frq,on=c("SNP"),c("MAF"):=i.MAF]
  p$dsStat$panel.meta[code=="hm3",c("m")]<-nrow(hm3)
  p$dsStat$panel.meta[code=="hm3",c("m.0_01")]<-nrow(hm3[is.finite(MAF) & MAF<0.01,])
  p$dsStat$panel.meta[code=="hm3",c("m.01_05")]<-nrow(hm3[is.finite(MAF) & MAF>0.01 & MAF <0.05,])
  p$dsStat$panel.meta[code=="hm3",c("m.05_50")]<-nrow(hm3[is.finite(MAF) & MAF>0.05 & MAF <0.5,])
  rm(hm3)
  rm(tgp.old.frq)
  
  cat("\nhc1kg")
  tgp <- shru::readFile(filePath = p$dsStat$panel.meta[code=="hc1kg",]$path, nThreads = p$nThread)
  setkeyv(tgp,cols = c("SNP"))
  p$dsStat$panel.meta[code=="hc1kg",c("m")]<-nrow(tgp)
  p$dsStat$panel.meta[code=="hc1kg",c("m.0_01")]<-nrow(tgp[is.finite(MAF) & MAF<0.01,])
  p$dsStat$panel.meta[code=="hc1kg",c("m.01_05")]<-nrow(tgp[is.finite(MAF) & MAF>0.01 & MAF <0.05,])
  p$dsStat$panel.meta[code=="hc1kg",c("m.05_50")]<-nrow(tgp[is.finite(MAF) & MAF>0.05 & MAF <0.5,])
  rm(tgp)

  saveRDS(object = p$dsStat,file = p$filepath.dsStat)
  
}

if(p$clOptions$task=="stat") quit(save = "no")


```

# Preliminary annotation of chosen datasets, excluding mean chi2

```{r annotation of chosen datasets, fig.width=10, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}
#View(p$sumstats.sel)
#View(p$sumstats.sel.raw)

#selected sumstats
p$sumstats.sel.table<-p$sumstats.sel.raw[,c("name.nice.and_code","reference.nice","year","n_case","n_control", "samplePrevalence","populationPrevalence")]
#View(p$sumstats.sel.table)
#p$sumstats.sel.table

p$plots.sumstats.sel.table<-p$sumstats.sel.table %>% 
  gt() %>% 
  fmt_number(columns = vars(samplePrevalence), decimals = 3) %>%
  fmt_number(columns = vars(populationPrevalence), decimals = 4) %>%
  fmt_number(columns = vars(n_case,n_control), decimals = 0) %>%
  tab_header(
    title = "Selected GWAS summary statistics datasets"
  ) %>% cols_label(
    name.nice.and_code  = "Trait",
    reference.nice = "Reference",
    year = "Year",
    #ancestry = "Ancestry",
    #sex = "Sex",
    n_case = "N case or total",
    n_control = "N control",
    samplePrevalence = html("Prev<sub>sample</sub>"),
    populationPrevalence = html("Prev<sub>population</sub>")
  ) %>%
  tab_style(
    style = cell_text(size = px(14)),
    locations = cells_column_labels(everything())       
  ) %>%
  tab_style(
    style = cell_text(size = px(16),weight = "bold"),
    locations = cells_body(everything())        
  )

p$plots.sumstats.sel.table

gtsave(data = p$plots.sumstats.sel.table, filename = paste0(p$folderpath.plots,"/sumstats.sel.table.rtf"))


#annotation of datasets including imputation validation metrics
# p$dsStat$sumstats.meta[,colnames(p$dsStat$sumstats.meta)!="code"]<-sapply(X = p$dsStat$sumstats.meta[,colnames(p$dsStat$sumstats.meta)!="code"], FUN=as.numeric) #fix
p$sumstats.sel.table<-p$sumstats.sel.raw[,c("name.nice.and_code","code")]
setDT(p$sumstats.sel.table)
p$sumstats.sel.table<-merge(p$sumstats.sel.table,p$dsStat$sumstats.meta,by = "code")
#View(p$sumstats.sel.table)
p$sumstats.sel.table[,code:=NULL]

p$plots.sumstats.sel.table<-p$sumstats.sel.table %>% 
  gt() %>% 
  #fmt_number(columns =  starts_with(c("meanAssocChi2.","medianAssocChi2.","cor")), decimals = 3) %>%
  #fmt_number(columns =  starts_with("m."), decimals = 0) %>%
  #fmt_number(columns =  m, decimals = 0) %>%
  #fmt_number(columns =  starts_with(c("rmse","bias")), decimals = 4) %>%
  tab_header(
    title = "LD-IMP validation metrics"
  ) %>% cols_label(
    name.nice.and_code  = "Trait"
  ) %>%
  tab_style(
    style = cell_text(size = px(14)),
    locations = cells_column_labels(everything())       
  ) %>%
  tab_style(
    style = cell_text(size = px(16),weight = "bold"),
    locations = cells_body(everything())        
  )

p$plots.sumstats.sel.table

gtsave(data = p$plots.sumstats.sel.table, filename = paste0(p$folderpath.plots,"/sumstats.sel.impval.table.rtf"))


```


# Multivariate LD
The multivariate LDSC and HDL procedure calculates genetic correlations between the different traits and estimates of correlation standard errors, producing S (variances and covariances = heritabilities and coheritabilities) and V (diagonal: squared standard errors of elements in S. Off-diagonal: Covariances of elements in S - "dependencies between estimation errors used to model dependencies due to sample overlap") matrices used later in the Genomic SEM model fitting.

HDL is an improved method to account for linkage disequilibrium while estimating genetic effects from GWAS.

```{r multivariate LD}
print("***Multivariate LD***")

p$filepath.mvLD<-file.path(p$folderpath.workingDirectory,paste0("mvLD.",p$setup.code,".Rds"))

if (file.exists(p$filepath.mvLD)) {
  print("Using existing covariance structures from previous LD computations.")
  p$mvLD<-readRDS(file=p$filepath.mvLD)
} else {
  p$mvLD<-c()
}

if(p$clOptions$task=="mvLD" || (!file.exists(p$filepath.mvLD) & p$clOptions$task=="0"))
{
  print("Running (multivariate) LD score regression with different methods. This might take a while. If the procedure runs for too long you may want to abort the process.")
  
  cat("The current task is specified as:",p$clOptions$task,"\n")
  
  #run mvLDSC
  
  #test of ldscpp
  # cat("\n\n*** LDSC: TEST***\n")
  # p$mvLD$covstruct.TEST<-ldscpp(
  #   traits = c(p$sumstats.sel[c("BODY14","BODYT2MI","BODYTM"),]$mungedpath,p$sumstats.sel[c("BODYTM","BODY14"),]$imputedpath.05cm),
  #   sample.prev =  p$sumstats.sel[c("BODY14","BODYT2MI","BODYTM","BODYTM","BODY14"),]$samplePrevalence,
  #   population.prev = p$sumstats.sel[c("BODY14","BODYT2MI","BODYTM","BODYTM","BODY14"),]$populationPrevalence,
  #   trait.names = c(p$sumstats.sel[c("BODY14","BODYT2MI","BODYTM"),]$code,"BODYTMI","BODY14I"),
  #   filepathLD = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   filter.maf = 0.01,
  #   filter.sinfo = 0.85,
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = F,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel[c("BODY14","BODYT2MI","BODYTM","BODYTM","BODY14"),]$n_total,
  #   ldsc.log = p$setup.code.date
  #   )
  

  # readyMergedTraitsF<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   ld = p$folderpath.data.mvLDSC.ld.1kg,
  #   #filepathVariantsAdditional = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   filter.info = 0.6,
  #   filter.maf = 0.01,
  #   #filter.chisq.min = NA,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   ldsc.log = p$setup.code.date,
  #   exportReadyMergedTraits = T,
  #   force.M = 7184778
  #   )

  # readyMergedTraits<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   ld = p$folderpath.data.mvLDSC.ld.1kg,
  #   #filepathVariantsAdditional = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   #filter.info = 0.6,
  #   filter.maf = 0.01,
  #   #filter.chisq.min = NA,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   ldsc.log = p$setup.code.date,
  #   exportReadyMergedTraits = T,
  #   force.M = 7184778
  #   )

  # cat("\n\n*** LDSC: covstruct.mvLDSC.1kg.original ***\n")
  # p$mvLD$covstruct.mvLDSC.1kg.original<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   readyMergedTraits = readyMergedTraitsF,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   ld = p$folderpath.data.mvLDSC.ld.1kg,
  #   #filepathVariantsAdditional = p$filepath.SNPReference.hc1kg,
  #   n.blocks = 200,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = F,
  #   preweight.INFO=F,
  #   resamplingMethod="jn",
  #   blocksizeCM = NA, #inactivate CM window def
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   filter.info = 0.6,
  #   filter.maf = 0.01,
  #   force.M = 7184778,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # cat("\n\n***END LDSC: covstruct.mvLDSC.1kg.original ***\n")
  # 
  
    # #restricted 1kg to hm3 variants
    # df_ld.hm3 <- fread(file = p$filepath.SNPReference.hm3, na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, showProgress = F, nThread = p$nThread, data.table=T)
    # #df_ld.1kg <- fread(file = p$filepath.SNPReference.1kg, na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, showProgress = F, nThread = p$nThread, data.table=T)
    # df_ld.1kg <- do.call("rbind", lapply(list.files(path = p$folderpath.data.mvLDSC.ld.1kg, pattern = "\\.l2\\.ldscore\\.gz$"), function(i) {
    #     suppressMessages(fread(file = file.path(p$folderpath.data.mvLDSC.ld.1kg, i), na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, showProgress = F, nThread = p$nThread, data.table=T))
    #   }))
    # 
    # df_ld.hm3<-df_ld.hm3[,c("SNP")]
    # setkeyv(df_ld.hm3,cols = c("SNP"))
    # setkeyv(df_ld.1kg,cols = c("SNP"))
    # df_ld.1kg.hm3res <- df_ld.1kg[df_ld.hm3, on=c("SNP"), nomatch=0]
    # rm(df_ld.hm3)
    # rm(df_ld.1kg)

  # cat("\n\n*** LDSC: covstruct.mvLDSC.1kg.hm3res.original***\n")
  # p$mvLD$covstruct.mvLDSC.1kg.hm3res.original<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   df_ld = df_ld.1kg.hm3res,
  #   n.blocks = 200,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = F,
  #   preweight.INFO=F,
  #   resamplingMethod="jn",
  #   blocksizeCM = NA, #inactivate CM window def
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   filter.info = 0.6,
  #   filter.maf = 0.01,
  #   force.M = 7184778,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # cat("\n\n***END LDSC: covstruct.mvLDSC.1kg.hm3res.original***\n")
  # #rm(df_ld.1kg.hm3res)
  # 
  # cat("\n\n*** LDSC: covstruct.mvLDSC.hm3.original ***\n")
  # p$mvLD$covstruct.mvLDSC.hm3.original<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   ld = p$folderpath.data.mvLDSC.ld.hm3,
  #   n.blocks = 200,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = F,
  #   preweight.INFO=F,
  #   resamplingMethod="jn",
  #   blocksizeCM = NA, #inactivate CM window def
  #   filter.region.df = p$highld_b38,
  #   filter.info = 0.6,
  #   filter.maf = 0.01,
  #   N = p$sumstats.sel$n_total,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # cat("\n\n***END LDSC: covstruct.mvLDSC.hm3.original ***\n")
  # 
  # # cat("\n\n*** LDSC: covstruct.mvLDSC.hc1kg.original ***\n")
  # # p$mvLD$covstruct.mvLDSC.hc1kg.original<-ldscpp(
  # #   traits = p$sumstats.sel$mungedpath,
  # #   sample.prev =  p$sumstats.sel$samplePrevalence,
  # #   population.prev = p$sumstats.sel$populationPrevalence,
  # #   trait.names = p$sumstats.sel$code,
  # #   filepathLD = p$filepath.SNPReference.hc1kg,
  # #   n.blocks = 200,
  # #   ancestrySetting = "EUR",
  # #   referenceAncestrySetting = "EUR",
  # #   preweight.ChiSquare = F,
  # #   correctAttenuationBias = F,
  # #   doubleRegressionRoutine = F,
  # #   preweight.INFO=F,
  # #   resamplingMethod="jn",
  # #   blocksizeCM = NA, #inactivate CM window def
  # #   filter.info = 0.6,
  # #   filter.maf = 0.01,
  # #   filter.region.df = p$highld_b38,
  # #   N = p$sumstats.sel$n_total,
  # #   ldsc.log = p$setup.code.date
  # #   )
  # # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # # cat("\n\n***END LDSC: covstruct.mvLDSC.hc1kg.original ***\n")
  # 
  # cat("\n\n*** LDSC: covstruct.mvLDSC.1kg.vbcs ***\n")
  # p$mvLD$covstruct.mvLDSC.1kg.vbcs<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   #readyMergedTraits = readyMergedTraitsF,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   ld = p$folderpath.data.mvLDSC.ld.1kg,
  #   filepathVariantsAdditional = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = F,
  #   preweight.INFO=F,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   filter.info = 0.6,
  #   filter.maf = 0.01,
  #   force.M = 7184778,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # cat("\n\n***END LDSC: covstruct.mvLDSC.1kg.vbcs ***\n")
   
  # cat("\n\n*** LDSC: covstruct.mvLDSC.1kg.hm3res.vbcs ***\n")
  # p$mvLD$covstruct.mvLDSC.1kg.hm3res.vbcs<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   df_ld = df_ld.1kg.hm3res,
  #   filepathVariantsAdditional = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = F,
  #   preweight.INFO=F,
  #   filter.region.df = p$highld_b38,
  #   filter.info = 0.6,
  #   filter.maf = 0.01,
  #   N = p$sumstats.sel$n_total,
  #   force.M = 7184778,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  #  cat("\n\n***END LDSC: covstruct.mvLDSC.1kg.hm3res.vbcs ***\n")
  #  
  # cat("\n\n*** LDSC: covstruct.mvLDSC.hm3.vbcs ***\n")
  # p$mvLD$covstruct.mvLDSC.hm3.vbcs<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   ld = p$folderpath.data.mvLDSC.ld.hm3,
  #   filepathVariantsAdditional = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = F,
  #   preweight.INFO=F,
  #   filter.region.df = p$highld_b38,
  #   filter.info = 0.6,
  #   filter.maf = 0.01,
  #   N = p$sumstats.sel$n_total,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  #  cat("\n\n***END LDSC: covstruct.mvLDSC.hm3.vbcs ***\n")
  # 
  # cat("\n\n*** LDSC: covstruct.mvLDSC.1kg.vbcs.nocm ***\n")
  # p$mvLD$covstruct.mvLDSC.1kg.vbcs.nocm<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   readyMergedTraits = readyMergedTraitsF,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   ld = p$folderpath.data.mvLDSC.ld.1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   blocksizeCM = NA,
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = F,
  #   preweight.INFO=F,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   filter.info = 0.6,
  #   filter.maf = 0.01,
  #   force.M = 7184778,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # cat("\n\n***END LDSC: covstruct.mvLDSC.1kg.vbcs.nocm ***\n")
  # 
  # cat("\n\n*** LDSC: covstruct.mvLDSC.1kg.hm3res.vbcs.nocm ***\n")
  # p$mvLD$covstruct.mvLDSC.1kg.hm3res.vbcs.nocm<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   df_ld = df_ld.1kg.hm3res,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   blocksizeCM = NA,
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = F,
  #   preweight.INFO=F,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   filter.info = 0.6,
  #   filter.maf = 0.01,
  #   force.M = 7184778,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # cat("\n\n***END LDSC: covstruct.mvLDSC.1kg.hm3res.vbcs.nocm ***\n")
  # 
  # cat("\n\n*** LDSC: covstruct.mvLDSC.hm3.vbcs.nocm ***\n")
  # p$mvLD$covstruct.mvLDSC.hm3.vbcs.nocm<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   ld = p$folderpath.data.mvLDSC.ld.hm3,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   blocksizeCM = NA,
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = F,
  #   preweight.INFO=F,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   filter.info = 0.6,
  #   filter.maf = 0.01,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # cat("\n\n***END LDSC: covstruct.mvLDSC.hm3.vbcs.nocm ***\n")


  # cat("\n\n*** LDSC: covstruct.mvLDSC.1kg.vbcs.unfiltered ***\n")
  # p$mvLD$covstruct.mvLDSC.1kg.vbcs.unfiltered<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   ld = p$folderpath.data.mvLDSC.ld.1kg,
  #   filepathVariantsAdditional = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = F,
  #   preweight.INFO=F,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   filter.maf = 0.01,
  #   force.M = 7184778,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # cat("\n\n***END LDSC: covstruct.mvLDSC.1kg.vbcs.unfiltered ***\n")
  # 
  # cat("\n\n*** LDSC: covstruct.mvLDSC.1kg.vbcs.winfo ***\n")
  # p$mvLD$covstruct.mvLDSC.1kg.vbcs.winfo<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   ld = p$folderpath.data.mvLDSC.ld.1kg,
  #   filepathVariantsAdditional = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = F,
  #   preweight.INFO=T,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   filter.maf = 0.01,
  #   force.M = 7184778,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # cat("\n\n***END LDSC: covstruct.mvLDSC.1kg.vbcs.winfo ***\n")
  
  # cat("\n\n*** LDSC: covstruct.mvLDSC.1kg.vbcs.nocm.unfiltered ***\n")
  # p$mvLD$covstruct.mvLDSC.1kg.vbcs.nocm.unfiltered<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   ld = p$folderpath.data.mvLDSC.ld.1kg,
  #   filepathVariantsAdditional = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   blocksizeCM = NA,
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = F,
  #   preweight.INFO=F,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   filter.maf = 0.01,
  #   force.M = 7184778,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # cat("\n\n***END LDSC: covstruct.mvLDSC.1kg.vbcs.nocm.unfiltered ***\n")
  # 
  # cat("\n\n*** LDSC: covstruct.mvLDSC.1kg.vbcs.nocm.winfo ***\n")
  # p$mvLD$covstruct.mvLDSC.1kg.vbcs.nocm.winfo<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   ld = p$folderpath.data.mvLDSC.ld.1kg,
  #   filepathVariantsAdditional = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   blocksizeCM = NA,
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = F,
  #   preweight.INFO=T,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   filter.maf = 0.01,
  #   force.M = 7184778,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # cat("\n\n***END LDSC: covstruct.mvLDSC.1kg.vbcs.nocm.winfo ***\n")
  
  # cat("\n\n*** LDSC: covstruct.mvLDSC.1kg.hm3res.vbcs.nocm.winfo ***\n")
  # p$mvLD$covstruct.mvLDSC.1kg.hm3res.vbcs.nocm.winfo<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   df_ld = df_ld.1kg.hm3res,
  #   filepathVariantsAdditional = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   blocksizeCM = NA,
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = F,
  #   preweight.INFO=T,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   filter.maf = 0.01,
  #   force.M = 7184778,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # cat("\n\n***END LDSC: covstruct.mvLDSC.1kg.hm3res.vbcs.nocm.winfo ***\n")
  
  
  # 
  # cat("\n\n*** LDSC: covstruct.mvLDSC.1kg.vbcs.drc ***\n")
  # p$mvLD$covstruct.mvLDSC.1kg.vbcs.drc<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   readyMergedTraits = readyMergedTraitsF,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   filepathLD = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = T,
  #   preweight.INFO=F,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # 
  # 
  # cat("\n\n*** LDSC: covstruct.mvLDSC.1kg.vbcs.drc.nocm ***\n")
  # p$mvLD$covstruct.mvLDSC.1kg.vbcs.drc.nocm<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   readyMergedTraits = readyMergedTraitsF,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   filepathLD = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = T,
  #   preweight.INFO=F,
  #   blocksizeCM = NA,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # 
  # cat("\n\n*** LDSC: covstruct.mvLDSC.1kg.vbcs.drc.winfo ***\n")
  # p$mvLD$covstruct.mvLDSC.1kg.vbcs.drc.winfo<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   readyMergedTraits = readyMergedTraits,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   filepathLD = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = T,
  #   preweight.INFO=T,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # 
  # 
   
  #USING NO CM BLOCKS AS DEFAULT FROM HERE!!!!
  cat("\n\n*** LDSC: covstruct.mvLDSC.hc1kg.largeonly***\n")
  p$mvLD$covstruct.mvLDSC.hc1kg.largeonly<-ldscpp(
    traits = p$sumstats.sel.ssimp$mungedpath,
    sample.prev =  p$sumstats.sel.ssimp$samplePrevalence,
    population.prev = p$sumstats.sel.ssimp$populationPrevalence,
    trait.names = p$sumstats.sel.ssimp$code,
    filepathLD = p$filepath.SNPReference.hc1kg,
    ancestrySetting = "EUR",
    referenceAncestrySetting = "EUR",
    filter.maf = 0.01,
    preweight.ChiSquare = F,
    correctAttenuationBias = F,
    doubleRegressionRoutine = F,
    blocksizeCM = NA,
    filter.region.df = p$highld_b38,
    N = p$sumstats.sel$n_total,
    ldsc.log = p$setup.code.date
    )
  saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  cat("\n\n***END LDSC: covstruct.mvLDSC.hc1kg.largeonly***\n")
  
  # cat("\n\n*** LDSC: covstruct.mvLDSC.hc1kg***\n")
  # p$mvLD$covstruct.mvLDSC.hc1kg<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   filepathLD = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   filter.maf = 0.01,
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = F,
  #   blocksizeCM = NA,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # cat("\n\n***END LDSC: covstruct.mvLDSC.hc1kg***\n")
  # 
  # cat("\n\n*** LDSC: covstruct.mvLDSC.hc1kg.small ***\n")
  # p$mvLD$covstruct.mvLDSC.hc1kg.small<-ldscpp(
  #   traits = p$sumstats.sel.ssimp$mungedpath,
  #   sample.prev =  p$sumstats.sel.ssimp$samplePrevalence,
  #   population.prev = p$sumstats.sel.ssimp$populationPrevalence,
  #   trait.names = p$sumstats.sel.ssimp$code,
  #   filepathLD = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   leave.chr = list(1,2,6,7,9,11),
  #   filter.maf = 0.01,
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = F,
  #   blocksizeCM = NA,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel.ssimp$n_total,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # cat("\n\n***END LDSC: covstruct.mvLDSC.hc1kg.small ***\n")
  # 
  # cat("\n\n*** LDSC: covstruct.mvLDSC.hm3 ***\n")
  # p$mvLD$covstruct.mvLDSC.hm3<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   ld = p$folderpath.data.mvLDSC.ld.hm3,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   filter.maf = 0.01,
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = F,
  #   blocksizeCM = NA,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # cat("\n\n***END LDSC: covstruct.mvLDSC.hm3 ***\n")
  # 
  # 
  # 
  #  #restricted hc1kg to hm3 variants
  #  df_ld.hm3 <- fread(file = p$filepath.SNPReference.hm3, na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, showProgress = F, nThread = p$nThread, data.table=T)
  #  #df_ld.1kg <- fread(file = p$filepath.SNPReference.1kg, na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, showProgress = F, nThread = p$nThread, data.table=T)
  #  df_ld.hc1kg <- fread(file = p$filepath.SNPReference.hc1kg, na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, showProgress = F, nThread = p$nThread, data.table=T)
  # 
  #  df_ld.hm3<-df_ld.hm3[,c("SNP")]
  #  setkeyv(df_ld.hm3,cols = c("SNP"))
  #  setkeyv(df_ld.hc1kg,cols = c("SNP"))
  #  df_ld.hc1kg.hm3res <- df_ld.hc1kg[df_ld.hm3, on=c("SNP"), nomatch=0]
  #  rm(df_ld.hm3)
  #  rm(df_ld.hc1kg)
  # 
  # cat("\n\n*** LDSC: covstruct.mvLDSC.hc1kg.hm3res ***\n")
  # p$mvLD$covstruct.mvLDSC.hc1kg.hm3res<-ldscpp(
  #   traits = p$sumstats.sel$mungedpath,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   df_ld = df_ld.hc1kg.hm3res,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   filter.maf = 0.01,
  #   preweight.ChiSquare = F,
  #   correctAttenuationBias = F,
  #   doubleRegressionRoutine = F,
  #   blocksizeCM = NA,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   force.M = 7291342,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # cat("\n\n***END LDSC: covstruct.mvLDSC.hc1kg.hm3res ***\n")
  # 
  # cat("\n\n*** LDSC: covstruct.mvLDSC.1kg.0.5cM ***\n")
  # p$mvLD$covstruct.mvLDSC.1kg.05cm<-ldscpp(
  #   traits = p$sumstats.sel$imputedpath.05cm,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   filepathLD = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   filter.maf = 0.01,
  #   blocksizeCM = NA,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  
  #
  # cat("\n\n*** LDSC: covstruct.mvLDSC.1kg.500 ***\n")
  # p$mvLD$covstruct.mvLDSC.1kg.500<-ldscpp(
  #   traits = p$sumstats.sel$imputedpath,
  #   sample.prev =  p$sumstats.sel$samplePrevalence,
  #   population.prev = p$sumstats.sel$populationPrevalence,
  #   trait.names = p$sumstats.sel$code,
  #   filepathLD = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   filter.maf = 0.01,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  #
  # cat("\n\n*** LDSC: covstruct.mvLDSC.1kg.500.small ***\n")
  # p$mvLD$covstruct.mvLDSC.1kg.500.small<-ldscpp(
  #   traits = p$sumstats.sel.ssimp$imputedpath,
  #   sample.prev =  p$sumstats.sel.ssimp$samplePrevalence,
  #   population.prev = p$sumstats.sel.ssimp$populationPrevalence,
  #   trait.names = p$sumstats.sel.ssimp$code,
  #   filepathLD = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   leave.chr = list(1,2,6,7,9,11),
  #   filter.maf = 0.01,
  #   filter.simpute.fraction = 0.10, #10% to compare between the two methods
  #   blocksizeCM = NA,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # 
  # cat("\n\n*** LDSC: covstruct.mvLDSC.1kg.ssimp.small ***\n")
  # p$mvLD$covstruct.mvLDSC.1kg.ssimp.small<-ldscpp(
  #   traits = p$sumstats.sel.ssimp$imputedpath2.ssimp,
  #   sample.prev =  p$sumstats.sel.ssimp$samplePrevalence,
  #   population.prev = p$sumstats.sel.ssimp$populationPrevalence,
  #   trait.names = p$sumstats.sel.ssimp$code,
  #   filepathLD = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   resetImputedN = T, #Because SSimp sets N according to imputation quality
  #   leave.chr = list(1,2,6,7,9,11),
  #   reinflateImputedGWAS = F, #because SSIMP
  #   filter.maf = 0.01,
  #   filter.simpute.fraction = 0.10, #10% to compare between the two methods
  #   blocksizeCM = NA,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)

  #experimental - there is a bug
  # cat("\n\n*** LDSC: covstruct.mvLDSC.1kg.500only.small ***\n")
  # p$mvLD$covstruct.mvLDSC.1kg.500only.small<-ldscpp(
  #   traits = p$sumstats.sel.ssimp$imputedpath,
  #   sample.prev =  p$sumstats.sel.ssimp$samplePrevalence,
  #   population.prev = p$sumstats.sel.ssimp$populationPrevalence,
  #   trait.names = p$sumstats.sel.ssimp$code,
  #   filepathLD = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   leave.chr = list(1,2,6,7,9,11),
  #   filter.maf = 0.01,
  #   filter.gwasssimputedonly = T,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  #
  # cat("\n\n*** LDSC: covstruct.mvLDSC.1kg.ssimponly.small ***\n")
  # p$mvLD$covstruct.mvLDSC.1kg.ssimponly.small<-ldscpp(
  #   traits = p$sumstats.sel.ssimp$imputedpath2.ssimp,
  #   sample.prev =  p$sumstats.sel.ssimp$samplePrevalence,
  #   population.prev = p$sumstats.sel.ssimp$populationPrevalence,
  #   trait.names = p$sumstats.sel.ssimp$code,
  #   filepathLD = p$filepath.SNPReference.hc1kg,
  #   ancestrySetting = "EUR",
  #   referenceAncestrySetting = "EUR",
  #   resetImputedN = T, #Because SSimp sets N according to imputation quality
  #   leave.chr = list(1,2,6,7,9,11),
  #   reinflateImputedGWAS = F, #because SSIMP
  #   filter.maf = 0.01,
  #   filter.gwasssimputedonly = T,
  #   filter.region.df = p$highld_b38,
  #   N = p$sumstats.sel$n_total,
  #   ldsc.log = p$setup.code.date
  #   )
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)

  
  #   
#   
#   #original ldsc test
#   p$mvLD$ldscTest<-c()
#   for(cTrait in p$sumstats.sel$code){
#     p$mvLD$ldscTest[cTrait] <- list(
#       ldsc.orig(trait_codes = list(cTrait),trait_filepaths = p$sumstats.sel[cTrait,]$mungedpath, ldsc_filepath = "/users/k19049801/project/JZ_GED_PHD_ADMIN_GENERAL/software/ldsc/ldsc.py", ld_filepath = file.path(p$folderpath.data.mvLDSC.ld.1kg,"hc1kgp3.b38.eur.jz2023.1cm.250blocks"),samp_prev = p$sumstats.sel[cTrait,]$samplePrevalence, pop_prev = p$sumstats.sel[cTrait,]$populationPrevalence,output_file_path = paste0(cTrait,"_h2munged.ldsc"), blocks = 200)
#       )
#   }
#   saveRDS(object = p$mvLD,file = p$filepath.mvLD)

  
  #run original ldsc per dataset to get heritabilities
  # p$mvLD$h2.munged<-c()
  # for(cTrait in p$sumstats.sel$code){
  #   p$mvLD$h2.munged[cTrait] <- list(
  #     ldsc.orig(trait_codes = list(cTrait),trait_filepaths = p$sumstats.sel[cTrait,]$mungedpath2, ldsc_filepath = "/users/k19049801/project/JZ_GED_PHD_ADMIN_GENERAL/software/ldsc/ldsc.py", ld_filepath = file.path(p$folderpath.data.mvLDSC.ld.1kg,"hc1kgp3.b38.eur.1cm.400blocks"),samp_prev = p$sumstats.sel[cTrait,]$samplePrevalence, pop_prev = p$sumstats.sel[cTrait,]$populationPrevalence,output_file_path = paste0(cTrait,"_h2munged.ldsc"), blocks = 200)
  #     )
  # }
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # 
  # #SSIMP trait subset only!!!
  # p$mvLD$h2.500<-c()
  # for(cTrait in p$sumstats.sel.ssimp$code){
  #   p$mvLD$h2.500[cTrait] <- list(
  #     ldsc.orig(trait_codes = list(cTrait),trait_filepaths = p$sumstats.sel[cTrait,]$imputedpath2.500, ldsc_filepath = "/users/k19049801/project/JZ_GED_PHD_ADMIN_GENERAL/software/ldsc/ldsc.py", ld_filepath = file.path(p$folderpath.data.mvLDSC.ld.1kg,"hc1kgp3.b38.eur.1cm.400blocks"),samp_prev = p$sumstats.sel[cTrait,]$samplePrevalence, pop_prev = p$sumstats.sel[cTrait,]$populationPrevalence, output_file_path = paste0(cTrait,"_h2500.ldsc"), blocks = 200)
  #     )
  # }
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  # 
  # p$mvLD$h2.ssimp<-c()
  # for(cTrait in p$sumstats.sel.ssimp$code){
  #   p$mvLD$h2.ssimp[cTrait] <- list(
  #     ldsc.orig(trait_codes = list(cTrait),trait_filepaths = p$sumstats.sel[cTrait,]$imputedpath2.ssimp, ldsc_filepath = "/users/k19049801/project/JZ_GED_PHD_ADMIN_GENERAL/software/ldsc/ldsc.py", ld_filepath = file.path(p$folderpath.data.mvLDSC.ld.1kg,"hc1kgp3.b38.eur.1cm.400blocks"),samp_prev = p$sumstats.sel[cTrait,]$samplePrevalence, pop_prev = p$sumstats.sel[cTrait,]$populationPrevalence, output_file_path = paste0(cTrait,"_h2ssimp.ldsc"), blocks = 200)
  #     )
  # }
  # saveRDS(object = p$mvLD,file = p$filepath.mvLD)


  #set the default mvLDSC object to use
  p$mvLD$covstruct.mvLDSC<-p$mvLD$covstruct.mvLDSC.1kg.05cm
  #p$mvLD$covstruct.mvLDSC<-p$mvLD$covstruct.mvLDSC.1kg.noimp
  
  #Additional computations
  #saving the original S in case of smoothing experiments later stored in S
  p$mvLD$covstruct.mvLDSC$S.orig<-p$mvLD$covstruct.mvLDSC$S
  p$mvLD$covstruct.mvLDSC$S.smooth<-as.matrix((nearPD(p$mvLD$covstruct.mvLDSC$S, corr = FALSE))$mat)
  
  rm(readyMergedTraits)
  rm(readyMergedTraitsF)
  
  #save the mvLD output
  saveRDS(object = p$mvLD,file = p$filepath.mvLD)
  print("Multivariate LD score regression is done now and the resulting covariance structure should have been saved to a file.")
  
}


# 
# if(p$clOptions$task=="mvLD.gwis" || (!file.exists(p$filepath.mvLD.gwis) & p$clOptions$task=="0"))
# {
#   print("Running (multivariate) LD score regression. This might take a while. If the procedure runs for too long you may want to abort the process.")
#   
#   cat("The current task is specified as:",p$clOptions$task,"\n")
#   
#   #run mvLDSC
#   
#   #requires the bmigwas selection of traits
#   cat("\n\n*** LDSC: covstruct.mvLDSC.gwis ***\n")
#   p$mvLD.gwis$covstruct.mvLDSC.gwis.nonimputed<-ldscpp(
#     traits = p$sumstats.sel.gwis$mungedpath,
#     sample.prev =  p$sumstats.sel.gwis$samplePrevalence,
#     population.prev = p$sumstats.sel.gwis$populationPrevalence,
#     trait.names = p$sumstats.sel.gwis$code,
#     filepathLD = p$filepath.SNPReference.hc1kg,
#     filter.info = 0.6,
#     filter.maf = 0.01,
#     filter.region.df = p$highld_b38,
#     N = p$sumstats.sel.gwis$n_total,
#     ldsc.log = p$setup.code.date
#     )
#   saveRDS(object = p$mvLD.gwis,file = p$filepath.mvLD.gwis)
#   
#   print("Multivariate LD score regression is done now and the resulting covariance structure should have been saved to a file.")
#   
# }


if(p$clOptions$task=="mvLD" || p$clOptions$task=="mvLD.gwis"){
      quit(save = "no")
    }

#adding standard errors from the V matrices, unstandardised and standardised. I added these calculations to the modified ldsc.

#retrieve the standard errors of S (variances and covariances) from the diagonal of V (contains both).

# p$mvLD$covstruct.mvLDSC$S.SE<-matrix(0, p$k.sel, p$k.sel)
# rownames(p$mvLD$covstruct.mvLDSC$S.SE)<-colnames(p$mvLD$covstruct.mvLDSC$S)
# colnames(p$mvLD$covstruct.mvLDSC$S.SE)<-colnames(p$mvLD$covstruct.mvLDSC$S)
# p$mvLD$covstruct.mvLDSC$S_Stand.SE<-matrix(0, p$k.sel, p$k.sel)
# rownames(p$mvLD$covstruct.mvLDSC$S_Stand.SE)<-colnames(p$mvLD$covstruct.mvLDSC$S)
# colnames(p$mvLD$covstruct.mvLDSC$S_Stand.SE)<-colnames(p$mvLD$covstruct.mvLDSC$S)
# 
# p$mvLD$covstruct.mvLDSC$S.SE[lower.tri(p$mvLD$covstruct.mvLDSC$S.SE,diag=TRUE)] <-sqrt(diag(p$mvLD$covstruct.mvLDSC$V))
# p$mvLD$covstruct.mvLDSC$S.SE[upper.tri(p$mvLD$covstruct.mvLDSC$S.SE)]<-t(p$mvLD$covstruct.mvLDSC$S.SE)[upper.tri(p$mvLD$covstruct.mvLDSC$S.SE)]
# p$mvLD$covstruct.mvLDSC$S_Stand.SE[lower.tri(p$mvLD$covstruct.mvLDSC$S_Stand.SE,diag=TRUE)] <-sqrt(diag(p$mvLD$covstruct.mvLDSC$V_Stand))
# p$mvLD$covstruct.mvLDSC$S_Stand.SE[upper.tri(p$mvLD$covstruct.mvLDSC$S_Stand.SE)]<-t(p$mvLD$covstruct.mvLDSC$S_Stand.SE)[upper.tri(p$mvLD$covstruct.mvLDSC$S_Stand.SE)]

  
#add newly computed heritabilities to the selected summary statistics table
p$sumstats.sel$h2.liability_mvLDSC.hm3<-diag(p$mvLD$covstruct.mvLDSC.hm3$S)[p$sumstats.sel$code]
p$sumstats.sel$h2.se.liability_mvLDSC.hm3<-diag(p$mvLD$covstruct.mvLDSC.hm3$S.SE)[p$sumstats.sel$code]
p$sumstats.sel$h2.liability_mvLDSC.1kg<-diag(p$mvLD$covstruct.mvLDSC.1kg.vbcs.nocm.winfo$S)[p$sumstats.sel$code]
p$sumstats.sel$h2.se.liability_mvLDSC.1kg<-diag(p$mvLD$covstruct.mvLDSC.1kg.vbcs.nocm.winfo$S.SE)[p$sumstats.sel$code]
p$sumstats.sel$h2.liability_mvLDSC.1kg.hm3res<-diag(p$mvLD$covstruct.mvLDSC.1kg.hm3res.vbcs.nocm.winfo$S)[p$sumstats.sel$code]
p$sumstats.sel$h2.se.liability_mvLDSC.1kg.hm3res<-diag(p$mvLD$covstruct.mvLDSC.1kg.hm3res.vbcs.nocm.winfo$S.SE)[p$sumstats.sel$code]
p$sumstats.sel$h2.liability_mvLDSC.hc1kg<-diag(p$mvLD$covstruct.mvLDSC.hc1kg$S)[p$sumstats.sel$code]
p$sumstats.sel$h2.se.liability_mvLDSC.hc1kg<-diag(p$mvLD$covstruct.mvLDSC.hc1kg$S.SE)[p$sumstats.sel$code]
p$sumstats.sel$h2.liability_mvLDSC.hc1kg.hm3res<-diag(p$mvLD$covstruct.mvLDSC.hc1kg.hm3res$S)[p$sumstats.sel$code]
p$sumstats.sel$h2.se.liability_mvLDSC.hc1kg.hm3res<-diag(p$mvLD$covstruct.mvLDSC.hc1kg.hm3res$S.SE)[p$sumstats.sel$code]
p$sumstats.sel$h2.liability_mvLDSC.hc1kg.small<-diag(p$mvLD$covstruct.mvLDSC.hc1kg.small$S)[p$sumstats.sel$code]
p$sumstats.sel$h2.se.liability_mvLDSC.hc1kg.small<-diag(p$mvLD$covstruct.mvLDSC.hc1kg.small$S.SE)[p$sumstats.sel$code]
p$sumstats.sel$h2.liability_mvLDSC.hc1kg.ldimp<-diag(p$mvLD$covstruct.mvLDSC.1kg.05cm$S)[p$sumstats.sel$code]
p$sumstats.sel$h2.se.liability_mvLDSC.hc1kg.ldimp<-diag(p$mvLD$covstruct.mvLDSC.1kg.05cm$S.SE)[p$sumstats.sel$code]
p$sumstats.sel$h2.liability_mvLDSC.hc1kg.ldimp.small<-diag(p$mvLD$covstruct.mvLDSC.1kg.500.small$S)[p$sumstats.sel$code]
p$sumstats.sel$h2.se.liability_mvLDSC.hc1kg.ldimp.small<-diag(p$mvLD$covstruct.mvLDSC.1kg.500.small$S.SE)[p$sumstats.sel$code]
p$sumstats.sel$h2.liability_mvLDSC.hc1kg.ssimp.small<-diag(p$mvLD$covstruct.mvLDSC.1kg.ssimp.small$S)[p$sumstats.sel$code]
p$sumstats.sel$h2.se.liability_mvLDSC.hc1kg.ssimp.small<-diag(p$mvLD$covstruct.mvLDSC.1kg.ssimp.small$S.SE)[p$sumstats.sel$code]

# add when running original ldsc again
# p$sumstats.sel$h2_orig.liability_mvLDSC.1kg.small<-as.numeric(lapply(X = p$mvLD$h2.munged, FUN = function(x){ifelse(any(colnames(x$df)=="h2_liab"),x$df$h2_liab,x$df$h2_obs)}))
# p$sumstats.sel$h2_orig.se.liability_mvLDSC.1kg.small<-as.numeric(lapply(X = p$mvLD$h2.munged, FUN = function(x){ifelse(any(colnames(x$df)=="h2_liab_se"),x$df$h2_liab_se,x$df$h2_obs_se)}))
# p$sumstats.sel$h2_orig.liability_mvLDSC.1kg.ldimp.small<-as.numeric(lapply(X = p$mvLD$h2.500, FUN = function(x){ifelse(any(colnames(x$df)=="h2_liab"),x$df$h2_liab,x$df$h2_obs)}))
# p$sumstats.sel$h2_orig.se.liability_mvLDSC.1kg.ldimp.small<-as.numeric(lapply(X = p$mvLD$h2.500, FUN = function(x){ifelse(any(colnames(x$df)=="h2_liab_se"),x$df$h2_liab_se,x$df$h2_obs_se)}))
# p$sumstats.sel$h2_orig.liability_mvLDSC.1kg.ssimp.small<-as.numeric(lapply(X = p$mvLD$h2.ssimp, FUN = function(x){ifelse(any(colnames(x$df)=="h2_liab"),x$df$h2_liab,x$df$h2_obs)}))
# p$sumstats.sel$h2_orig.se.liability_mvLDSC.1kg.ssimp.small<-as.numeric(lapply(X = p$mvLD$h2.ssimp, FUN = function(x){ifelse(any(colnames(x$df)=="h2_liab_se"),x$df$h2_liab_se,x$df$h2_obs_se)}))

#add variant counts to sumstats
p$sumstats.sel$variants_raw<-p$mvLD$covstruct.mvLDSC.1kg$impstats$m
p$sumstats.sel$variants_ldimp<-p$mvLD$covstruct.mvLDSC.1kg.05cm$impstats$m.imputed
p$sumstats.sel$variants_ldimp.small<-p$mvLD$covstruct.mvLDSC.1kg.05cm.small$impstats[p$sumstats.sel$code,]$m.imputed
p$sumstats.sel$variants_ssimp.small<-p$mvLD$covstruct.mvLDSC.1kg.ssimp.small$impstats[p$sumstats.sel$code,]$m.imputed

  
```
# Overview of LD score regression CV's
```{r overview ldsc cv, fig.width=9, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}

#m_names <- paste0(colnames(p$mvLD$covstruct.mvLDSC.1kg.original$S_Stand.SE),"_",rownames(S_Stand.SE))
#excludeTraits <- c("BODYT2MI")
excludeTraits <- c("BODYT2MI","BODYTM")

cv.S_StandLimit <- 0.05 #0.05
cCovstruct<-p$mvLD$covstruct.mvLDSC.1kg.hm3res.original
S_StandForCV<-abs(cCovstruct$S_Stand)
S_StandForCV[excludeTraits,]<-NA_real_
S_StandForCV[,excludeTraits]<-NA_real_
S_StandForCV[S_StandForCV<cv.S_StandLimit]<-cv.S_StandLimit #cap to avoid extreme values
CV <- cCovstruct$S_Stand.SE/S_StandForCV
p$cv_coverage.1kg.hm3res.original <- data.frame(
  cv=CV[lower.tri(CV,diag = T)],
  se=cCovstruct$S_Stand.SE[lower.tri(cCovstruct$S_Stand.SE,diag = T)],
  m=cCovstruct$m.nonimputed[lower.tri(cCovstruct$m.nonimputed,diag = T)],
  blocks=cCovstruct$cov.blocks[lower.tri(cCovstruct$cov.blocks,diag = T)]
  )
p$cv_coverage.1kg.hm3res.original$l<-"jn.1kg.hm3res"
p$cv_coverage.1kg.hm3res.original$g<-"jn"

cCovstruct<-p$mvLD$covstruct.mvLDSC.1kg.original
S_StandForCV<-abs(cCovstruct$S_Stand)
S_StandForCV[excludeTraits,]<-NA_real_
S_StandForCV[,excludeTraits]<-NA_real_
S_StandForCV[S_StandForCV<cv.S_StandLimit]<-cv.S_StandLimit #cap to avoid extreme values
CV <- cCovstruct$S_Stand.SE/S_StandForCV
p$cv_coverage.1kg.original <- data.frame(
  cv=CV[lower.tri(CV,diag = T)],
  se=cCovstruct$S_Stand.SE[lower.tri(cCovstruct$S_Stand.SE,diag = T)],
  m=cCovstruct$m.nonimputed[lower.tri(cCovstruct$m.nonimputed,diag = T)],
  blocks=cCovstruct$cov.blocks[lower.tri(cCovstruct$cov.blocks,diag = T)]
  )
p$cv_coverage.1kg.original$l<-"jn.1kg"
p$cv_coverage.1kg.original$g<-"jn"

cCovstruct<-p$mvLD$covstruct.mvLDSC.1kg.hm3res.vbcs.nocm
S_StandForCV<-abs(cCovstruct$S_Stand)
S_StandForCV[excludeTraits,]<-NA_real_
S_StandForCV[,excludeTraits]<-NA_real_
S_StandForCV[S_StandForCV<cv.S_StandLimit]<-cv.S_StandLimit #cap to avoid extreme values
CV <- cCovstruct$S_Stand.SE/S_StandForCV
p$cv_coverage.1kg.hm3res.vbcs.nocm <- data.frame(
  cv=CV[lower.tri(CV,diag = T)],
  se=cCovstruct$S_Stand.SE[lower.tri(cCovstruct$S_Stand.SE,diag = T)],
  m=cCovstruct$m.nonimputed[lower.tri(cCovstruct$m.nonimputed,diag = T)],
  blocks=cCovstruct$cov.blocks[lower.tri(cCovstruct$cov.blocks,diag = T)]
  )
p$cv_coverage.1kg.hm3res.vbcs.nocm$l<-"vbcs.1kg.hm3res"
p$cv_coverage.1kg.hm3res.vbcs.nocm$g<-"vbcs"

cCovstruct<-p$mvLD$covstruct.mvLDSC.1kg.vbcs.nocm
S_StandForCV<-abs(cCovstruct$S_Stand)
S_StandForCV[excludeTraits,]<-NA_real_
S_StandForCV[,excludeTraits]<-NA_real_
S_StandForCV[S_StandForCV<cv.S_StandLimit]<-cv.S_StandLimit #cap to avoid extreme values
CV <- cCovstruct$S_Stand.SE/S_StandForCV
p$cv_coverage.1kg.vbcs.nocm <- data.frame(
  cv=CV[lower.tri(CV,diag = T)],
  se=cCovstruct$S_Stand.SE[lower.tri(cCovstruct$S_Stand.SE,diag = T)],
  m=cCovstruct$m.nonimputed[lower.tri(cCovstruct$m.nonimputed,diag = T)],
  blocks=cCovstruct$cov.blocks[lower.tri(cCovstruct$cov.blocks,diag = T)]
  )
p$cv_coverage.1kg.vbcs.nocm$l<-"vbcs.1kg"
p$cv_coverage.1kg.vbcs.nocm$g<-"vbcs"

cCovstruct<-p$mvLD$covstruct.mvLDSC.1kg.hm3res.vbcs
S_StandForCV<-abs(cCovstruct$S_Stand)
S_StandForCV[excludeTraits,]<-NA_real_
S_StandForCV[,excludeTraits]<-NA_real_
S_StandForCV[S_StandForCV<cv.S_StandLimit]<-cv.S_StandLimit #cap to avoid extreme values
CV <- cCovstruct$S_Stand.SE/S_StandForCV
p$cv_coverage.1kg.hm3res.vbcs <- data.frame(
  cv=CV[lower.tri(CV,diag = T)],
  se=cCovstruct$S_Stand.SE[lower.tri(cCovstruct$S_Stand.SE,diag = T)],
  m=cCovstruct$m.nonimputed[lower.tri(cCovstruct$m.nonimputed,diag = T)],
  blocks=cCovstruct$cov.blocks[lower.tri(cCovstruct$cov.blocks,diag = T)]
  )
p$cv_coverage.1kg.hm3res.vbcs$l<-"rvbcs.1kg.hm3res"
p$cv_coverage.1kg.hm3res.vbcs$g<-"rvbcs"

cCovstruct<-p$mvLD$covstruct.mvLDSC.1kg.vbcs
S_StandForCV<-abs(cCovstruct$S_Stand)
S_StandForCV[excludeTraits,]<-NA_real_
S_StandForCV[,excludeTraits]<-NA_real_
S_StandForCV[S_StandForCV<cv.S_StandLimit]<-cv.S_StandLimit #cap to avoid extreme values
CV <- cCovstruct$S_Stand.SE/S_StandForCV
p$cv_coverage.1kg.vbcs <- data.frame(
  cv=CV[lower.tri(CV,diag = T)],
  se=cCovstruct$S_Stand.SE[lower.tri(cCovstruct$S_Stand.SE,diag = T)],
  m=cCovstruct$m.nonimputed[lower.tri(cCovstruct$m.nonimputed,diag = T)],
  blocks=cCovstruct$cov.blocks[lower.tri(cCovstruct$cov.blocks,diag = T)]
  )
p$cv_coverage.1kg.vbcs$l<-"rvbcs.1kg"
p$cv_coverage.1kg.vbcs$g<-"rvbcs"

p$cv_coverage <- rbind(
  #p$cv_coverage.1kg.hm3res.original,
  p$cv_coverage.1kg.original,
  #p$cv_coverage.1kg.hm3res.vbcs.nocm,
  p$cv_coverage.1kg.vbcs.nocm,
  #p$cv_coverage.1kg.hm3res.vbcs,
  p$cv_coverage.1kg.vbcs
  )

p$cv_coverage<-p$cv_coverage[!is.na(p$cv_coverage$cv),]

cTest.m.cv.jn<-corr.test(x = p$cv_coverage[p$cv_coverage$g=="jn",]$m, y=p$cv_coverage[p$cv_coverage$g=="jn",]$cv)
cTest.m.cv.jn
# cTest<-corr.test(x = p$cv_coverage[p$cv_coverage$g=="vbcs",]$m, y=p$cv_coverage[p$cv_coverage$g=="vbcs",]$cv)
# cTest
cTest.m.cv.rvbcs<-corr.test(x = p$cv_coverage[p$cv_coverage$g=="rvbcs",]$m, y=p$cv_coverage[p$cv_coverage$g=="rvbcs",]$cv)
cTest.m.cv.rvbcs

cTest.m.se.jn<-corr.test(x = p$cv_coverage[p$cv_coverage$g=="jn",]$m, y=p$cv_coverage[p$cv_coverage$g=="jn",]$se)
cTest.m.se.jn
# cTest<-corr.test(x = p$cv_coverage[p$cv_coverage$g=="vbcs",]$m, y=p$cv_coverage[p$cv_coverage$g=="vbcs",]$se)
# cTest
cTest.m.se.rvbcs<-corr.test(x = p$cv_coverage[p$cv_coverage$g=="rvbcs",]$m, y=p$cv_coverage[p$cv_coverage$g=="rvbcs",]$se)
cTest.m.se.rvbcs

cTest.S<-as.data.frame(matrix(data=NA,nrow=2,ncol=2))
colnames(cTest.S)<-c("cv","se")
rownames(cTest.S)<-c("jn","rvbcs")
cTest.S["jn","cv"]<-cTest.m.cv.jn$r
cTest.S["rvbcs","cv"]<-cTest.m.cv.rvbcs$r
cTest.S["jn","se"]<-cTest.m.se.jn$r
cTest.S["rvbcs","se"]<-cTest.m.se.rvbcs$r

cTest.p<-as.data.frame(matrix(data=NA,nrow=2,ncol=2))
colnames(cTest.p)<-c("cv","se")
rownames(cTest.p)<-c("jn","rvbcs")
cTest.p["jn","cv"]<-cTest.m.cv.jn$p
cTest.p["rvbcs","cv"]<-cTest.m.cv.rvbcs$p
cTest.p["jn","se"]<-cTest.m.se.jn$p
cTest.p["rvbcs","se"]<-cTest.m.se.rvbcs$p

cTest.se<-as.data.frame(matrix(data=NA,nrow=2,ncol=2))
colnames(cTest.se)<-c("cv","se")
rownames(cTest.se)<-c("jn","rvbcs")
cTest.se["jn","cv"]<-cTest.m.cv.jn$se
cTest.se["rvbcs","cv"]<-cTest.m.cv.rvbcs$se
cTest.se["jn","se"]<-cTest.m.se.jn$se
cTest.se["rvbcs","se"]<-cTest.m.se.rvbcs$se

#Fisher transformation of correlations to make them approximate normal
SCorrected<-atanh(cTest.S)

#confidence intervals
SCorrected.ci.lower<-as.data.frame(matrix(data = NA,nrow=nrow(SCorrected),ncol = 2))
SCorrected.ci.upper<-as.data.frame(matrix(data = NA,nrow=nrow(SCorrected),ncol = 2))
rownames(SCorrected.ci.lower)<-rownames(SCorrected)
rownames(SCorrected.ci.upper)<-rownames(SCorrected)
colnames(SCorrected.ci.lower)<-colnames(SCorrected)
colnames(SCorrected.ci.upper)<-colnames(SCorrected)

SCorrected.ci.lower<-SCorrected - 1.96*cTest.se
SCorrected.ci.upper<-SCorrected + 1.96*cTest.se
SCorrected.ci.lower
SCorrected
SCorrected.ci.upper

#test correlation difference - not sure if correct!
mTest<-t(SCorrected["rvbcs",])-t(SCorrected["jn",])
varTest<-2*abs(t(cTest.se["rvbcs",])^2-t(cTest.se["jn",])^2)
pTest<-pnorm(q = mTest,sd = sqrt(varTest), lower.tail = F)
pTest

library(ggpubr)
ggplot(data = p$cv_coverage, aes(x=m, y=cv, shape=l, color=g)) +
  geom_point(size=3) +
  geom_smooth(method="glm", aes(group=g, color=g)) +
  coord_cartesian(ylim = c(0, 0.9)) +
  ggtitle(label = "LDSC genetic correlation, number of variants against coefficient of variance (CV)") + 
  stat_cor(method="pearson", label.x.npc = 0.4,label.y.npc = 1.0, aes(group=g))
  #stat_cor(method="pearson", label.x.npc = "middle",label.y.npc = "bottom")
ggsave(filename=file.path(p$folderpath.plots,"ldsc_m_cv.1kgnohm3.png"), plot = last_plot(), width = 200, height = 200, units = "mm")

ggplot(data = p$cv_coverage, aes(x=m, y=se, shape=l, color=g)) +
  geom_point(size=3) +
  geom_smooth(method="glm", aes(group=g, color=g)) + 
  coord_cartesian(ylim = c(0, 0.1)) +
  ggtitle(label = "LDSC genetic correlation, number of variants against S.E.") +
  stat_cor(method="pearson", label.x.npc = 0,label.y.npc = 0, aes(group=g, color=g))
  #stat_cor(method="pearson", label.x.npc = "middle",label.y.npc = "bottom")
ggsave(filename=file.path(p$folderpath.plots,"ldsc_m_se.1kgnohm3.png"), plot = last_plot(), width = 200, height = 200, units = "mm")

# 
# ggplot(data = p$cv_coverage, aes(x=blocks, y=cv, shape=l, color=g)) +
#   geom_point(size=3) +
#   geom_smooth(method=lm, aes(group=g, color=g))


```


# Overview of rg between selected traits
```{r overview pairwise rg, fig.width=9, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}


#View(p$sumstats.sel.table)
# 
# library(heatmaply)
# #ggheatmap() #static version
# #heatmaply()
# heatmaply(
#     p$mvLD$covstruct.mvLDSC.1kg$S.forPlot,
#     cellnote = round(p$mvLD$covstruct.mvLDSC.1kg$S,digits = 3),
#     cellnote_size = 16,
#     cellnote_textposition = "middle center",
#     show_dendrogram = c(T,F),
#     xlab = "Trait GWAS",
#     ylab = "Trait GWAS",
#     main = "cov<sub>g</sub>",
#     scale_fill_gradient_fun = ggplot2::scale_fill_gradient2(
#         low = theme.color$contrastDark3, 
#         mid = "black",
#         high = theme.color$contrastLight3,
#         breaks = c(-0.5,0,0.5)
#       ),
#     file=file.path(p$folderpath.plots,paste0("cov_cluster.noimp.png")),
#     width = 1200, height = 1200,
#     hclust_method = "ward.D2"
#     #scale = "row"
#   )
# 
# heatmaply(
#     clipValues(p$mvLD$covstruct.mvLDSC.1kg$S_Stand.forPlot,-1,1),
#     cellnote = round(clipValues(p$mvLD$covstruct.mvLDSC.1kg$S_Stand,-1,1),digits = 3),
#     cellnote_size = 16,
#     cellnote_textposition = "middle center",
#     show_dendrogram = c(T,F),
#     xlab = "Trait GWAS",
#     ylab = "Trait GWAS",
#     main = "r<sub>g</sub>",
#     scale_fill_gradient_fun = ggplot2::scale_fill_gradient2(
#         low = theme.color$contrastDark3, 
#         mid = "black",
#         high = theme.color$contrastLight3,
#         breaks = c(-1,0,1)
#       ),
#     file=file.path(p$folderpath.plots,paste0("rg_cluster.noimp.png")),
#     width = 1200, height = 1200,
#     hclust_method = "ward.D2"
#     #scale = "row"
#   )
# 
# heatmaply(
#     p$mvLD$covstruct.mvLDSC.1kg.500$S.forPlot,
#     cellnote = round(p$mvLD$covstruct.mvLDSC.1kg.500$S,digits = 3),
#     cellnote_size = 16,
#     cellnote_textposition = "middle center",
#     show_dendrogram = c(T,F),
#     xlab = "Trait GWAS",
#     ylab = "Trait GWAS",
#     main = "cov<sub>g</sub>",
#     scale_fill_gradient_fun = ggplot2::scale_fill_gradient2(
#         low = theme.color$contrastDark3, 
#         mid = "black",
#         high = theme.color$contrastLight3,
#         breaks = c(-0.5,0,0.5)
#       ),
#     file=file.path(p$folderpath.plots,paste0("cov_cluster.500.png")),
#     width = 1200, height = 1200,
#     hclust_method = "ward.D2"
#     #scale = "row"
#   )
# 
# heatmaply(
#     clipValues(p$mvLD$covstruct.mvLDSC.1kg.500$S_Stand.forPlot,-1,1),
#     cellnote = round(clipValues(p$mvLD$covstruct.mvLDSC.1kg.500$S_Stand,-1,1),digits = 3),
#     cellnote_size = 16,
#     cellnote_textposition = "middle center",
#     show_dendrogram = c(T,F),
#     xlab = "Trait GWAS",
#     ylab = "Trait GWAS",
#     main = "r<sub>g</sub>",
#     scale_fill_gradient_fun = ggplot2::scale_fill_gradient2(
#         low = theme.color$contrastDark3, 
#         mid = "black",
#         high = theme.color$contrastLight3,
#         breaks = c(-1,0,1)
#       ),
#     file=file.path(p$folderpath.plots,paste0("rg_cluster.500.png")),
#     width = 1200, height = 1200,
#     hclust_method = "ward.D2"
#     #scale = "row"
#   )
# 
# heatmaply(
#     p$mvLD$covstruct.mvLDSC.1kg.ssimp.small$S.forPlot,
#     cellnote = round(p$mvLD$covstruct.mvLDSC.1kg.ssimp.small$S.forPlot,digits = 3),
#     cellnote_size = 16,
#     cellnote_textposition = "middle center",
#     show_dendrogram = c(T,F),
#     xlab = "Trait GWAS",
#     ylab = "Trait GWAS",
#     main = "cov<sub>g</sub>",
#     scale_fill_gradient_fun = ggplot2::scale_fill_gradient2(
#         low = theme.color$contrastDark3,
#         mid = "black",
#         high = theme.color$contrastLight3,
#         breaks = c(-1,0,1)
#       ),
#     file=file.path(p$folderpath.plots,paste0("cov_cluster.ssimp.png")),
#     width = 1200, height = 1200,
#     hclust_method = "ward.D2"
#     #scale = "row"
#   )


# p$printCorrSimplified(
#   corr = clipValues(p$mvLD$covstruct.mvLDSC.1kg$S_Stand.forPlot,-1,1),
#   #SE = p$mvLD$covstruct.mvLDSC.1kg$S_Stand.SE,
#   filename = file.path(p$folderpath.plots,"rg_simple.png"),
#   is.corr = T
#   )

# p$printCorrSimplified(
#   corr = clipValues(abs(p$mvLD$covstruct.mvLDSC$S_Stand.forPlot),-1,1),
#   #SE = p$mvLD$covstruct.mvLDSC.1kg$S_Stand.SE,
#   filename = file.path(p$folderpath.plots,"rg_abs_simple.png"),
#   is.corr = F,
#   absScale=T
#   )


#new main correlation plot 1A
# cPlot<-ggcorr(data = NULL, cor_matrix = clipValues(p$mvLD$covstruct.mvLDSC.1kg$S_Stand,-1,1), geom = "tile")
# ggsave(filename=file.path(p$folderpath.plots, paste0("rg.large.png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 3)


corrForPlot <- clipValues(p$mvLD$covstruct.mvLDSC.1kg.vbcs.nocm.winfo$S_Stand,-1,1)
pForPlot <- p$mvLD$covstruct.mvLDSC.1kg.vbcs.nocm.winfo$cov.p
colnames(corrForPlot)<-p$sumstats.sel$code.nice
rownames(corrForPlot)<-p$sumstats.sel$code.nice
colnames(pForPlot)<-p$sumstats.sel$code.nice
rownames(pForPlot)<-p$sumstats.sel$code.nice
corrForPlot<-corrForPlot[order(colnames(corrForPlot)),order(colnames(corrForPlot))]
#diag(corrForPlot) <- NA_real_
pForPlot<-pForPlot[order(colnames(pForPlot)),order(colnames(pForPlot))]
png(file.path(p$folderpath.plots,"rg.large.A.png"), width = 9, height = 9, units = 'in', res = 300, family = "Helvetica")
par(xpd=TRUE) #keep labels inside margins
pal<-colorRampPalette(c("#FF6666","#EEEEEE","#6666FF"))
corrplot(corr = corrForPlot, method = "circle", insig='blank', order = "original", p.mat = pForPlot, sig.level = c(0.05), pch.cex = 1.5, tl.cex = 0.8, full_col=FALSE, na.label = "square", na.label.col = "grey30", title = "A: LDSC++ genetic correlations, 1kG reference:\nGWAS (non-imputed) + GWIS of male BMI (LD-IMP augmented height & weight)", tl.pos = 'd', mar=c(0,0,4,0), type = "upper", cl.pos = "r", col = pal(200))$corrPos -> p1 #type = "lower", diag=F, addCoef.col = 'black'
#text(p1$x, p1$y, round(p1$corr, 2))
p1$corr <- ifelse(0==-p1$y + ncol(corrForPlot)-p1$x + 1, NA_real_, p1$corr)
text(p1$x, p1$y, round(p1$corr, 2))
dev.off()

corrForPlot <- clipValues(p$mvLD$covstruct.mvLDSC.hc1kg$S_Stand,-1,1)
pForPlot <- p$mvLD$covstruct.mvLDSC.hc1kg$cov.p
colnames(corrForPlot)<-p$sumstats.sel$code.nice
rownames(corrForPlot)<-p$sumstats.sel$code.nice
colnames(pForPlot)<-p$sumstats.sel$code.nice
rownames(pForPlot)<-p$sumstats.sel$code.nice
corrForPlot<-corrForPlot[order(colnames(corrForPlot)),order(colnames(corrForPlot))]
#diag(corrForPlot) <- NA_real_
pForPlot<-pForPlot[order(colnames(pForPlot)),order(colnames(pForPlot))]
png(file.path(p$folderpath.plots,"rg.large.B.png"), width = 9, height = 9, units = 'in', res = 300, family = "Helvetica")
par(xpd=TRUE) #keep labels inside margins
pal<-colorRampPalette(c("#FF6666","#EEEEEE","#6666FF"))
corrplot(corr = corrForPlot, method = "circle", insig='blank', order = "original", p.mat = pForPlot, sig.level = c(0.05), pch.cex = 1.5, tl.cex = 0.8, full_col=FALSE, na.label = "square", na.label.col = "grey30", title = "B: LDSC++ genetic correlations, HC1kG reference:\nGWAS (non-imputed) + GWIS of male BMI (LD-IMP augmented height & weight)", tl.pos = 'd', mar=c(0,0,4,0), type = "upper", cl.pos = "r", col = pal(200))$corrPos -> p1 #type = "lower", diag=F, addCoef.col = 'black'
#text(p1$x, p1$y, round(p1$corr, 2))
p1$corr <- ifelse(0==-p1$y + ncol(corrForPlot)-p1$x + 1, NA_real_, p1$corr)
text(p1$x, p1$y, round(p1$corr, 2))
dev.off()


corrForPlot <- clipValues(p$mvLD$covstruct.mvLDSC.1kg.05cm$S_Stand,-1,1)
pForPlot <- p$mvLD$covstruct.mvLDSC.1kg.05cm$cov.p
colnames(corrForPlot)<-p$sumstats.sel$code.nice
rownames(corrForPlot)<-p$sumstats.sel$code.nice
colnames(pForPlot)<-p$sumstats.sel$code.nice
rownames(pForPlot)<-p$sumstats.sel$code.nice
corrForPlot<-corrForPlot[order(colnames(corrForPlot)),order(colnames(corrForPlot))]
pForPlot<-pForPlot[order(colnames(pForPlot)),order(colnames(pForPlot))]
png(file.path(p$folderpath.plots,"rg.large.C.png"), width = 9, height = 9, units = 'in', res = 300, family = "Helvetica")
par(xpd=TRUE) #keep labels inside margins
pal<-colorRampPalette(c("#FF6666","#EEEEEE","#6666FF"))
corrplot(corr = corrForPlot, method = "circle", insig='blank', order = "original", p.mat = pForPlot, sig.level = c(0.05), pch.cex = 1.5, tl.cex = 0.8, full_col=FALSE, na.label = "square", na.label.col = "grey30", title = "C: LDSC++ genetic correlations, HC1kG reference:\nLD-IMP augmented GWAS + GWIS of male BMI (LD-IMP augmented height & weight)", tl.pos = 'd', mar=c(0,0,4,0), type = "upper", cl.pos = "r", col = pal(200))$corrPos -> p1 #type = "lower", diag=F, addCoef.col = 'black'
#text(p1$x, p1$y, round(p1$corr, 2))
p1$corr <- ifelse(0==-p1$y + ncol(corrForPlot)-p1$x + 1, NA_real_, p1$corr)
text(p1$x, p1$y, round(p1$corr, 2))
dev.off()

corrForPlot <- clipValues(p$mvLD$covstruct.mvLDSC.hc1kg$S_Stand.unsigned,-1,1)
pForPlot <- p$mvLD$covstruct.mvLDSC.hc1kg$cov.p.unsigned
colnames(corrForPlot)<-p$sumstats.sel$code.nice
rownames(corrForPlot)<-p$sumstats.sel$code.nice
colnames(pForPlot)<-p$sumstats.sel$code.nice
rownames(pForPlot)<-p$sumstats.sel$code.nice
corrForPlot<-corrForPlot[order(colnames(corrForPlot)),order(colnames(corrForPlot))]
#diag(corrForPlot) <- NA_real_
pForPlot<-pForPlot[order(colnames(pForPlot)),order(colnames(pForPlot))]
png(file.path(p$folderpath.plots,"rg.large.D.png"), width = 9, height = 9, units = 'in', res = 300, family = "Helvetica")
par(xpd=TRUE) #keep labels inside margins
pal<-colorRampPalette(c("#FF6666","#EEEEEE","#6666FF"))
corrplot(corr = corrForPlot, method = "circle", insig='blank', order = "original", p.mat = pForPlot, sig.level = c(0.05), pch.cex = 1.5, tl.cex = 0.8, full_col=FALSE, na.label = "square", na.label.col = "grey30", title = "D: LDSC++ genetic unsigned correlations, HC1kG reference:\nGWAS (non-imputed) + GWIS of male BMI (LD-IMP augmented height & weight)", tl.pos = 'd', mar=c(0,0,4,0), type = "upper", cl.pos = "r", col = pal(200))$corrPos -> p1 #type = "lower", diag=F, addCoef.col = 'black'
#text(p1$x, p1$y, round(p1$corr, 2))
p1$corr <- ifelse(0==-p1$y + ncol(corrForPlot)-p1$x + 1, NA_real_, p1$corr)
text(p1$x, p1$y, round(p1$corr, 2))
dev.off()

corrForPlot <- clipValues(p$mvLD$covstruct.mvLDSC.hc1kg$S_Stand.unsigned-abs(p$mvLD$covstruct.mvLDSC.hc1kg$S_Stand),-1,1)
pForPlot <- p$mvLD$covstruct.mvLDSC.hc1kg$cov.p.unsigned
colnames(corrForPlot)<-p$sumstats.sel$code.nice
rownames(corrForPlot)<-p$sumstats.sel$code.nice
colnames(pForPlot)<-p$sumstats.sel$code.nice
rownames(pForPlot)<-p$sumstats.sel$code.nice
corrForPlot<-corrForPlot[order(colnames(corrForPlot)),order(colnames(corrForPlot))]
pForPlot<-pForPlot[order(colnames(pForPlot)),order(colnames(pForPlot))]
png(file.path(p$folderpath.plots,"rg.large.E.png"), width = 9, height = 9, units = 'in', res = 300, family = "Helvetica")
par(xpd=TRUE) #keep labels inside margins
pal<-colorRampPalette(c("#FF6666","#EEEEEE","#6666FF"))
corrplot(corr = corrForPlot, method = "circle", insig='blank', order = "original", p.mat = pForPlot, sig.level = c(0.05), pch.cex = 1.5, tl.cex = 0.8, full_col=FALSE, na.label = "square", na.label.col = "grey30", title = "E: LDSC++ 'residual' genetic correlations, HC1kG reference:\nGWAS (non-imputed) + GWIS of male BMI (LD-IMP augmented height & weight)", tl.pos = 'd', mar=c(0,0,4,0), type = "upper", cl.pos = "r", col = pal(200))$corrPos -> p1 #type = "lower", diag=F, addCoef.col = 'black'
#text(p1$x, p1$y, round(p1$corr, 2))
p1$corr <- ifelse(0==-p1$y + ncol(corrForPlot)-p1$x + 1, NA_real_, p1$corr)
text(p1$x, p1$y, round(p1$corr, 2))
dev.off()


#Comparisons of incrementally introduced additions to LDSC

p$plotAndTestBatteryForMVLDSC(mvldsc = p$mvLD$covstruct.mvLDSC.1kg.original, code = "original", titleTemplate = "original LDSC (Genomic SEM), 1kG reference,
GWAS (non-imputed) + GWIS of male BMI (LD-IMP augmented height & weight),", titleAddition = "\nBlock-Jackknife Resampling")

p$plotAndTestBatteryForMVLDSC(mvldsc = p$mvLD$covstruct.mvLDSC.1kg.vbcs.nocm, code = "vbcs", titleTemplate = "LDSC++, 1kG reference,
GWAS (non-imputed) + GWIS of male BMI (LD-IMP augmented height & weight),", titleAddition = "\nVariable Block-Count Sampling (no cM blocks)",mvldscComparison = p$mvLD$covstruct.mvLDSC.1kg.original,titleAdditionComparison = "\ncomparing with original LDSC (Genomic SEM) settings\n and Block-Jackknife Resampling")

p$plotAndTestBatteryForMVLDSC(mvldsc = p$mvLD$covstruct.mvLDSC.1kg.vbcs, code = "vbcs.cm", titleTemplate = "LDSC++, 1kG reference,
GWAS (non-imputed) + GWIS of male BMI (LD-IMP augmented height & weight),", titleAddition = "\nVariable Block-Count Sampling (cM blocks)",mvldscComparison = p$mvLD$covstruct.mvLDSC.1kg.original, titleAdditionComparison = "\ncomparing with original LDSC (Genomic SEM) settings\n and Block-Jackknife Resampling")

p$plotAndTestBatteryForMVLDSC(mvldsc = p$mvLD$covstruct.mvLDSC.1kg.vbcs.nocm, code = "vbcs.nocmcm", titleTemplate = "LDSC++, 1kG reference,
GWAS (non-imputed) + GWIS of male BMI (LD-IMP augmented height & weight),", titleAddition = "\nVariable Block-Count Sampling (no cM blocks)",mvldscComparison = p$mvLD$covstruct.mvLDSC.1kg.vbcs, titleAdditionComparison = "\ncomparing with Variable Block-Count Sampling (cM blocks)")

infoTraits<-p$sumstats[which(p$sumstats$hasinfo==T),]$code
p$plotAndTestBatteryForMVLDSC(mvldsc = p$mvLD$covstruct.mvLDSC.1kg.vbcs.nocm.winfo, code = "vbcs.winfo",titleTemplate = "LDSC++, 1kG reference,
GWAS (non-imputed) + GWIS of male BMI (LD-IMP augmented height & weight),", titleAddition = "\nVariable Block-Count Sampling (no cM based blocks) and imputation weighting",mvldscComparison = p$mvLD$covstruct.mvLDSC.1kg.vbcs.nocm, testOnlyTraitNameCodes = infoTraits, titleAdditionComparison = "\ncomparing with Variable Block-Count Sampling\n (no cM based blocks)")

# p$plotAndTestBatteryForMVLDSC(mvldsc = p$mvLD$covstruct.mvLDSC.1kg.vbcs.drc, code = "vbcs.drc",titleAddition = "VBCS + DRC",mvldscComparison = p$mvLD$covstruct.mvLDSC.1kg.vbcs, titleAdditionComparison = "VBCS + DRC comparing with VBCS only")
# 
# 
# p$plotAndTestBatteryForMVLDSC(mvldsc = p$mvLD$covstruct.mvLDSC.1kg.vbcs.drc.nocm, code = "vbcs.drc.nocm",titleAddition = "No cM based VBCS + DRC",mvldscComparison = p$mvLD$covstruct.mvLDSC.1kg.vbcs.drc, testOnlyTraitNameCodes = infoTraits, titleAdditionComparison = "No cM based VBCS + DRC + DRC + WINFO comparing with VBCS + DRC only")
# 
# 
# p$plotAndTestBatteryForMVLDSC(mvldsc = p$mvLD$covstruct.mvLDSC.1kg.vbcs.drc.winfo, code = "vbcs.drc.winfo",titleAddition = "VBCS + DRC + WINFO",mvldscComparison = p$mvLD$covstruct.mvLDSC.1kg.vbcs.drc, testOnlyTraitNameCodes = infoTraits, titleAdditionComparison = "VBCS + DRC + WINFO comparing with VBCS + DRC only")


#GWAS summary statistics panel comparison
p$plotAndTestBatteryForMVLDSC(mvldsc = p$mvLD$covstruct.mvLDSC.hm3, code = "hm3",titleTemplate = "LDSC++, HM3 reference,
GWAS (non-imputed) + GWIS of male BMI (LD-IMP augmented height & weight)")

p$plotAndTestBatteryForMVLDSC(mvldsc = p$mvLD$covstruct.mvLDSC.1kg.vbcs.nocm.winfo, code = "1kg",titleTemplate = "LDSC++, 1kG reference,
GWAS (non-imputed) + GWIS of male BMI (LD-IMP augmented height & weight)")

p$plotAndTestBatteryForMVLDSC(mvldsc = p$mvLD$covstruct.mvLDSC.1kg.hm3res.vbcs.nocm.winfo, code = "1kg.hm3res",titleTemplate = "LDSC++, 1kG reference, restricted to HM3,
GWAS (non-imputed) + GWIS of male BMI (LD-IMP augmented height & weight)")

p$plotAndTestBatteryForMVLDSC(mvldsc = p$mvLD$covstruct.mvLDSC.hc1kg.hm3res, code = "panel.hc1kg.hm3res_1kg",titleTemplate = "LDSC++, HC1kG reference, restricted to HM3,
GWAS (non-imputed) + GWIS of male BMI (LD-IMP augmented height & weight)",mvldscComparison = p$mvLD$covstruct.mvLDSC.1kg.hm3res.vbcs.nocm.winfo,titleAdditionComparison = "\ncomparing with 1kG restricted to HM3 variants")

# p$plotAndTestBatteryForMVLDSC(mvldsc = p$mvLD$covstruct.mvLDSC.hc1kg, code = "panel.hc1kg_hm3",titleAddition = "HC1kG",mvldscComparison = p$mvLD$covstruct.mvLDSC.hm3,titleAdditionComparison = "\ncomparing with HM3")
# 
# p$plotAndTestBatteryForMVLDSC(mvldsc = p$mvLD$covstruct.mvLDSC.hc1kg.hm3res, code = "panel.hc1kg.hm3res_hm3",titleAddition = "HC1kG restricted to HM3",mvldscComparison = p$mvLD$covstruct.mvLDSC.hm3,titleAdditionComparison = "\ncomparing with HM3")

p$plotAndTestBatteryForMVLDSC(mvldsc = p$mvLD$covstruct.mvLDSC.hc1kg, code = "panel.hc1kg_1kg",titleAddition = "HC1kG",mvldscComparison = p$mvLD$covstruct.mvLDSC.1kg.vbcs.nocm.winfo, titleAdditionComparison = "\ncomparing with 1kG")



# p$plotAndTestBatteryForMVLDSC(mvldsc = p$mvLD$covstruct.mvLDSC.1kg.mix, code = "panel.mix",titleAddition = "HC1kG (MIX Reference)",mvldscComparison = p$mvLD$covstruct.mvLDSC.hm3,titleAdditionComparison = "comparing with HM3")

#GWAS summary statistics imputation comparison
imptraits<-p$sumstats.sel[which(p$sumstats.sel$code!="BODYT2MI"),]$code
p$plotAndTestBatteryForMVLDSC(mvldsc = p$mvLD$covstruct.mvLDSC.1kg.05cm, code = "ldimp",titleAddition = "0.5cM imputation window",mvldscComparison = p$mvLD$covstruct.mvLDSC.1kg.vbcs.nocm.winfo, testOnlyTraitNameCodes = imptraits,titleTemplate = "HC1kG reference,\nLD-IMP augmented GWAS + GWIS of male BMI (LD-IMP augmented height & weight),\n", titleAdditionComparison = "comparing with LDSC++ of non-imputed GWAS")

p$plotAndTestBatteryForMVLDSC(mvldsc = p$mvLD$covstruct.mvLDSC.1kg.500.small, code = "ldimp.small",titleAddition = "(selected chromosomes)",mvldscComparison = p$mvLD$covstruct.mvLDSC.1kg.ssimp.small,titleTemplate = "HC1kG reference,\nLD-IMP augmented GWAS (500kb imputation window) + GWIS of male BMI (LD-IMP augmented height & weight),\n", titleAdditionComparison = "comparing with LDSC++ of SSimp imputed GWAS")



cat("\nLDSC stats - LDIMP (small)")
print(p$mvLD$covstruct.mvLDSC.1kg.500.small$impstats)

cat("\nLDSC stats - SSIMP (small)")
print(p$mvLD$covstruct.mvLDSC.1kg.ssimp.small$impstats)

  

```

# Compute post-analysis statistics and plots per-trait
```{r post-analysis per-trait statistics, fig.width=9, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}

#library(ROCR)

#TODO Add (adjusted? - see the SSimp publication) correlation measures for imputed-genotyped effects, as in the SSimp publication 

#imputed ld-imp
#limits<-c(4,5,6,7)
#ratios<-as.data.frame(matrix(data = NA, nrow = 0, ncol = 0))
for(iTrait in 1:nrow(p$sumstats.sel)){
  #iTrait<-1
  
  if(!file.exists(p$sumstats.sel[iTrait,]$imputedpath.05cm)) next
  
  cSumstats <- shru::readFile(filePath = p$sumstats.sel[iTrait,]$imputedpath.05cm, nThreads = 5)
  nrow(cSumstats)
  cond.invertedMAF<-cSumstats$FRQ > .5
  cSumstats$MAF<-ifelse(cond.invertedMAF,1-cSumstats$FRQ,cSumstats$FRQ)
  cSumstats <- cSumstats[MAF>0.01,]
  nrow(cSumstats)
  
  if(!any("BETA.I"==colnames(cSumstats))){
    cSumstats[,BETA.I:=BETA][,SE.I:=SE]
  }
  
  if(!any("LDIMP.L2.SUM"==colnames(cSumstats))){
    cSumstats[,LDIMP.L2.SUM:=NA_real_]
  }
  
  cSumstats[,ZZ:=Z*Z][,Z.I:=(BETA.I/SE.I)][,ZZ.I:=(BETA.I/SE.I)^2][,AC:=FRQ*N][,MAC:=MAF*N][,VSNP:=2*FRQ*(1-FRQ)][,NEF:=round((((BETA.I/SE.I)/BETA.I)^2)/VSNP,digits = 0)][,IMPUTED:=((is.finite(LDIMP.L2.SUM) | is.finite(SINFO)) & BETA.I==BETA)]
  cSumstats[is.na(ZZ.I),ZZ.I:=ZZ]
  quantile(cSumstats$ZZ)
  setkeyv(cSumstats,cols = c("CHR","BP"))
  
  #fix faulty SINFO - remove when it has been fixed in supermunge
  if(any("SINFO"==colnames(cSumstats)) & any("LDIMP.K"==colnames(cSumstats))){
    if(nrow(cSumstats[abs(SINFO)>0.1,])>0.01*nrow(cSumstats)){
      #re-compute SINFO
      cSumstats[!(is.na(LDIMP.L2.SUM) & is.na(SINFO)),LDIMP.Q:=LDIMP.K*L2_REF/(LDIMP.L2.SUM)][,SINFO:=as.double(pnorm(q = LDIMP.Q, mean = 1, sd = 1))]
    }
  }
  
  cSumstats[IMPUTED==F & (is.na(LDIMP.L2.SUM) & is.na(SINFO)),GROUP:=1]
  cSumstats[IMPUTED==F & !(is.na(LDIMP.L2.SUM) & is.na(SINFO)),GROUP:=2]
  cSumstats[IMPUTED==T, GROUP:=3]
  cSumstats$GROUP<-as.factor(cSumstats$GROUP)
  nrow(cSumstats[GROUP==1,])
  nrow(cSumstats[GROUP==2,])
  nrow(cSumstats[GROUP==3,])
  nrow(cSumstats[!is.finite(GROUP),])
  cSumstats[GROUP==2,c('d.z','d.beta','d.se') :=list((BETA.I/SE.I)-(BETA/SE),BETA.I-BETA,SE.I-SE)]
  cSumstats[GROUP==2,c('d.z.abs','d.beta.abs','d.se.abs') :=list(abs(d.z),abs(d.beta),abs(d.se))]
  
  cSumstatsPlot <- cSumstats[is.finite(ZZ),] #CHR == 1 #c("SNP","CHR", "IMPUTED","NAL","Z", "ZZ","ZZ.I","SINFO","LDIMP.L2.SUM","LDIMP.K","GROUP",'d.z','d.beta','d.se','d.z.abs','d.beta.abs','d.se.abs')
  cSumstatsPlot$index<-1:nrow(cSumstatsPlot)
  cSumstatsPlot$bucket<-ntile(cSumstatsPlot$index,n = nrow(cSumstatsPlot)/50)
  cSumstatsPlot[, c('iLDIMP.L2.SUM') := list(mean(LDIMP.L2.SUM,na.rm=T)), by = bucket]
  cSumstatsPlot[GROUP==1,c('LDIMP.L2.SUM'):=list(iLDIMP.L2.SUM)] #non-imputed, non-validated
  
  
  #scaling parameter obtained from SCHI04 as
  # cSumstatsStats <- cSumstatsPlot[IMPUTED==F,]
  # scalingParameter.LD_IMP.SUM <- mean(cSumstatsStats$LD_IMP.SUM, na.rm=T) #1039080898
  # scalingParameter.ZZ <- mean(cSumstatsStats$ZZ, na.rm=T) #2.09409
  # scalingParameter<-scalingParameter.LD_IMP.SUM*scalingParameter.ZZ
  # scalingParameter<-1039080898*2.09409
  # 
  # cSumstatsPlot[,LDIMP.SUM.CORR1:=LDIMP.L2.SUM*ZZ]
  # cSumstatsPlot[,LDIMP.SUM.CORR1.scaled:=(LDIMP.L2.SUM*ZZ)/eval(scalingParameter)]
  #cSumstatsPlot$LD_IMP.SUM.CORR1.scaled<-scale(cSumstatsPlot$LD_IMP.SUM.CORR1,center = F)
  #cSumstatsPlot[,SINFO:=pnorm(q = log10(LD_IMP.SUM.CORR1), mean = 0, sd = sd(cSumstatsPlot$LD_IMP.SUM.CORR1,na.rm = T))]
  #cSumstatsPlot[,SINFO:=pnorm(q = LD_IMP.SUM.CORR1.scaled, mean = 1, sd = sd(cSumstatsPlot$LD_IMP.SUM.CORR1.scaled,na.rm = T))]
  #cSumstatsPlot[,SINFO:=exp(LD_IMP.SUM.CORR1.scaled)/(1+exp(LD_IMP.SUM.CORR1.scaled))]
  
 
  
  #new scatterplots of genoptyped vs imputed effects
  
  #total 
  mzz <- mean(cSumstatsPlot$ZZ,na.rm=T)
  mbeta <- mean(abs(cSumstatsPlot$BETA),na.rm=T)
  mse <- mean(cSumstatsPlot$SE,na.rm=T)
  if(any("L2_REF"==colnames(cSumstatsPlot))){
    cPlot <- ggplot(cSumstatsPlot[ZZ>1.5 & ZZ<mzz*20,], aes(x=L2_REF,y=ZZ, color=IMPUTED)) +
      geom_point(alpha = 0.2, size=1) +
      theme_light() +
      ggtitle(paste("Association against LD score: ",p$sumstats.sel[iTrait,]$code.nice)," , Z^2 > 1.5") +
      xlab("LD score") + ylab("Association (Chi-squared)") +
      guides(fill=guide_legend(title="Imputed or non-imputed")) #does not work :(
    ggsave(filename=file.path(p$folderpath.plots, paste0("ZZ_L2.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 1)
  }
  
  cPlot <- ggplot(cSumstatsPlot[GROUP==2 & ZZ<mzz*40,], aes(x=Z,y=Z.I)) +
      geom_point(alpha = 0.2, size=1, aes(colour=SINFO)) +
      theme_light() +
      ggtitle(paste("Association against imputed association: ",p$sumstats.sel[iTrait,]$code.nice)) +
      xlab("Association Z") + ylab("Imputed association Z")
  ggsave(filename=file.path(p$folderpath.plots, paste0("Z.I_Z.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 1)
    
  cPlot <- ggplot(cSumstatsPlot[GROUP==2 & ZZ<mzz*40,], aes(x=BETA,y=BETA.I)) +
      geom_point(alpha = 0.2, size=1, aes(colour=SINFO)) +
      theme_light() +
      ggtitle(paste("Unstandardised GWAS regression coefficient against imputed coefficient: ",p$sumstats.sel[iTrait,]$code.nice)) +
      xlab("Regression coefficient") + ylab("Imputed regression coefficient")
    ggsave(filename=file.path(p$folderpath.plots, paste0("BETA.I_BETA",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 1)
    
  cPlot <- ggplot(cSumstatsPlot[GROUP==2 & ZZ<mzz*20,], aes(x=SE,y=SE.I)) +
      geom_point(alpha = 0.2, size=1, aes(colour=SINFO)) +
      theme_light() +
       ggtitle(paste("Unstandardised GWAS regression coefficient standard error against imputed coefficient standard error: ",p$sumstats.sel[iTrait,]$code.nice)) +
      xlab("Regression coefficient s.e.") + ylab("Imputed regression coefficient s.e.")
    ggsave(filename=file.path(p$folderpath.plots, paste0("SE.I_SE",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 1)
    
    cSumstatsPlot[,rel.d.z.abs:=d.z.abs/abs(Z)][!is.finite(rel.d.z.abs), rel.d.z.abs:=NA_real_]
    cVal <- cor(x = cSumstatsPlot$SINFO,y = cSumstatsPlot$rel.d.z.abs, use = "pairwise.complete.obs")
    cPlot <- ggplot(cSumstatsPlot[GROUP==2 & ZZ<mzz*40 & ZZ> 1.5,], aes(x=SINFO,y=rel.d.z.abs)) +
      geom_point(alpha = 0.2, size=1, aes(colour=L2_REF)) +
      theme_light() +
       ggtitle(paste("Relative absolute error in association statistic against imputation quality score: ",p$sumstats.sel[iTrait,]$code.nice," , cor=",round(cVal,4)," , Z^2 >1.5")) +
      xlab("Imputation quality score (SINFO)") + ylab("Absolute error in association statistic Z relative to original Z")
    ggsave(filename=file.path(p$folderpath.plots, paste0("RADZ_SINFO",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 1)
  
  cPlot <- ggplot(cSumstatsPlot[ZZ<mzz*10,], aes(x=Z, group=IMPUTED, fill=IMPUTED)) +
    geom_density(adjust=1.5,alpha = 0.5, linewidth=1) +
    theme_light() +
    ggtitle(paste("Density of GWAS association statistic: ",p$sumstats.sel[iTrait,]$code.nice)) +
      xlab("Association Z") + ylab("Kernel density")
  ggsave(filename=file.path(p$folderpath.plots, paste0("Z.density.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 1)
  
  cPlot <- ggplot(cSumstatsPlot[ZZ<mzz*30 & ZZ>2,], aes(x=abs(Z), group=IMPUTED, fill=IMPUTED)) +
    geom_density(adjust=1.5,alpha = 0.5, size=1) +
    theme_light() +
    ggtitle(paste("Density of GWAS association statistic, high (Z^2>2) absolute associations: ",p$sumstats.sel[iTrait,]$code.nice)) +
    xlab("Association Z") + ylab("Kernel density")
  ggsave(filename=file.path(p$folderpath.plots, paste0("absZ.density.high.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 1)
  
  cPlot <- ggplot(cSumstatsPlot[abs(BETA)<mbeta*20,], aes(x=BETA, group=IMPUTED, fill=IMPUTED)) +
    geom_density(adjust=1.5,alpha = 0.5, size=1) +
    theme_light() +
    ggtitle(paste("Density of GWAS regression coefficient: ",p$sumstats.sel[iTrait,]$code.nice)) +
      xlab("Regression coefficient") + ylab("Kernel density")
  ggsave(filename=file.path(p$folderpath.plots, paste0("BETA.density.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 1)
  
  cPlot <- ggplot(cSumstatsPlot[SE<mse*5,], aes(x=SE, group=IMPUTED, fill=IMPUTED)) +
    geom_density(adjust=1.5,alpha = 0.5, size=1) +
    theme_light() + ggtitle(paste("Density of GWAS regression coefficient standard error: ",p$sumstats.sel[iTrait,]$code.nice)) +
      xlab("Regression coefficient standard error") + ylab("Kernel density")
  ggsave(filename=file.path(p$folderpath.plots, paste0("SE.density.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 1)
  
  
  
  # if(nrow(cSumstats[GROUP==2,])>0){
  #   #construct set with double entries for validated variants
  #   cSumstatsPlot2 <- cSumstats[GROUP==2,.(SNP,ZZ,BETA,SE,IMPUTED=F)]
  #   cSumstatsPlot2 <- rbind(cSumstatsPlot2,cSumstats[GROUP==2,.(SNP,ZZ=ZZ.I,BETA=BETA.I,SE=SE.I,IMPUTED=T)])
  }
  
#stat_summary_bin(fun.y='mean', bins=1000, color='black', size=2, geom='point'))
  
  # cPlot <- ggplot(cSumstatsPlot, aes(x=LDIMP.L2.SUM,y=ZZ, color=GROUP)) +
  # geom_point(alpha = 0.02, size=3) +
  # stat_summary_bin(fun='mean', bins=100,color='black', size=2, geom='point')
  # #cPlot
  # ggsave(filename=file.path(p$folderpath.plots, paste0("ldsum.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 2)
  # 
  # cPlot <- ggplot(cSumstatsPlot, aes(x=LDIMP.L2.SUM,y=(d.z^2)/ZZ, color=GROUP)) +
  # geom_point(alpha = 0.2, size=3) +
  # stat_summary_bin(fun='mean', bins=100,color='black', size=2, geom='point')
  # #cPlot
  # ggsave(filename=file.path(p$folderpath.plots, paste0("ldsum.val.dzz.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 2)
  # 
  # 
  # cPlot <- ggplot(cSumstatsPlot, aes(x=LDIMP.L2.SUM*ZZ,y=ZZ, color=GROUP)) +
  # geom_point(alpha = 0.02, size=3) +
  # stat_summary_bin(fun='mean', bins=100,color='black', size=2, geom='point')
  # #cPlot
  # ggsave(filename=file.path(p$folderpath.plots, paste0("impqual.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 2)
  # 
  # cPlot <- ggplot(cSumstatsPlot, aes(x= LDIMP.L2.SUM*ZZ,y=((d.z)^2)/ZZ, color=GROUP)) +
  # geom_point(alpha = 0.2, size=3) +
  # stat_summary_bin(fun='mean', bins=100,color='black', size=2, geom='point')
  # #cPlot
  # ggsave(filename=file.path(p$folderpath.plots, paste0("impqual.val.dzz.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 2)
  # 
  #  cPlot <- ggplot(cSumstatsPlot, aes(x= log10(LDIMP.L2.SUM*ZZ),y=log10(ZZ), color=GROUP)) +
  # geom_point(alpha = 0.02, size=3) +
  # stat_summary_bin(fun='mean', bins=100,color='black', size=2, geom='point')
  # #cPlot
  # ggsave(filename=file.path(p$folderpath.plots, paste0("impqual.log.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 2)
  # 
  # cPlot <- ggplot(cSumstatsPlot, aes(x= log10(LDIMP.L2.SUM*ZZ),y=((d.z)^2)/ZZ, color=GROUP)) +
  # geom_point(alpha = 0.02, size=3) +
  # stat_summary_bin(fun='mean', bins=100,color='black', size=2, geom='point')
  # #cPlot
  # ggsave(filename=file.path(p$folderpath.plots, paste0("impqual.val.dzz.log.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 2)
  # 
  # cPlot <- ggplot(cSumstatsPlot, aes(x= log10(LDIMP.L2.SUM*ZZ),y=log10(((d.z)^2)/ZZ), color=GROUP)) +
  # geom_point(alpha = 0.02, size=3) +
  # stat_summary_bin(fun='mean', bins=100,color='black', size=2, geom='point')
  # #cPlot
  # ggsave(filename=file.path(p$folderpath.plots, paste0("impqual.val.dzz.log.2.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 2)
  
  # #add N*VSNP ?
  # cPlot <- ggplot(cSumstatsPlot, aes(x=log10(LDIMP.L2.SUM*L2_REF*sqrt(ZZ.I)),y=log10(d.z.abs/sqrt(ZZ)), color=L2_REF)) +
  # geom_point(alpha = 0.02, size=3) +
  # stat_summary_bin(fun='mean', bins=100,color='black', size=2, geom='point')
  # cPlot
  # #ggsave(filename=file.path(p$folderpath.plots, paste0("impqual.separation.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 2)
  # 
  # cPlot <- ggplot(cSumstatsPlot, aes(x= log10(N*VSNP*LDIMP.L2.SUM*L2_REF*sqrt(ZZ.I)),y=log10(sqrt(ZZ)), color=GROUP)) +
  # geom_point(alpha = 0.02, size=3) +
  # stat_summary_bin(fun='mean', bins=100,color='black', size=2, geom='point')
  #   #geom_smooth(method='lm')
  # cPlot
  # #ggsave(filename=file.path(p$folderpath.plots, paste0("impqual.log.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 2)
  # 
  # #for testing
  # cSumstatsPlot<-cSumstatsPlot[CHR==1,]
  # cPlot <- ggplot(cSumstatsPlot, aes(x=L2_REF/VSNP,y=d.z.abs/sqrt(ZZ), color=d.z)) +
  # geom_point(alpha = 0.02, size=3) +
  # stat_summary_bin(fun='mean', bins=100,color='black', size=2, geom='point')
  # #geom_smooth(method='lm') #formula= y~x
  # cPlot
  # #ggsave(filename=file.path(p$folderpath.plots, paste0("impqual.experimental.",p$sumstats.sel[iTrait,]$code,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 2)
  # 
  # 
  # 
  # 
  # #for testing
  # #cSumstatsPlot<-cSumstatsPlot[CHR==1,]
  # 
  # #comparison between methods
  # cSumstatsPlot[,y:=d.z.abs/sqrt(ZZ)]
  # #setup measurements
  # cSumstatsPlot[,x1:=L2_REF/VSNP] #INFO 1
  # # cSumstatsPlot[,x2:=LDIMP.L2.SUM/(VSNP*LDIMP.K)] #INFO 2
  # # cSumstatsPlot[,x3:=(SE.I^2)/VSNP] #INFO 3
  # cSumstatsPlot[,x2:=LDIMP.L2.SUM*L2_REF] #custom 2
  # cSumstatsPlot[,x3:=LDIMP.L2.SUM*L2_REF*sqrt(ZZ.I)] #custom 3
  # cSumstatsPlot[,x4:=N*VSNP*LDIMP.L2.SUM*L2_REF] #custom 4
  # cSumstatsPlot[,x5:=N*VSNP*LDIMP.L2.SUM*L2_REF*sqrt(ZZ.I)] #custom 5
  # cSumstatsPlot[,x6:=L2_REF/(LDIMP.L2.SUM)] #custom 6
  # cSumstatsPlot[,x7:=LDIMP.K*L2_REF/(LDIMP.L2.SUM)] #custom 7
  # cSumstatsPlot[,x8:=pnorm(q = LDIMP.K*L2_REF/(LDIMP.L2.SUM), mean = 1, sd = 1)] #scaled and 0 -1 transformed custom 7
  # 
  # 
  # ratios.measurement<-as.data.frame(matrix(data = NA, nrow = 0, ncol = 0))
  # for(iMeasurement in 1:8){
  #   #iMeasurement<-8
  #   cCol<-paste0("x",iMeasurement)
  #   cSumstatsPlot$x<-cSumstatsPlot[,..cCol]
  #   
  #   x.cutoff<-mean(cSumstatsPlot$x,na.rm = T)
  #   #x.cutoff<-quantile(cSumstatsPlot$x,c(.75),na.rm = T)
  #   
  #   cSumstatsPlot[GROUP==2 & d.z/sqrt(ZZ) < 1,x.true:=T][GROUP==2 & d.z/sqrt(ZZ) > 1,x.true:=F]
  #   cSumstatsPlot[GROUP==2 & x>eval(x.cutoff),x.positive:=T][GROUP==2 & x<eval(x.cutoff),x.positive:=F]
  #   
  #   #ROC here!!
  #   dfROC<-as.data.frame(cSumstatsPlot[GROUP==2 & ZZ>0.1,.(predictions=x,labels=x.true)])
  #   pred <- prediction(predictions = dfROC$predictions, labels = dfROC$labels)
  #   perf <- performance(pred,"tpr","fpr")
  #   # plot(perf,main = paste0("ROC ",p$sumstats.sel[iTrait,]$code," model ",cCol), colorize=TRUE)
  #   # abline(a = 0, b = 1)
  #   perf <- performance(pred, measure = "auc")
  #   perf@y.values
  #   
  #   #correlation estimate
  #   dfCorr<-as.data.frame(cSumstatsPlot[GROUP==2 & ZZ>0.1,.(x,y)])
  #   estCor<- cor(x = dfCorr$x, y = dfCorr$y)
  #   
  #   nTot <- nrow(cSumstatsPlot[GROUP==2,])
  #   nPositive <- nrow(cSumstatsPlot[GROUP==2 & x.positive,])
  #   nTrue <- nrow(cSumstatsPlot[GROUP==2 & x.true,])
  #   nTruePositive <- nrow(cSumstatsPlot[GROUP==2 & x.true & x.positive,])
  #   nFalsePositive <- nrow(cSumstatsPlot[GROUP==2 & !x.true & x.positive,])
  #   nTrueNegative <- nrow(cSumstatsPlot[GROUP==2 & !x.true & !x.positive,])
  #   nFalseNegative <- nrow(cSumstatsPlot[GROUP==2 & x.true & !x.positive,])
  #   
  #   ratios.measurement[iMeasurement,c("measurement","m","cutoff", "PR","NR","TPR","TNR","FPR","FNR","PPV","NPV","AUC","cor")] <-c(
  #     cCol,
  #     nTot,
  #     x.cutoff,
  #     round(nPositive/nTot,digits = 3),
  #     round((nTot-nPositive)/nTot,digits = 3),
  #     round(nTruePositive/nTrue,digits = 3), #TPR
  #     round(nTrueNegative/(nTot-nTrue),digits = 3), #TNR
  #     round(nFalsePositive/(nTot-nTrue),digits = 3), #FPR
  #     round(nFalseNegative/nTrue,digits = 3), #FNR
  #     round(nTruePositive/(nTruePositive+nFalsePositive),digits = 3), #PPV
  #     round(nTrueNegative/(nTrueNegative+nFalseNegative),digits = 3), #NPV
  #     round(perf@y.values[[1]], digits = 4),
  #     round(estCor, digits = 4)
  #   )
  #   
  #   cPlot <- ggplot(cSumstatsPlot, aes(x=x,y=log10(y), color=d.z)) +
  #   geom_point(alpha = 0.02, size=3) +
  #   stat_summary_bin(fun='mean', bins=100,color='black', size=2, geom='point') +
  #   geom_vline(xintercept = x.cutoff, color="red") +
  #   ylab("log10(Absolute difference in Z/(Z^2))") + 
  #   theme(text = element_text(size=20)) 
  #   #geom_smooth(method='lm') #formula= y~x
  #   #cPlot
  #   ggsave(filename=file.path(p$folderpath.plots, paste0("impqual.measurement.",p$sumstats.sel[iTrait,]$code,".",cCol,".png")), plot = cPlot, width = 297, height = 210, units = "mm", dpi = 320, scale = 1)
  # }
  # 
  # setDT(ratios.measurement)
  # ratios.measurement[ ,x.eval:=round(as.numeric(PPV)*as.numeric(NPV),digits = 4)]
  # 
  # #ratios.measurement[ ,x.eval:=round(as.numeric(PPV)*as.numeric(NPV)*as.numeric(TPR)*as.numeric(TNR)/(as.numeric(FPR)*as.numeric(FNR)),digits = 3)]
  # 
  # #View(ratios.measurement)
  # ratios.measurement
  # fwrite(x = ratios.measurement, file = file.path(p$folderpath.plots,paste0("pnrates.",p$sumstats.sel[iTrait,]$code,".validation.pnrates.tsv")))
  # 
  # for(cLim in limits){
  #   #cLim<-4
  #   nTot <- nrow(cSumstatsPlot[GROUP==2,])
  #   nPositive <- nrow(cSumstatsPlot[GROUP==2 & log10(LDIMP.L2.SUM*ZZ)>cLim,])
  #   nTrue <- nrow(cSumstatsPlot[GROUP==2 & ((d.z)^2)/ZZ < 1,])
  #   nTruePositive <- nrow(cSumstatsPlot[GROUP==2 & log10(LDIMP.L2.SUM*ZZ)>cLim & ((d.z)^2)/ZZ < 1,])
  #   nFalsePositive <- nrow(cSumstatsPlot[GROUP==2 & log10(LDIMP.L2.SUM*ZZ)>cLim & ((d.z)^2)/ZZ > 1,])
  #   nTrueNegative <- nrow(cSumstatsPlot[GROUP==2 & log10(LDIMP.L2.SUM*ZZ)<cLim & ((d.z)^2)/ZZ > 1,])
  #   nFalseNegative <- nrow(cSumstatsPlot[GROUP==2 & log10(LDIMP.L2.SUM*ZZ)<cLim & ((d.z)^2)/ZZ < 1,])
  #   
  #   ratios[iTrait,c("trait","m", paste0("PR.",cLim), paste0("NR.",cLim), paste0("TPR.",cLim), paste0("TNR.",cLim), paste0("FPR.",cLim), paste0("FNR.",cLim))] <-c(
  #     p$sumstats.sel[iTrait,]$code,
  #     nTot,
  #     nPositive/nTot,
  #     (nTot-nPositive)/nTot,
  #     nTruePositive/nTrue, #TPR
  #     nTrueNegative/(nTot-nTrue), #TNR
  #     nFalsePositive/(nTot-nTrue), #FPR
  #     nFalseNegative/nTrue #FNR
  #   )
  # }
 # (ggplot(cSumstatsPlot, aes(x=ZZ,y=NAL,color=IMPUTED)) + geom_point(alpha = 0.4))
  
  
  
  
  #nrow(cSumstatsPlot[ZZ>5,])
  
}

ratios

#fwrite(x = ratios, file = paste0(p$folderpath.plots,"/imputation.validation.pnrates.tsv"))

```




# Other genetic covariancve and imputation results plots
```{r other plots, fig.width=9, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}
require(ROCR)



p$sumstats.sel.table<-p$sumstats.sel[,c("name.nice.and_code",
                                        "chisquare_mean",
                                        "cSumstats_impval_rmse_z",
                                        "cSumstats_impval_bias_z",
                                        "cSumstats_impval_rmse_z_01_05",
                                        "cSumstats_impval_bias_z_01_05",
                                        "cSumstats_impval_rmse_z_05_50",
                                        "cSumstats_impval_bias_z_05_50",
                                        "mean.S_Stand.deltaimpnoimp.500",
                                        "mean.S_Stand.SE.deltaimpnoimp.500",
                                        "variants_ldimp_mean_cell_partial",
                                        "variants_nonimputed_mean_cell"
                                        )]

p$sumstats.sel.table$ratio.ldimp.partial<-p$sumstats.sel.table$variants_ldimp_mean_cell_partial/p$sumstats.sel.table$variants_nonimputed_mean_cell


ggplot(p$sumstats.sel.table, aes(x=chisquare_mean, y=cSumstats_impval_rmse_z)) +
  geom_line(color=theme.color$contrastLight1, size=2, alpha=0.9) +
  geom_label_repel(aes(label = name.nice.and_code), size = 7, nudge_x = 0.3) +
  ggtitle("RMSE Z")

ggplot(p$sumstats.sel.table, aes(x=chisquare_mean, y=mean.S_Stand.deltaimpnoimp.500)) +
  geom_line(color=theme.color$contrastLight1, size=2, alpha=0.9) +
  geom_label_repel(aes(label = name.nice.and_code), size = 7, nudge_x = 0.3) +
  ggtitle("Mean absolute standardised genetic covariance difference, LDimp vs genotyped")


ggplot(p$sumstats.sel.table, aes(x=ratio.ldimp.partial, y=mean.S_Stand.deltaimpnoimp.500)) +
  geom_line(color=theme.color$contrastLight1, size=2, alpha=0.9) +
  geom_label_repel(aes(label = name.nice.and_code), size = 7, nudge_x = 0.3) +
  ggtitle("Mean absolute standardised genetic covariance difference, LDimp vs genotyped, 2")


ggplot(p$sumstats.sel.table, aes(x=chisquare_mean, y=mean.S_Stand.SE.deltaimpnoimp.500)) +
  geom_line(color=theme.color$contrastLight1, size=2, alpha=0.9) +
  geom_label_repel(aes(label = name.nice.and_code), size = 7, nudge_x = 0.3) +
  ggtitle("Mean standardised genetic covariance S.E. difference, LDimp vs genotyped")

#This does not work properly - really needed?
for(iTrait in 1:nrow(p$sumstats.sel)){
  #iTrait<-10
  if(!file.exists(p$sumstats.sel[iTrait,]$imputedpath.500)) next
  cSumstats <- shru::readFile(filePath = p$sumstats.sel[iTrait,]$imputedpath.500, nThreads = 5)

  nrow(cSumstats)
  cond.invertedMAF<-cSumstats$FRQ > .5
  cSumstats$MAF<-ifelse(cond.invertedMAF,1-cSumstats$FRQ,cSumstats$FRQ)
  cSumstats <- cSumstats[MAF>0.01,]
  nrow(cSumstats)
  cSumstats[,ZZ:=Z*Z][,ZZ.I:=(BETA.I/SE.I)^2][,AC:=FRQ*N][,MAC:=MAF*N][,VSNP:=2*FRQ*(1-FRQ)][,NEF:=round((((BETA.I/SE.I)/BETA.I)^2)/VSNP,digits = 0)][,IMPUTED:=(is.finite(LDIMP.L2.SUM) & BETA.I==BETA)]

  cSumstats[,IMPUTED:=(is.finite(LDIMP.L2.SUM) & BETA.I==BETA)][,SINFO:=NA_real_]
  cSumstats$SINFO<-as.double(cSumstats$SINFO)
  cSumstats[IMPUTED==T & is.finite(L2_REF),SINFO:=pnorm(q = LDIMP.K*L2_REF/(LDIMP.L2.SUM), mean = 1, sd = 1)]

  setkeyv(cSumstats,cols = c("CHR","BP"))
  cSumstats$d.z<-NA_real_
  cSumstats[,d.z :=(BETA.I/SE.I)-(BETA/SE)]
  cSumstats[,d.z.abs:=abs(d.z)]

  cSumstats$y<-NA_real_
  cSumstats[,y:=d.z.abs/sqrt(ZZ)][,x:=SINFO]
  cSumstats[,y.true:=ifelse(y<0.5,T,F)]

  #ROC here!!
  dfROC<-as.data.frame(cSumstats[ZZ>0.01579077 & is.finite(x) & is.finite(y),.(predictions=x,labels=y.true)])
  pred <- prediction(predictions = dfROC$predictions, labels = dfROC$labels)
  perf <- performance(pred,"tpr","fpr")
  plot(perf,main = paste0("ROC ",p$sumstats.sel[iTrait,]$code), colorize=TRUE)
  # abline(a = 0, b = 1)
  perf <- performance(pred, measure = "auc")
  perf@y.values
}

```

# Improved annotation of chosen datasets

```{r improved annotation of chosen datasets, fig.width=10, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}
#View(p$sumstats.sel)


#selected sumstats with heritabilities
p$sumstats.sel.table<-p$sumstats.sel[,c("name.nice.and_code",
                                        #"chisquare_mean",
                                        "h2.liability_mvLDSC.hm3",
                                        "h2.se.liability_mvLDSC.hm3",
                                        "h2.liability_mvLDSC.1kg.hm3res",
                                        "h2.se.liability_mvLDSC.1kg.hm3res",
                                        "h2.liability_mvLDSC.hc1kg.hm3res",
                                        "h2.se.liability_mvLDSC.hc1kg.hm3res",
                                        "h2.liability_mvLDSC.1kg",
                                        "h2.se.liability_mvLDSC.1kg",
                                        "h2.liability_mvLDSC.hc1kg",
                                        "h2.se.liability_mvLDSC.hc1kg",
                                        "h2.liability_mvLDSC.hc1kg.ldimp",
                                        "h2.se.liability_mvLDSC.hc1kg.ldimp"
                                        )]

p$sumstats.sel.table$h2.liability_mvLDSC.hm3.table<-paste0(round( p$sumstats.sel.table$h2.liability_mvLDSC.hm3,digits = 3)," (",round(p$sumstats.sel.table$h2.se.liability_mvLDSC.hm3,digits = 4),")")

p$sumstats.sel.table$h2.liability_mvLDSC.1kg.hm3res.table<-paste0(round( p$sumstats.sel.table$h2.liability_mvLDSC.1kg.hm3res,digits = 3)," (",round(p$sumstats.sel.table$h2.se.liability_mvLDSC.1kg.hm3res,digits = 4),")")

p$sumstats.sel.table$h2.liability_mvLDSC.hc1kg.hm3res.table<-paste0(round( p$sumstats.sel.table$h2.liability_mvLDSC.hc1kg.hm3res,digits = 3)," (",round(p$sumstats.sel.table$h2.se.liability_mvLDSC.hc1kg.hm3res,digits = 4),")")

p$sumstats.sel.table$h2.liability_mvLDSC.1kg.table<-paste0(round( p$sumstats.sel.table$h2.liability_mvLDSC.1kg,digits = 3)," (",round(p$sumstats.sel.table$h2.se.liability_mvLDSC.1kg,digits = 4),")")

p$sumstats.sel.table$h2.liability_mvLDSC.hc1kg.table<-paste0(round( p$sumstats.sel.table$h2.liability_mvLDSC.hc1kg,digits = 3)," (",round(p$sumstats.sel.table$h2.se.liability_mvLDSC.hc1kg,digits = 4),")")

p$sumstats.sel.table$h2.liability_mvLDSC.hc1kg.ldimp.table<-paste0(round( p$sumstats.sel.table$h2.liability_mvLDSC.hc1kg.ldimp,digits = 3)," (",round(p$sumstats.sel.table$h2.se.liability_mvLDSC.hc1kg.ldimp,digits = 4),")")

p$sumstats.sel.table<-p$sumstats.sel.table[,c("name.nice.and_code",
                                              #"chisquare_mean",
                                              #"log_nxm_mvldsc_1kg500_nohighld",
                                              "h2.liability_mvLDSC.hm3.table",
                                              "h2.liability_mvLDSC.1kg.hm3res.table",
                                              "h2.liability_mvLDSC.hc1kg.hm3res.table",
                                              "h2.liability_mvLDSC.1kg.table",
                                              "h2.liability_mvLDSC.hc1kg.table",
                                              "h2.liability_mvLDSC.hc1kg.ldimp.table"
                                              #"h2_orig.liability_mvLDSC.1kg.table",
                                              #"h2_orig.liability_mvLDSC.1kg.ssimp.table",
                                              #"h2_orig.liability_mvLDSC.1kg.ldimp.table"
                                              )]
#View(p$sumstats.sel.table)
#p$sumstats.sel.table

p$plots.sumstats.sel.table<-p$sumstats.sel.table %>% 
  gt() %>% 
  #fmt_number(columns = vars(chisquare_mean), decimals = 2) %>%
  tab_header(
    title = "LDSC++ trait heritabilities: panel comparison"
  ) %>% cols_label(
    name.nice.and_code  = "Trait",
    #chisquare_mean = html("Mean X<sup>2</sup>, merged"),
    h2.liability_mvLDSC.hm3.table = html("h<sup>2</sup><sub>HM3</sub> (sd)"),
    h2.liability_mvLDSC.1kg.hm3res.table = html("h<sup>2</sup><sub>1kG res. HM3</sub> (sd)"),
    h2.liability_mvLDSC.hc1kg.hm3res.table = html("h<sup>2</sup><sub>HC1kG res. HM3</sub> (sd)"),
    h2.liability_mvLDSC.1kg.table = html("h<sup>2</sup><sub>1kG</sub> (sd)"),
    h2.liability_mvLDSC.hc1kg.table = html("h<sup>2</sup><sub>HC1kG</sub> (sd)"),
    h2.liability_mvLDSC.hc1kg.ldimp.table = html("h<sup>2</sup><sub>HC1kG & LD-IMP</sub> (sd)")
  ) %>%
  tab_style(
    style = cell_text(size = px(14)),
    locations = cells_column_labels(everything())       
  ) %>%
  tab_style(
    style = cell_text(size = px(16),weight = "bold"),
    locations = cells_body(everything())        
  )

p$plots.sumstats.sel.table

gtsave(data = p$plots.sumstats.sel.table, filename = paste0(p$folderpath.plots,"/sumstats.sel.table.heritabilities.rtf"))

for(cPanel in c("hm3","1kg","ihc1kg")){
  #cPanel<-"hm3"
  cImpstats<-NULL
  if(cPanel == "hm3") {
    cImpstats <- p$mvLD$covstruct.mvLDSC.hm3$impstats 
  } else if(cPanel == "1kg") {
    cImpstats <- p$mvLD$covstruct.mvLDSC.1kg.vbcs.nocm.winfo$impstats
  # } else if(cPanel == "hc1kg"){
  #   cImpstats <- p$mvLD$covstruct.mvLDSC.hc1kg$impstats 
  } else if(cPanel == "ihc1kg") {
    cImpstats <- p$mvLD$covstruct.mvLDSC.1kg.05cm$impstats
  }
        
  
  #general variant count: ldimp only
  p$sumstats.sel.table<-cImpstats[,c(
                                          "trait.name",
                                          "medianChiSquare.tot",
                                          "medianChiSquare.imputed",
                                          "medianChiSquare.nonimputed",
                                          "m",
                                          "m.imputed",
                                          "m.merged",
                                          "m.merged.imputed",
                                          "m.cell.mean.nonimputed",
                                          "m.cell.mean.imputed.full",
                                          "m.cell.mean.imputed.partial"
                                          )]
  setDT(p$sumstats.sel.table)
  p$sumstats.sel.table<-p$sumstats.sel.table[,.(
    code=trait.name,
    medianChiSquare.nonimputed=ifelse(is.na(medianChiSquare.nonimputed),
    medianChiSquare.tot,medianChiSquare.nonimputed),
    medianChiSquare.imputed,
    m.merged.nonimputed=ifelse(is.na(m.merged.imputed),m.merged,m.merged-m.merged.imputed),
    m.merged.imputed,
    m.cell.mean.nonimputed,
    m.cell.mean.imputed.full,
    m.cell.mean.imputed.partial)]
  
  cat("\nCurrent panel: ",cPanel)
  
  #medianMerged.m<-5931905 #hard coded - from LDSC++
  medianMerged.m<-median(p$sumstats.sel.table$m.merged.nonimputed,na.rm = T)
  cat("\nMedian merged variant count (non-imputed): ",medianMerged.m)
  cat("\nMean LDSC cell overlap (non-imputed) with the median merged variant count (non-imputed): ",mean(p$sumstats.sel.table$m.cell.mean.nonimputed,na.rm=T)/medianMerged.m)
  cat("\nMean LDSC cell overlap (non-imputed+imputed) with the median merged variant count (non-imputed):",
      mean(p$sumstats.sel.table$m.cell.mean.nonimputed+p$sumstats.sel.table$m.cell.mean.imputed.full+p$sumstats.sel.table$m.cell.mean.imputed.partial,na.rm=T)/medianMerged.m)
  cat("\nRatio of mean imputed variant cell count to nonimputed: ",
      mean(p$sumstats.sel.table$m.cell.mean.imputed.full+p$sumstats.sel.table$m.cell.mean.imputed.partial,na.rm=T)/mean(p$sumstats.sel.table$m.cell.mean.nonimputed,na.rm=T))
  
  
  
  
  p$sumstats.sel.table[p$dsStat$sumstats.meta,on=c("code"),c("variants_raw"):=i.m.genotyped]
  p$sumstats.sel.table[code=="BODYT2MI",variants_raw:=1973473] #i.e. m of WEIG04M
  
  p$sumstats.sel.table[p$sumstats.sel,on=c("code"),c("name.nice.and_code"):=i.name.nice.and_code]
  
  p$sumstats.sel.table[,code:=NULL]
  
  p$sumstats.sel.table<-p$sumstats.sel.table[,c("name.nice.and_code","medianChiSquare.nonimputed","medianChiSquare.imputed","variants_raw","m.merged.nonimputed","m.merged.imputed","m.cell.mean.nonimputed","m.cell.mean.imputed.full","m.cell.mean.imputed.partial")]
  
  p$plots.sumstats.sel.table<-p$sumstats.sel.table %>% 
    gt() %>% 
    fmt_number(columns = vars(
      variants_raw,
      m.merged.nonimputed,
      m.merged.imputed,
      m.cell.mean.nonimputed,
      m.cell.mean.imputed.full,
      m.cell.mean.imputed.partial
      ), decimals = 0) %>%
    fmt_number(columns = vars(
      medianChiSquare.imputed,
      medianChiSquare.nonimputed
      ), decimals = 3) %>%
    tab_header(
      title = paste("GWAS summary statistics genetic variant count: ", cPanel)
    ) %>% cols_label(
      name.nice.and_code  = "Trait",
      medianChiSquare.nonimputed = md("Median Chi<sup>2</sup>, genotyped"),
      medianChiSquare.imputed = md("Median Chi<sup>2</sup>, imputed"),
      variants_raw = md("Original no. variants"),
      m.merged.nonimputed = md("Merged no. variants, genotyped"),
      m.merged.imputed = md("Merged no. variants, imputed"),
      m.cell.mean.nonimputed = md("Mean no. variants, LDSC, genotyped"),
      m.cell.mean.imputed.full = md("Mean no. variants, LDSC, imputed*2"),
      m.cell.mean.imputed.partial = md("Mean no. variants, LDSC, imputed*1")
    ) %>%
    tab_style(
      style = cell_text(size = px(14)),
      locations = cells_column_labels(everything())       
    ) %>%
    tab_style(
      style = cell_text(size = px(16),weight = "bold"),
      locations = cells_body(everything())        
    )
  
  p$plots.sumstats.sel.table
  
  gtsave(data = p$plots.sumstats.sel.table, filename = paste0(p$folderpath.plots,"/sumstats.sel.table.variants.ldimp.",cPanel,".rtf"))

}


#panel variant counts
p$sumstats.sel.table<-p$dsStat$panel.meta[,c("code","m","m.0_01","m.01_05","m.05_50")]

p$plots.sumstats.sel.table<-p$sumstats.sel.table %>% 
  gt() %>% 
  fmt_number(columns = vars(
    m,
    m.0_01,
    m.01_05,
    m.05_50
    ), decimals = 0) %>%
  tab_header(
    title = "Reference panel genetic variant count"
  ) %>% cols_label(
    code  = "Panel",
    m = md("Total"),
    m.0_01 = md("MAF < 0.01"),
    m.01_05 = md("0.01 < MAF < 0.05"),
    m.05_50 = md("0.05 < MAF < 0.5"),
  ) %>%
  tab_style(
    style = cell_text(size = px(14)),
    locations = cells_column_labels(everything())       
  ) %>%
  tab_style(
    style = cell_text(size = px(16),weight = "bold"),
    locations = cells_body(everything())        
  )

p$plots.sumstats.sel.table

gtsave(data = p$plots.sumstats.sel.table, filename = paste0(p$folderpath.plots,"/panel.table.variants.ldimp.rtf"))


```


# Exploratory Factor Analysis
I am using EFA, clustering and  PCA as a complement to the previous genetic correlation matrix to visualise possible cluster patterns. EFA and other techniques are used to inform CFA models later.

```{r EFA }
print("***EFA***")
#saving efa results between runs as to always use the same randomised start for clustering for example
p$filepath.efa<-file.path(p$folderpath.workingDirectory,paste0("efa.",p$setup.code,".Rds"))
if (file.exists(p$filepath.efa)) {
  print("Using existing EFA results from previous run.")
  p$EFA<-readRDS(file=p$filepath.efa)
} else {

  #visualisation of up to max factors EFA models with varimax
  # for(iefa in 1:max(p$CFA$nFactors)){
  #   res <- psych::fa(r = abs(p$mvLD$covstruct.mvLDSC$S.smooth),nfactors = iefa, rotate = 'varimax', symmetric = T, warnings = T, fm='ols', max.iter = 1000)
  #   #print(res)
  #   print(res$loadings)
  #   print(res$fit)
  #   #print(kmeans(x = p$mvLD$covstruct.mvLDSC$S_Stand, centers = iefa, iter.max = 1000, nstart = 30))
  # }
  
  #visualise factors in a scree plot
  if(!p$clOptions$location=="cluster"){
      p$plots.efa.plot.scree<-fa.parallel(abs(p$mvLD$covstruct.mvLDSC$S.smooth), fa = "fa")
      png(filename = file.path(p$folderpath.plots,"efa.plot.scree.png"), width = 800, height = 500)
      fa.parallel(abs(p$mvLD$covstruct.mvLDSC$S.smooth), fa = "fa")
      dev.off()
  }
  
  
  #fit EFA models for each nFactor configuration
  print("Setting upp and computing new EFA results.")
  p$EFA<-c()
  p$EFA$PCA<-c()
  #iFactorConfiguration<-1
  for(iFactorConfiguration in 1:length(p$CFA$nFactors)) {
    cNFactors<-p$CFA$nFactors[iFactorConfiguration]
    p$EFA$PCA[[iFactorConfiguration]]<-eigen(x = abs(p$mvLD$covstruct.mvLDSC$S_Stand), symmetric = TRUE)
    rownames(p$EFA$PCA[[iFactorConfiguration]]$vectors)<-p$sumstats.sel.code
    p$EFA$PCA[[iFactorConfiguration]]$vector_values<-t(p$EFA$PCA[[iFactorConfiguration]]$vectors*p$EFA$PCA[[iFactorConfiguration]]$values)[,1:cNFactors] #has to be transposed as well!(?)
  
    p$EFA$fa.result.ORT[[iFactorConfiguration]] <- psych::fa(r = abs(p$mvLD$covstruct.mvLDSC$S.smooth),nfactors = cNFactors, rotate = 'varimax', symmetric = T, warnings = T, fm='ols', max.iter = 1000)
    
    p$EFA$fa.result.OBL[[iFactorConfiguration]] <- psych::fa(r = abs(p$mvLD$covstruct.mvLDSC$S.smooth),nfactors = cNFactors, rotate = 'oblimin', symmetric = T, warnings = T, fm='ols', max.iter = 1000)
    
    p$EFA$kmeans.result[[iFactorConfiguration]]<- kmeans(x = abs(p$mvLD$covstruct.mvLDSC$S_Stand), centers = cNFactors, iter.max = 1000, nstart = 30)
    #View(p$clustering$centers)
    #View(fitted(p$clustering))
    #View(abs(p$mvLD$covstruct.mvLDSC$S_Stand))
    #resid<-abs(p$mvLD$covstruct.mvLDSC$S_Stand)-fitted(p$clustering)
    #View(resid)
    p$EFA$kmeans.centerDistance[[iFactorConfiguration]]<-apply(X = abs(p$mvLD$covstruct.mvLDSC$S_Stand), MARGIN = 1, FUN = function(x){
      #test
      #x<-abs(p$mvLD$covstruct.mvLDSC$S_Stand)[1,]
      #cat("\nOBS:",x)
      ss<-apply(X=(abs(x)-p$EFA$kmeans.result[[iFactorConfiguration]]$centers)^2, FUN = sum, MARGIN = 1)
      #cat("\nSS:",ss)
      s<-sum(abs(x))
      #cat("\nS:",s)
      return (ss/s)
    })
    #transpose this to conform with indicator loading data frames
    p$EFA$kmeans.centerDistance[[iFactorConfiguration]]<-t(p$EFA$kmeans.centerDistance[[iFactorConfiguration]])
    rownames(p$EFA$kmeans.centerDistance[[iFactorConfiguration]])<-p$sumstats.sel.code
    
    
  cat("\nPCA vector values\n")
  print(p$EFA$PCA[[iFactorConfiguration]]$vector_values)
  cat("\nFA fa result, ORTHOGONAL rotation\n")
  print(p$EFA$fa.result.ORT[[iFactorConfiguration]])
  cat("\nFA fa result, OBLIQUE rotation\n")
  print(p$EFA$fa.result.OBL[[iFactorConfiguration]])
  #cat("\nFA factanal result\n")
  #print(p$EFA$factanal.result)
  cat("\nKmeans clustering centers\n")
  print(t(p$EFA$kmeans.result[[iFactorConfiguration]]$centers))
  cat("\nKmeans clustering residuals\n")
  print(p$EFA$kmeans.centerDistance[[iFactorConfiguration]])
    
  }
  
  
  
  saveRDS(object = p$EFA,file = p$filepath.efa)
}



```


# Confirmatory Factor Analysis

CFA.

## Create CFA indicator loading patterns

```{r CFA indicator loading pattern creation}
print("***CFA indicator loading pattern creation***")

## CFA aditional settings
p$sumstats.sel$residualSizeLimitMax<-NA_real_
#p$sumstats.sel$residualSizeLimitMax[which(p$sumstats.sel$code=="ANXI03" | p$sumstats.sel$code=="DEPR05")]<-0.10
#(1/p$sumstats.sel$h2.se.liability_mvLDSC^2)/sum(1/p$sumstats.sel$h2.se.liability_mvLDSC^2)+0.01
p$CFA$nIndicators=length(p$sumstats.sel$code)

p$filepath.cfa<-file.path(p$folderpath.workingDirectory,paste0("cfa.",p$setup.code,".Rds"))
#p$filepath.cfa_converged_results<-file.path(p$folderpath.workingDirectory,paste0("cfa.",p$setup.code,".converged.txt"))
p$filepath.cfa.FactorConfiguration<-c()

if(!file.exists(p$filepath.cfa)){
  
  p$CFA$indicatorLoadingPatterns.PCA<-c()
  p$CFA$indicatorLoadingPatterns.fa.ORT<-c()
  p$CFA$indicatorLoadingPatterns.fa.OBL<-c()
  p$CFA$indicatorLoadingPatterns.kmeans<-c()
  #iFactorConfiguration<-1
  for(iFactorConfiguration in 1:length(p$CFA$nFactors)) {
  ##kmeans clustering based models
  p$CFA$indicatorLoadingPatterns.kmeans[[iFactorConfiguration]]<-semplate$generateIndicatorLoadingPatternsFromFactorLoadings(factorLoadings = t(p$EFA$kmeans.result[[iFactorConfiguration]]$centers), increment = 0.0005,forceOneIndicatorLoading = T)
  
  ##fa, orthogonal based models
  p$CFA$indicatorLoadingPatterns.fa.ORT[[iFactorConfiguration]]<-semplate$generateIndicatorLoadingPatternsFromFactorLoadings(factorLoadings = p$EFA$fa.result.ORT[[iFactorConfiguration]]$loadings, increment = 0.0005,forceOneIndicatorLoading = T)
  
  ##fa, oblique based models
  p$CFA$indicatorLoadingPatterns.fa.OBL[[iFactorConfiguration]]<-semplate$generateIndicatorLoadingPatternsFromFactorLoadings(factorLoadings = p$EFA$fa.result.OBL[[iFactorConfiguration]]$loadings, increment = 0.0005,forceOneIndicatorLoading = T)
    
  #PCA based models
  p$CFA$indicatorLoadingPatterns.PCA[[iFactorConfiguration]]<-semplate$generateIndicatorLoadingPatternsFromFactorLoadings(factorLoadings = p$EFA$PCA[[iFactorConfiguration]]$vector_values, increment = 0.0005,forceOneIndicatorLoading = T)
    
  p$CFA$sessionIndicatorLoadingPatterns[[iFactorConfiguration]]<-unique(rbind(p$CFA$indicatorLoadingPatterns.kmeans[[iFactorConfiguration]],p$CFA$indicatorLoadingPatterns.fa.ORT[[iFactorConfiguration]],p$CFA$indicatorLoadingPatterns.fa.OBL[[iFactorConfiguration]],p$CFA$indicatorLoadingPatterns.PCA[[iFactorConfiguration]]))
  
  }
  
  

}

```


## Evaluate CFA models

```{r CFA model evaluation}
print("***CFA model evaluation***")

#test
#p$clOptions$task<-"cfa"
#p$clOptions$task_argument<-"1"

match.row<-function(row_v,tomatch_df){
  #row_v<-lp
  #tomatch_df<-lplib
  toreturn<-vector()
  for(nTomatch in 1:nrow(tomatch_df)){
    #nTomatch<-2
    toreturn[nTomatch]<-all(row_v==tomatch_df[nTomatch,])
  }
  return(toreturn)
}

p$CFA$models<-data.frame(nModel=c(),code=c(),nFactors=c(),correlation=c(),estimator=c(), lModel=c(),lResults=c())

p$CFA$resultColumnNames<-c("chisq","df","p_chisq","AIC","CFI","SRMR")

if (file.exists(p$filepath.cfa)) {
  print("Using existing CFA results from previous run and appending to these if needed.")
  p$CFA<-readRDS(file=p$filepath.cfa)
} else {
  
  nModel<-0
  nFittingModelsFound<-0
  #compute total number of models across factor configurations
  totalNumberOfModels<-0
  nVariables<-ncol(p$mvLD$covstruct.mvLDSC$S)
  nUniqueCovariances<-nVariables*(nVariables+1)/2
  for(iFactorConfiguration in 1:length(p$CFA$nFactors)) {
    sessionPatternLength<-nrow(p$CFA$sessionIndicatorLoadingPatterns[[iFactorConfiguration]])
    totalNumberOfModels<-totalNumberOfModels+sessionPatternLength*length(p$CFA$correlation)*length(p$CFA$estimator)
  }
  
  for(iFactorConfiguration in 1:length(p$CFA$nFactors)) {
    #test
    #iFactorConfiguration<-1
    
    if(p$clOptions$task=="cfa" & length(p$clOptions$task_argument)>0 & p$clOptions$task_argument!=iFactorConfiguration) next
    
    p$filepath.cfa.FactorConfiguration[iFactorConfiguration]<-file.path(p$folderpath.workingDirectory,paste0("cfa.",p$setup.code,"_",iFactorConfiguration,".Rds"))
    
    if(file.exists(p$filepath.cfa.FactorConfiguration[iFactorConfiguration])){
      storedFactorConfigurationModelResults <- readRDS(file=p$filepath.cfa.FactorConfiguration[iFactorConfiguration])
      p$CFA$models <- rbind(p$CFA$models,storedFactorConfigurationModelResults)
      nModel<-nrow(p$CFA$models)
      next
    }
    
    
    if(p$clOptions$task!="cfa") next #do not evaluate models if not in cfa task
    
    sessionPatternLength<-nrow(p$CFA$sessionIndicatorLoadingPatterns[[iFactorConfiguration]])
    
    cat("\nAnalysing",sessionPatternLength, "patterns for this factor configuration...\n")
    for(nSessioPattern in 1:sessionPatternLength){
      #test
      #nSessioPattern<-1
      
      for(iCorrelationConfiguration in 1:length(p$CFA$correlation)){
        #iCorrelationConfiguration<-1
        cCorrelation<-p$CFA$correlation[iCorrelationConfiguration]
        
        # #avoid correlated factors if above 8 factors
        # if(p$CFA$nFactors[iFactorConfiguration]>8 & cCorrelation=="COR") next
        # 
        # #avoid oblique factors if below 9 factors
        # if(p$CFA$nFactors[iFactorConfiguration]<9 & cCorrelation=="OBL") next
        # 
        # #avoid orthogonal factors if below 7 factors
        # if(p$CFA$nFactors[iFactorConfiguration]<7 & cCorrelation=="ORT") next
        
        for(iParameterEstimator in 1:length(p$CFA$estimator)){
          #iParameterEstimator<-1
          cEstimator<-p$CFA$estimator[iParameterEstimator]
          
          #new model row
          nModel<-nModel+1
          
          if(!is.null(p$CFA$models.selected)){
            if(!nModel %in% p$CFA$models.selected$nModel) next
          }
          
          #set specific nmodel for reevaluation
          #nModel<-35
          #nSessioPattern<-35
          
          #init columns
          p$CFA$models[nModel,]<-NA
          
          #nModel
          p$CFA$models[nModel,c("nModel")]<-nModel
          
          #record code
          p$CFA$models[nModel,c("code")]<-paste0("M",p$CFA$nIndicators,"_",p$CFA$nFactors[iFactorConfiguration],
          "_",nSessioPattern,
          ".",cCorrelation,
          ".",cEstimator
          )
          
          #record nFactors
          p$CFA$models[nModel,c("nFactors")]<-p$CFA$nFactors[iFactorConfiguration]
          
          #record correlation
          p$CFA$models[nModel,c("correlation")]<-cCorrelation
          
          #record estimator
          p$CFA$models[nModel,c("estimator")]<-cEstimator
          
          #p$CFA$models$totalBitValue[nModel]<-NA #because otherwise the later assignment will crash
          p$CFA$models[nModel,c("loading_pattern","loading_pattern_pca","loading_pattern_fa","loading_pattern_kmeans")]<-NA
          p$CFA$models[nModel,c("lModel")]<-NA_character_
          p$CFA$models[nModel,c("gsemResults")]<-NA
          p$CFA$models[nModel,p$CFA$resultColumnNames]<-NA
          
          #loading pattern
          lp<-p$CFA$sessionIndicatorLoadingPatterns[[iFactorConfiguration]][nSessioPattern,]
          p$CFA$models[[nModel,c("loading_pattern")]]<-list(lp)
          cIndicatorLoadings<-matrix(data = lp, nrow = p$CFA$nIndicators, ncol = p$CFA$nFactors[iFactorConfiguration]) 
          row.names(cIndicatorLoadings)<-p$sumstats.sel$code
          
          p$CFA$models[nModel,c("loading_pattern_pca")]<-any(match.row(lp,p$CFA$indicatorLoadingPatterns.PCA[[iFactorConfiguration]]))
          p$CFA$models[nModel,c("loading_pattern_fa.ORT")]<-any(match.row(lp,p$CFA$indicatorLoadingPatterns.fa.ORT[[iFactorConfiguration]]))
          p$CFA$models[nModel,c("loading_pattern_fa.OBL")]<-any(match.row(lp,p$CFA$indicatorLoadingPatterns.fa.OBL[[iFactorConfiguration]]))
          p$CFA$models[nModel,c("loading_pattern_kmeans")]<-any(match.row(lp,p$CFA$indicatorLoadingPatterns.kmeans[[iFactorConfiguration]]))
          
          #further filter rules
          indicatorsLoadedOnFactors <- apply(cIndicatorLoadings, 1, FUN = any)
          factorsHasIndicatorsLoaded <- apply(cIndicatorLoadings, 2, FUN = any)
          ##check factor configuration is of an identified model
          if(cCorrelation!="ORT"){
            isIdentified <- (nVariables + sum(cIndicatorLoadings) + factorial(nVariables)/(factorial(2)*factorial(nVariables-2))) <= nUniqueCovariances #real condition
            p$CFA$models[nModel,c("identified")]<-isIdentified
             isIdentified <- (nVariables + sum(cIndicatorLoadings) + (factorial(nVariables)/(factorial(2)*factorial(nVariables-2)))/2) <= nUniqueCovariances #relax this condition in case my calculation is wrong
          } else { #ORT
            isIdentified<-nVariables + sum(cIndicatorLoadings) <= nUniqueCovariances
          }
          
          #allow evaluation if filter rules are met
          if(all(indicatorsLoadedOnFactors) & all(factorsHasIndicatorsLoaded)){ #& isIdentified
            
            #generate lavaan model
            p$CFA$models[nModel,c("lModel")]<- semplate$generateLavaanCFAModel(
              allow_loading.table.indicator_factor = cIndicatorLoadings,
              #indicatorArgs = p$sumstats.sel[,c("code","residualSizeLimitMax")],
              #universalResidualLimitMin = 0.0001,
              orthogonal = (cCorrelation=="ORT"),
              universalCorrelationLimitMax = ifelse((cCorrelation=="OBL"),0.3,NA)
              )
            
            #evaluate lavaan model in GenomicSEM
            cat("\n\n#Found fitting=",nFittingModelsFound,",\tevaluating new model:\t",nModel,"/",totalNumberOfModels,"\n", p$CFA$models[nModel,c("code")],"\n")
            cModelResults = tryCatch(
              usermodel.mod(covstruc = p$mvLD$covstruct.mvLDSC,
                model = p$CFA$models[nModel,c("lModel")],
                estimation = cEstimator,
                fix_resid = F,
                CFIcalc = F #ifelse(is.null(p$CFA$models.selected),F,T) #set this to true for CFI evaluation
                ), error= function(e) e
              )
            
            if(!inherits(cModelResults, "try-error") & !is.null(cModelResults$modelfit)){
              if(nrow(cModelResults$modelfit)>0 && any(p$CFA$resultColumnNames %in% colnames(cModelResults$modelfit))) {
                print(cModelResults$modelfit)
                #record results even though not fitting
                p$CFA$models[nModel,c("gsemResults")]<-NA
                p$CFA$models[[nModel,c("gsemResults")]]<-list(cModelResults)
                cRescolnames<-intersect(p$CFA$resultColumnNames,colnames(cModelResults$modelfit))
                p$CFA$models[nModel,cRescolnames]<-cModelResults$modelfit[1,cRescolnames]
                if(is.numeric(cModelResults$modelfit$chisq)){
                  #This is considered a fitting model
                  nFittingModelsFound<-nFittingModelsFound+1
                  cat("\nFITTING!:",p$CFA$models[nModel,c("code")],"\n")
                }
              } else {
                cat("\nThe model did not yield correct results.")
              }
            } else {
              cat("\nThe model did not converge.")
            }
            
          } else {warning("\nThe pattern configuration was deemed to yield an non-identified or otherwise not plausible model!")} #evaluation block
        } #for(iParameterEstimator in 1:length(p$CFA$estimator))
      } #for(iCorrelationConfiguration in 1:length(p$CFA$correlation))
    } #for(nSessioPattern in 1:sessionPatternLength)
  
    
    saveRDS(object = p$CFA$models,file = p$filepath.cfa.FactorConfiguration[iFactorConfiguration])
  print("Intermediate CFA results for this factor configuration are now done and the result should have been saved into a file.")
  
  if(p$clOptions$task=="cfa" & p$clOptions$task_argument==iFactorConfiguration){quit(save = "no")}
  
  }
  
  rownames(p$CFA$models)<-p$CFA$models$code
    
  saveRDS(object = p$CFA,file = p$filepath.cfa)
  print("CFA for this session is now done and the result should have been saved into a file.")
}



#View(p$CFA$models)
#p$CFA$models$lModel[which(p$CFA$models$nModel==57 & p$CFA$models$code=="M3-17.ML._-1107563521_389110_0_0_0_0_0_0_")]
if(p$clOptions$task=="cfa"){quit(save = "no")}

```

## Select CFA results

```{r CFA select}
print("***CFA select***")
#View(p$CFA$models[which(p$CFA$models$AIC<10000 & p$CFA$models$correlation=="ORT"),c("code","nModel","identified", "loading_pattern","loading_pattern_pca","loading_pattern_fa.ORT","loading_pattern_fa.OBL","loading_pattern_kmeans",p$CFA$resultColumnNames)])


p$CFA$models.selected<-p$CFA$models[c("M20_6_172.COR.ML","M20_6_30.ORT.ML"),] #this is a manual setting after choosing the best fitting models from the previous results
#View(p$CFA$models.selected)


```


# Pre-analysis

This is a complete alternate analysis containing a smaller set of traits

```{r pre-analysis}

print("***Pre-analysis***")

if(p$clOptions$task=="pre"){
  p$sumstats.sel.pre.code<-c("EDUC03","NEUR02","RISK02","RISK03","SCHI04")
  p$sumstats.sel.pre<-p$sumstats[which(p$sumstats$code %in% p$sumstats.sel.pre.code),]
  
  #export modified munged files
  
  p$pre<-c()
  p$pre$filepath.mvLD<-file.path(p$folderpath.workingDirectory,paste0("mvLD.pre.",p$setup.code,".Rds"))
  p$pre$filepath.models<-file.path(p$folderpath.workingDirectory,paste0("cfa.pre.",p$setup.code,".Rds"))
  
  if (file.exists(p$pre$filepath.mvLD)) {
    print("Using existing covariance structures from previous LD computations.")
    p$pre$mvLD<-readRDS(file=p$pre$filepath.mvLD)
  } else {
      
    p$pre$mvLD<-c()
    p$pre$mvLD$covstructs<-c()
    
    p$pre$mvLD$covstructs[[1]]<-ldsc.mod(
        traits = p$sumstats.sel.pre$mungedpath,
        sample.prev =  p$sumstats.sel.pre$samplePrevalence,
        population.prev = p$sumstats.sel.pre$populationPrevalence,
        trait.names = p$sumstats.sel.pre$code,
        ld = p$folderpath.data.mvLDSC.ld.1kg,
        wld = p$folderpath.data.mvLDSC.ld.1kg,
        n.blocks = 600, #a bit more here if it can support the larger reference panel used
        info.filter = 0.6,
        maf.filter = 0.01,
        mhc.filter = 37,
        N = p$sumstats.sel.pre$n_total,
        #forceN = T, # Consider this when some of the original N's may be untrustworthy (ANXI04!) - TODO - fix in supermunge
        ldsc.log = p$setup.code.date
        )
    
    for(iChr in 1:11){
      p$pre$mvLD$covstructs[[iChr+1]]<-ldsc.mod(
        traits = p$sumstats.sel.pre$mungedpath,
        sample.prev =  p$sumstats.sel.pre$samplePrevalence,
        population.prev = p$sumstats.sel.pre$populationPrevalence,
        trait.names = p$sumstats.sel.pre$code,
        ld = p$folderpath.data.mvLDSC.ld.1kg,
        wld = p$folderpath.data.mvLDSC.ld.1kg,
        n.blocks = 600, #a bit more here if it can support the larger reference panel used
        info.filter = 0.6,
        maf.filter = 0.01,
        mhc.filter = 37,
        N = p$sumstats.sel.pre$n_total,
        #forceN = T, # Consider this when some of the original N's may be untrustworthy (ANXI04!) - TODO - fix in supermunge
        ldsc.log = p$setup.code.date,
        leave.chr=c(2*iChr-1,2*iChr)
        )
    
    }
      
    #save the mvLD output
    saveRDS(object = p$pre$mvLD,file = p$pre$filepath.mvLD)
    print("Multivariate LD correction is done now and the resulting covariance structure should have been saved to a file.")
      
  }
  
  
  #analyse the differences in genetic correlation matrices
  p$pre$mvLD$covstructs.leaveoneout<-p$pre$mvLD$covstructs[2:11]
  length(p$pre$mvLD$covstructs.leaveoneout)
  p$pre$mvLD$covstructs[[1]]$S
  p$pre$mvLD$covstructs[[1]]$S.SE
  
  p$pre$mvLD$covstructs[[2]]$S
  p$pre$mvLD$covstructs[[2]]$S.SE
  
  p$pre$mvLD$covstructs.leaveoneout.S<-matrix(NA,nrow = nrow(p$pre$mvLD$covstructs[[1]]$S), ncol = ncol(p$pre$mvLD$covstructs[[1]]$S))
  
  length(p$pre$mvLD$covstructs.leaveoneout.S)
  for(i in 1:length(p$pre$mvLD$covstructs.leaveoneout.S)){
    #i<-1
    p$pre$mvLD$covstructs.leaveoneout.S[[i]]<-mean(unlist(lapply(p$pre$mvLD$covstructs.leaveoneout,function(x){x$S[i]})))
  }
  p$pre$mvLD$covstructs.leaveoneout.S<-matrix(as.numeric(p$pre$mvLD$covstructs.leaveoneout.S),nrow = nrow(p$pre$mvLD$covstructs[[1]]$S), ncol = ncol(p$pre$mvLD$covstructs[[1]]$S))
  p$pre$mvLD$covstructs.leaveoneout.S
  p$pre$mvLD$covstructs[[1]]$S
  
  as.matrix( p$pre$mvLD$covstructs.leaveoneout.S) - as.matrix(p$pre$mvLD$covstructs[[1]]$S)
  mean(as.matrix( p$pre$mvLD$covstructs.leaveoneout.S) - as.matrix(p$pre$mvLD$covstructs[[1]]$S))
  
  #EFA
  p$pre$fa.result.OBL <- psych::fa(r = abs(p$pre$mvLD$covstructs[[1]]$S),nfactors = 2, rotate = 'oblimin', symmetric = T, warnings = T, fm='ols', max.iter = 1000)
  print(p$pre$fa.result.OBL)
  p$pre$PCA<-eigen(x = abs(p$pre$mvLD$covstructs[[1]]$S), symmetric = TRUE)
  print(p$pre$PCA)
  p$pre$PCA$vector_values<-t(p$pre$PCA$vectors*p$pre$PCA$values)[,1:2]
  
  #CFA
  p$pre$resultColumnNames<-c("chisq","df","p_chisq","AIC","CFI","SRMR")
  p$pre$indicatorLoadingPatterns<-semplate$generateIndicatorLoadingPatternsFromFactorLoadings(factorLoadings = p$pre$fa.result.OBL$loadings, increment = 0.0005,forceOneIndicatorLoading = T)
  #p$pre$indicatorLoadingPatterns<-semplate$generateIndicatorLoadingPatternsFromFactorLoadings(factorLoadings = p$pre$PCA$vector_values, increment = 0.0005,forceOneIndicatorLoading = T)
  p$pre$models<-data.frame(nModel=c(),code=c(),nFactors=c(),correlation=c(),estimator=c(), lModel=c(),lResults=c(),gsemResults=c())
  
  
  if(file.exists(p$pre$filepath.models)) {
    print("Using existing models.")
    p$pre$models<-readRDS(file=p$pre$filepath.models)
  } else {
    for(iPat in 1:nrow(p$pre$indicatorLoadingPatterns)){
      #iPat<-1
      p$pre$models[iPat,]<-NA
      p$pre$models[iPat,c("nModel")]<-iPat
      
      #record code
      p$pre$models[iPat,c("code")]<-paste0("MPRE_2",
      "_",iPat,
      ".COR",
      ".ML"
      )
      
      p$pre$models[iPat,c("nFactors")]<-2
      p$pre$models[iPat,c("correlation")]<-"COR"
      p$pre$models[iPat,c("estimator")]<-"ML"
            
      lp<-p$pre$indicatorLoadingPatterns[iPat,]
      p$pre$models[iPat,c("loading_pattern")]<-NA
      p$pre$models[[iPat,c("loading_pattern")]]<-list(lp)
      cIndicatorLoadings<-matrix(data = lp, nrow = nrow(p$pre$mvLD$covstructs[[1]]$S), ncol = 2) 
      row.names(cIndicatorLoadings)<-row.names(p$pre$mvLD$covstructs[[1]]$S)
      p$pre$models[iPat,c("lModel")]<-semplate$generateLavaanCFAModel(allow_loading.table.indicator_factor = cIndicatorLoadings)
      
      cModelResults = tryCatch(
        usermodel.mod(covstruc = p$pre$mvLD$covstructs[[1]],
          model = p$pre$models[iPat,c("lModel")],
          estimation = "ML",
          fix_resid = F,
          CFIcalc = F #ifelse(is.null(p$CFA$models.selected),F,T) #set this to true for CFI evaluation
          ), error= function(e) e
        )
      
      if(!inherits(cModelResults, "try-error") & !is.null(cModelResults$modelfit)){
                if(nrow(cModelResults$modelfit)>0 && any(p$pre$resultColumnNames %in% colnames(cModelResults$modelfit))) {
                  print(cModelResults$modelfit)
                  #record results even though not fitting
                  p$pre$models[iPat,c("gsemResults")]<-NA
                  p$pre$models[[iPat,c("gsemResults")]]<-list(cModelResults)
                  cRescolnames<-intersect(p$pre$resultColumnNames,colnames(cModelResults$modelfit))
                  p$pre$models[iPat,cRescolnames]<-cModelResults$modelfit[1,cRescolnames]
                  if(is.numeric(cModelResults$modelfit$chisq)){
                    #This is considered a fitting model
                    cat("\nFITTING!:",p$pre$models[iPat,c("code")],"\n")
                  }
                } else {
                  cat("\nThe model did not yield correct results.")
                }
              } else {
                cat("\nThe model did not converge.")
              }
      
    } #for
    
    rownames(p$pre$models)<-p$pre$models$code
    saveRDS(object = p$pre$models,file = p$pre$filepath.models)
    print("PRE CFA is done now and the resultins should have been saved to a file.")
  }
  
  #setup results to be run in the later part of the script as if they were coming out of the standard script analysis
  p$sumstats.sel<-p$sumstats.sel.pre
  p$mvLD<-c()
  p$mvLD$covstruct.mvLDSC<-p$pre$mvLD$covstructs[[1]]
  
  #Additional computations
  #saving the original S in case of smoothing experiments later stored in S
  p$mvLD$covstruct.mvLDSC$S.orig<-p$mvLD$covstruct.mvLDSC$S
  p$mvLD$covstruct.mvLDSC$S.smooth<-as.matrix((nearPD(p$mvLD$covstruct.mvLDSC$S, corr = FALSE))$mat)
  
  
  p$CFA$models.selected<-p$pre$models[c("MPRE_2_1.COR.ML"),]
  
}

if(p$clOptions$task=="pre"){
  p$clOptions$task<-"lfgwas"
  }


```

# Process CFA result models and prepare them for latent factor GWAS

```{r Process CFA results}

p$CFA$models.selected$parsedGsemResults<-NA
p$CFA$models.selected$lModel.fixed<-NA
for(iSelected in 1:nrow(p$CFA$models.selected)){
  #test
  #iSelected<-1
  p$CFA$models.selected[[iSelected,c("parsedGsemResults")]]<-list(semplate$parseGenomicSEMResultAsMatrices(p$CFA$models.selected[iSelected,]$gsemResults[[1]][[1]]$results))
  
  # model explained variance is calculated by the parse function from the standardised residuals
  # vars<-vector()
  # for(iManifest in 1:nrow(p$mvLD$covstruct.mvLDSC$S)){
  #   vars[iManifest]<-p$mvLD$covstruct.mvLDSC$S[iManifest,iManifest]
  # }
  # 1-(p$CFA$models.selected[[iSelected,c("parsedGsemResults")]][[1]]$residualVaraiances.matrix/vars)
  
  
  #using the standardised pattern coefficients to fix the model
  #summary(p$CFA$model.bestFitting$gsemResults[[1]]$lresults, standardized=T)
  p$CFA$models.selected[[iSelected,c("parsedGsemResults")]][[1]]$patternCoefficientsSTDGenotype.matrix
  
  #prepare fixed lavaan model
      
  cIndicatorLoadings.loadingPattern<-matrix(
    data = p$CFA$models.selected[iSelected,]$loading_pattern[[1]][[1]],
    ncol = ncol(p$CFA$models.selected[iSelected,]$parsedGsemResults[[1]][[1]]$patternCoefficientsSTDGenotype.matrix),
    nrow = nrow(p$CFA$models.selected[iSelected,]$parsedGsemResults[[1]][[1]]$patternCoefficientsSTDGenotype.matrix)) 
  row.names(cIndicatorLoadings.loadingPattern)<-p$sumstats.sel$code
  cIndicatorLoadings.result<-!is.na(p$CFA$models.selected[iSelected,]$parsedGsemResults[[1]][[1]]$patternCoefficientsSTDGenotype.matrix)
  
  if(!all(cIndicatorLoadings.loadingPattern==cIndicatorLoadings.result)) stop("Difference in provided and result loading patterns detected!")
  
  cIndicatorLoadings<-cIndicatorLoadings.loadingPattern
  
  #test of free SEM parameters rather than fixed (pretend it is the fixed model)
  # p$CFA$models.selected[[iSelected,c("lModel.fixed")]]<-semplate$generateLavaanCFAModel(
  #   allow_loading.table.indicator_factor = cIndicatorLoadings,
  #   universalResidualLimitMin = NA,
  #   orthogonal = (p$CFA$models.selected[iSelected,]$correlation[[1]][[1]]=="ORT"))

  #original fixed setup
  p$CFA$models.selected[[iSelected,c("lModel.fixed")]]<-semplate$generateLavaanCFAModel(
    allow_loading.table.indicator_factor = cIndicatorLoadings,
    fix_loading.table.indicator_factor = p$CFA$models.selected[iSelected,]$parsedGsemResults[[1]][[1]]$patternCoefficientsSTDGenotype.matrix, fixResidualVariance_v = p$CFA$models.selected[iSelected,]$parsedGsemResults[[1]][[1]]$residualVaraiancesSTDGenotype.matrix,
    fix_correlation.table.factor_factor = p$CFA$models.selected[iSelected,]$parsedGsemResults[[1]][[1]]$covariancesSTDGenotype.matrix,
    orthogonal = (p$CFA$models.selected[iSelected,]$correlation[[1]][[1]]=="ORT"))

}

```

# Visualise CFA results

This will not work if the model does not converge.

```{r CFA visualise, fig.width=9, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}
#devtools::install_github("cjvanlissa/tidySEM")
library(tidySEM)
library(DiagrammeR)

for(iSelected in 1:nrow(p$CFA$models.selected)){

  #test
  #iSelected<-1
  
  #plot full model
  cModel<-p$CFA$models.selected[iSelected,]
  
  dir.create(path = file.path(p$folderpath.plots,cModel$code))
  
  p$CFA$semGraphLayout <- get_layout(
    "F1","","F2","","F3","","F4","","F5","","F6","","F7","","F8","","F9","","F10","","","","","","",
            "ADHD05","ALCD03","ANOR02","ANXI03","ANXI04","AUTI07","BIPO02", "DEPR05","DEPR08","EDUC03","EXTR01","HEAL01","INCO03","INSO02","INTE03","LONG07", "MIGR01","NEUR02","PTSD04","RISK01","RISK02","RISK03","SCHI04","SUBJ01","TIRE01",
            "","","","","","","","","","","","","","","","","","","","","","","","","",
            rows = 3)
  
  #this does not work anymore after package updates
  # graph_sem(
  #   #model = cModelResults$lresults,
  # model=cModel$gsemResults[[1]][[1]]$lresults,
  # layout = p$CFA$semGraphLayout,
  # spacing_y=8,
  # spacing_x=4,
  # ellipses_width=5,
  # rect_width=3,
  # variance_diameter=0.5,
  # angle=180
  # )
  
  #ggsave(filename=file.path(p$folderpath.plots,cModel$code,paste0("cfa.png")), plot = last_plot(), width = 1200, height = 600, units = "mm")
  
  
  #https://rpubs.com/danmirman/plotting_factor_analysis
  df<-as.data.frame(cModel$parsedGsemResults[[1]][[1]]$patternCoefficientsSTDGenotype.matrix)
  #df<-as.data.frame(sign(cModel$parsedGsemResults[[1]][[1]]$patternCoefficientsSTDGenotype.matrix)*cModel$parsedGsemResults[[1]][[1]]$relativeVarianceExplainedPerFactor) #plotting variance explained rather than factor loadings - only works for orthogonal factors!
  #add proportion of explained variance
  colnames(df)<-paste0(colnames(df),"(mExp=",round(cModel$parsedGsemResults[[1]][[1]]$meanRelativeVarianceExplainedPerFactor,digits = 2),")")
  df[,c(paste0("~disturbance(mExp=",round(cModel$parsedGsemResults[[1]][[1]]$meanTotalRelativeVarianceExplained,digits = 2),")"))]<-cModel$parsedGsemResults[[1]][[1]]$residualVariancesSTDGenotype.matrix #add disturbances
  df<-rownames_to_column(df,var = "var")
  
  #set nice rownames
  df$var <- p$sumstats.sel[df$var, ]$name.nice
  #df<-df[order(df$var, decreasing = T,method = "radix"),]
  df$var <- as.factor(df$var)
  
  df.l <- pivot_longer(data = df,  -var)
  
  ggplot(df.l, aes(x = abs(value), y = var, fill=value)) + 
  facet_wrap(~ name, nrow=1) + #place the factors in separate facets #scales = "free_x"
  geom_bar(stat="identity") + #make the bars
  #coord_flip() + #flip the axes so the test names can be horizontal  
  #define the fill color gradient: blue=positive, red=negative
  scale_fill_gradient2(name = "Loading", 
                       high = theme.color$contrastLight3, mid = "grey90", low = theme.color$contrastDark3, 
                       midpoint=0, guide=F) +
  xlab("Std. factor loading") + #improve y-axis label
  #xlab("Variance explained in indicator * sign(loading)") + #improve y-axis label
  ylab("Indicator") +
  theme_bw(base_size=22) #use a black-and white theme with set font size
  
  ggsave(filename=file.path(p$folderpath.plots,cModel$code, paste0("ipc.png")), plot = last_plot(), width = 800, height = 400, units = "mm")
  
  if(!all(is.na(cModel$parsedGsemResults[[1]][[1]]$covariances.SE.matrix))){
    #p$printCorr(corr = as.numeric(cModel$parsedGsemResults[[1]][[1]]$covariancesSTDGenotype.matrix),SE = as.numeric(cModel$parsedGsemResults[[1]][[1]]$covariances.SE.matrix),filename = file.path(p$folderpath.plots,cModel$code, paste0("factorCorrelations.png")),is.corr = F,addrect = NULL)
    
    
    png(filename = file.path(p$folderpath.plots,cModel$code, paste0("factorCorrelations.png")), width = 1200, height = 1000)
    palette<-colorRampPalette(c(theme.color$contrastDark3,"#FFFFFF",theme.color$contrastLight3))
    corrplot(
      corr = cModel$parsedGsemResults[[1]][[1]]$covariancesSTDGenotype.matrix,
      #uppCI.mat = corr.uppCI,
      #lowCI.mat = corr.lowCI,
      #plotCI = ifelse(is.null(SE),c("n"),"circle"),
      order = "hclust",
      hclust.method = "ward.D",
      method = "square",
      type="full",
      addCoef.col = theme.color$contrastDark1,
      addgrid.col = theme.color$contrastDark1,
      is.corr = T,
      outline = T,
      col = palette(200),
      rect.col = theme.color$contrastLight1,
      rect.lwd = 6,
      tl.cex = 1.7,
      tl.col = theme.color$contrastDark2,
      tl.srt = 75,
      cl.cex = 2,
      cl.ratio = 0.2,
      cl.pos = "n",
      number.cex = 1,
      number.digits = 2
      )
    dev.off()
    
  }
  
  #cModelResults$modelfit
  #nFactor<-1
  for(nFactor in 1:ncol(cModel$parsedGsemResults[[1]][[1]]$patternCoefficientsSTDGenotype.matrix)){
    p$CFA$semGraphLayout <- get_layout("","","","","","","","","","","",paste0("F",nFactor),"","","","","","","","","","","","","",
            "ADHD05","ALCD03","ANOR02","ANXI03","ANXI04","AUTI07","BIPO02", "DEPR05","DEPR08","EDUC03","EXTR01","HEAL01","INCO03","INSO02","INTE03","LONG07", "MIGR01","NEUR01","PTSD04","RISK01","RISK02","RISK03","SCHI04","SUBJ01","TIRE01",
            "","","","","","","","","","","","","","","","","","","","","","","","","",
            rows = 3)
  
    
    # graph_sem(
    #   #model = cModelResults$lresults,
    # model=p$CFA$model.bestFitting$gsemResults[[1]]$lresults,
    # layout = p$CFA$semGraphLayout,
    # spacing_y=8,
    # spacing_x=4,
    # ellipses_width=7,
    # rect_width=3,
    # variance_diameter=0.5,
    # angle=180
    # )
    #ggsave(filename=file.path(p$folderpath.plots,paste0("cfa.plot.bestfitting.F",nFactor,".png")), plot = last_plot(), width = 500, height = 300, units = "mm")
    #dev.off()
    
    # dftoplot<-data.frame(
    #   indicator=p$sumstats.sel$name.nice,
    #   #indicator=rownames(p$CFA$model.bestFitting$parsedGenomicSEMResult[[1]]$patternCoefficients),
    #   pattern=cModel$parsedGsemResults[[1]][[1]]$patternCoefficients[,nFactor]
    #   )
    # dftoplot$bar_aes <- ifelse(dftoplot$pattern < 0, "-1", "1")
    # ggplot(
    #   data = dftoplot,
    #   aes(x=indicator, y=pattern)) + 
    #   geom_bar(stat = "identity", aes(fill=bar_aes), width = 0.5) +
    #   scale_fill_manual(name="Indicator pattern loading", 
    #                   labels = c("Negative", "Positive"), 
    #                   values = c("-1"=theme.color$contrastDark3, "1"=theme.color$contrastLight3)) +
    #   geom_text(aes(label=paste(indicator,round(pattern,digits = 3),sep = "\n")), size=4.5) +
    #   #geom_text(aes(label=paste(indicator,round(pattern,digits = 3),sep = "\n")), vjust=-0.3, size=5) +
    #   labs(title=paste0("Factor",nFactor),
    #        y="Std. indicator loading",
    #        x="Indicator"
    #      ) +
    #   theme_minimal()
    
    #ggsave(filename=file.path(p$folderpath.plots,cModel$code, paste0("cfa.F",nFactor,".png")), plot = last_plot(), width = 500, height = 300, units = "mm")
      #coord_flip()
    
    #semplate plotting does not work now for some reason
    #dot<-semplate$parseGenomicSEMResultAsDOTDataframes(resultDf = cModel$gsemResults[[1]][[1]]$results)
    #semplate$parseAndPrintGenomicSEMResult(resultDf = cModel$gsemResults[[1]][[1]]$results)
  }
  
  
  # p$CFA$semGraphLayout <- get_layout("F1","","F2","","F3","","F4","","F5","","F6","","F7","","F8","","F9",
  #           "ADHD05","ALCD03","ANXI03","AUTI07","BIPO02", "DEPR05","DEPR08","HEAL01","INCO03","INSO02", "MIGR01","NEUR01","RISK02","RISK03","SCHI04","SUBJ01","TIRE01",
  #           "","","","","","","","","","","","","","","","","",
  #           rows = 3)
  
  
  
  
  # graph_sem(model=cModelResults$lresults)
  # parsedSEMResult<-semplate$parseGenomicSEMResult(cModel$gsemResults[[1]][[1]]$results)
  # dot<-semplate$generateDOT(nodeDf=parsedSEMResult$variable, edgeDf=parsedSEMResult$loading)
  # grViz(dot)
  #grViz(semplate$parseAndPrintGenomicSEMResult(resultDf = cModelResults$results))

}

```


# Latent factor GWAS

## Naive variant effect meta-analysis
```{r naive variant effect meta-analysis }
#test
#p$clOptions$task<-"nmeta"
#p$clOptions$task_argument<-"M20_6_172.COR.ML:1"

cat("\n***Naive variant effect meta-analysis***\n")

if(p$clOptions$task=="nmeta"){
  
  p$nmeta<-c()
  
  p$lfGWAS$sumstats<-readRDS(file=p$filepath.lfgwas.sumstats)
  setDT(p$lfGWAS$sumstats)
  print("Read summary statistics for latent factor GWAS from file.")
  head(p$lfGWAS$sumstats)
  
  colBeta<-colnames(p$lfGWAS$sumstats)[grep("^BETA\\.", ignore.case = TRUE,colnames(p$lfGWAS$sumstats))]
  colSE<-colnames(p$lfGWAS$sumstats)[grep("^SE\\.", ignore.case = TRUE,colnames(p$lfGWAS$sumstats))]
  
  #sumstats QC
  ## effects
  rsum<-rowSums(abs(p$lfGWAS$sumstats[,..colBeta]),na.rm = T)
  rem<-rsum<(length(colBeta)*1e-19)
  p$lfGWAS$sumstats<-p$lfGWAS$sumstats[!rem,]
  rm("rsum")
  cat("\nRemoved ",sum(rem), " variants as part of QC before nmeta.\n")
  
  SESNP<-p$lfGWAS$sumstats[,..colSE]
  for(i in colSE)
    SESNP[is.na(get(i)), (i):=1] #assign the value 1 to NA SNP SE
  POPVARSNP<-2*p$lfGWAS$sumstats$MAF*(1-p$lfGWAS$sumstats$MAF) #2pq according to the genomic SEM publication
  
  #S<-as.matrix(p$mvLD$covstruct.mvLDSC$S)
  #V<-as.matrix(p$mvLD$covstruct.mvLDSC$V)
  I<-as.matrix(p$mvLD$covstruct.mvLDSC$I)
  #diag(I)<-ifelse(diag(I)<= 1, 1, diag(I)) #as in genomic SEM implementation. removed this because we sum all intercepts rather than only using the diagonal.
  I_diag<-diag(I)
  mI<-diag(nrow(I))
  for (x in 1:ncol(SESNP)) {
    for (y in 1:ncol(SESNP)) {
            mI[[x,y]]<-I[[x,y]]*I[[x,x]]*I[[y,y]]
        }
  }
  
  mI.sum<-colSums(mI,na.rm = T)
  
  BETASNP<-p$lfGWAS$sumstats[,..colBeta]
  #BETAVECTORS<-data.table()
  #adjust with the full ldsc intercept
  for (iCol in 1:ncol(BETASNP)){
    #iCol<-3
    col<-colnames(BETASNP)[iCol]
    set(x = BETASNP, j = col, value = BETASNP[[col]]/ifelse(mI.sum[iCol]<1,1,mI.sum[iCol]))
    #exprimental
    # if(iCol==1)
    #   set(x = BETAVECTORS, j = beta, value = BETASNP[[col]])
    # else
    #   set(x = BETAVECTORS, j = beta, value = c(BETAVECTORS[[,"beta"]],BETASNP[[col]]))
    #BETASNP[, (col):=(..col)]
    #BETASNP[, (col):=(col)(I_diag[[iCol]])]
  }
  
  #k<-apply(X = BETASNP,MARGIN = 1,FUN = function(x){sum(!is.na(x))})
  
  if(length(grep(pattern = "\\:",x = p$clOptions$task_argument))>0){
    p$nmeta$cModel<-strsplit(x = p$clOptions$task_argument, split = ':')[[1]][1]
    p$nmeta$cFactor<-strsplit(x = p$clOptions$task_argument, split = ':')[[1]][2]
    } else {
      p$nmeta$cModel<-p$clOptions$task_argument
      p$nmeta$cFactor<-NULL
    }
  
  for(iModel in 1:nrow(p$CFA$models.selected)){
    #test
    #iModel<-1
    
    cModel<-p$CFA$models.selected[iModel,]
    if(!is.null(p$nmeta$cModel) & !is.na(p$nmeta$cModel) & p$nmeta$cModel!=cModel$code) next
    cat("\nModel:  ",cModel$code)
    
    for(iFactor in 1:cModel$nFactors){
      #test
      #iFactor<-1
      if(is.null(p$nmeta$cFactor)){} else if(p$nmeta$cFactor!=iFactor) next
      factorFilepath<-file.path(p$folderpath.workingDirectory,paste0("nmeta.",cModel$code,".F",iFactor,".",p$setup.code,".Rds"))
      if(file.exists(factorFilepath)){
        modelGWAS<-readRDS(factorFilepath)
        iSNPStart<-nrow(modelGWAS[!is.na(BETA)])+1 #THIS DOES NOT DETECT THE RIGHT START POSITION!
        cat("\nContinuing nmeta from variant with index ",iSNPStart,"\n")
      } else {
        modelGWAS<-p$lfGWAS$sumstats[,c("SNP","CHR","BP","MAF","A1","A2")]
        iSNPStart<-1
      }
      cat("\nFactor:  ",iFactor,"\n")
      W<-cModel$parsedGsemResults[[1]][[1]]$relativeVarianceExplainedPerFactor[,iFactor]*sign(cModel$parsedGsemResults[[1]][[1]]$patternCoefficients.matrix[,iFactor]) #only weighted by the factor loadings here, rather than on the dataset variances
      W2<-W^2
      sqrt.W<-sqrt(abs(W))
      signed.sqrt.W<-sign(W)*sqrt.W
      k_W<-sum(!is.na(W))
      k_tot<-ncol(SESNP)
      #W0<-W
      #W0[is.na(W0)]<-0
      nSNP<-nrow(BETASNP)
      
      #mCovarTemplate<-setDT(as.data.frame(diag(k_tot)))
      #C_old<-sum(W,na.rm = T)-sum(W2,na.rm = T)/sum(W,na.rm = T)
      
      
      for(iSNP in iSNPStart:nSNP){
        #test
        #iSNP<-1L
        #iSNP<-8952400L
        #if(!iSNP %% 10 == 0) next  #for testing
        if(iSNP %% 100000 == 0){
          cat("#SNP ",iSNP, p$lfGWAS$sumstats[[iSNP,c("SNP")]],"\n")

          saveRDS(object = modelGWAS,file = factorFilepath)
          #cat("\nSaved intermediate results!\n")
          }
        
        mCovar<-diag(k_tot)
        #mI<-diag(nrow(I))
        #set snp variances adjusted for ldsc intercepts and sample overlap (through the ldsc intercepts - see genomic sem publication)
        for (x in 1:k_tot) {
          for (y in 1:k_tot) {
            #mCovar[x,y]<-(SESNP[[iSNP,y]]*SESNP[[iSNP,x]]*mI[[x,y]]*POPVARSNP[[iSNP]]^2)
            #mCovar[[x,y]]<-(SESNP[[iSNP,y]]*SESNP[[iSNP,x]]*mI[[x,y]]*POPVARSNP[[iSNP]]^2)
            mCovar[[x,y]]<-(signed.sqrt.W[x]*signed.sqrt.W[y]*SESNP[[iSNP,y]]*SESNP[[iSNP,x]]*mI[[x,y]]*POPVARSNP[[iSNP]]^2)
          }
        }
        
        abs.mCovar.sum<-abs(colSums(mCovar,na.rm = T)) #The individual variance components of each separate dataset

        #BETASNP.wmean<-weighted.mean(x = BETASNP[iSNP,], w = W0, na.rm = T)
        #BETASNP.wmean<-weighted.mean(x = BETASNP[iSNP,], w = W0/sqrt(abs.mCovar.sum), na.rm = T) #slightly corrected by the covariances
        # C<-sum(W/abs.mCovar.sum,na.rm = T)-sum(W2/(abs.mCovar.sum^2),na.rm = T)/sum(W/abs.mCovar.sum,na.rm = T)
        # Q_part<-((BETASNP[iSNP,]-BETASNP.wmean)^2)/abs.mCovar.sum
        # Q_part[is.na(Q_part)]<-0
        #Q<-sum(Q_part)
        #Q<-sum(((BETASNP[iSNP,]-BETASNP.wmean)^2)/abs.mCovar.sum, na.rm = T)
        #k<-sum(!is.na(W*BETASNP[iSNP,]))
        # T2<-max( c(
        #   (W0*Q - (k_W-1))/C,
        #   0
        #   ))
        # T2_part<-(W*Q_part - 1 + 1/k_W)/C
        # T2_part[T2_part<0]<-0

        #W_FULL<-W/(abs.mCovar.sum+T2) #as in a standard random effects meta-analysis
        #W_FULL<-W/(abs.mCovar.sum+T2_part)
        #W_FULL<-W/abs.mCovar.sum #fixed-effect meta-analysis
        #W_FULL<-W/(1+abs.mCovar.sum) #fixed-effect meta-analysis
        W_FULL<-W/(abs.mCovar.sum) #fixed-effect meta-analysis
        
        set(x = modelGWAS,i =iSNP, j = "BETA",
            #value = sum(W_FULL*BETASNP[iSNP,],na.rm = T)/sum(abs(W_FULL), na.rm = T)
            value = sum(W_FULL*BETASNP[iSNP,],na.rm = T)/sum(abs(W_FULL[!is.na(BETASNP[iSNP,])]), na.rm = T)
            )
        set(x = modelGWAS,i =iSNP, j = "SE",
            value = sqrt(sum(abs.mCovar.sum))
            #value = sqrt(sum(abs.mCovar.sum)/sqrt(k_tot)) #reduced SE correction, /k_tot sends the effects through the roof!
            )
        # set(x = modelGWAS,i =iSNP, j = "k",
        #     value = k[iSNP]
        #     )
        # set(x = modelGWAS,i =iSNP, j = "Q",
        #     value = sum(Q_part)
        #     )
        
      } #for iSNP
      
      #this is probably wrong
      #modelGWAS[, NEF:=(SE^2)/POPVARSNP] #Calculate Effective Sample Size for Factor 1 - from the Genomic SEM Wiki, citation: https://www.biorxiv.org/content/10.1101/603134v3
      modelGWAS[, P:=2*pnorm(q = abs((BETA/SE)),mean = 0, sd = 1, lower.tail = F)] #two sided!
      
      #just to conform to the use of FRQ rather than MAF when possible
      if(any(colnames(modelGWAS)=="MAF") && !any(colnames(modelGWAS)=="FRQ")) colnames(modelGWAS)[colnames(modelGWAS)=="MAF"]<-"FRQ"
      saveRDS(object = modelGWAS,file = factorFilepath) #compress = "bzip2"
      factorCode<-paste0("nmeta.",cModel$code,".F",iFactor,".",p$setup.code)
      
     
      #fwrite(x = modelGWAS, file = factorFilepath, append = F, quote = F, sep = "\t", nThread=5)
      supermunge.result<-supermunge(list_df = list(modelGWAS),traitNames = factorCode, pathDirOutput = p$folderpath.data.sumstats.munged)
      print("Naive metaanalysis of this model factor is done and the result has been exported to a file.")
    }
  } #for iModel
  
  rm("p$lfGWAS$sumstats") #to avoid oom problems 
  
}

if(p$clOptions$task=="nmeta"){quit(save = "no")}


```


## Launch Genomic SEM latent factor GWAS
If using HDL - do not use GC:
https://rpubs.com/MichelNivard/640145
"... Note that with out of sample LD hdl() may esitmate somewhat lower heritability, and a higher intercept, this means you should NOT use the intercept to shrink effect sizes if you run a GWAS in GenomicSEM."

```{r latent factor GWAS}

print("***Genomic SEM latent factor GWAS***")
#library(lavaan)
#library(gdata)
#library(parallel)
#library(doParallel)

#on implicit multithreading  
#https://hpc.nih.gov/apps/R.html#threading
# p$numCores<-parallel::detectCores()
# cat("\nNumber of cores detected to be ",p$numCores)
# .Internal(setMaxNumMathThreads(p$numCores-1)) 
# .Internal(setNumMathThreads(p$numCores-1))

#test
#p$clOptions$task<-"lfgwas"
#p$clOptions$task_argument<-"M20_6_172.COR.ML:1"
#p$clOptions$task_argument<-"M20_6_198.COR.ML:1"
#p$clOptions$task_argument<-"M20_6_198.COR.ML:22:1"


 #load intermediate results
# do not remove !p$clOptions$task=="lfgwas" as this will cause any lfgwas job to generate the composite results
if(!p$clOptions$task=="lfgwas" & !file.exists(file.path(p$folderpath.workingDirectory,paste0("lfGWAS.gwas.",p$setup.code,".Rds")))){
  print("Reading in latent factor gwas intermediate results.")
  p$lfGWAS$gwas<-list()
  
  for(iModel in 1:nrow(p$CFA$models.selected)){
    #test
    #iModel<-1
    cModel<-p$CFA$models.selected[iModel,]
    
    
    p$lfGWAS$intermediateResultFiles<-list.files(path = p$folderpath.workingDirectory, pattern = paste0("^lfGWAS\\.gwas\\.",p$setup.code,"\\.",cModel$code,"\\.F.+\\..+\\.Rds"), full.names = T, ignore.case=T)
    #p$lfGWAS$intermediateResultFiles<-list.files(path = p$folderpath.workingDirectory, pattern = paste0("^lfGWAS\\.gwas\\.",p$setup.code,"\\.M.+-.+\\..+\\..+\\.F.+\\..+\\.Rds"), full.names = T, ignore.case=T)
    #lfGWAS.gwas.setup4.M25-4.74.ML.F_ALL.chr8.Rds
    nIntermediateFactors<-NULL
    if(length(p$lfGWAS$intermediateResultFiles)>0){
      p$lfGWAS$gwas[[cModel$code]]<-list()
      for(nIntermediateResultFile in 1:length(p$lfGWAS$intermediateResultFiles)){
        #nIntermediateResultFile<-1
        intermediateResult<-readRDS(file=p$lfGWAS$intermediateResultFiles[nIntermediateResultFile])
        #initialise storage
        if(is.null(nIntermediateFactors)){
          #p$lfGWAS$gwas<-list()
          nIntermediateFactors<-length(intermediateResult)
          if(nIntermediateFactors!=p$CFA$nFactors) warning(paste0("\nNumber of read lfGWAS factors (",nIntermediateFactors,") do not match settings!\n"))
          for(nFactor in 1:nIntermediateFactors){
            p$lfGWAS$gwas[[cModel$code]][[nFactor]]<-intermediateResult[[nFactor]]
          }
        } else {
          for(nFactor in 1:nIntermediateFactors){
            p$lfGWAS$gwas[[cModel$code]][[nFactor]]<-rbind(p$lfGWAS$gwas[[cModel$code]][[nFactor]],intermediateResult[[nFactor]]) 
          }
        }
      }
    }
    
  }
  
  if(length(p$lfGWAS$gwas)>0){
    saveRDS(object = p$lfGWAS$gwas,file = file.path(p$folderpath.workingDirectory,paste0("lfGWAS.gwas.",p$setup.code,".Rds")))
    print("Read latent factor gwas results and saved latent factor summary file.")
    if(p$clOptions$task=="lfgwas"){quit(save = "no")}
    
  }
  
}

if(p$clOptions$task=="lfgwas" & !file.exists(file.path(p$folderpath.workingDirectory,paste0("lfGWAS.gwas.",p$setup.code,".Rds")))) 
{
  
  p$lfGWAS$sumstats<-readRDS(file=p$filepath.lfgwas.sumstats)
  setDT(p$lfGWAS$sumstats)
  setkeyv(p$lfGWAS$sumstats, cols = c("SNP","CHR","BP"))
  print("Read summary statistics for latent factor GWAS from file.")
  
  #Filter columns of chosen traits only
  #chromosomes<- sort(as.integer(unique(p$lfGWAS$sumstats$CHR)))
  colBeta<-c()
  colSE<-c()
  colFRQ<-c()
  colINFO.LIMP<-c()
  colK<-c()
  for(iTrait in 1:nrow(p$sumstats.sel)){
    #iTrait<-1
    colBeta<-c(colBeta,colnames(p$lfGWAS$sumstats)[grep(paste0("^BETA\\.",p$sumstats.sel[iTrait,c("code")],"$"), ignore.case = TRUE,colnames(p$lfGWAS$sumstats))])
    colSE<-c(colSE,colnames(p$lfGWAS$sumstats)[grep(paste0("^SE\\.",p$sumstats.sel[iTrait,c("code")],"$"), ignore.case = TRUE,colnames(p$lfGWAS$sumstats))])
    colFRQ<-c(colFRQ,colnames(p$lfGWAS$sumstats)[grep(paste0("^FRQ\\.",p$sumstats.sel[iTrait,c("code")],"$"), ignore.case = TRUE,colnames(p$lfGWAS$sumstats))])
    colINFO.LIMP<-c(colINFO.LIMP,colnames(p$lfGWAS$sumstats)[grep(paste0("^INFO.LIMP\\.",p$sumstats.sel[iTrait,c("code")],"$"), ignore.case = TRUE,colnames(p$lfGWAS$sumstats))])
    colK<-c(colK,colnames(p$lfGWAS$sumstats)[grep(paste0("^K\\.",p$sumstats.sel[iTrait,c("code")],"$"), ignore.case = TRUE,colnames(p$lfGWAS$sumstats))])
    # colBeta<-colnames(p$lfGWAS$sumstats)[grep("^BETA\\.", ignore.case = TRUE,colnames(p$lfGWAS$sumstats))]
    # colSE<-colnames(p$lfGWAS$sumstats)[grep("^SE\\.", ignore.case = TRUE,colnames(p$lfGWAS$sumstats))]
  }
  
  colAll<-c("SNP","CHR","BP","MAF","A1","A2",colBeta,colSE,colFRQ,colINFO.LIMP,colK)
  
  
  #full
  #nrow(p$lfGWAS$sumstats)
  #nrow(na.omit(p$lfGWAS$sumstats))
  
  #selected subset
  p$lfGWAS$sumstats<-p$lfGWAS$sumstats[,..colAll]
  #nrow(p$lfGWAS$sumstats)
  #nrow(na.omit(p$lfGWAS$sumstats))
  
  print("Processing summary statistics for latent factor GWAS - NA values")
  #fill NA values - should be replaced with proper imputation
  
  setDT(p$lfGWAS$sumstats)
  setkeyv(x = p$lfGWAS$sumstats, cols = "SNP")
  colIsRaw<-c()
  for(iTrait in 1:nrow(p$sumstats.sel)){
    cColBeta<-colBeta[iTrait]
    cColK<-colK[iTrait]
    cColIsRaw<-paste0("is.raw.",p$sumstats.sel[iTrait,c("code")])
    p$lfGWAS$sumstats[,(cColIsRaw):=!is.na(get(cColBeta)) & is.na(get(cColK))]
    colIsRaw<-c(colIsRaw,cColIsRaw)
  }
  p$lfGWAS$sumstats[,K:=apply(.SD,MARGIN = 1,FUN = function(x){sum(x)}), .SDcols=colIsRaw]
  p$lfGWAS$sumstats[,K.IMP:=apply(.SD,MARGIN = 1,FUN = function(x){sum(!is.na(x))}), .SDcols=colBeta]
  p$lfGWAS$sumstats[,sumK:=rowSums(.SD,na.rm = T), .SDcols=colK]
  p$lfGWAS$sumstats[,sumINFO.LIMP:=rowSums(.SD,na.rm = T), .SDcols=colINFO.LIMP]
  p$lfGWAS$sumstats[,sumBETA:=rowSums(.SD,na.rm = T), .SDcols=colBeta]
  p$lfGWAS$sumstats[,sumSE:=rowSums(.SD,na.rm = T), .SDcols=colSE]
  p$lfGWAS$sumstats[,meanBETA:=sumBETA/K.IMP][,meanSE:=sumSE/K.IMP]
  
  #process still missing values
  for(iTrait in 1:nrow(p$sumstats.sel)){
    #iTrait<-19
    cColBeta<-colBeta[iTrait]
    cColSE<-colSE[iTrait]
    #nrow(p$lfGWAS$sumstats[is.na(get(cColBeta)),])
    #p$lfGWAS$sumstats[is.na(get(cColBeta)) & K.IMP>0.5*length(colBeta) & K>0.2*length(colBeta),] 
    p$lfGWAS$sumstats[is.na(get(cColBeta)) & K.IMP>0.5*length(colBeta) & K>0.2*length(colBeta), (cColBeta):=meanBETA] 
    p$lfGWAS$sumstats[is.na(get(cColSE)) & K.IMP>0.5*length(colBeta) & K>0.2*length(colBeta), (cColSE):=meanSE] 
    #nrow(p$lfGWAS$sumstats[is.na(get(cColBeta)),])
    #nrow(p$lfGWAS$sumstats[is.na(get(cColSE)),])
    #p$lfGWAS$sumstats[is.na(get(cColBeta)), (cColBeta):=(1e-20)]
    #p$lfGWAS$sumstats[is.na(get(cColSE)), (cColSE):=1]
  }
  
  cat("\nA total of ",nrow(p$lfGWAS$sumstats), " variants before QC.\n")
  
  #nrow(na.omit(p$lfGWAS$sumstats[,..colBeta]))
  #filter columns to those required for lfGWAS
  colLfGWAS<-c("SNP","CHR","BP","MAF","A1","A2",colBeta,colSE)
  #QC - remove variants with NA effects or SE
  p$lfGWAS$sumstats<-na.omit(p$lfGWAS$sumstats[,..colLfGWAS])
  
  cat("\nA total of ",nrow(p$lfGWAS$sumstats), " variants after QC.\n")

  
  #to data frame to conform with userGWAS below
  p$lfGWAS$sumstats<-as.data.frame(p$lfGWAS$sumstats)
  
  p$lfGWAS$cModel<-NULL
  p$lfGWAS$cFn<-NULL
  p$lfGWAS$cChr<-NULL
  #test #p$lfGWAS$cChr<-22
  
  if(length(grep(pattern = "\\:",x = p$clOptions$task_argument))>0){
    p$lfGWAS$cModel<-strsplit(x = p$clOptions$task_argument, split = ':')[[1]][1]
    p$lfGWAS$cChr<-strsplit(x = p$clOptions$task_argument, split = ':')[[1]][2]
    #p$lfGWAS$cFn<-strsplit(x = p$clOptions$task_argument, split = ':')[[1]][3]
  } else if(exists(p$clOptions$task_argument)){
    p$lfGWAS$cModel<-p$clOptions$task_argument
  } else {
    p$lfGWAS$cModel<-p$CFA$models.selected[1,]$code
  }
  
  
  #if(is.null(p$lfGWAS$cFn)) p$lfGWAS$cFn<-"1"
  #if(is.null(p$lfGWAS$cChr)) p$lfGWAS$cChr<-"1"
  
  
  cat("\nPerforming latent factor GWAS")
  cat("\nSelected model:",p$lfGWAS$cModel)
  cat("\nSelected factor ",ifelse(is.null(p$lfGWAS$cFn),"ALL",paste0(p$lfGWAS$cFn))," and chromosome ",ifelse(is.null(p$lfGWAS$cChr),"ALL",paste0(p$lfGWAS$cChr)),". This will take a while!\n")
  
  #select model from code
  cModel<-p$CFA$models.selected[p$lfGWAS$cModel,]
  
  if(is.null(p$lfGWAS$cFn)){
    p$lfGWAS$lmodel<-paste0(cModel$lModel.fixed,paste0("\nF",(1:cModel$nFactors),"~SNP", collapse = ""))
  } else {
    p$lfGWAS$lmodel<-paste0(cModel$lModel.fixed,paste0("\nF",p$lfGWAS$cFn,"~SNP"))
  }
  
  cat("\nExpanded CFA model with SNP effects:")
  print(p$lfGWAS$lmodel)
  
  if(length(p$lfGWAS$cChr)>0){
    cat("\nAnalysing only the specified chromosome: ",paste0(p$lfGWAS$cChr))
    #TEST
    #p$lfGWAS$sumstats.selected<-head(p$lfGWAS$sumstats[which(as.character(p$lfGWAS$sumstats$CHR)==p$lfGWAS$cChr),])
    p$lfGWAS$sumstats<-p$lfGWAS$sumstats[which(as.character(p$lfGWAS$sumstats$CHR)==p$lfGWAS$cChr),]
  }
  
  #TEST settings - restrict to a subset of variants
  #p$lfGWAS$sumstats<-head(p$lfGWAS$sumstats, n = 100)
  
  print("Head of processed sumstats table selection")
  print(head(p$lfGWAS$sumstats))
    
  p$lfGWAS$gwas<-userGWAS.mod(
    covstruc = p$mvLD$covstruct.mvLDSC,
    SNPs = p$lfGWAS$sumstats,
    estimation = "ML",
    model = p$lfGWAS$lmodel,
    modelchi = FALSE,
    printwarn = TRUE,
    sub=paste0("F",(1:cModel$nFactors),"~SNP"),
    parallel=T,
    GC="conserv",
    smooth_check = T,
    TWAS = F,
    #parallel_outfile = file.path(p$folderpath.workingDirectory,"lfgwas.progress.txt"),
    cores = 10 #set cores as standard
    #turbo=T
    )
  
  cat("\nuser GWAS done returning results for ",length(p$lfGWAS$gwas),"factors and ",nrow(p$lfGWAS$gwas[[1]])," SNPs.")
  
  saveRDS(object = p$lfGWAS$gwas,file = file.path(p$folderpath.workingDirectory,paste0("lfGWAS.gwas.",p$setup.code,".",p$lfGWAS$cModel,
                                                                                                   ".F",ifelse(length(p$lfGWAS$cFn)>0,p$lfGWAS$cFn,"ALL"),
                                                                                                   ".",ifelse(length(p$lfGWAS$cChr)>0,paste0("chr",p$lfGWAS$cChr),"ALL"),".Rds")))
  
  print("DONE performing latent factor GWAS. The results should have been saved to a file.")

}


if(p$clOptions$task=="lfgwas"){quit(save = "no")}

```

## Process latent factor GWAS results
Both effects and standard errors are adjusted by the GC-function in the userGWAS funcion, where they are either divided by or multiplied with variants of the ldsc-intecept (square-root of or plain).
```{r process latent factor GWAS results}
cat("\n***Process latent factor GWAS results***\n")
#check the first model and first factor file
if(!file.exists(file.path(p$folderpath.data.sumstats.munged,paste0(p$CFA$models.selected[1,]$code,".F",1,".gz")))){
  
  cat("\nProcessing latent factor GWAS results...\n")
  NTot<-sum(p$sumstats.sel$n_total)
  
  p$lfGWAS$gwas<-readRDS(file=file.path(p$folderpath.workingDirectory,paste0("lfGWAS.gwas.",p$setup.code,".Rds")))
    print("Read previously stored latent factor GWAS results from file.")
  
  for(iModel in 1:nrow(p$CFA$models.selected)){
    #test
    #iModel<-1
    cModel<-p$CFA$models.selected[iModel,] 
    
    inflationFactorTotal<-1/cModel$parsedGsemResults[[1]][[1]]$meanTotalRelativeVarianceExplained
    
    if(length(p$lfGWAS$gwas[[cModel$code]])>0){
      
      patCoef<-cModel$parsedGsemResults[[1]][[1]]$patternCoefficientsSTDGenotype.matrix
      patCoefSq<-patCoef^2
      disVars<-cModel$parsedGsemResults[[1]][[1]]$residualVariances.matrix
      #factorSpecificWeight<-colMeans(patCoefSq[,1:ncol(patCoefSq)]*rep((1-disVars),times=ncol(patCoefSq)),na.rm=T)
      #factorSpecificWeight<-colMeans(patCoefSq[,1:ncol(patCoefSq)],na.rm=T)
      factorSpecificWeight<-colSums(patCoefSq[,1:ncol(patCoefSq)]*rep((1-disVars),times=ncol(patCoefSq)),na.rm=T)
      
      #explainedVariance <- patCoef #TODO
      factorWeightSum<-nrow(patCoefSq)
      #factorWeightSum<-sum(factorSpecificWeight)
      effectiveN<-vector()
      
      #loop for calculating the effective N
      #inflating effect sizes - if needed - and saving factor GWAS output files
      for(iFactor in 1:cModel$nFactors){
        #test
        #iFactor<-1
        factorCode<-paste0(cModel$code,".F",iFactor)
        #factorFilepath<-file.path(p$folderpath.workingDirectory,paste0("lfGWAS.",factorCode,".",p$setup.code,".Rds"))
        
         #adjust variant effect size
        #inflationFactorFactor<-inflationFactorTotal*factorSpecificWeight[iFactor]
        #head(p$lfGWAS$gwas[[cModel$code]][[iFactor]])
        #NTot/effectiveN[iFactor]
        p$lfGWAS$gwas[[cModel$code]][[iFactor]]$Z_adj<-p$lfGWAS$gwas[[cModel$code]][[iFactor]]$Z_Estimate
        
        #adjust variant p estimate
        #p$lfGWAS$gwas[[cModel$code]][[iFactor]]$p_adj<-2*pnorm(q = p$lfGWAS$gwas[[cModel$code]][[iFactor]]$Z_Estimate, sd = (1/sqrt(nrow(p$sumstats.sel))), lower.tail = F)
        p$lfGWAS$gwas[[cModel$code]][[iFactor]]$p_adj<-2*pnorm(q = p$lfGWAS$gwas[[cModel$code]][[iFactor]]$Z_Estimate, lower.tail = F)
        #head(p$lfGWAS$gwas[[cModel$code]][[iFactor]])[,c("SNP","Z_Estimate","Z_smooth","Z_adj", "Pval_Estimate","p_adj")]
      
      
        #set which values to use for output
        #p$lfGWAS$gwas[[cModel$code]][[iFactor]]$p<-p$lfGWAS$gwas[[cModel$code]][[iFactor]]$p_adj
        p$lfGWAS$gwas[[cModel$code]][[iFactor]]$P<-p$lfGWAS$gwas[[cModel$code]][[iFactor]]$Pval_Estimate
        p$lfGWAS$gwas[[cModel$code]][[iFactor]]$BETA<-p$lfGWAS$gwas[[cModel$code]][[iFactor]]$est
        p$lfGWAS$gwas[[cModel$code]][[iFactor]]$Z<-p$lfGWAS$gwas[[cModel$code]][[iFactor]]$Z_Estimate
        p$lfGWAS$gwas[[cModel$code]][[iFactor]]$CHISQ<-p$lfGWAS$gwas[[cModel$code]][[iFactor]]$chisq
        p$lfGWAS$gwas[[cModel$code]][[iFactor]]$DF<-p$lfGWAS$gwas[[cModel$code]][[iFactor]]$chisq_df
        
        
        #save the factor GWAS to file
        #saveRDS(object = (p$lfGWAS$gwas[[cModel$code]][[iFactor]])[,c("SNP","CHR","BP","MAF","A1","A2","BETA","SE","Z","CHISQ","DF","P","NEF")],file = factorFilepath)
        supermunge(
          list_df = list((p$lfGWAS$gwas[[cModel$code]][[iFactor]])[,c("SNP","CHR","BP","MAF","A1","A2","BETA","SE","Z","CHISQ","DF","P")]),traitNames = factorCode, pathDirOutput = p$folderpath.data.sumstats.munged
          )
        }
    }
    
  }
}
```


## Setup additional latent traits for later analysis

```{r setup additional traits}

p$sumstats$code.file<-p$sumstats$code #default as code

#GSEM pre-analysis (simple, no NA effects)
factorCode<-"PRE.F1"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"MPRE_2_1.COR.ML.F1","Risk F1",294363)
factorCode<-"PRE.F2"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"MPRE_2_1.COR.ML.F2","Risk F2",364476)


#GSEM latent factor GWAS
factorCode<-"GSEM.F1"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"M20_6_172.COR.ML.F1","Factor neuroticism",364979)
factorCode<-"GSEM.F2"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"M20_6_172.COR.ML.F2","Factor psychoticism",159862)
factorCode<-"GSEM.F3"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"M20_6_172.COR.ML.F3","Factor depression",448644)
factorCode<-"GSEM.F4"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"M20_6_172.COR.ML.F4","Factor risktaking",46293)
factorCode<-"GSEM.F5"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"M20_6_172.COR.ML.F5","Factor deprivation",271911)
factorCode<-"GSEM.F6"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"M20_6_172.COR.ML.F6","Factor neuropsyche",91409)


#nmeta latent factor GWAS
factorCode<-"nmeta.CF1"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_172.COR.ML.F1.setup7","Anxiety CF",237392)
factorCode<-"nmeta.CF2"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_172.COR.ML.F2.setup7","Thought CF",1406685)
factorCode<-"nmeta.CF3"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_172.COR.ML.F3.setup7","Depression CF",1051408)
factorCode<-"nmeta.CF4"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_172.COR.ML.F4.setup7","Externalising CF",1131595)
factorCode<-"nmeta.CF5"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_172.COR.ML.F5.setup7","SE deprivation CF",865415)
factorCode<-"nmeta.CF6"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_172.COR.ML.F6.setup7","Neuropsychiatric CF",2091884)

factorCode<-"nmeta.OF1"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_30.ORT.ML.F1.setup7","Externalising(inv) OF",2379693)
factorCode<-"nmeta.OF2"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_30.ORT.ML.F2.setup7","Neuropsychiatric OF",1957237)
factorCode<-"nmeta.OF3"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_30.ORT.ML.F3.setup7","Fear OF",282511)
factorCode<-"nmeta.OF4"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_30.ORT.ML.F4.setup7","Depression OF",360436)
factorCode<-"nmeta.OF5"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_30.ORT.ML.F5.setup7","Distress(inv) OF",572446)
factorCode<-"nmeta.OF6"
p$sumstats[factorCode,c("code","code.file","name","n_effective")]<-c(factorCode,"nmeta.M20_6_30.ORT.ML.F6.setup7","Thought OF",1096993)


p$sumstats.sel.code<-c("PRE.F1","PRE.F2","GSEM.F1","GSEM.F2","GSEM.F3","GSEM.F4","GSEM.F5","GSEM.F6","nmeta.CF1","nmeta.CF2","nmeta.CF3","nmeta.CF4","nmeta.CF5","nmeta.CF6","nmeta.OF1","nmeta.OF2","nmeta.OF3","nmeta.OF4","nmeta.OF5","nmeta.OF6")

# set nice name for selected traits
p$sumstats[p$sumstats.sel.code,]$name.nice<-p$sumstats[p$sumstats.sel.code,]$name

##Add sumstat cleaned and munged file paths
p$sumstats[p$sumstats.sel.code,c("cleanedpath")]<-file.path(p$folderpath.data.sumstats.cleaned,paste0(p$sumstats[p$sumstats.sel.code,c("code.file")],p$filename.suffix.data.sumstats.munged))

p$sumstats[p$sumstats.sel.code,c("mungedpath")]<-file.path(p$folderpath.data.sumstats.munged,paste0(p$sumstats[p$sumstats.sel.code,c("code.file")],p$filename.suffix.data.sumstats.munged))

##Add a combined nice name plus code label
p$sumstats$name.nice.and_code<-paste0(p$sumstats$name.nice," (",p$sumstats$code,")")

#set order of datasets to sorted by code
p$sumstats<-p$sumstats[order(p$sumstats$name.nice),]

#re-calculate effective N from file information - perform manually as needed
if(F){
        factorCode<-"nmeta.OF6"
        gwasForEffectiveN<-fread(file = file.path(p$folderpath.data.sumstats.munged,paste0( p$sumstats[factorCode,]$code.file,".gz")), na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, key = c("SNP","CHR","BP"), data.table = T,showProgress = F, nThread=6)
  ##Calculate Effective Sample Size for Factor 1 - from the Genomic SEM Wiki
        #citation: https://www.biorxiv.org/content/10.1101/603134v3
        #restrict to MAF of 40% and 10%
        #change to use adjusted Z if this has been set above
        #added to supermunge also
        gwasForEffectiveN[,MAF:=ifelse(FRQ>0.5,1-FRQ,FRQ)][,VSNP:=2*FRQ*(1-FRQ)]
        gwasForEffectiveN<-gwasForEffectiveN[MAF>=.1 & MAF<=.4,]
        setDT(gwasForEffectiveN)
        #gwasForEffectiveN[,NEF:=round(((Z/EFFECT)^2)/VSNP,digits = 0)]
        effectiveN<-mean(gwasForEffectiveN$NEF,na.rm=T)
        round(effectiveN,digits = 0)
        
}
```


## Variable selection and project configuration, second iteration
```{r GWAS sumstat dataset variable selection 2}

#selection based on specific traits
#p$sumstats.sel.code<-c("ANXI04")
#p$sumstats.sel.code<-c("ADHD05","ANXI04")
#p$sumstats.sel.code<-c("RISK02","RISK03","SCHI04","SUBJ01","TIRE01")
#p$sumstats.sel.code<-c("TIRE01")
#p$sumstats.sel.uv.code<-c("EDUC03","NEUR02","RISK02","RISK03","SCHI04")
p$sumstats.sel.uv.code<-c("ADHD05","ALCD03","ANOR02","ANXI03","ANXI04","AUTI07","BIPO02", "DEPR05","DEPR08","EDUC03","HEAL01","INCO03","INSO02","NEUR02", "PTSD04","RISK02","RISK03","SCHI04","SUBJ01","TIRE01")
#p$sumstats.sel.lfgwas.code<-c("PRE.F1","PRE.F2")
p$sumstats.sel.set1_spec.code<-c("GSEM.F1","GSEM.F2","GSEM.F3","GSEM.F4","GSEM.F5","GSEM.F6")
p$sumstats.sel.set2_spec.code<-c("nmeta.CF1","nmeta.CF2","nmeta.CF3","nmeta.CF4","nmeta.CF5","nmeta.CF6")
p$sumstats.sel.set3_spec.code<-c("nmeta.OF1","nmeta.OF2","nmeta.OF3","nmeta.OF4","nmeta.OF5","nmeta.OF6")
p$sumstats.sel.set1.code<-c(p$sumstats.sel.uv.code,p$sumstats.sel.set1_spec.code)
p$sumstats.sel.set2.code<-c(p$sumstats.sel.uv.code,p$sumstats.sel.set2_spec.code)
p$sumstats.sel.set3.code<-c(p$sumstats.sel.uv.code,p$sumstats.sel.set3_spec.code)
p$sumstats.sel.code<-c(p$sumstats.sel.uv.code,p$sumstats.sel.set1_spec.code,p$sumstats.sel.set2_spec.code,p$sumstats.sel.set3_spec.code)
p$sumstats.sel<-p$sumstats[which(p$sumstats$code %in% p$sumstats.sel.code),]

p$sumstats.sel[,c("code","name","name.nice","name.nice.and_code", "year","n_case","n_control","n_total","n_effective", "pmid","reference_doi","samplePrevalence","populationPrevalence","dependent_variable.OLS","dependent_variable.linprob","se.logit","mungedpath")]
p$k.sel<-nrow(p$sumstats.sel)
#View(p$sumstats.sel[,c("code","n_total","pmid","reference_doi","samplePrevalence","populationPrevalence","mungedpath")])
#set order of datasets to sorted by code
p$sumstats.sel[is.na(p$sumstats.sel$name.nice),c("name.nice")]<-p$sumstats.sel[is.na(p$sumstats.sel$name.nice),c("name")]
p$sumstats.sel[,c("n_consensus")] <- as.numeric(
                                        ifelse(is.na(p$sumstats.sel$n_total),
                                               p$sumstats.sel$n_effective,
                                               p$sumstats.sel$n_total)
                                              )

p$sumstats.sel<-p$sumstats.sel[order(p$sumstats.sel$name.nice),]

write.table(p$sumstats.sel[,c("code", "name.nice","year", "n_case","n_control","n_total","n_effective","samplePrevalence","populationPrevalence", "reference_doi")], file = file.path(p$folderpath.workingDirectory,paste0(p$setup.code,".sumstatinfo.tsv")), quote = TRUE, sep = "\t", row.names = FALSE, col.names = TRUE)

#this should not be needed as the SNP's already have their NEF
#set n-total for new latent traits from efective n
# cond<-is.na(p$sumstats.sel$n_total)&!is.na(p$sumstats.sel$n_effective)
# p$sumstats.sel[cond,c("n_total")]<-p$sumstats.sel[cond,c("n_effective")]

#View(p$sumstats.sel)

```


# Multivariate LD-score regression including latent factors, second iteration

```{r mvLD 2, including latent factors}
print("***Multivariate LD 2***")
p$filepath.mvLD2.set1<-file.path(p$folderpath.workingDirectory,paste0("mvLD2.set1.",p$setup.code,".Rds"))
p$filepath.mvLD2.set2<-file.path(p$folderpath.workingDirectory,paste0("mvLD2.set2.",p$setup.code,".Rds"))
p$filepath.mvLD2.set3<-file.path(p$folderpath.workingDirectory,paste0("mvLD2.set3.",p$setup.code,".Rds"))

#set1 - GSEM
if (file.exists(p$filepath.mvLD2.set1)) {
  print("Using existing covariance structures from previous LD computations.")
  p$mvLD2.set1<-readRDS(file=p$filepath.mvLD2.set1)
} else {
  
  print("Running multivariate LD regression with different methods. This might take a while. If the procedure runs for too long you may want to abort the process.")
  
  cat("The current task is specified as:",p$clOptions$task)
  p$mvLD2.set1<-c()
  
  if(p$clOptions$task=="mvLD2"){
    #run mvLDSC

    p$mvLD2.set1$covstruct.mvLDSC.1kg<-ldsc.mod(
      traits = p$sumstats.sel[p$sumstats.sel.set1.code,]$mungedpath,
      sample.prev =  p$sumstats.sel[p$sumstats.sel.set1.code,]$samplePrevalence,
      population.prev = p$sumstats.sel[p$sumstats.sel.set1.code,]$populationPrevalence,
      trait.names = p$sumstats.sel[p$sumstats.sel.set1.code,]$code,
      ld = p$folderpath.data.mvLDSC.ld.1kg,
      wld = p$folderpath.data.mvLDSC.ld.1kg,
      n.blocks = 600, #a bit more here if it can support the larger reference panel used
      info.filter = 0.6,
      maf.filter = 0.01,
      mhc.filter = 37,
      #chisq.min = 1e-3,
      N = p$sumstats.sel[p$sumstats.sel.set1.code,]$n_total,
      #forceN = T, # Consider this when some of the original N's may be untrustworthy (ANXI04!) - TODO - fix in supermunge
      ldsc.log = p$setup.code.date
      )

    
    saveRDS(object = p$mvLD2.set1,file = p$filepath.mvLD2.set1)
    print("Multivariate LD correction is done now and the resulting covariance structure should have been saved to a file.")
  
  } 
}

#set2 - nmeta, best correlated factor model
if (file.exists(p$filepath.mvLD2.set2)) {
  print("Using existing covariance structures from previous LD computations.")
  p$mvLD2.set2<-readRDS(file=p$filepath.mvLD2.set2)
} else if (F){
  
  print("Running multivariate LD regression with different methods. This might take a while. If the procedure runs for too long you may want to abort the process.")
  
  cat("The current task is specified as:",p$clOptions$task)
  p$mvLD2.set2<-c()
  
  if(p$clOptions$task=="mvLD2"){
    #run mvLDSC

    p$mvLD2.set2$covstruct.mvLDSC.1kg<-ldsc.mod(
      traits = p$sumstats.sel[p$sumstats.sel.set2.code,]$mungedpath,
      sample.prev =  p$sumstats.sel[p$sumstats.sel.set2.code,]$samplePrevalence,
      population.prev = p$sumstats.sel[p$sumstats.sel.set2.code,]$populationPrevalence,
      trait.names = p$sumstats.sel[p$sumstats.sel.set2.code,]$code,
      ld = p$folderpath.data.mvLDSC.ld.1kg,
      wld = p$folderpath.data.mvLDSC.ld.1kg,
      n.blocks = 600, #a bit more here if it can support the larger reference panel used
      info.filter = 0.6,
      maf.filter = 0.01,
      mhc.filter = 37,
      #chisq.min = 1e-3,
      N = p$sumstats.sel[p$sumstats.sel.set2.code,]$n_total,
      #forceN = T, # Consider this when some of the original N's may be untrustworthy (ANXI04!) - TODO - fix in supermunge
      ldsc.log = p$setup.code.date
      )

    
    saveRDS(object = p$mvLD2.set2,file = p$filepath.mvLD2.set2)
    print("Multivariate LD correction is done now and the resulting covariance structure should have been saved to a file.")
  
  } 
}

#set3 - nmeta, best orthogonal factor model
if (file.exists(p$filepath.mvLD2.set3)) {
  print("Using existing covariance structures from previous LD computations.")
  p$mvLD2.set3<-readRDS(file=p$filepath.mvLD2.set3)
} else if(F){
  
  print("Running multivariate LD regression with different methods. This might take a while. If the procedure runs for too long you may want to abort the process.")
  
  cat("The current task is specified as:",p$clOptions$task)
  p$mvLD2.set3<-c()
  
  if(p$clOptions$task=="mvLD2"){
    #run mvLDSC

    p$mvLD2.set3$covstruct.mvLDSC.1kg<-ldsc.mod(
      traits = p$sumstats.sel[p$sumstats.sel.set3.code,]$mungedpath,
      sample.prev =  p$sumstats.sel[p$sumstats.sel.set3.code,]$samplePrevalence,
      population.prev = p$sumstats.sel[p$sumstats.sel.set3.code,]$populationPrevalence,
      trait.names = p$sumstats.sel[p$sumstats.sel.set3.code,]$code,
      ld = p$folderpath.data.mvLDSC.ld.1kg,
      wld = p$folderpath.data.mvLDSC.ld.1kg,
      n.blocks = 600, #a bit more here if it can support the larger reference panel used
      info.filter = 0.6,
      maf.filter = 0.01,
      mhc.filter = 37,
      #chisq.min = 1e-3,
      N = p$sumstats.sel[p$sumstats.sel.set3.code,]$n_total,
      #forceN = T, # Consider this when some of the original N's may be untrustworthy (ANXI04!) - TODO - fix in supermunge
      ldsc.log = p$setup.code.date
      )

    
    saveRDS(object = p$mvLD2.set3,file = p$filepath.mvLD2.set3)
    print("Multivariate LD correction is done now and the resulting covariance structure should have been saved to a file.")
  
  } 
}


if(p$clOptions$task=="mvLD2"){
      quit(save = "no")
}


#add newly computed heritabilities and LDSC intercepts to the selected summary statistics table
p$sumstats.sel[p$sumstats.sel.set1.code,c("h2.liability_mvLDSC")]<-diag(p$mvLD2.set1$covstruct.mvLDSC.1kg$S[p$sumstats.sel.set1.code,p$sumstats.sel.set1.code])
p$sumstats.sel[p$sumstats.sel.set1.code,c("h2.se.liability_mvLDSC")]<-diag(p$mvLD2.set1$covstruct.mvLDSC.1kg$S.SE[p$sumstats.sel.set1.code,p$sumstats.sel.set1.code])

if(F){
  p$sumstats.sel[p$sumstats.sel.set2_spec.code,c("h2.se.liability_mvLDSC")]<-diag(p$mvLD2.set2$covstruct.mvLDSC.1kg$S[p$sumstats.sel.set2_spec.code,p$sumstats.sel.set2_spec.code])
  p$sumstats.sel[p$sumstats.sel.set2_spec.code,c("h2.se.liability_mvLDSC")]<-diag(p$mvLD2.set2$covstruct.mvLDSC.1kg$S.SE[p$sumstats.sel.set2_spec.code,p$sumstats.sel.set2_spec.code])
  
  p$sumstats.sel[p$sumstats.sel.set3_spec.code,c("h2.se.liability_mvLDSC")]<-diag(p$mvLD2.set3$covstruct.mvLDSC.1kg$S[p$sumstats.sel.set3_spec.code,p$sumstats.sel.set3_spec.code])
  p$sumstats.sel[p$sumstats.sel.set3_spec.code,c("h2.se.liability_mvLDSC")]<-diag(p$mvLD2.set3$covstruct.mvLDSC.1kg$S.SE[p$sumstats.sel.set3_spec.code,p$sumstats.sel.set3_spec.code])
}

colnames(p$mvLD2.set1$covstruct.mvLDSC.1kg$I)<-colnames(p$mvLD2.set1$covstruct.mvLDSC.1kg$S)
rownames(p$mvLD2.set1$covstruct.mvLDSC.1kg$I)<-rownames(p$mvLD2.set1$covstruct.mvLDSC.1kg$S)
p$sumstats.sel[p$sumstats.sel.set1.code,c("lambda_ldsc")]<-diag(p$mvLD2.set1$covstruct.mvLDSC.1kg$I[p$sumstats.sel.set1.code,p$sumstats.sel.set1.code])


#compute scaling factor relative to sample size and overall trait heritability
p$sumstats.sel[,c("power_scale_factor")]<-p$sumstats.sel$h2.liability_mvLDSC*p$sumstats.sel$n_consensus


```

# Overview of rg between selected traits, including latent factors
```{r overview pairwise rg 2, fig.width=9, fig.height=6, out.width="1600px", out.height="1000px", purl=FALSE}

cMvLDset<-p$mvLD2.set1
cMvLDset.names<-colnames(cMvLDset$covstruct.mvLDSC.1kg$S)
#edit the selection of traits here for the plot
cMvLDset$covstruct.mvLDSC.1kg$S_Stand.forPlot<-cMvLDset$covstruct.mvLDSC.1kg$S_Stand

rownames(cMvLDset$covstruct.mvLDSC.1kg$S_Stand.forPlot)<-p$sumstats.sel[cMvLDset.names,]$name.nice.and_code
colnames(cMvLDset$covstruct.mvLDSC.1kg$S_Stand.forPlot)<-cMvLDset.names

p$printCorrSimplified(
  corr = clipValues(cMvLDset$covstruct.mvLDSC.1kg$S_Stand.forPlot,-1,1),
  #SE = cMvLDset$covstruct.mvLDSC$S_Stand.SE,
  filename = file.path(p$folderpath.plots,"rg.full.simple.png"),
  is.corr = T
  )

p$printCorrSimplified(
  corr = clipValues(abs(cMvLDset$covstruct.mvLDSC.1kg$S_Stand.forPlot),-1,1),
  #SE = cMvLDset$covstruct.mvLDSC$S_Stand.SE,
  filename = file.path(p$folderpath.plots,"absrg.full.simple.png"),
  is.corr = F,
  absScale=T
  )

p$printCorr(
  corr = clipValues(cMvLDset$covstruct.mvLDSC.1kg$S_Stand.forPlot,-1,1),
  SE = cMvLDset$covstruct.mvLDSC.1kg$S_Stand.SE,
  filename = file.path(p$folderpath.plots,"rg.full.png"),
  is.corr = T,
  addrect = NULL
  )

library(heatmaply)
#ggheatmap() #static version
#heatmaply()
heatmaply(
    clipValues(cMvLDset$covstruct.mvLDSC.1kg$S_Stand.forPlot,-1,1),
    cellnote = round(clipValues(cMvLDset$covstruct.mvLDSC.1kg$S_Stand.forPlot,-1,1),digits = 2),
    cellnote_size = 9,
    cellnote_textposition = "middle center",
    show_dendrogram = c(T,F),
    xlab = "Trait GWAS",
    ylab = "Trait GWAS",
    main = "r<sub>g</sub>",
    scale_fill_gradient_fun = ggplot2::scale_fill_gradient2(
        low = theme.color$contrastDark3, 
        mid = "black",
        high = theme.color$contrastLight3,
        breaks = c(-1,0,1)
      ),
    file=file.path(p$folderpath.plots,paste0("rg.full2.png")),
    width = 1200, height = 1200,
    hclust_method = "ward.D2"
    #scale = "row"
  )


print("Heritabilities")
p$plots.heritabilities<-data.frame(
  trait=colnames(cMvLDset$covstruct.mvLDSC.1kg$S),
  heritability=diag(cMvLDset$covstruct.mvLDSC.1kg$S),
  se=diag(cMvLDset$covstruct.mvLDSC.1kg$S.SE),
  heritability_se=paste0(format(diag(cMvLDset$covstruct.mvLDSC.1kg$S),digits=1)," (",format(diag(cMvLDset$covstruct.mvLDSC.1kg$S.SE),digits=1),")")
  )

p$plots.heritabilities


```




# Process, export, visualise corrected GWAS results

```{r process latent factor GWAS, purl=FALSE, eval=FALSE}

#install.packages("qqman")

settingLIMPFilter<-T
if(settingLIMPFilter){
    #p$lfGWAS$sumstats<-copy(readRDS(file=p$filepath.lfgwas.sumstats))
    cSumstatsAll<-readRDS(file=p$filepath.lfgwas.sumstats)
    setDT(cSumstatsAll)
    
    colBeta<-c()
    colSE<-c()
    colFRQ<-c()
    colINFO.LIMP<-c()
    colK<-c()
    for(iTrait in 1:nrow(p$sumstats.sel)){
      #iTrait<-1
      colBeta<-c(colBeta,colnames(cSumstatsAll)[grep(paste0("^BETA\\.",p$sumstats.sel[iTrait,c("code")],"$"), ignore.case = TRUE,colnames(cSumstatsAll))])
    colSE<-c(colSE,colnames(cSumstatsAll)[grep(paste0("^SE\\.",p$sumstats.sel[iTrait,c("code")],"$"), ignore.case = TRUE,colnames(cSumstatsAll))])
    colFRQ<-c(colFRQ,colnames(cSumstatsAll)[grep(paste0("^FRQ\\.",p$sumstats.sel[iTrait,c("code")],"$"), ignore.case = TRUE,colnames(cSumstatsAll))])
      colINFO.LIMP<-c(colINFO.LIMP,colnames(cSumstatsAll)[grep(paste0("^INFO.LIMP\\.",p$sumstats.sel[iTrait,c("code")],"$"), ignore.case = TRUE,colnames(cSumstatsAll))])
      colK<-c(colK,colnames(cSumstatsAll)[grep(paste0("^K\\.",p$sumstats.sel[iTrait,c("code")],"$"), ignore.case = TRUE,colnames(cSumstatsAll))])
    }
    
    colIsRaw<-c()
    for(iTrait in 1:length(colBeta)){
      #iTrait<-1
      cColBeta<-colBeta[iTrait]
      cColK<-colK[iTrait]
      cColIsRaw<-paste0("is.raw.",p$sumstats.sel[iTrait,c("code")])
      cSumstatsAll[,(cColIsRaw):=!is.na(get(cColBeta)) & is.na(get(cColK))]
      colIsRaw<-c(colIsRaw,cColIsRaw)
    }
    cSumstatsAll[,KRAW:=apply(.SD,MARGIN = 1,FUN = function(x){sum(x)}), .SDcols=colIsRaw]
    cSumstatsAll[,KIMP:=apply(.SD,MARGIN = 1,FUN = function(x){sum(!is.na(x))}), .SDcols=colBeta]
    cSumstatsAll[,sumK:=rowSums(.SD,na.rm = T), .SDcols=colK]
    cSumstatsAll[,sumINFO.LIMP:=rowSums(.SD,na.rm = T), .SDcols=colINFO.LIMP]
    cSumstatsAll[,sumBETA:=rowSums(.SD,na.rm = T), .SDcols=colBeta]
    cSumstatsAll[,sumSE:=rowSums(.SD,na.rm = T), .SDcols=colSE]
    cSumstatsAll[,meanBETA:=sumBETA/KIMP][,meanSE:=sumSE/KIMP]
    cSumstatsAll[,KREL:=(1-(KIMP-KRAW)/KIMP)][,sumINFO.LIMP.REL:=ifelse(sumK>0,sumINFO.LIMP/(KIMP-KRAW),NA_real_)][,sumK.REL:=ifelse(sumK>0,sumK/(KIMP-KRAW),NA_real_)]
    
    cSumstatsAll<-cSumstatsAll[,c("SNP","CHR","BP","MAF","KRAW","KIMP","sumK","sumINFO.LIMP","sumBETA","sumSE","meanBETA","meanSE","sumINFO.LIMP.REL","sumK.REL","KREL")]
    
}

#p$sumstats.sel.set1.code
#p$sumstats.sel.set1_spec.code

#Export trait codes for selected sets
write.table(x = p$sumstats.sel[p$sumstats.sel.set1.code,c("code")],file = file.path(p$folderpath.workingDirectory, "sumstats.sel.set1.code.txt"),sep="\t", quote = FALSE, row.names = F, col.names = F, append = F)
write.table(x = p$sumstats.sel[p$sumstats.sel.uv.code,c("code")],file = file.path(p$folderpath.workingDirectory, "sumstats.sel.uv.code.txt"),sep="\t", quote = FALSE, row.names = F, col.names = F, append = F)
write.table(x = p$sumstats.sel[p$sumstats.sel.set1_spec.code,c("code")],file = file.path(p$folderpath.workingDirectory, "sumstats.sel.set1_spec.code.txt"),sep="\t", quote = FALSE, row.names = F, col.names = F, append = F)


chosenSet<-p$sumstats.sel[p$sumstats.sel.set1_spec.code,] #SET SELECTED SUMSTATS HERE


for(iTrait in 1:nrow(chosenSet)){
  #test
  #iTrait<-10
  
  p$lfGWAS$gwas.for.display.info<-chosenSet[iTrait,]
  p$lfGWAS$gwas.for.display.info$code
  
  is.latent<-!is.na(p$lfGWAS$gwas.for.display.info$n_effective)
  # cColname.INFO.LIMP <- colnames(cSumstatsAll)[grep(paste0("^INFO.LIMP\\.",p$lfGWAS$gwas.for.display.info$code,"$"), ignore.case = TRUE,colnames(cSumstatsAll))]
  # cColname.K <- colnames(cSumstatsAll)[grep(paste0("^K\\.",p$lfGWAS$gwas.for.display.info$code,"$"), ignore.case = TRUE,colnames(cSumstatsAll))]
  
                                                                    
  if(!file.exists(p$lfGWAS$gwas.for.display.info$mungedpath) #| #is.na(p$lfGWAS$gwas.for.display.info$n_effective) #only latent factors
     ) next 
  #p$lfGWAS$gwas.for.display <- read.table(p$lfGWAS$gwas.for.display.info$mungedpath,header=T, quote="\"",fill=T,na.string=c(".",NA,"NA",""))
  cSumstats<-fread(file = p$lfGWAS$gwas.for.display.info$mungedpath, na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, key = c("SNP","CHR","BP"), data.table = T,showProgress = F, nThread=5)
  
  #setDT(cSumstats) - not needed because of fread arg
  if(any(colnames(cSumstats)=="MAF") & !any(colnames(cSumstats)=="FRQ")) cSumstats[,FRQ:=MAF]
  if(any(colnames(cSumstats)=="NEF") & !any(colnames(cSumstats)=="N")) cSumstats[,N:=round(NEF,digits = 0)] #special - also fix NEF format to integer
  if(!any(colnames(cSumstats)=="Z")) cSumstats <- cSumstats[,Z:=EFFECT/SE]
  if(!any(colnames(cSumstats)=="SE")) cSumstats[,c("SE")]<-1
  
  #imputation quality filter
  if(settingLIMPFilter){
    setkeyv(cSumstats,cols = "SNP")
    setkeyv(cSumstatsAll,cols = "SNP")
    cSumstats[cSumstatsAll,c("KRAW","KIMP","sumK","sumINFO.LIMP","sumBETA","sumSE","meanBETA","meanSE","sumINFO.LIMP.REL","sumK.REL","KREL") :=list(i.KRAW,i.KIMP,i.sumK,i.sumINFO.LIMP,i.sumBETA,i.sumSE,i.meanBETA,i.meanSE,i.sumINFO.LIMP.REL,i.sumK.REL,i.KREL)]
  }
  
  # update sumstat metadata with genomic inflation factors
  medianChisq<-median(cSumstats$Z^2)
  meanChisq<-mean(x = cSumstats$Z^2)
  p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambdaGC_median")]<-medianChisq/qchisq(0.5,1)
  p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambdaGC_mean")]<-meanChisq/qchisq(0.5,1)
  #lambda 1000 is the inflation factor scaled relative to 1000 cases and 1000 controls
  if(!is.na(p$lfGWAS$gwas.for.display.info$n_case) || !is.na(p$lfGWAS$gwas.for.display.info)){
    p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambda1000")]<-1+(p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambdaGC_median")]-1)*(1/as.numeric( p$lfGWAS$gwas.for.display.info$n_case) + 1/as.numeric(p$lfGWAS$gwas.for.display.info$n_control))/(2/1000)
  } else if (!is.na(p$lfGWAS$gwas.for.display.info$n_total)){
     p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambda1000")]<-1+(p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambdaGC_median")]-1)*(1/as.numeric(p$lfGWAS$gwas.for.display.info$n_total))/(1/1000)
  } else if (!is.na(p$lfGWAS$gwas.for.display.info$n_effective)){
     p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambda1000")]<-1+(p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambdaGC_median")]-1)*(1/as.numeric(p$lfGWAS$gwas.for.display.info$n_effective))/(1/1000)
  }
  cat("\n",p$lfGWAS$gwas.for.display.info$code,", lambda(using median,mean)=", p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambdaGC_median")],p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambdaGC_mean")])
  
  cat("\n",p$lfGWAS$gwas.for.display.info$code,", lambda1000=", p$sumstats.sel[p$lfGWAS$gwas.for.display.info$code,c("lambda1000")])
  
  cat("\n",p$lfGWAS$gwas.for.display.info$code,", LDSC intercept (uv)=", p$lfGWAS$gwas.for.display.info$lambda_ldsc)
  
  #FILTERS
  cSumstats.n<-nrow(cSumstats)
  cat("\nRows before filtering:",nrow(cSumstats),"\n")
  #FRQ
  if(any(colnames(cSumstats)=="FRQ")) cSumstats <- cSumstats[FRQ>=0.001 & 1-FRQ>=0.001,]
  cat("\nRows filtered by FRQ:",cSumstats.n-nrow(cSumstats),"\n")
  cSumstats.n<-nrow(cSumstats)
  
  if(any(colnames(cSumstats)=="INFO")) cSumstats <- cSumstats[INFO>=0.6,]
  cat("\nRows filtered by INFO:",cSumstats.n-nrow(cSumstats),"\n")
  cSumstats.n<-nrow(cSumstats)
  
  if(is.latent){
    #use well informed latent factor variants, includes imputed information 
    cSumstats <- cSumstats[KREL>0.75 | is.na(sumINFO.LIMP.REL) | (KREL>0.5 & sumINFO.LIMP.REL>0.5),]
  } else {
    #do not use imputed SNPs for trait GWAS
    cSumstats <- cSumstats[is.na(INFO.LIMP),]
  }
  cat("\nRows filtered by LD-imputation quality:",cSumstats.n-nrow(cSumstats),"\n")
  cat("\nRows after filtering:",nrow(cSumstats),"\n")
 
  #export ALL
  fwrite(x = na.omit(cSumstats[,c("SNP","CHR","A1","A2","BP","P","N")]), file = file.path(p$folderpath.data.sumstats.export,paste0(p$lfGWAS$gwas.for.display.info$code,".gz")), append = F, quote = F, sep = "\t", nThread=5)

  #export SNPLOC
  fwrite(x = na.omit(cSumstats[,c("SNP","CHR","BP")]), file = file.path(p$folderpath.data.sumstats.export,paste0(p$lfGWAS$gwas.for.display.info$code,".SNPLOC")), append = F, quote = F, sep = "\t", nThread=5)

  #export PVAL_FILE
  fwrite(x = na.omit(cSumstats[,c("SNP","P","N")]), file = file.path(p$folderpath.data.sumstats.export,paste0(p$lfGWAS$gwas.for.display.info$code,".PVAL")), append = F, quote = F, sep = "\t", nThread=5)
  
  #head(p$lfGWAS$gwas.for.display)
  
  
  # restore chr info if missing
  # ref <- read.table(p$filepath.SNPReference.hc1kg,header=T, quote="\"",fill=T,na.string=c(".",NA,"NA",""))
  # 
  # ref <- setDT(ref)
  # # Column harmonisation
  # ref.keys<-c('SNP')
  # ref$SNP <- tolower(as.character(ref$SNP))
  # ref$A1 <- toupper(as.character(ref$A1))
  # ref$A2 <- toupper(as.character(ref$A2))
  # ref$CHR <- toupper(as.character(ref$CHR))
  # ref.keys<-c(ref.keys,'CHR')
  # ref$BP <- as.integer(ref$BP)
  # ref.keys<-c(ref.keys,'BP')
  # 
  # names(ref)<-paste0(names(ref),"_REF")
  # setkeyv(ref, cols = paste0(ref.keys,"_REF"))
  # 
  # p$lfGWAS$gwas.for.display2<-ref[p$lfGWAS$gwas.for.display, on=c(SNP_REF='SNP'), nomatch=0]
  # p$lfGWAS$gwas.for.display2[,SNP:=SNP_REF][,BP:=BP_REF][,CHR:=CHR_REF][,MAF:=MAF_REF][,A1:=A1_REF][,A2:=A2_REF]
  # p$lfGWAS$gwas.for.display<-p$lfGWAS$gwas.for.display2[,c("SNP","BP","CHR","MAF","A1","A2","BETA","SE","P")]
  # 
  # saveRDS(object = p$lfGWAS$gwas.for.display,file =p$lfGWAS$gwas.for.display.filename)
  #View(p$lfGWAS$gwas.for.display)
  
  
  #top SNPs
  #View(p$lfGWAS$gwas.for.display[order(p$lfGWAS$gwas.for.display$P),c("SNP","CHR","MAF","P")])
  
  cTable <- cSumstats[P<5e-8,][order(-Z,decreasing = T),] %>% 
    slice_head(n = 50) %>%
    mutate(i=row_number()) %>%
    select(i,SNP,CHR,FRQ,sumINFO.LIMP.REL,sumK.REL,KREL,Z,P) %>%
  gt() %>% 
  fmt_scientific(columns = vars(P), decimals = 4) %>%
  fmt_number(columns = vars(FRQ,Z,sumINFO.LIMP.REL,sumK.REL,KREL), decimals = 4) %>%
  #fmt_number(columns = vars(K,K.IMP,sumK), decimals = 0) %>%
  tab_header(
    title = paste0("Top-50 highly associated COMMON variants for\n",p$lfGWAS$gwas.for.display.info$name.nice.and_code)
  ) %>%
  tab_style(
    style = cell_text(size = px(12)),
    locations = cells_column_labels(everything())       
  ) %>%
  tab_style(
    style = cell_text(size = px(12),weight = "bold"),
    locations = cells_body(everything())        
  )

  cTable

  #dir.create(path = file.path(p$folderpath.plots,p$lfGWAS$gwas.for.display.info$code))
  gtsave(data = cTable, filename = file.path(p$folderpath.plots,paste0("top.",p$lfGWAS$gwas.for.display.info$code,".rtf")))
  
  #manhattan plots
  #cPlot <- manhattan.custom(df = p$lfGWAS$gwas.for.display)
  #cPlot
  #ggsave(filename=file.path(p$folderpath.plots,cModel$code,paste0("gwas.F",iGwas,".png")), plot = last_plot(), width = 500, height = 300, units = "mm")
  
  #qqman adaptations
  qqmanGwas<-cSumstats
  qqmanGwas$P<- shru::clipValues(qqmanGwas$P,min = 10^(-24), max = NULL)
  qqmanGwas<-qqmanGwas[which(!is.na(qqmanGwas$P)),]
  qqmanGwas<-qqmanGwas[,c("SNP","BP","CHR","P")]
  qqmanGwas$CHR<-as.integer(qqmanGwas$CHR)
  
  #manhattan plot, fastman
  png(filename = file.path(p$folderpath.plots,paste0("man.",p$lfGWAS$gwas.for.display.info$code,".png")), width = 1200, height = 600)
  fastman(
    m = as.data.frame(qqmanGwas),
    speedup = T, 
    #col = 
    maxP = 24,
    annotatePval = 1e-8,
    annotationWinMb = 4,
    annotationCol = theme.color$contrastDark2,
    cex.text = 0.7
    #annotateTop = T,
    #annotateN = 3
      )
  dev.off()
  
  png(filename = file.path(p$folderpath.plots,paste0("qq.",p$lfGWAS$gwas.for.display.info$code,".png")), width = 600, height = 600)
  fastqq(
    p = qqmanGwas$P,
    speedup = T,
    lambda = T,
    fix_zero = F
         )
  dev.off()
  
  #manhattan plot, qqman
  # png(filename = file.path(p$folderpath.plots,paste0("man.",p$lfGWAS$gwas.for.display.info$code,".png")), width = 1200, height = 600)
  # qqman::manhattan(x = qqmanGwas)
  # dev.off()
  
  #qqman::qq(p$lfGWAS$gwas.for.display$Pval_Estimate)
  
  #qq plot, qqman
  # png(filename = file.path(p$folderpath.plots,paste0("qq.",p$lfGWAS$gwas.for.display.info$code,".png")), width = 600, height = 600)
  # qqman::qq(qqmanGwas$P)
  # dev.off()
  
}

```

# Visualise exported latent factor GWAS results in manhattan and qq plots
```{r visualise composite manhattan and qq plots, purl=FALSE, eval=FALSE}

chosenSet<-p$sumstats.sel[p$sumstats.sel.set1_spec.code,] #SET SELECTED SUMSTATS HERE

manhattanPlots<-c()
qqPlots<-c()

for(iTrait in 1:nrow(chosenSet)){
  #test
  #iTrait<-1
  
  p$lfGWAS$gwas.for.display.info<-chosenSet[iTrait,]
  p$lfGWAS$gwas.for.display.info$code
  
  cSumstats <- fread(file = file.path(p$folderpath.data.sumstats.export,paste0(p$lfGWAS$gwas.for.display.info$code,".gz")), na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, key = c("SNP","CHR","BP"), data.table = T,showProgress = F, nThread=5)
  
  
  
  # manhattanPlots[iTrait] <- fastman(
  #   m = as.data.frame(cSumstats),
  #   speedup = T, 
  #   #col = 
  #   maxP = 16,
  #   annotatePval = 1e-7,
  #   annotationWinMb = 4,
  #   annotationCol = theme.color$contrastDark2,
  #   cex.text = 0.7
  #   #annotateTop = T,
  #   #annotateN = 3
  #     )
  
  manhattanPlots[[iTrait]] <- plot.manhattan.custom(cSumstats,y_limits = c(0,24),maxNLogP = 24)
  
  #test save
  #ggsave(filename=file.path(p$folderpath.plots, paste0("man_test.png")), plot = manhattanPlots[[iTrait]], width = 800, height = 400, units = "mm")

  qqPlots[[iTrait]] <- plot.qq.custom(cSumstats$P)
  #test save
  #ggsave(filename=file.path(p$folderpath.plots, paste0("qq_test.png")), plot = qqPlots[[iTrait]], width = 400, height = 400, units = "mm")
  
  
}

full <- cowplot::plot_grid(plotlist = c(manhattanPlots,qqPlots),labels = "AUTO",ncol = 2, nrow = 6,byrow=F)

ggsave(filename=file.path(p$folderpath.plots, paste0("manqq.factors.png")), plot = full, width = 210, height = 297, units = "mm", dpi = 320, scale = 3)
#A4 is 210 x 297 mm


```

# Genome-wide genetic association results

## Read genome-wide genetic associations per dataset

```{r read genetic associations}
cat("\n***READ GENETIC ASSOCIATIONS***")

p$filepath.results.gwa<-file.path(p$folderpath.workingDirectory,paste0("results.gwa.",p$setup.code,".Rds"))

if (file.exists(p$filepath.results.gwa)) {
  print("Using existing GWA results from previous run.")
  p$results.gwa<-readRDS(file=p$filepath.results.gwa)
} else {

  chosenSet<-p$sumstats.sel[p$sumstats.sel.set1.code,] #configure selected trait set here!
  
  p$results.gwa<-c()
  p$results.gwa$topHits<-c()
  
  for(iTrait in 1:nrow(chosenSet)){
    #iTrait<-1
    cSumstats<-fread(file = chosenSet[iTrait,]$mungedpath, na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, key = c("SNP","CHR","BP"), data.table = T,showProgress = F, nThread=5)
    cSumstats<-cSumstats[P<5e-8,]
    p$results.gwa$topHits[[chosenSet[iTrait,]$code]]<-cSumstats$SNP
    
  }
  
  saveRDS(object = p$results.gwa,file = p$filepath.results.gwa)
}


p$results.gwa$unique<-c()

p$results.gwa$unique.uv<-unique(unlist(p$results.gwa$topHits[p$sumstats.sel.uv.code]))

#GSEM.F1 - Factor Neuroticism
# p$results.gwa$unique[["GSEM.F1"]]<-list(unlist(p$results.gwa$topHits["GSEM.F1"])[
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["ANXI03"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["ANXI04"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["DEPR05"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["DEPR08"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["NEUR02"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["HEAL01"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["TIRE01"]))])

p$results.gwa$unique[["GSEM.F1"]]<-list(unlist(p$results.gwa$topHits["GSEM.F1"])[!(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% p$results.gwa$unique.uv)])
length(p$results.gwa$unique[["GSEM.F1"]][[1]])

#GSEM.F2 - Factor Psychoticism
p$results.gwa$unique[["GSEM.F2"]]<-list(unlist(p$results.gwa$topHits["GSEM.F2"])[!(unlist(p$results.gwa$topHits["GSEM.F2"]) %in% p$results.gwa$unique.uv)])
length(p$results.gwa$unique[["GSEM.F2"]][[1]])

#GSEM.F3 - Factor Depression
p$results.gwa$unique[["GSEM.F3"]]<-list(unlist(p$results.gwa$topHits["GSEM.F3"])[!(unlist(p$results.gwa$topHits["GSEM.F3"]) %in% p$results.gwa$unique.uv)])
length(p$results.gwa$unique[["GSEM.F3"]][[1]])

#GSEM.F4 - Factor Risktaking
p$results.gwa$unique[["GSEM.F4"]]<-list(unlist(p$results.gwa$topHits["GSEM.F4"])[!(unlist(p$results.gwa$topHits["GSEM.F4"]) %in% p$results.gwa$unique.uv)])
length(p$results.gwa$unique[["GSEM.F4"]][[1]])

#GSEM.F5 - Factor Deprivation
p$results.gwa$unique[["GSEM.F5"]]<-list(unlist(p$results.gwa$topHits["GSEM.F5"])[!(unlist(p$results.gwa$topHits["GSEM.F5"]) %in% p$results.gwa$unique.uv)])
length(p$results.gwa$unique[["GSEM.F5"]][[1]])

#GSEM.F6 - Factor Neuropsyche
p$results.gwa$unique[["GSEM.F6"]]<-list(unlist(p$results.gwa$topHits["GSEM.F6"])[!(unlist(p$results.gwa$topHits["GSEM.F6"]) %in% p$results.gwa$unique.uv)])
length(p$results.gwa$unique[["GSEM.F6"]][[1]])


```


## Read gene associations per dataset, output top gene lists
Added gene and gene level analysis results read

```{r read gene associations}
cat("\n***READ GENE, GENE LEVEL ASSOCIATIONS***")
p$filepath.results.ga<-file.path(p$folderpath.workingDirectory,paste0("results.ga.",p$setup.code,".Rds")) #gene analysis
p$filepath.results.gs<-file.path(p$folderpath.workingDirectory,paste0("results.gs.",p$setup.code,".Rds")) #gene level analysis

if (file.exists(p$filepath.results.ga)) {
  print("Using existing GA results from previous run.")
  p$results.ga<-readRDS(file=p$filepath.results.ga)
} else {

  chosenSet<-p$sumstats.sel[p$sumstats.sel.set1.code,] #configure selected trait set here!
  
  p$results.ga<-c()
  p$results.ga$geneAssociation<-c()
  
  p$geneMap<-fread(file = p$filepath.geneMapping, na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, data.table = T,showProgress = F, nThread=5)
  
  #TODO - Get map for transcript codes to gene codes!
  #p$transcriptionTargetMap.mirdb<-fread(file = p$filepath.transcriptionTargetMap.mirdb, na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, data.table = T,showProgress = F, nThread=5)
  
  for(iTrait in 1:nrow(chosenSet)){
    #iTrait<-1
    cat("\nProcessing ",chosenSet[iTrait,]$code)
    cGeneAssoc<-fread(file = file.path(p$folderpath.workingDirectory,paste0(p$setup.code,".geneanalysis.",chosenSet[iTrait,]$code,".genes.out")), na.strings =c(".",NA,"NA",""), encoding = "UTF-8",check.names = T, fill = T, blank.lines.skip = T, key = c("GENE","CHR","START","STOP"), data.table = T,showProgress = F, nThread=5)
    cGeneAssoc[p$geneMap, on=c(GENE='V1'), c("CODE"):=list(i.V6)]
    #cSigLevel<-(0.05/nrow(cGeneAssoc))
    cGeneAssoc$P.FDR<-p.adjust(p = cGeneAssoc$P,method = "fdr")
    #cat("Adj. sig. lev. ",chosenSet[iTrait,]$code,": ",cSigLevel)
    p$results.ga$geneAssociation[[chosenSet[iTrait,]$code]]<-list(cGeneAssoc)
    #topGenes <- cGeneAssoc[P<cSigLevel & P<0.01,]
    topGenes <- cGeneAssoc[P.FDR<0.05,]
    cat(", n sig. genes ",chosenSet[iTrait,]$code,":",nrow(topGenes))
    write.table(x = topGenes[,c("CODE")],file = file.path(p$folderpath.workingDirectory, paste0(chosenSet[iTrait,]$code,".top.genes.txt")),sep="\t", quote = FALSE, row.names = F, col.names = F, append = F)
    
  }
  
  saveRDS(object = p$results.ga,file = p$filepath.results.ga)
}


if (file.exists(p$filepath.results.gs)) {
  print("Using existing GS results from previous run.")
  p$results.gs<-readRDS(file=p$filepath.results.gs)
} else {

  chosenSet<-p$sumstats.sel[p$sumstats.sel.set1.code,] #configure selected trait set here!
  
  p$results.gs<-c()
  
  for(cCode in chosenSet$code){
    #cCode<-"ADHD05"
    p$results.gs[[cCode]]<-c()
    
    #gene sets, standard, and or gene property sets
    toprocess<-c("gtex8_rnaseq_median","brainspan_rnaseq_mean","msigdb.h.all.v7.5.1","msigdb.c2.cp.biocarta.v7.5.1","msigdb.c2.cp.kegg.v7.5.1", "msigdb.c3.mir.mirdb.v7.5.1","msigdb.c3.tft.gtrd.v7.5.1", "msigdb.c5.all.v7.5.1","msigdb.c7.all.v7.5.1","msigdb.c8.all.v7.5.1") #sets to process
    for(igeneset in 1:length(toprocess)){
      #igeneset<-1
      cat("\nProcessing ",cCode, " and ",toprocess[igeneset])
      cGeneSet.filepath <- file.path(p$folderpath.workingDirectory,paste0(p$setup.code, ".geneset.",toprocess[igeneset],".",cCode,".gsa.out"))
      cGeneSet<-read.table(cGeneSet.filepath, header=T, quote="\"",fill=T,na.string=c(".",NA,"NA",""), comment.char = "#")
      #cGeneSet$P.FDR<-p.adjust(p = cGeneSet$P,method = "fdr") #moved until later to calculate per subset rather than the full set (i.e. for msigdb c5)
      p$results.gs[[cCode]][[toprocess[igeneset]]]<-cGeneSet
    }
  }
 
  
  
  saveRDS(object = p$results.gs,file = p$filepath.results.gs)
}



p$results.ga$unique<-c()

p$results.ga$unique.uv<-unique(unlist(lapply(p$results.ga$geneAssociation[p$sumstats.sel.uv.code], function(x){x[[1]] [P.FDR<0.05,c("CODE")]})))

#GSEM.F1 - Factor Neuroticism
# p$results.gwa$unique[["GSEM.F1"]]<-list(unlist(p$results.gwa$topHits["GSEM.F1"])[
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["ANXI03"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["ANXI04"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["DEPR05"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["DEPR08"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["NEUR02"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["HEAL01"])) &
#   !(unlist(p$results.gwa$topHits["GSEM.F1"]) %in% unlist(p$results.gwa$topHits["TIRE01"]))])

cGeneAssoc<-unlist(p$results.ga$geneAssociation["GSEM.F1"][[1]][[1]][P.FDR<0.05,c("CODE")],use.names = F)
p$results.ga$unique[["GSEM.F1"]]<-list(cGeneAssoc[!(cGeneAssoc %in% p$results.ga$unique.uv)])
length(p$results.ga$unique[["GSEM.F1"]][[1]])

#GSEM.F2 - Factor Psychoticism
cGeneAssoc<-unlist(p$results.ga$geneAssociation["GSEM.F2"][[1]][[1]][P.FDR<0.05,c("CODE")],use.names = F)
p$results.ga$unique[["GSEM.F2"]]<-list(cGeneAssoc[!(cGeneAssoc %in% p$results.ga$unique.uv)])
length(p$results.ga$unique[["GSEM.F2"]][[1]])

#GSEM.F3 - Factor Depression
cGeneAssoc<-unlist(p$results.ga$geneAssociation["GSEM.F3"][[1]][[1]][P.FDR<0.05,c("CODE")],use.names = F)
p$results.ga$unique[["GSEM.F3"]]<-list(cGeneAssoc[!(cGeneAssoc %in% p$results.ga$unique.uv)])
length(p$results.ga$unique[["GSEM.F3"]][[1]])

#GSEM.F4 - Factor Risktaking
cGeneAssoc<-unlist(p$results.ga$geneAssociation["GSEM.F4"][[1]][[1]][P.FDR<0.05,c("CODE")],use.names = F)
p$results.ga$unique[["GSEM.F4"]]<-list(cGeneAssoc[!(cGeneAssoc %in% p$results.ga$unique.uv)])
length(p$results.ga$unique[["GSEM.F4"]][[1]])

#GSEM.F5 - Factor Deprivation
cGeneAssoc<-unlist(p$results.ga$geneAssociation["GSEM.F5"][[1]][[1]][P.FDR<0.05,c("CODE")],use.names = F)
p$results.ga$unique[["GSEM.F5"]]<-list(cGeneAssoc[!(cGeneAssoc %in% p$results.ga$unique.uv)])
length(p$results.ga$unique[["GSEM.F5"]][[1]])

#GSEM.F6 - Factor Neuropsyche
cGeneAssoc<-unlist(p$results.ga$geneAssociation["GSEM.F6"][[1]][[1]][P.FDR<0.05,c("CODE")],use.names = F)
p$results.ga$unique[["GSEM.F6"]]<-list(cGeneAssoc[!(cGeneAssoc %in% p$results.ga$unique.uv)])
length(p$results.ga$unique[["GSEM.F6"]][[1]])

```

## Process gene-set analysis results
```{r Process gene-set analysis results}
cat("\n***Process gene-set analysis results***")

chosenSet<-p$sumstats.sel[p$sumstats.sel.set1.code,] #configure selected trait set here!
toprocess<-c("gtex8_rnaseq_median","brainspan_rnaseq_mean","msigdb.h.all.v7.5.1","msigdb.c2.cp.biocarta.v7.5.1","msigdb.c2.cp.kegg.v7.5.1","msigdb.c3.mir.mirdb.v7.5.1","msigdb.c3.tft.gtrd.v7.5.1","msigdb.c5.gobp.v7.5.1","msigdb.c5.gocc.v7.5.1","msigdb.c5.gomf.v7.5.1","msigdb.c5.hpo.v7.5.1","msigdb.c5.other.v7.5.1","msigdb.c7.all.v7.5.1","msigdb.c8.all.v7.5.1") #sets to process
#toprocess<-c("gtex8_rnaseq_median","brainspan_rnaseq_mean","msigdb.h.all.v7.5.1","msigdb.c3.all.v7.5.1","msigdb.c5.all.v7.5.1","msigdb.c7.all.v7.5.1","msigdb.c8.all.v7.5.1") #sets to process

p$mGeneLevelBeta <-c()
p$mGeneLevelSE <-c()
p$mGeneLevelBetaSTD <-c()
p$mGeneLevelP <-c()
p$mGeneLevelP.FDR <-c()
p$geneSetVariables <-c()

for(igeneset in 1:length(toprocess)){
  #igeneset<-3
  cCodes <- c()
  cNames <- c()
  
  cGeneSetDataCode <- toprocess[igeneset]
  if(toprocess[igeneset] %in% c("msigdb.c5.gobp.v7.5.1","msigdb.c5.gocc.v7.5.1","msigdb.c5.gomf.v7.5.1","msigdb.c5.hpo.v7.5.1","msigdb.c5.other.v7.5.1")) cGeneSetDataCode <- "msigdb.c5.all.v7.5.1" #these share the same dataset
  #if(toprocess[igeneset] %in% c("msigdb.c3.mir.v7.5.1","msigdb.c3.tft.v7.5.1")) cGeneSetDataCode <- "msigdb.c3.all.v7.5.1" #these share the same dataset
  
  
  #assess the full set of set variables across GWAS datasets
  for(cCode in chosenSet$code){
    cCodes <- c(cCodes, p$results.gs[[cCode]][[cGeneSetDataCode]]$VARIABLE)
    cNames <- c(cNames, p$results.gs[[cCode]][[cGeneSetDataCode]]$FULL_NAME)
  }
  
  cGeneSetVariables <- data.frame(code=cCodes, name=cNames)
  cGeneSetVariables <- unique(cGeneSetVariables)
  #rownames(cGeneSetVariables)<-cGeneSetVariables$code #fails at duplicates
  
  #special treatment of some sets, subsets etc
  if(toprocess[igeneset]=="brainspan_rnaseq_mean"){
    cGeneSetVariables <- cGeneSetVariables[cGeneSetVariables$code %in% c("amygdaloid_complex","anterior_(rostral)_cingulate...1","caudal_ganglionic_eminence","	
cerebellar_cortex","cerebellum","dorsal_thalamus","dorsolateral_prefrontal_cort...1","hippocampus_(hippocampal_for...1","inferolateral_temporal_corte...1","lateral_ganglionic_eminence","medial_ganglionic_eminence","occipital_neocortex","orbital_frontal_cortex","parietal_neocortex","posterior_(caudal)_superior_...1","posteroventral_(inferior)_pa...1","primary_auditory_cortex_(cor...1","primary_motor_cortex_(area_M...1","	
primary_motor-sensory_cortex...1","primary_somatosensory_cortex...1","primary_visual_cortex_(stria...1","striatum","temporal_neocortex","upper_(rostral)_rhombic_lip","ventrolateral_prefrontal_cor...1"),]
  } else if(toprocess[igeneset] == "msigdb.c5.gobp.v7.5.1"){
    cGeneSetVariables <- cGeneSetVariables[cGeneSetVariables$code %in% grep("^gobp\\_", ignore.case = T, cGeneSetVariables$code, value = T),]
  } else if(toprocess[igeneset] == "msigdb.c5.gocc.v7.5.1"){
    cGeneSetVariables <- cGeneSetVariables[cGeneSetVariables$code %in% grep("^gocc\\_", ignore.case = T, cGeneSetVariables$code, value = T),]
  } else if(toprocess[igeneset] == "msigdb.c5.gomf.v7.5.1"){
    cGeneSetVariables <- cGeneSetVariables[cGeneSetVariables$code %in% grep("^gomf\\_", ignore.case = T, cGeneSetVariables$code, value = T),]
  } else if(toprocess[igeneset] == "msigdb.c5.hpo.v7.5.1"){
    cGeneSetVariables <- cGeneSetVariables[cGeneSetVariables$code %in% grep("^hp\\_", ignore.case = T, cGeneSetVariables$code, value = T),]
  } else if(toprocess[igeneset] == "msigdb.c5.other.v7.5.1"){
    cGeneSetVariables <- cGeneSetVariables[cGeneSetVariables$code %in% grep("^[^gobp\\_|gocc\\_|gomf\\_|hpo\\_]", ignore.case = T, cGeneSetVariables$code, value = T),]
  }
    
  
  p$mGeneLevelBeta[toprocess[igeneset]] <- list(matrix(NA,ncol = nrow(chosenSet), nrow = nrow(cGeneSetVariables)))
  colnames(p$mGeneLevelBeta[toprocess[igeneset]][[1]]) <- chosenSet$code
  rownames(p$mGeneLevelBeta[toprocess[igeneset]][[1]]) <- cGeneSetVariables$name
  p$mGeneLevelBetaSTD[toprocess[igeneset]] <- p$mGeneLevelBeta[toprocess[igeneset]]
  p$mGeneLevelSE[toprocess[igeneset]] <- p$mGeneLevelBeta[toprocess[igeneset]]
  p$mGeneLevelP[toprocess[igeneset]] <- p$mGeneLevelBeta[toprocess[igeneset]]
  p$mGeneLevelP.FDR[toprocess[igeneset]] <- p$mGeneLevelBeta[toprocess[igeneset]]
  p$geneSetVariables[toprocess[igeneset]] <-list(cGeneSetVariables)
  
  for(cCode in chosenSet$code){
    #cCode<-"ALCD03"
    cGeneSetResult <- p$results.gs[[cCode]][[cGeneSetDataCode]]
    rownames(cGeneSetResult)<-cGeneSetResult$FULL_NAME #changed to full name
    
    p$mGeneLevelP[toprocess[igeneset]][[1]][,cCode] <- cGeneSetResult[cGeneSetVariables$name,]$P
    p$mGeneLevelP.FDR[toprocess[igeneset]][[1]][,cCode] <- p.adjust(p =  cGeneSetResult[cGeneSetVariables$name,]$P, method = "fdr") #FDR adjustment
    p$mGeneLevelBeta[toprocess[igeneset]][[1]][,cCode] <- cGeneSetResult[cGeneSetVariables$name,]$BETA
    p$mGeneLevelBetaSTD[toprocess[igeneset]][[1]][,cCode] <- cGeneSetResult[cGeneSetVariables$name,]$BETA_STD
    p$mGeneLevelSE[toprocess[igeneset]][[1]][,cCode] <- cGeneSetResult[cGeneSetVariables$name,]$SE
    # #effects are scaled to trait dataset power (heritability x sample size)
    # p$mGeneLevelBeta[toprocess[igeneset]][[1]][,cCode] <- cGeneSetResult[cGeneSetVariables$code,]$BETA/p$sumstats.sel[cCode,]$power_scale_factor
    # p$mGeneLevelBetaSTD[toprocess[igeneset]][[1]][,cCode] <- cGeneSetResult[cGeneSetVariables$code,]$BETA_STD/p$sumstats.sel[cCode,]$power_scale_factor
   
  }
} 


```

# Plots, tables, and diagrams

## Improved annotation of all traits, including latent factor traits

```{r improved annotation, fig.width=10, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}
#View(p$sumstats.sel)

p$sumstats.sel.table<-p$sumstats.sel[p$sumstats.sel.set1.code,c("name.nice","code","reference.nice","year","n_consensus","h2.liability_mvLDSC","h2.se.liability_mvLDSC","lambda_ldsc")] #full trait list
#p$sumstats.sel.table<-p$sumstats.sel[p$sumstats.sel.l.code,c("name.nice","code","n_effective","h2.liability_mvLDSC","h2.se.liability_mvLDSC","lambda_ldsc")]

p$sumstats.sel.table$h2.liability_mvLDSC.table<-paste0(round( p$sumstats.sel.table$h2.liability_mvLDSC,digits = 3)," (",round(p$sumstats.sel.table$h2.se.liability_mvLDSC,digits = 3),")")

p$sumstats.sel.table<-p$sumstats.sel.table[,c("name.nice","code","year","reference.nice","n_consensus","h2.liability_mvLDSC.table","lambda_ldsc")] #"lambda1000"
#View(p$sumstats.sel.table)
#p$sumstats.sel.table

p$plots.factors.sel.table<-p$sumstats.sel.table %>% 
  gt() %>% 
  fmt_number(columns = c("n_consensus"), decimals = 0) %>%
  fmt_number(columns = c("lambda_ldsc"), decimals = 2) %>%
  tab_header(
    title = "Selected GWAS summary statistics datasets, including latent factors"
  ) %>% cols_label(
    name.nice  = "Trait",
    code = "Code",
    reference.nice = "Study",
    year = "Year",
    n_consensus = "N",
    h2.liability_mvLDSC.table = html("h<sup>2</sup><sub>mvLDSC</sub> (S.E.)"),
    lambda_ldsc = "LDSC intercept"
    #lambda1000 = "lambda1000"
  ) %>%
  tab_style(
    style = cell_text(size = px(12)),
    locations = cells_column_labels(everything())       
  ) %>%
  tab_style(
    style = cell_text(size = px(12),weight = "bold"),
    locations = cells_body(everything())        
  )

p$plots.factors.sel.table

gtsave(data = p$plots.factors.sel.table, filename = paste0(p$folderpath.plots,"/factors.sel.table.rtf"))


```

## Gene association analyses, multivariate
```{r Plots gene association analyses - multivariate, fig.width=10, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}
library(UpSetR)
#https://upset.app/
#Don't forget to cite!
chosenSet<-p$sumstats.sel[p$sumstats.sel.set1.code,] #configure selected trait set here!

codesAllSets <- list()

for(iTrait in 1:nrow(chosenSet)){
  #iTrait<-3
  cCode <- chosenSet$code[iTrait]
  cAssociation <- p$results.ga$geneAssociation[cCode][[1]][[1]]
  cAssociation <- cAssociation[cAssociation$P.FDR<0.05,]
  codesAllSets[[cCode]] <- c(cAssociation$CODE)
}

#set nice names
names(codesAllSets) <- p$sumstats.sel[names(codesAllSets), ]$name.nice

#png(filename = file.path(p$folderpath.plots,paste0("ga.png")), width = 800, height = 600, units = "px")
pdf(file = file.path(p$folderpath.plots,paste0("ga.pdf")))
upset(
  fromList(codesAllSets),
  nsets = 12,
  nintersects = 50,
  order.by = "freq",
  matrix.color = theme.color$contrastDark1,
  main.bar.color = theme.color$contrastLight3,
  sets.bar.color = theme.color$contrastLight3,
  text.scale = c(1, 0.7, 1, 1, 1, 0.6) #c(intersection size title, intersection size tick labels, set size title, set size tick labels, set names, numbers above bars)
  )
#upset(fromList(codesAllSets),order.by = "freq", nintersects=20)
#upset(fromList(codesAllSets), group.by = "sets", order.by = "freq")
dev.off()

#Get gene publications - also needs a gene - id map
#publishedGenes.df<-read_tsv("ftp://ftp.ncbi.nlm.nih.gov/gene/DATA/gene2pubmed.gz",col_names=T)

```

## Gene level analyses, multivariate

```{r Plots gene level analyses - multivariate, fig.width=10, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}
#install.packages("heatmaply")
library(heatmaply)

toprocess<-c("gtex8_rnaseq_median","brainspan_rnaseq_mean","msigdb.h.all.v7.5.1") #sets to process


for(igeneset in 1:length(toprocess)){
  #igeneset<-2
  cGeneSetVariables <-  p$geneSetVariables[[toprocess[igeneset]]]
  if(nrow(cGeneSetVariables)>100) next #safety not to run large sets
  cGeneLevelBeta <- p$mGeneLevelBeta[toprocess[igeneset]][[1]]
  cGeneLevelBetaSTD <- p$mGeneLevelBetaSTD[toprocess[igeneset]][[1]]
  cGeneLevelSE <- p$mGeneLevelSE[toprocess[igeneset]][[1]]
  cGeneLevelP <- p$mGeneLevelP[toprocess[igeneset]][[1]]
  cGeneLevelP.FDR <- p$mGeneLevelP.FDR[toprocess[igeneset]][[1]]
  
  rownames(cGeneLevelBeta) <- cGeneSetVariables$name
  rownames(cGeneLevelBetaSTD) <- cGeneSetVariables$name
  
  cGeneLevelNlog10P<-(-log10(cGeneLevelP.FDR))
  cGeneLevelNlog10P[is.na(cGeneLevelNlog10P)]<-0 #replace na with 0
  
  heatmaply(
    cGeneLevelNlog10P,
    #cGeneLevelBetaSTD,
            xlab = "Traits",
            ylab = "Feature",
            main = paste("-log10(p), p-value of t(set/property regression coefficient), ",toprocess[igeneset]),
             #main = paste("Gene level effect sizes (raw beta), ",toprocess[igeneset]),
            #main = paste("Gene level effect sizes (semi-standardised), ",toprocess[igeneset]),
            scale_fill_gradient_fun = ggplot2::scale_fill_gradient2(
                low = theme.color$contrastDark3, 
                mid = "black",
                high = theme.color$contrastLight3
              ),
            file=file.path(p$folderpath.plots,paste0("genelevel.heatcluster.", toprocess[igeneset],".png")),
            width = 1200, height = 1600,
            hclust_method = "ward.D2"
            #scale = "row"
            )
  
}



```

## Gene level analyses, single datasets

```{r Plots - gene level analyses - single datasets, fig.width=10, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}
#p$sumstats.sel.set1.code
chosenSet<-p$sumstats.sel[c("EDUC03","SCHI04","NEUR02","RISK03","GSEM.F1","RISK02","GSEM.F5","BIPO02","GSEM.F3","GSEM.F2","INSO02","ANOR02"),] #configure selected trait set here!
toprocess<-c("gtex8_rnaseq_median","brainspan_rnaseq_mean","msigdb.h.all.v7.5.1","msigdb.c2.cp.biocarta.v7.5.1","msigdb.c2.cp.kegg.v7.5.1","msigdb.c3.mir.mirdb.v7.5.1","msigdb.c3.tft.gtrd.v7.5.1","msigdb.c5.gobp.v7.5.1","msigdb.c5.gocc.v7.5.1","msigdb.c5.gomf.v7.5.1","msigdb.c5.hpo.v7.5.1","msigdb.c5.other.v7.5.1","msigdb.c7.all.v7.5.1","msigdb.c8.all.v7.5.1") #sets to process

for(igeneset in 1:length(toprocess)){
  #igeneset<-13
  cGeneSetVariables <-  p$geneSetVariables[[toprocess[igeneset]]]
  cGeneLevelBeta <- p$mGeneLevelBeta[toprocess[igeneset]][[1]]
  cGeneLevelBetaSTD <- p$mGeneLevelBetaSTD[toprocess[igeneset]][[1]]
  cGeneLevelSE <- p$mGeneLevelSE[toprocess[igeneset]][[1]]
  cGeneLevelP <- p$mGeneLevelP[toprocess[igeneset]][[1]]
  cGeneLevelP.FDR <- p$mGeneLevelP.FDR[toprocess[igeneset]][[1]]
  
  cGeneLevelNlog10P<-(-log10(cGeneLevelP.FDR))
  
  cGeneLevelZ<-cGeneLevelBeta/cGeneLevelSE
  
  for(iTrait in 1:nrow(chosenSet)){
    #iTrait<-1
    cTraitVal.df <- data.frame(val=cGeneLevelBetaSTD[,chosenSet$code[iTrait]],feature=cGeneSetVariables$name, p=cGeneLevelP.FDR[,chosenSet$code[iTrait]])
    #cTraitVal.df <- data.frame(val=cGeneLevelBetaSTD[,chosenSet$code[iTrait]],feature=cGeneSetVariables$name, p=cGeneLevelP[,chosenSet$code[iTrait]])
    #cTraitVal.df <- cTraitVal.df[cTraitVal.df$p<0.1,]
    cTraitVal.df <- head(cTraitVal.df[order(cTraitVal.df$val,decreasing = T),],60)
    cTraitVal.df$sig<-ifelse(cTraitVal.df$p<0.05 & cTraitVal.df$val>0,"s","n")
    if(nrow(cTraitVal.df)>1){
      cplot<-ggplot(cTraitVal.df, aes(x = reorder(feature,val), y = val, fill=sig)) + 
      scale_fill_manual(name = "stat. significance",
                     values = c("s" = theme.color$contrastLight3,
                                "n" = theme.color$contrastDark1),
                     labels = c("*", "")) +
      # scale_fill_gradient2(name = "p-value",
      #                      mid = theme.color$contrastLight3,
      #                      low = theme.color$contrastDark3,
      #                      midpoint=0,
      #                      limits=c(0,1)) +
      geom_bar(position="dodge", stat="identity") +
      theme_bw(base_size=22) +
      theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5)) + 
      coord_flip()
     # theme_bw(base_size=22) #use a black-and white theme with set font size
      #dir.create(path = file.path(p$folderpath.plots,chosenSet$code[iTrait]))
      ggsave(filename=file.path(p$folderpath.plots, paste0("genelevel.",toprocess[igeneset],".",chosenSet$code[iTrait],".png")), plot = cplot, width = 700, height = 500, units = "mm")
    }
  }
}



```


## Gene level analyses, selected differences

```{r Plots - gene level analyses - selected differences, fig.width=10, fig.height=6, out.width="1600px", out.height="1000px", eval=FALSE, purl=FALSE}
library(cowplot)

chosenSet <- p$sumstats.sel[c("GSEM.F1"),] #configure selected trait set here!
#comparisonSet <- p$sumstats.sel["EDUC03","NEUR02","INSO02","RISK02","RISK03","SUBJ01","TIRE01","ANXI03","DEPR05",GSEM.F1","GSEM.F2","GSEM.F3","GSEM.F5"] #comparison traits, apart from general mean
#comparisonSet <- p$sumstats.sel[p$sumstats.sel.set1.code,] #comparison traits, apart from general mean
comparisonSet <- p$sumstats.sel[c("NEUR02","GSEM.F1"),] #comparison traits, place main trait towards end if to include in combination plot
#comparisonSet <- p$sumstats.sel[c("EDUC03","NEUR02","GSEM.F1"),] #comparison traits, place main trait towards end if to include in combination plot
#comparisonSet <- p$sumstats.sel[c("SCHI04","BIPO02","GSEM.F1","GSEM.F3"),] #comparison traits, place main trait towards end if to include in combination plot
#Old well powered
# toprocess <- c(
#   #"gtex8_rnaseq_median",
#   "brainspan_rnaseq_mean",
#   "msigdb.h.all.v7.5.1",
#   #"msigdb.c2.cp.biocarta.v7.5.1",
#   #"msigdb.c2.cp.kegg.v7.5.1",
#   #"msigdb.c3.mir.mirdb.v7.5.1",
#   #"msigdb.c3.tft.gtrd.v7.5.1",
#   "msigdb.c5.gobp.v7.5.1",
#   "msigdb.c5.gocc.v7.5.1",
#   "msigdb.c5.gomf.v7.5.1",
#   #"msigdb.c5.hpo.v7.5.1",
#   #"msigdb.c5.other.v7.5.1",
#   "msigdb.c7.all.v7.5.1",
#   "msigdb.c8.all.v7.5.1"
#   ) #sets to process

toprocess <- c(
  "msigdb.c5.gobp.v7.5.1",
  "msigdb.c5.gomf.v7.5.1"
  ) #sets to process

df.traits<-list()


for(igeneset in 1:length(toprocess)){
  #igeneset<-3
  cGeneSetVariables <-  p$geneSetVariables[[toprocess[igeneset]]]
  cGeneLevelBeta <- p$mGeneLevelBeta[toprocess[igeneset]][[1]]
  cGeneLevelBetaSTD <- p$mGeneLevelBetaSTD[toprocess[igeneset]][[1]]
  cGeneLevelSE <- p$mGeneLevelSE[toprocess[igeneset]][[1]]
  cGeneLevelP <- p$mGeneLevelP[toprocess[igeneset]][[1]]
  cGeneLevelP.FDR <- p$mGeneLevelP.FDR[toprocess[igeneset]][[1]]
  
  cGeneLevelNlog10P<-(-log10(cGeneLevelP.FDR))
  
  cGeneLevelZ<-cGeneLevelBeta/cGeneLevelSE
  
  cGeneLevelBetaSTD.scaled<-scale(cGeneLevelBetaSTD)
  #cGeneLevelBetaSTD.scaled<-ifelse(cGeneLevelP<0.05,cGeneLevelBetaSTD.scaled,NA_real_)
  cGeneLevelBetaSTD.scaled.rmean<-rowMeans(cGeneLevelBetaSTD.scaled,na.rm = T)
  cGeneLevelBetaSTD.rmean<-rowMeans(cGeneLevelBetaSTD,na.rm = T)
  
  for(iTrait in 1:nrow(chosenSet)){
    #iTrait<-1
    
    dir.create(path = file.path(p$folderpath.plots,chosenSet$code[iTrait]))
    
    #run comparison traits per main trait
    for(iComparison in 1:nrow(comparisonSet)){
      #iComparison<-1
      
      #comparison plot, main trait vs comparison trait
      cTraitVal.df <- data.frame(val=cGeneLevelBetaSTD[,chosenSet$code[iTrait]]-cGeneLevelBetaSTD[,comparisonSet$code[iComparison]],feature=cGeneSetVariables$name, p=cGeneLevelP.FDR[,chosenSet$code[iTrait]])
      #cTraitVal.df <- cTraitVal.df[cTraitVal.df$p<0.1,]
      cTraitVal.df<-cTraitVal.df[which(cTraitVal.df$p<0.05),] #only select differences from main significant associations.
      cTraitVal.df <- head(cTraitVal.df[order(cTraitVal.df$val,decreasing = T),],30)
      cTraitVal.df$sig<-ifelse(cTraitVal.df$p<0.05,"s","n")
      if(nrow(cTraitVal.df)>1 & chosenSet$code[iTrait]!=comparisonSet$code[iComparison]){ #inactivated with F!!!
        cplot<-ggplot(cTraitVal.df, aes(x = reorder(feature,val), y = val, fill=sig)) + 
        scale_fill_manual(name = "stat. significance",
                       values = c("s" = theme.color$contrastLight3,
                                  "n" = theme.color$contrastDark1),
                       labels = c("*", "")) +
        # scale_fill_gradient2(name = "p-value",
        #                      mid = theme.color$contrastLight3,
        #                      low = theme.color$contrastDark3,
        #                      midpoint=0,
        #                      limits=c(0,1)) +
        geom_bar(position="dodge", stat="identity") +
        theme_bw(base_size=22) +
        theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5)) +
        coord_flip()
       # theme_bw(base_size=22) #use a black-and white theme with set font size
        ggsave(filename=file.path(p$folderpath.plots,chosenSet$code[iTrait], paste0("genelevel.diff.",toprocess[igeneset],".",chosenSet$code[iTrait],"-",comparisonSet$code[iComparison],".png")), plot = cplot, width = 700, height = 500, units = "mm")
      }
      
      
      #multi-plot, main trait
      cTraitVal.df1 <- data.frame(
        trait=chosenSet$code[iTrait],
        var=cGeneSetVariables$name,
        val0=cGeneLevelBetaSTD[,chosenSet$code[iTrait]],
        se0=cGeneLevelSE[,chosenSet$code[iTrait]],
        #high=cGeneLevelBeta[,chosenSet$code[iTrait]]+qnorm(0.05,lower.tail = F)*cGeneLevelSE[,chosenSet$code[iTrait]],
        #low=cGeneLevelBeta[,chosenSet$code[iTrait]]-qnorm(0.05,lower.tail = F)*cGeneLevelSE[,chosenSet$code[iTrait]],
        p=abs(cGeneLevelP.FDR[,chosenSet$code[iTrait]])
        )
      cTraitVal.df1$zCorrected <- qnorm(cTraitVal.df1$p/2,lower.tail = F)
      cTraitVal.df1$val <- cTraitVal.df1$val0
      cTraitVal.df1$se <- abs(cTraitVal.df1$val/cTraitVal.df1$zCorrected)
      
      #pair-plot, comparison trait
      cTraitVal.df2 <- data.frame(
        trait=comparisonSet$code[iComparison],
        var=cGeneSetVariables$name,
        val0=cGeneLevelBetaSTD[,comparisonSet$code[iComparison]],
        se0=cGeneLevelSE[,comparisonSet$code[iComparison]],
        #high=cGeneLevelBeta[,comparisonSet$code[iComparison]]+qnorm(0.05,lower.tail = F)*cGeneLevelSE[,comparisonSet$code[iComparison]],
        #low=cGeneLevelBeta[,comparisonSet$code[iComparison]]-qnorm(0.05,lower.tail = F)*cGeneLevelSE[,comparisonSet$code[iComparison]],
        p=abs(cGeneLevelP.FDR[,comparisonSet$code[iComparison]])
        )
      cTraitVal.df2$zCorrected <- qnorm(cTraitVal.df2$p/2,lower.tail = F)
      cTraitVal.df2$val <- cTraitVal.df2$val0
      cTraitVal.df2$se <- abs(cTraitVal.df2$val/cTraitVal.df2$zCorrected)
      
      cTraitVal.df1$p2<-cTraitVal.df2$p
      cTraitVal.df2$p2<-cTraitVal.df1$p
      cTraitVal.df1 <- cTraitVal.df1[(cTraitVal.df1$p<0.05) & !is.nan(cTraitVal.df1$se) & cTraitVal.df1$val>0,] #|cTraitVal.df1$p2<0.05 #only select results significant in main trait
      if(chosenSet$code[iTrait]==comparisonSet$code[iComparison]){
        #comparison trait is the main trait
        cTraitVal.df2 <- cTraitVal.df2[cTraitVal.df2$var %in% df.traits[iTrait][[1]]$var,] #& cTraitVal.df2$val>0
        # cTraitVal.df2$z <- cTraitVal.df2$val/cTraitVal.df2$se
        # dfOrder <- head(na.omit(cTraitVal.df2[order(-cTraitVal.df2$val,na.last = T),]),30)
      } else {
        #comparison trait as standard
        cTraitVal.df2 <- cTraitVal.df2[cTraitVal.df2$var %in% cTraitVal.df1$var & cTraitVal.df2$val>0 & cTraitVal.df1$val>0,]
       
      }
      
      cTraitVal.df1$z <- cTraitVal.df1$val/cTraitVal.df1$se
      dfOrder <- head(na.omit(cTraitVal.df1[order(-cTraitVal.df1$val,na.last = T),]),30)
      
      #df <- rbind(cTraitVal.df1,cTraitVal.df2)
      df <- cTraitVal.df2
      varOrder<-rev(unique(dfOrder$var))
      
      #df <- df[df$p<0.05,]
      df <- na.omit(df)
      df <- df[df$var %in% varOrder,]
      
      
      df$trait <- factor(df$trait)
      df$var <- factor(df$var,levels = varOrder)
      df$val <- as.numeric(df$val)
      df$high <- df$val + qnorm(0.05,lower.tail = F)*df$se
      df$low <- df$val - qnorm(0.05,lower.tail = F)*df$se
      
      if(nrow(df)>1) {
        df$set <- toprocess[igeneset]
        df.traits[iTrait] <- list(rbindlist(l = list(df.traits[iTrait][[1]],df),use.names = T,fill = T,idcol = F))
      }
      # if(nrow(df)>1){
      #    cplot  <- ggplot(df, aes(x=var, y=val, ymin=low, ymax=high,col=trait,fill=trait)) +
      #       #geom_errorbar(aes(xmin = low, xmax = high)) +
      #       geom_linerange(size=2,position=position_dodge(width = 0.5)) +
      #       geom_hline(yintercept=0, lty=2) +
      #       geom_point(size=3, shape=21, colour="white", stroke = 0.5,position=position_dodge(width = 0.5)) +
      #       scale_fill_manual(values=c(theme.color$contrastDark1,theme.color$contrastDark1)) +
      #       scale_color_manual(values=c(theme.color$contrastLight3,theme.color$contrastDark3)) +
      #       scale_x_discrete(name="Set") +
      #       scale_y_continuous(name="Regression beta", limits = c(min(df$low)-0.1*max(abs(df$val)), max(df$high)+0.1*max(abs(df$val)))) +
      #       coord_flip() +
      #       theme_bw() +
      #       ggtitle(label = paste0("Gene-level MAGMA regression betas and standard errors: ",toprocess[igeneset]))
      #    
      #    glplotsgrid[iTrait] <- append(glplotsgrid[iTrait],list(cplot))
      #     
      #     #ggsave(filename=file.path(p$folderpath.plots,chosenSet$code[iTrait], paste0("genelevel.pair.",toprocess[igeneset],".",chosenSet$code[iTrait],"-",comparisonSet$code[iComparison],".png")), plot = cplot, width = 700, height = 500, units = "mm")
      # }
  
    }
  }
}

#plot all subplots in grid for selected trait
#https://stackoverflow.com/questions/58657802/forest-plot-with-subgroups-in-ggplot2
for(iTrait in 1:nrow(chosenSet)){
  #iTrait<-1
  df <- df.traits[iTrait][[1]]
  df <- df[which(df$set!="gtex8_rnaseq_median" & df$set!="brainspan_rnaseq_mean"),]
  df$set <- as.factor(df$set)
  
  #df.l <- pivot_longer(data = df,cols = set)
  
  
  if(nrow(df)>0){
       cplot  <- ggplot(df, aes(x=var, y=val, ymin=low, ymax=high,col=trait,fill=trait)) +
          geom_hline(yintercept=0, lty=2) + 
          #geom_boxplot() +
          geom_linerange(size=0.3, position=position_dodge(width = 0.8)) +
          
          geom_point(size=0.8, shape=21, colour="white", stroke = 0.2,position=position_dodge(width = 0.8)) +
          
          scale_fill_manual(values=c(theme.color$contrastDark3,theme.color$contrastLight3)) +
          scale_color_manual(values=c(theme.color$contrastDark3,theme.color$contrastLight3)) +
          scale_x_discrete(name="Set") +
          scale_y_continuous(name="Regression beta") +
          #scale_y_continuous(name="Regression beta", limits = c(min(df$low)-0.1*max(abs(df$val)), max(df$high)+0.1*max(abs(df$val)))) +
          coord_flip() +
          facet_wrap(~ set, ncol = 1, shrink = T, drop = T, scales = "free") +
          theme_bw(base_size = 8) +
          theme(axis.text.y =element_text(size=7)) +
          ggtitle(label = paste0("Gene-level MAGMA std. regression betas and standard errors"))

        ggsave(filename=file.path(p$folderpath.plots,chosenSet$code[iTrait], paste0("genelevel.multi.",chosenSet$code[iTrait],".png")), plot = cplot, width = 210, height = 297, units = "mm")
        #A4 is 210 x 297 mm
  }
  
}


```




#Scratch area
```{r scratch area, include=FALSE, eval=FALSE, purl=FALSE}

# p$munge$results <- supermunge(
#             #filePaths = c(file.path(p$folderpath.data,"gwas_sumstats","raw","Retro_prospective_meta_childhoodmaltreatment.txt.gz")),
#             filePaths = c("~/Downloads/GLAD_EDGI_NBR_rsid_sex_chrALL_bpd.regenie.gz"),
#             traitNames = c("BPDTEST"),
#             process = T,
#             filter.maf = 0.01,
#             filter.info = 0.6,
#             pathDirOutput = p$folderpath.data.sumstats.munged
#               )

# p$munge$results<-munge(files = c(file.path(p$folderpath.data,"gwas_sumstats","raw","230608_pgced3_meta_to_share", "daner_BENARROW.meta.gz")), hm3 = p$filepath.SNPReference.hc1kg, trait.names = c("TESTBENARROW"),N = c(20000)
# )


# #QQ-plot for Helena
# 
# sumstatH <- shru::readFile(filePath = file.path(p$folderpath.data,"gwas_sumstats","raw","gcta_fastGWA_dep_gwas_4pcs_array.fastGWA"), nThreads = 5)
# 
# sumstatH<-sumstatH[log10(P)>(-30),]
# 
# shru::plot.qq.custom(ps = sumstatH$P)

p$CFA$test<-c()

max(p$mvLD$covstruct.mvLDSC$S.smooth-p$mvLD$covstruct.mvLDSC$S.orig)

#p$mvLD$covstruct.mvLDSC$S<-p$mvLD$covstruct.mvLDSC$S.smooth
#p$mvLD$covstruct.mvLDSC$S<-p$mvLD$covstruct.mvLDSC$S.orig

cModel <- p$CFA$models.selected["M18_4_14.C.DWLS",]


#p$lfGWAS$sumstats.test<-p$lfGWAS$sumstats[which(p$lfGWAS$sumstats$CHR=='22'),]
  
p$test$gwasResults<-usermodel.mod(
  covstruc = p$mvLD$covstruct.mvLDSC,
  model = cModel$lModel,
  #model = p$efaSEM$lmodel,
  estimation = p$CFA$estimator[1],
  fix_resid = F,
  CFIcalc = T,
  imp_cov = T
  )

p$test$gwasResults$modelfit
p$test$gwasResults$results

p$test$gwasResults.matrix<-semplate$parseGenomicSEMResultAsMatrices(resultDf = p$test$gwasResults$results)

p$test$gwasResults.matrix$relativeVarianceExplainedPerFactor


```

#GSEM Scratch area
```{r gSEM TEST scratch area, include=FALSE, eval=FALSE, purl=FALSE}
p$CFA$test<-c()

max(p$mvLD$covstruct.mvLDSC$S.smooth-p$mvLD$covstruct.mvLDSC$S.orig)

#p$mvLD$covstruct.mvLDSC$S<-p$mvLD$covstruct.mvLDSC$S.smooth
#p$mvLD$covstruct.mvLDSC$S<-p$mvLD$covstruct.mvLDSC$S.orig


p$CFA$test$lmodel<-"
F1 =~ 0.539641264951842*ADHD05+0.301549201476588*ANXI03+0.254983357523383*DEPR05+0.516478144100956*DEPR08+(-0.913884414704993)*HEAL01+0.550680494996066*INCO03+0.496387381827906*INSO02+0.294766753034134*MIGR01+(-0.211404258261124)*RISK02+(-0.361814282182997)*SUBJ01+0.773443804538135*TIRE01
F2 =~ 0.358713644817655*ALCD03+0.608742286980208*ANXI03+0.659101734283354*DEPR05+0.48894150805209*DEPR08+0.345469173361549*INSO02+0.933173107768295*NEUR01+(-0.283942826541694)*RISK02+(-0.692978677882566)*SUBJ01+0.334430724866043*TIRE01
F3 =~ 0.217320562834197*ADHD05+0.362548259169021*ALCD03+0.392626636082975*ANXI03+0.209526495296818*AUTI07+0.719358812724766*BIPO02+0.601432867622906*DEPR05+0.322194158145306*DEPR08+0.471966530358034*SCHI04+(-0.2086147893327*SUBJ01)+0.22790907391054*TIRE01
F4 =~ 0.834026681568278*ALCD03+0.338368216706376*DEPR05+0.298883066770123*DEPR08+0.517986168598069*INCO03+0.52623652437116*RISK03
F5 =~ 0.496871917208472*ANXI03+0.500470483364792*AUTI07+0.544236896104398*DEPR08+0.282647157511683*NEUR01+0.20837509707694*SCHI04+0.278253900439062*TIRE01
ADHD05~~ADHD05
ALCD03~~ALCD03
ANXI03~~ANXI03
AUTI07~~AUTI07
BIPO02~~BIPO02
DEPR05~~DEPR05
DEPR08~~DEPR08
HEAL01~~HEAL01
INCO03~~INCO03
INSO02~~INSO02
MIGR01~~MIGR01
NEUR01~~NEUR01
RISK02~~RISK02
RISK03~~RISK03
SCHI04~~SCHI04
SUBJ01~~SUBJ01
TIRE01~~TIRE01
F1~~1*F1
F2~~1*F2
F3~~1*F3
F4~~1*F4
F5~~1*F5
F1~~1*F2
F1~~1*F3
F1~~1*F4
F1~~1*F5
F2~~1*F3
F2~~1*F4
F2~~1*F5
F3~~1*F4
F3~~1*F5
F4~~1*F5
"

#p$lfGWAS$sumstats.test<-p$lfGWAS$sumstats[which(p$lfGWAS$sumstats$CHR=='22'),]
  
p$test$gwasResults<-usermodel.mod(
  covstruc = p$mvLD$covstruct.mvLDSC,
  model = p$CFA$test$lmodel,
  #model = p$efaSEM$lmodel,
  estimation = p$CFA$estimator,
  fix_resid = FALSE,
  CFIcalc = T,
  imp_cov = T
  )

p$test$gwasResults$modelfit
p$test$gwasResults$results

```
---
title: "GED MSc Research Project, Analysis Script, Setup 3"
author: "Johan Zvrskovec"
date: "03/09/2020"
output:
  html_document:
    fig_height: 6
    fig_width: 9
  pdf_document: default
  word_document:
    fig_height: 6
    fig_width: 9
---

```{r clean, include=FALSE}
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
gc() #free up memrory and report the memory usage.
```
# Title, Project references
**Genomic Structural Equation Modelling of GWAS Summary Statistics Outline the Genetic Architecture of Anxiety Disorder**


# Project settings
```{r settings}
project<-c() #create project metadata object
project$setup.version<-3
project$setup.code<-paste0("SETUP",project$setup.version)
project$filename.plain<-"analysis_setup3_20200903"
project$filename.rmd<-paste0(project$filename.plain,".Rmd")
project$filename.r<-paste0(project$filename.plain,".R")
project$date.run<-Sys.Date()

project$host<-"local" #this is the place where the code is run [local,cluster]
project$seting.refreshPrepareSummaryStatistics<-FALSE
project$setting.refreshLatentFactorGWAS<-FALSE

#file path settings
##set project shared working directory **change if you have other settings**
if(project$host=="local") {
project$folderpath<-normalizePath("~/King's College London/MT-Translational Neuropsychiatric Genomics - Johan_Zvrskovec_PhD - Johan_Zvrskovec_PhD/JZ_GED_RESEARCHPROJECT")
} else if (project$host=="cluster") {
project$folderpath<-normalizePath("/scratch/users/k19049801/project/JZ_GED_RESEARCHPROJECT")
}
##project working directory subfolders
project$folderpath.working_directory<-normalizePath(paste0(project$folderpath,"/","working_directory"))
project$folderpath.data<-normalizePath(paste0(project$folderpath,"/","data"))
project$folderpath.data_raw<-normalizePath(paste0(project$folderpath,"/","data_raw"))
project$folderpath.scripts<-normalizePath(paste0(project$folderpath,"/","scripts"))
project$folderpath.include<-normalizePath(paste0(project$folderpath,"/","include"))
project$folderpath.plots<-normalizePath(paste0(project$folderpath,"/","plots"))

##cleaned datasets folder
if(project$host=="local") {
  project$cleanedpath<-normalizePath("~/Documents/local_db/JZ_GED_RESEARCHPROJECT/data/cleaned")
} else if (project$host=="cluster") {
  project$cleanedpath<-normalizePath("/mnt/lustre/groups/ukbiobank/sumstats/cleaned")
}

##munged datasets folder
if(project$host=="local") {
  project$mungedpath<-normalizePath("~/Documents/local_db/JZ_GED_RESEARCHPROJECT/data/munged_noMHC")
} else if (project$host=="cluster") {
  project$mungedpath<-normalizePath("/mnt/lustre/groups/ukbiobank/sumstats/munged_noMHC")
}

##LD scores datasets folders (these strings need to have a trailing slash for the GSEM LDSC to work)
project$mvLDSCpath.ld <- paste0(project$folderpath.data_raw,"/eur_w_ld_chr/") #LD-scores
project$mvLDSCpath.wld <- paste0(project$folderpath.data_raw,"/eur_w_ld_chr/") #Weights, if different from LD-scores

##Reference file for calculating SNP variance across traits. Used in the preparation step for performing latent factor GWAS.
project$sumstats.refpath<-normalizePath(paste0(project$folderpath.data_raw,"/","reference.1000G.maf.0.005.txt")) #1000 genomes phase 3

#The vector of selected summary dataset codes to process for use in the GSEM modelling
project$code.sel<-c("DEPR05","ANXI03","NEUR01","TIRE01","SUBJ01","ALCD03","HEAL01")

#settings for generating automatic CFA model specifications from EFA results
#project$cfa.absCutoff=seq(0.01,0.99,by = 0.01)
project$cfa.absCutoff.2F.oblq=c(0.30,0.35,0.4) #for promax
project$cfa.absCutoff.2F.orth=c(0.35,0.4,0.45) #for varimax
project$cfa.absCutoff.3F.oblq=c(0.2,0.3,0.4) #for promax
project$cfa.absCutoff.3F.orth=c(0.2,0.3,0.4,0.5) #for varimax



project$cfa.estimator=c("ML","DWLS")
project$cfa.orthogonal=c(TRUE,FALSE)
project$cfa.fixedLoadings=c(TRUE,FALSE) 

#latent factor GWAS filter settings
project$info.filter=.6
project$maf.filter=0.01

#color theme settings
theme.color<-c()
theme.color$contrastDark1<-"#2D2D2D"
theme.color$contrastDark2<-"#CC99CC"
theme.color$contrastDark3<-"#6699CC"
theme.color$contrastDark4<-"#99CC99"
theme.color$contrastLight1<-"#66CCCC"
theme.color$contrastLight2<-"#FFCC66"
theme.color$contrastLight3<-"#F99157"
theme.color$contrastLight4<-"#F2777A"

setwd(dir = normalizePath(project$folderpath.working_directory))

```

```{r knitr setup, include=FALSE, purl=FALSE}
knitr::opts_chunk$set(echo = TRUE,comment=NA,prompt=FALSE,cache=FALSE)
knitr::opts_knit$set(root.dir=normalizePath(project$folderpath.working_directory))

```

```{r purl export, include=FALSE, purl=FALSE, eval=FALSE}
#running this will produce an R-script with the same name as the Rmd-file. Used for running the program on computational clusters (Rosalind), when the code just has to be run rather than creating a knitted output.
knitr::purl(project$filename.rmd)
  
```

```{r setup, echo=FALSE, warning=F}
getwd() #print wd

#package setup
#require(parameters) #not compatible with Genomic SEM models?

#remove.packages("GenomicSEM")
#devtools::install_github("MichelNivard/GenomicSEM",ref = 'v2.1') #specify branch for better stability
#devtools::install_github("MichelNivard/GenomicSEM") #master branch as default

#remove.packages("semPlate")
#devtools::install_github(repo = "k19049801/semPlate", host="github.kcl.ac.uk", ) #does not work
#devtools::install_local(path =  paste(project$folderpath.include,"/semPlate_0.1.tar.gz"))
#install.packages("skimr")
#install.packages("psych")
#install.packages("Matrix")
#install.packages("stats")
#remove.packages("semPlot")
#install.packages("semPlot") #from http://sachaepskamp.com/documentation/semPlot/semPaths.html
#devtools::install_github("SachaEpskamp/semPlot")
#install.packages("lavaanPlot")
#install.packages("tidyverse")
#install.packages("ggrepel")
#install.packages("DiagrammeR")
#install.packages("gt")
#install.packages("kableExtra")
#devtools::install_github("taiyun/corrplot", build_vignettes = TRUE)

library(GenomicSEM)
library(skimr)
library(psych)
library(Matrix)
library(stats)
#library(semPlot)
#library(lavaanPlot)

library(tidyverse)
library(ggrepel)
library(DiagrammeR)
library(gt)
library(kableExtra)
library(corrplot)

#source(normalizePath(paste0(project$folderpath.scripts,"/","gsem.usermodel.mod.R")))

```


# Project timeline
Analysis optimally finished by the end of June. 

# Background
## Prerequisites
Based on earlier discussion the research project will use the method Genomic SEM (Grotzinger et al. 2019) on primarily summary statistic type data. The project might also involve or prepare for future work on visualization of collected data in the GLAD project and attempts to improve performance of existing Genomic SEM program workflows.

An example of the application of Genomic SEM is the paper by Allegrini and colleagues (Allegrini et al. 2019).

A newer example is the recent preprint by Thorp et al. 2020: https://www.medrxiv.org/content/10.1101/2020.04.08.20057653v1

The project should follow the TNG SOP on project folder structure etc as much as possible:
https://docs.google.com/document/d/1uLwjQVmlqpNHSPMV1sukYiJ6Jsxh2iw7kOCNSoZFd5E/edit

## Project variations and ideas
MTAG is another method; a subtype of Genomic SEM that may be worth looking into.

## Psychiatric Disorders
```{r psychiatric disorder metadata}
#,echo=FALSE
project$psychiatricDisorder<-data.frame(
  code=c("ANXI","DEPR","BIPO","ALCD"),
  populationPrevalence=c(
    .16, #Any type of anxiety disorder, Via https://doi.org/10.1038/s41380-019-0559-1 (2019), originally from https://doi.org/10.1017/S1121189X00001421 (2009)
    .15, #MDD, from the LD-calculations in https://doi.org/10.1038/s41588-018-0090-3 (2018), but with a possible reference to https://doi.org/10.1146/annurev-publhealth-031912-114409 (2013) which states 11.1% lifetime prevalence of MDE.
    .007, #mean of male and female global prevalence rate (2013) from https://doi.org/10.1111/bdi.12423 (2016)
    .159 # From https://doi.org/10.1001/archpsyc.64.7.830 via the value used for European ancestry in https://doi.org/10.1038/s41593-018-0275-1 (how was this calculated though?)
    ), 
  reference_doi=c(
    "https://doi.org/10.1017/S1121189X00001421",
    "https://doi.org/10.1038/s41588-018-0090-3",
    "https://doi.org/10.1111/bdi.12423",
    "https://doi.org/10.1001/archpsyc.64.7.830"
    ))

project$psychiatricDisorder

project$psychiatricDisorder[which(project$psychiatricDisorder$code %in% c("ANXI","DEPR","ALCD")),] %>% 
  gt() %>% 
  fmt_number(columns = vars(populationPrevalence), decimals = 2) %>%
  tab_header(
    title = "Psychiatric disorder information",
  )

```

# Main objectives
1. Exploratory factor analysis (EFA) of genetic covariance matrices of anxiety, depression, bipolar disorder and possibly other datasets. Aim to find genetic latent factors for overall exogenous variables. Maybe add a factor for smoking or other addiction.
2. Confirmatory factor analysis (CFA) to confirm factors from 1.
3. Maybe genetic multivariable regression: correlations between unique anxiety/depression and trauma?
4. Discovery GWAS of SNP-effects in the common factors models - synthetic GWAS. Find effects of SNP’s on latent factors from 1,2.
5. Find specific, non-shared effects of SNP’s on latent factors from 1,2 (for each disorder, and for subtypes if possible).
6. Explain or possibly explore further steps of pathway analysis of implied functional variants.

# Datasets
I will use GWAS summary statistics datasets from the TNG/UK Biobank GWAS repository. Below follows a list of datasets from the repository referenced in the project. The datasets have gone through a cleaning step which has to be documented here further.

Datasets included in the current project setup have been selected to primarily include participants of European ancestry and corresponding European LD scores. To include datasets on individuals of other ancestry I would have to complete the analysis using LD scores corresponding to these ancestries as well.

The dataset metadata is completed with additional information required for the further analysis steps, in case it is missing in the obtained metadata from the TNG/UKBB GWAS repository. This data should optimally be fed back to the shared database/application.

Metadata completed here:
- Results from the preparatory LDSC step where rG was calculated with ANXI03 
- Data on the dataset DEPR05
- DOI links for all dataset publications, and PMID
- A variable for whether the effects are on a logistic scale or not.
- A variable for whether the effect SEs are on a logistic scale or not.
- A sample prevalence variable, based on the dataset n_case (number of cases) and n_total (total number of individuals).

```{r dataset metadata, warning=F}
#, echo=FALSE

project$sumstats<-read.table(paste0(project$folderpath.data_raw,"/","ukbb_sumstats_download202005.csv"), header=T, quote="\"", sep = ",", fill=T, blank.lines.skip=T,as.is = c(2), strip.white = T)
#View(project$sumstats)

project$sumstats.ldsc.rg.ANXI03 <- read.table(paste0(project$folderpath.data,"/","ANXI03_gc.txt"), header=T, quote="", sep = "") %>%
extract(col = p2, into = "code", regex = "_noMHC/(.*)_noMHC.sumstats.", remove = F, )
#View(project$sumstats.ldsc.rg.ANXI03)



#View(project$sumstats)

#rename and add columns
names(project$sumstats)[names(project$sumstats)=="n_cases"]<-"n_case"
names(project$sumstats)[names(project$sumstats)=="n_controls"]<-"n_control"
project$sumstats$gwas_name.nice<-NA_character_
project$sumstats$code.trait<-NA_character_
project$sumstats$reference_doi<-NA_character_
project$sumstats$effect.logit<-as.logical(NA)
project$sumstats$se.logit<-as.logical(NA)
project$sumstats$dependent_variable.OLS<-as.logical(NA)
project$sumstats$age.min<-NA_integer_
project$sumstats$age.max<-NA_integer_
project$sumstats$age.mean<-NA_real_
project$sumstats$age.sd<-NA_real_

#add missing datasets and data
project$sumstats[nrow(project$sumstats)+1,c("code","n_case","n_control","n_total","reference_doi")]=list(
  code=c("DEPR05"),
  n_case=16823,
  n_control=25632,
  n_total=42455,
  reference_doi=c("https://doi.org/10.1038/s41588-018-0090-3")
  )

#add previous ldsc results
project$sumstats <- project$sumstats %>%
  left_join(project$sumstats.ldsc.rg.ANXI03, by = "code")

#reformat columns
project$sumstats$gwas_name<-as.character(project$sumstats$gwas_name)
project$sumstats$gwas_name.nice<-project$sumstats$gwas_name

##Add comprehensive names as in the Google sheet
project$sumstats$gwas_name[which(project$sumstats$code=="DEPR05")]="Major depressive disorder (PGC2 29)"

##Add nice trait names to be used in the report
project$sumstats$gwas_name.nice[which(project$sumstats$code=="ALCD03")]="Alcohol dependence"
project$sumstats$gwas_name.nice[which(project$sumstats$code=="ANXI03")]="Anxiety disorder"
project$sumstats$gwas_name.nice[which(project$sumstats$code=="NEUR01")]="Neuroticism"
project$sumstats$gwas_name.nice[which(project$sumstats$code=="SUBJ01")]="Subjective well-being"
project$sumstats$gwas_name.nice[which(project$sumstats$code=="TIRE01")]="Self-reported tiredness"
project$sumstats$gwas_name.nice[which(project$sumstats$code=="DEPR05")]="Major depressive disorder"


##Add trait/disorder information
project$sumstats <- project$sumstats %>%
mutate(
  code.trait=substr(x = code, start = 1, stop = 4)
       ) %>%
  left_join(project$psychiatricDisorder[,c("code","populationPrevalence")], by = c("code.trait" = "code"))

##add reference year
project$sumstats$reference_year[which(project$sumstats$code=="ANXI03")]=2019
project$sumstats$reference_year[which(project$sumstats$code=="NEUR01")]=2016
project$sumstats$reference_year[which(project$sumstats$code=="DEPR05")]=2018

##Add doi links for easy access to dataset publication
project$sumstats$reference_doi[which(project$sumstats$code=="ALCD03")]="https://doi.org/10.1038/s41593-018-0275-1"
project$sumstats$reference_doi[which(project$sumstats$code=="ANXI03")]="https://doi.org/10.1038/s41380-019-0559-1"
project$sumstats$reference_doi[which(project$sumstats$code=="HEAL01")]="https://doi.org/10.1093/ije/dyw219"
project$sumstats$reference_doi[which(project$sumstats$code=="NEUR01")]="https://doi.org/10.1038/ng.3552"
project$sumstats$reference_doi[which(project$sumstats$code=="SUBJ01")]="https://doi.org/10.1038/ng.3552"
project$sumstats$reference_doi[which(project$sumstats$code=="TIRE01")]="https://doi.org/10.1038/mp.2017.5"


##Add PMID
project$sumstats$pmid[which(project$sumstats$code=="ANXI03")]="31748690"
project$sumstats$pmid[which(project$sumstats$code=="NEUR01")]="27089181"
project$sumstats$pmid[which(project$sumstats$code=="SUBJ01")]="27089181"
project$sumstats$pmid[which(project$sumstats$code=="DEPR05")]="29700475"

##add dependent variable type
project$sumstats$dependent_variable[which(project$sumstats$code=="NEUR01")]="continuous"
project$sumstats$dependent_variable[which(project$sumstats$code=="DEPR05")]="binary"

##add participant numbers
project$sumstats$n_total[which(project$sumstats$code=="NEUR01")]=170911

##add ancestry details
project$sumstats$ancestry[which(project$sumstats$code=="NEUR01")]="EUR"
project$sumstats$ancestry[which(project$sumstats$code=="DEPR05")]="EUR"

##add sex details
project$sumstats$sex[which(project$sumstats$code=="NEUR01")]="both"
project$sumstats$sex[which(project$sumstats$code=="DEPR05")]="both"

##add age range
project$sumstats$age.min[which(project$sumstats$code=="SUBJ01")]=40
project$sumstats$age.max[which(project$sumstats$code=="SUBJ01")]=73
project$sumstats$age.mean[which(project$sumstats$code=="SUBJ01")]=56.91
project$sumstats$age.sd[which(project$sumstats$code=="SUBJ01")]=7.93
project$sumstats$age.min[which(project$sumstats$code=="TIRE01")]=40
project$sumstats$age.max[which(project$sumstats$code=="TIRE01")]=73
project$sumstats$age.mean[which(project$sumstats$code=="TIRE01")]=56.91
project$sumstats$age.sd[which(project$sumstats$code=="TIRE01")]=7.93


##add data on whether effects are on log odds ratio or not
project$sumstats$effect.logit[which(project$sumstats$code=="ALCD03")]=T #Did not find the original readme for this, only looked at the readme for the 2018 subsequent release, and the data. Assuming log-scale from the naming of the variables (beta) and that it follows the standard of the 2018 release - explicitly states log scale beta. Values are consistent with regression betas or log OR. THESE MIGHT HAVE BEEN CONVERTED IN THE FLASK APP LATER THOUGH!! CHECK!!               
project$sumstats$effect.logit[which(project$sumstats$code=="ANXI03")]=F # Kirstin sort of confirm that she converted both effect and s.e. to linear scales. Data and readme is available from her KCL web site. Unclear which dataset was used for ANXI03 though. Confirm this later by comparing datasets?
project$sumstats$effect.logit[which(project$sumstats$code=="HEAL01")]=F #The original data including readme downloaded to data_raw/original. States "Beta" without explanation, and I assume linear beta.
project$sumstats$effect.logit[which(project$sumstats$code=="NEUR01")]=F #The official read-me states "regression beta"
project$sumstats$effect.logit[which(project$sumstats$code=="SUBJ01")]=F #The official read-me states "regression beta"
project$sumstats$effect.logit[which(project$sumstats$code=="TIRE01")]=F #The official read-me states "beta"
project$sumstats$effect.logit[which(project$sumstats$code=="DEPR05")]=F #https://www.med.unc.edu/pgc/files/2019/04/PGC_MDD_2018_README_third_180316.pdf # The readme states daner format, but that SE is s.e. of log(OR), while the daner format does not state log scale variables here. Assuming linear scale OR, which is consistent with the data.

##add data on whether the SEs are on a logistic scale or not
project$sumstats$se.logit[which(project$sumstats$code=="ALCD03")]=T #Did not find the original readme for this, only looked at the readme for the 2018 subsequent release, and the data. SE is strangely set to 1 for top rows. Assumes this is true because of log-scale beta.
project$sumstats$se.logit[which(project$sumstats$code=="ANXI03")]=F #Assume linear becasue of Kirstin Purves assuring that both were converted to linear scale.
project$sumstats$se.logit[which(project$sumstats$code=="HEAL01")]=F #Assume linear scale because of linear beta
project$sumstats$se.logit[which(project$sumstats$code=="NEUR01")]=F #Assume linear scale because of linear beta
project$sumstats$se.logit[which(project$sumstats$code=="SUBJ01")]=F #Assume linear scale because of linear beta
project$sumstats$se.logit[which(project$sumstats$code=="TIRE01")]=F #Assume linear scale because of linear beta
project$sumstats$se.logit[which(project$sumstats$code=="DEPR05")]=F #Assume linear scale because of linear OR


##add information on wether a continous dependent variable was analysed using an OLS (linear) estimator. Used for the latent factor GWAS preparation step.
project$sumstats$dependent_variable.OLS[which(project$sumstats$code=="ALCD03")]=F
project$sumstats$dependent_variable.OLS[which(project$sumstats$code=="ANXI03")]=F
project$sumstats$dependent_variable.OLS[which(project$sumstats$code=="DEPR05")]=F
project$sumstats$dependent_variable.OLS[which(project$sumstats$code=="HEAL01")]=T
project$sumstats$dependent_variable.OLS[which(project$sumstats$code=="NEUR01")]=T
project$sumstats$dependent_variable.OLS[which(project$sumstats$code=="SUBJ01")]=T
project$sumstats$dependent_variable.OLS[which(project$sumstats$code=="TIRE01")]=T



##add sample prevalence for all datasets
project$sumstats$sample_prevalence<-project$sumstats$n_case/project$sumstats$n_total

##define selected sumstats as in the selected set of datset codes
project$sumstats.sel<-project$sumstats[which(project$sumstats$code %in% project$code.sel),]

#save the project data
saveRDS(project,file = paste0(project$folderpath.working_directory,"/","project.",project$setup.code,".Rds"))

```

## Selected datasets for this analysis
```{r display selected sumstat datasets, fig.width=9, fig.height=6, out.width="1600px", out.height="1000px"}
project$sumstats.sel[,c("code","gwas_name","ancestry","sex", "dependent_variable","n_total","reference_year","sample_prevalence","populationPrevalence","se.logit","pmid","reference_doi")]

```



# Project Steps

## Munge and split of summary statistics
This is a step where the original cleaned summary statistics are converted into a file format that is suitable for the LDSC procedure later - munged. There are already previously munged data available on the Rosalind cluster as part of an internal UKBB summary statistics pipeline. The path to the munged datasets is specified by the mungedpath-folder setting. Variants located in the MHC-region have been removed before munging.

```{r prepare data for analysis}

#source("../scripts/prepare_data_for_analysis.R")

#munged data is here
project$mungedpath

```

## Multivariate LDSC
The multivariate LDSC procedure calculates genetic correlations between the different traits and estimates of correlation standard errors, producing S (variances and covariances = heritabilities and coheritabilities) and V (diagonal: squared standard errors of elements in S. Off-diagonal: Covariances of elements in S - "dependencies between estimation errors used to model dependencies due to sample overlap") matrices used later in the Genomic SEM model fitting.

```{r multivariate LDSC}

if (file.exists(paste0(project$folderpath.working_directory,"/","mvLDSC.",project$setup.code,".Rds"))) {
  mvLDSC<-readRDS(file=paste0(project$folderpath.working_directory,"/","mvLDSC.",project$setup.code,".Rds"))
} else {
  print("Running multivariate LDSC. This might take a while.")
  mvLDSC<-c()
  mvLDSC$trait<-c()
  mvLDSC$populationPrevalence<-c()
  mvLDSC$trait.name<-c()
  #could probably use regex here somehow:
  #grep(pattern = "ALCD",x = project$sumstats.sel$code,perl = T, value = F)
  for(cCode in project$sumstats.sel$code) {
    mvLDSC$trait<-c(mvLDSC$trait,paste0(project$mungedpath,"/",cCode,"_noMHC.sumstats.gz"))
    
    popPrevToAdd<-NA_real_
    
    if(cCode %in% c("ALCD01","ALCD03")) {
      popPrevToAdd=project$psychiatricDisorder$populationPrevalence[which(project$psychiatricDisorder$code=="ALCD")]
    } else if (cCode %in% c("ANXI03","ANXI09")) {
      popPrevToAdd=project$psychiatricDisorder$populationPrevalence[which(project$psychiatricDisorder$code=="ANXI")]
    } else if (cCode %in% c("DEPR05","DEPR09")) {
      popPrevToAdd=project$psychiatricDisorder$populationPrevalence[which(project$psychiatricDisorder$code=="DEPR")]
    }
    
    mvLDSC$populationPrevalence<-c(mvLDSC$populationPrevalence,popPrevToAdd)
  }
  
  
  project$sumstats.sel[,c("code","sample_prevalence")]
  mvLDSC$trait
  mvLDSC$populationPrevalence
  
  #run multivariable LDSC
  mvLDSC$output<-ldsc(mvLDSC$trait, project$sumstats.sel$sample_prevalence, mvLDSC$populationPrevalence, project$mvLDSCpath.ld, project$mvLDSCpath.wld, project$sumstats.sel$code,ldsc.log = project$setup.code)
  #View(mvLDSC$output$V)
  #View(mvLDSC$output$S)
  #View(mvLDSC$output$I)
  #View(mvLDSC$output$N)
  
  #prouce the standard errors of S (variances and covariances) from the diagonal of V (contains both).
  mvLDSC$output$S.k<-nrow(mvLDSC$output$S)
  mvLDSC$output$S.SE<-matrix(0, mvLDSC$output$S.k, mvLDSC$output$S.k)
  mvLDSC$output$S.SE[lower.tri(mvLDSC$output$S.SE,diag=TRUE)] <-sqrt(diag(mvLDSC$output$V))
  
  #save the LDSC output
  saveRDS(object = mvLDSC,file = paste0(project$folderpath.working_directory,"/","mvLDSC.",project$setup.code,".Rds"))
  print("LDSC is done now and the result should have been saved into a file.")
  
  
}

#mvLDSC$output$V
mvLDSC$output$S
mvLDSC$output$I
mvLDSC$output$N
mvLDSC$output$m

#make a version of the covariance structure with the trait names rather than the dataset coded names
mvLDSC$output.traits<-mvLDSC$output
colnames(mvLDSC$output.traits$S)<-project$sumstats.sel$code.trait

#calculate the genetic correlation matrix from the covariance matrix - this could have been avoided if we specified to also calculate the correlation matrix from the ldsc-function above.
mvLDSC$S_Cor<-cov2cor(mvLDSC$output$S)
#Testing different correlation tests
#mvLDSC$cor.test[[1,1]]<-cortest(R1 = mvLDSC$output$S[[1,1]], n1 = mvLDSC$output$N[1])
#mvLDSC$cor.test[[1,1]]<-cor.test(x = mvLDSC$output$S[[1,1]], n1 = mvLDSC$output$N[1])

#complete the selected metadata with variables from the multivariate LDSC outoput
#perform pairwise correlation test for each pair of traits **NOT DONE**

for(iTrait in 1:nrow(project$sumstats.sel)) {
  project$sumstats.sel$h2.liability[iTrait]<-mvLDSC$output$S[[iTrait,iTrait]]
  # for(iTrait2 in 1:iTrait) {
  #   mvLDSC$cor.test[[iTrait,iTrait2]]<-cortest(R1 = mvLDSC$output$S[[iTrait,iTrait2]], n1 = mvLDSC$output$N[iTrait,iTrait2],)
  # }
}

```

## Overview of previous ANXI03 rG calculations with LDSC, FIGURE 1
```{r display anxi rG, fig.width=9, fig.height=6, out.width="1000px", out.height="600px"}
#View(project$sumstats.sel)

figure1_anxi03RG<-ggplot(
  data = project$sumstats.sel, 
  mapping = 
         aes(x = h2.liability,
             y = rg)) +
         geom_point(
             aes(
             colour=se,
             size=100*se
             )
           ) +
  
  geom_label_repel(aes(
    label=as.character(paste0(code.trait," [",round(h2.liability,digits = 2),",",round(rg,digits = 2),"(",round(se,digits = 2),")]"  ))
    ),
                  box.padding   = 1.9,#0.9, 
                  point.padding = 0.7,
                  segment.color = theme.color$contrastDark1,
                  size = 5,
                  segment.size = 0.3,
                  segment.alpha = 0.7
                  ) +
  
  scale_size_continuous(range = c(5,30), guide = FALSE) +
  
  scale_color_gradientn(colours = c(theme.color$contrastDark3,theme.color$contrastLight3)) +
  
  geom_hline(
    yintercept = 0,
    color = theme.color$contrastDark2,
    size=1,
    linetype="twodash") +
  
  labs(y = expression(~r[g]),
       x = "SNP heritability, liability scale"
       #title = "Selected traits showing |rG| > .4 (p<1e-5) with the anxiety disorder trait (ANXI)") +
  ) +
  theme_bw() + 
  theme(
    axis.text=element_text(size=18),
    axis.title=element_text(size=20,face="bold"),
    legend.text=element_text(size=20),
    legend.title=element_text(size=18,face="bold")
    )

figure1_anxi03RG

png(filename = paste0(project$folderpath.plots,"/","figure1.png"), width = 1000, height = 600)
figure1_anxi03RG
dev.off()

```

## Overview of rG between selected traits FIGURE 2
```{r overview pairwise rG, fig.width=9, fig.height=6, out.width="1600px", out.height="1000px"}


colnames(mvLDSC$S_Cor)<-project$sumstats.sel$code.trait
rownames(mvLDSC$S_Cor)<-colnames(mvLDSC$S_Cor)

#mvLDSC$P_Cor<-cortest(R1 = mvLDSC$S_Cor,n1 = 10000 )

palette<-colorRampPalette(c(theme.color$contrastDark3,theme.color$contrastLight3))

figure2_rG<-corrplot(
  corr = mvLDSC$S_Cor,
  order = "hclust",
  hclust.method = "ward.D",
  method = "square",
  type="full",
  addCoef.col = theme.color$contrastDark1,
  addgrid.col = theme.color$contrastDark1,
  col = palette(200),
  is.corr = TRUE,
  outline = TRUE,
  addrect = 3,
  rect.col = theme.color$contrastLight1,
  rect.lwd = 10,
  tl.cex = 3,
  tl.col = theme.color$contrastDark2,
  tl.srt = 75,
  cl.cex = 2,
  cl.ratio = 0.2,
  number.cex = 1.9
  )

png(filename = paste0(project$folderpath.plots,"/","figure2.png"), width = 1000, height = 800)
figure2_rG<-corrplot(
  corr = mvLDSC$S_Cor,
  order = "hclust",
  hclust.method = "ward.D",
  method = "square",
  type="full",
  addCoef.col = theme.color$contrastDark1,
  addgrid.col = theme.color$contrastDark1,
  col = palette(200),
  is.corr = TRUE,
  outline = TRUE,
  addrect = 3,
  rect.col = theme.color$contrastLight1,
  rect.lwd = 10,
  tl.cex = 3,
  tl.col = theme.color$contrastDark2,
  tl.srt = 75,
  cl.cex = 2,
  cl.ratio = 0.2,
  number.cex = 1.9
  )
dev.off()

```

## Improved annotation of chosen datasets

```{r improved annotation of chosen datasets, fig.width=9, fig.height=6, out.width="1600px", out.height="1000px"}
skim(project$sumstats.sel)
project$sumstats.sel.table<-project$sumstats.sel[,c("gwas_name.nice","dependent_variable","n_total","reference_year","sample_prevalence","populationPrevalence")]
rownames(project$sumstats.sel.table)<-NULL #Remove the rowname column




for(iTrait in 1:nrow(project$sumstats.sel)) {
  project$sumstats.sel.table$h2.liability[iTrait]<-mvLDSC$output$S[[iTrait,iTrait]]
}

#project$sumstats.sel.table.names<-c("Trait","Dependent variable","Total number of participants","Reference year","Sample prevalence","Population prevalence", "Heritability(Liability Scale)")

#expression("h"^2)

project$sumstats.sel.table

project$plots.table1<-project$sumstats.sel.table %>% 
  gt() %>% 
  fmt_number(columns = vars(sample_prevalence, populationPrevalence, h2.liability), decimals = 2) %>%
  fmt_number(columns = vars(n_total), decimals = 0) %>%
  tab_header(
    title = "Selected GWAS summary statistics datasets"
  ) %>% cols_label(
    gwas_name.nice = "Trait",
    #ancestry = "Ancestry",
    #sex = "Sex",
    dependent_variable = "Dependent variable",
    n_total = "Total number of participants",
    reference_year = "Reference year",
    sample_prevalence = "Sample prevalence",
    populationPrevalence = "Population prevalence",
    h2.liability = html("h<sup>2</sup><sub>SNP,liability scale</sub>")
    
  ) %>%
  tab_style(
    style = cell_text(size = px(12)),
    locations = cells_column_labels(everything())       
  ) %>%
  tab_style(
    style = cell_text(size = px(12),weight = "bold"),
    locations = cells_body(everything())        
  )

project$plots.table1

gtsave(data = project$plots.table1, filename = paste0(project$folderpath.plots,"/Table1.rtf"))




# project$sumstats.sel.table %>% 
#   kable(col.names = project$sumstats.sel.table.names, row.names = FALSE) %>%
#   kable_styling()



```




## Exploratory Factor Analysis
EFA using the stats package using both orthogonal and oblique rotations with 3 factors. 4 factors are too many for 7 variables.

In the case of orthogonal rotation the squared factor loadings represent the amount of explained variance. SS (sum of squares) loadings are the sum of these squared loadings and represents the amount of explained variance per factor.

```{r EFA, purl=FALSE, fig.width=9, fig.height=6, out.width="1600px", out.height="1000px}

#scree(mvLDSC$S_Cor, pc=FALSE)

fa.parallel(mvLDSC$S_Cor, fa = "fa")
png(filename = paste0(project$folderpath.plots,"/","PlotScree.png"), width = 800, height = 500)
fa.parallel(mvLDSC$S_Cor, fa = "fa")
dev.off()


mvLDSC$output$S.smooth<-as.matrix((nearPD(mvLDSC$output$S, corr = FALSE))$mat)

#1 factor 
print("1 factor******************")
# 
# print("Rotation: Promax (Oblique)")
# EFA.promax<-factanal(
#   covmat = mvLDSC$output$S.smooth,
#   n.obs = max(mvLDSC$output$N),
#   factors = 1,
#   rotation = "promax"
#   )
# #print the loadings for each factor
# print(EFA.promax$loadings, cutoff = 0.10)

print("Rotation: Varimax (Orthogonal)")
EFA.1F.varimax<-factanal(
  covmat = mvLDSC$output$S.smooth,
  n.obs = max(mvLDSC$output$N),
  factors = 1,
  rotation = "varimax"
  )
#print the loadings for each factor
print(EFA.1F.varimax$loadings, cutoff = 0.10)


print("2 factors*****************")

print("Rotation: Promax (Oblique)")
EFA.2F.promax<-factanal(
  covmat = mvLDSC$output$S.smooth,
  n.obs = max(mvLDSC$output$N),
  factors = 2,
  rotation = "promax"
  )
#print the loadings for each factor
print(EFA.2F.promax$loadings, cutoff = 0.10)

print("Rotation: Varimax (Orthogonal)")
EFA.2F.varimax<-factanal(
  covmat = mvLDSC$output$S.smooth,
  n.obs = max(mvLDSC$output$N),
  factors = 2,
  rotation = "varimax"
  )
#print the loadings for each factor
print(EFA.2F.varimax$loadings, cutoff = 0.10)


print("3 factors*****************")

print("Rotation: Promax (Oblique)")
EFA.3F.promax<-factanal(
  covmat = mvLDSC$output$S.smooth,
  n.obs = max(mvLDSC$output$N),
  factors = 3,
  rotation = "promax"
  )
#print the loadings for each factor
print(EFA.3F.promax$loadings, cutoff = 0.10)

print("Rotation: Varimax (Orthogonal)")
EFA.3F.varimax<-factanal(
  covmat = mvLDSC$output$S.smooth,
  n.obs = max(mvLDSC$output$N),
  factors = 3,
  rotation = "varimax"
  )
#print the loadings for each factor
print(EFA.3F.varimax$loadings, cutoff = 0.10)


#create results table - manually!
project$efa<-data.frame()
project$efa.initialNames<-c("nFactors","rotation","dof","cumulativeVariance")
project$efa.factorLoadingNames.F1<-c(
  "F1.ALCD","F1.ANXI","F1.HEAL","F1.NEUR","F1.SUBJ","F1.TIRE","F1.DEPR"
  )
project$efa.factorLoadingNames.F2<-c(
  "F2.ALCD","F2.ANXI","F2.HEAL","F2.NEUR","F2.SUBJ","F2.TIRE","F2.DEPR"
  )
project$efa.factorLoadingNames.F3<-c(
  "F3.ALCD","F3.ANXI","F3.HEAL","F3.NEUR","F3.SUBJ","F3.TIRE","F3.DEPR"
  )
project$efa.factorLoadingNames<-c(project$efa.factorLoadingNames.F1,project$efa.factorLoadingNames.F2,project$efa.factorLoadingNames.F3)

project$efa[1,project$efa.initialNames]<-
  list(
  EFA.1F.varimax$factors,
  "either",
  EFA.1F.varimax$dof,
  0.581
)
project$efa[1,project$efa.factorLoadingNames]<-NA_real_
project$efa[1,project$efa.factorLoadingNames.F1]<-EFA.1F.varimax$loadings[1:7,1]

project$efa[nrow(project$efa)+1,project$efa.initialNames]<-
  list(
  EFA.2F.promax$factors,
  "promax",
  EFA.2F.promax$dof,
  0.741
)
project$efa[nrow(project$efa),project$efa.factorLoadingNames.F1]<-EFA.2F.promax$loadings[1:7,1]
project$efa[nrow(project$efa),project$efa.factorLoadingNames.F2]<-EFA.2F.promax$loadings[1:7,2]

project$efa[nrow(project$efa)+1,project$efa.initialNames]<-
  list(
  EFA.2F.varimax$factors,
  "varimax",
  EFA.2F.varimax$dof,
  0.711
)
project$efa[nrow(project$efa),project$efa.factorLoadingNames.F1]<-EFA.2F.varimax$loadings[1:7,1]
project$efa[nrow(project$efa),project$efa.factorLoadingNames.F2]<-EFA.2F.varimax$loadings[1:7,2]

project$efa[nrow(project$efa)+1,project$efa.initialNames]<-
  list(
  EFA.3F.promax$factors,
  "promax",
  EFA.3F.promax$dof,
  0.750
)
project$efa[nrow(project$efa),project$efa.factorLoadingNames.F1]<-EFA.3F.promax$loadings[1:7,1]
project$efa[nrow(project$efa),project$efa.factorLoadingNames.F2]<-EFA.3F.promax$loadings[1:7,2]
project$efa[nrow(project$efa),project$efa.factorLoadingNames.F3]<-EFA.3F.promax$loadings[1:7,3]

project$efa[nrow(project$efa)+1,project$efa.initialNames]<-
  list(
  EFA.3F.varimax$factors,
  "varimax",
  EFA.3F.varimax$dof,
  0.762
)
project$efa[nrow(project$efa),project$efa.factorLoadingNames.F1]<-EFA.3F.varimax$loadings[1:7,1]
project$efa[nrow(project$efa),project$efa.factorLoadingNames.F2]<-EFA.3F.varimax$loadings[1:7,2]
project$efa[nrow(project$efa),project$efa.factorLoadingNames.F3]<-EFA.3F.varimax$loadings[1:7,3]

#View(project$efa)

#vars( cumulativeVariance, F1.ALCD,F1.ANXI,F1.HEAL,"F1.NEUR","F1.SUBJ","F1.TIRE","F1.DEPR")

project$plots.tableEFA<-project$efa %>% 
  gt() %>% 
  fmt_number(columns = 4:ncol(project$efa), decimals = 2) %>%
  fmt_number(columns = vars(nFactors,dof), decimals = 0) %>%
  tab_header(
    title = "Exploratory factor analysis"
  ) %>% cols_label(
    nFactors = "nf",
    rotation = "rot",
    dof = "df",
    cumulativeVariance = "cvar",
    F1.ALCD = "ALCD", F1.ANXI="ANXI", F1.DEPR="DEPR", F1.HEAL="HEAL", F1.NEUR="NEUR", F1.SUBJ="SUBJ", F1.TIRE="TIRE",
    F2.ALCD = "ALCD", F2.ANXI="ANXI", F2.DEPR="DEPR", F2.HEAL="HEAL", F2.NEUR="NEUR", F2.SUBJ="SUBJ", F2.TIRE="TIRE",
    F3.ALCD = "ALCD", F3.ANXI="ANXI", F3.DEPR="DEPR", F3.HEAL="HEAL", F3.NEUR="NEUR", F3.SUBJ="SUBJ", F3.TIRE="TIRE"
  ) %>%
  tab_spanner(
    label = "F1",
    columns = vars(F1.ALCD, F1.ANXI, F1.DEPR, F1.HEAL, F1.NEUR, F1.SUBJ, F1.TIRE)
  ) %>%
  tab_spanner(
    label = "F2",
    columns = vars(F2.ALCD, F2.ANXI, F2.DEPR, F2.HEAL, F2.NEUR, F2.SUBJ, F2.TIRE)
  ) %>%
  tab_spanner(
    label = "F3",
    columns = vars(F3.ALCD, F3.ANXI, F3.DEPR, F3.HEAL, F3.NEUR, F3.SUBJ, F3.TIRE)
  ) %>%
  tab_style(
    style = cell_text(size = px(12)),
    locations = cells_column_labels(everything())       
  ) %>%
  tab_style(
    style = cell_text(size = px(12),weight = "bold"),
    locations = cells_body(everything())        
  ) %>%
  data_color(
    columns = c(project$efa.factorLoadingNames.F1,project$efa.factorLoadingNames.F2,project$efa.factorLoadingNames.F3),    #vars(population),
    colors = scales::col_numeric(
      palette = c(theme.color$contrastDark3,theme.color$contrastLight3),
      domain = c(-1.2,1.2))
  )

project$plots.tableEFA

# png(filename = paste0(project$folderpath.plots,"/","TableEFA.png"), width = 800, height = 500)
# project$plots.tableEFA
# dev.off()


gtsave(data = project$plots.tableEFA, filename = paste0(project$folderpath.plots,"/TableEFA.rtf"))
gtsave(data = project$plots.tableEFA, filename = paste0(project$folderpath.plots,"/TableEFA.png"), vwidth="1450")


```



```{r old EFA, include=FALSE, purl=FALSE}
#EFA using the psych package - did not work for some reason
#EFA.SETUP2<- psych::fa(
#  r = mvLDSC$output$S.smooth,
#  covar = T, #using a covariance matrix rather that a correlation matrix
#  nfactors = 3, #number of factors
#  n.obs = max(mvLDSC$output$N), #number of observations, required for correlation matrixes
#  n.iter = 1000, #Number of bootstrap interations to do in fa
#  rotate = "oblimin", #rotation, oblimin allows the factors to be correlated
#  fm = "ml", #for normal data - "ml" (maximum likelihood) is preferred, if you have skewed ordinal data, "wls" (weighted least squares) is preferred
#  scores = TRUE
#  )
#EFA.SETUP2

#print the loadings for each factor
#print(EFA.SETUP2$loadings, cutoff = 0.01)

#u2 is uniqueness - unique variance
#h2 is communality - common variance 

```


## Confirmatory Factor Analysis
Here are models exploring situations where the ANXI loading on the anxiety factor is preferably fixed to 1 and where the loadings generally are reflecting the results from the EFA.


### Define model actions
Functions to evaluate a model and to construct a lavaan definition from a model load specification
```{r CFA model actions, purl=FALSE}

project$model.define<-function(code.indicator, allow_loading.table.indicator_factor, fix_loading.table.indicator_factor=NULL, special.orthogonal=FALSE){
  #lavaan definition string
  lds<-""
  lds.factorSelf=""
  lds.factorOther=""
  
  nFactors<-ncol(allow_loading.table.indicator_factor)
  nIndicators<-nrow(allow_loading.table.indicator_factor)
  
  #factor loadings, factor variances
  for(iFactor in 1:nFactors){
    lds.factor=paste0("
                      F",iFactor," =~ ")
    
    hasFactor=FALSE
    for(iIndicator in 1:nIndicators){
      if(allow_loading.table.indicator_factor[iIndicator,iFactor]==TRUE){
        
        if(hasFactor==TRUE)
          lds.factor=paste0(lds.factor,"+")
          
        if(is.null(fix_loading.table.indicator_factor)==FALSE) {
          #use fixed loadings
          if(fix_loading.table.indicator_factor[iIndicator,iFactor]==TRUE) {
              vFixLoading="1*" #show this for both cases for clarity
          } else {
            if(hasFactor==TRUE)
              vFixLoading="" else
              vFixLoading="NA*"
          }
        } else {
          #do not use fixed loadings
          if(hasFactor==TRUE)
            vFixLoading="" else
            vFixLoading="NA*"
        }
           
        lds.factor=paste0(lds.factor,vFixLoading,code.indicator[iIndicator])
        hasFactor=TRUE
      }
    }
    if(hasFactor==TRUE){
      lds=paste0(lds,lds.factor)
      lds.factorSelf=paste0(lds.factorSelf,"
                            F",iFactor,"~~1*F",iFactor)
    }
  }
  
indexFactor<-data.frame(index=c(1:nFactors))
indexFactor<-indexFactor %>%
inner_join(indexFactor, by = character())


lds.factorOther=""

for(iComb in 1:nrow(indexFactor)) {
  row<-indexFactor[iComb,]
  if(row$index.x==row$index.y || row$index.y < row$index.x)
    next()
  
  if(special.orthogonal)
    lds.factorOther=paste0(lds.factorOther,"
                           F",row$index.x,"~~0*F",row$index.y) else
    lds.factorOther=paste0(lds.factorOther,"
                           F",row$index.x,"~~F",row$index.y)
}
  
return(paste0(lds,lds.factorSelf,lds.factorOther))
  
 
}

#test
# lavaanDefinition<-project$model.define(code.indicator = project$sumstats.sel$code.trait, allow_loading.table.indicator_factor = data.frame(
#   F1=c(TRUE,TRUE,FALSE,TRUE,TRUE,TRUE,TRUE),
#   F2=c(TRUE,FALSE,TRUE,FALSE,FALSE,TRUE,FALSE),
#   F3=c(FALSE,TRUE,FALSE,TRUE,TRUE,FALSE,TRUE)                                                                           ),
#   fix_loading.table.indicator_factor = data.frame(
#   F1=c(FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE),
#   F2=c(FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE),
#   F3=c(FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE)                                                                           ),
#   special.orthogonal = TRUE
#   )

# lavaanDefinition<-project$model.define(code.indicator = project$sumstats.sel$code.trait, allow_loading.table.indicator_factor = data.frame(
#   F1=c(TRUE,TRUE,FALSE,TRUE,TRUE,TRUE,TRUE),
#   F2=c(TRUE,FALSE,TRUE,FALSE,FALSE,TRUE,FALSE),
#   F3=c(FALSE,TRUE,FALSE,TRUE,TRUE,FALSE,TRUE)                                                                           ),
#   fix_loading.table.indicator_factor = NULL,
#   special.orthogonal = TRUE
#   )


project$model.calculateLogicalLoadingsFromEFA<-function(loadings.table.indicator_factor,absCutoff){
  return(as.data.frame(abs(loadings.table.indicator_factor) > absCutoff ))
}

#computes which of the second row (ANXI) loadings is the largest and sets the fixed loading logic
project$model.calculateLogicalFixedLoadingsFromEFA<-function(loadings.table.indicator_factor){
  #loadings.table.indicator_factor=project$cfa.loadings.EFA[[1]]$loadings #TEST
  toreturn<-data.frame(matrix(FALSE,ncol = ncol(loadings.table.indicator_factor),nrow = nrow(loadings.table.indicator_factor)))
  toreturn[2,]<-(rank(x = -loadings.table.indicator_factor[2,],ties.method = "first")==1)
  return(as.data.frame(toreturn))
}

project$model.evaluate<-function(covstruc, model, estimation="ML", code="defaultEvaluatedModel"){
  
  uModel<-usermodel(covstruc = covstruc, estimation = estimation, model = model)
    
  uModel$results$Unstand_SE<-as.numeric(uModel$results$Unstand_SE)
  uModel$results$STD_Genotype_SE<-as.numeric(uModel$results$STD_Genotype_SE)
  
  uModel$semResults<-semPlate::parseSEMResult(resultDf = uModel$results)
  uModel$path.graph.dot<-semPlate::generateDOT(nodeDf = uModel$semResults$nodeDf, edgeDf = uModel$semResults$edgeDf)
  
  f<-file(paste0(project$folderpath.plots,"/figure.path_",code,".dot.gv"))
  writeLines(uModel$path.graph.dot,f)
  close(f)
  
  grViz(uModel$path.graph.dot)
  
  png(filename = paste0(project$folderpath.plots,"/figure.path_",code,".png"), width = 800, height = 500)
  grViz(uModel$path.graph.dot)
  dev.off()
  
  
  tableModelFit<-uModel$modelfit %>% 
  gt() %>% 
  tab_header(
    title = "Model fit",
  )
  tableModelFit
  gtsave(data = tableModelFit, filename = paste0(project$folderpath.plots,"/table.modelFit_",code, ".rtf"))
  
  tableModelLoadings<-uModel$results %>% 
  gt() %>% 
  fmt_number(columns = vars(Unstand_Est,Unstand_SE,STD_Genotype,STD_Genotype_SE,STD_All), decimals = 2) %>%
  fmt_scientific(columns = vars(p_value), decimals = 2) %>%
  tab_header(
    title = "Loadings",
  )
  tableModelLoadings
  gtsave(data = tableModelLoadings, filename = paste0(project$folderpath.plots,"/table.modelLoadings_",code, ".rtf"))
  return(uModel)
    
}

```


### Generate model configurations automatically from the EFA results
Procedure to construct model load configurations from EFA loadings
```{r Generate CFA model specifications, purl=FALSE}
project$cfa.loadings.EFA=list(EFA.1F.varimax, EFA.2F.promax, EFA.2F.varimax, EFA.3F.promax, EFA.3F.varimax)
project$cfa.loadings.EFA.rotMethod=list("varimax", "promax", "varimax", "promax", "varimax")

#vLogicalFixedLoadings.FALSE=data.frame(matrix(FALSE,ncol = 3, nrow=3))
vLogicalFixedLoadings.FALSE=NULL

project$cfa.lc<-data.frame()
project$cfa.lc.initialNames<-c("nLatentFactor","estimator","hasOrthogonalFactorCorrelations","hasFixedLoadings","logicalLoadings","logicalFixedLoadings","factanalRotation","factanalLoadingCutoff")

project$cfa.lc.factorLoadingNames.F1<-c(
"F1.ALCD","F1.ANXI","F1.HEAL","F1.NEUR","F1.SUBJ","F1.TIRE","F1.DEPR"
)
project$cfa.lc.factorLoadingNames.F2<-c(
"F2.ALCD","F2.ANXI","F2.HEAL","F2.NEUR","F2.SUBJ","F2.TIRE","F2.DEPR"
)
project$cfa.lc.factorLoadingNames.F3<-c(
"F3.ALCD","F3.ANXI","F3.HEAL","F3.NEUR","F3.SUBJ","F3.TIRE","F3.DEPR"
)
project$cfa.lc.factorLoadingNames<-c(project$cfa.lc.factorLoadingNames.F1,project$cfa.lc.factorLoadingNames.F2,project$cfa.lc.factorLoadingNames.F3)

# if(is.null(estimatorToUse))
#   estimator<-c("MR","DWLS") else
# if(estimatorToUse=="MR")
#   estimator=c("MR") else
# if(estimatorToUse=="DWLS")
#   estimator=c("DWLS")
# 
# if(is.null(special.orthogonal))
#   orthogonal<-c(TRUE,FALSE) else
# if(special.orthogonal==TRUE)
#   orthogonal<-c(TRUE) else
# if(special.orthogonal==FALSE)
#   orthogonal<-c(FALSE)
# 
# if(is.null(special.fixedLoadings))
#   fixedLoadings<-c(TRUE,FALSE) else
# if(special.fixedLoadings==TRUE)
#   fixedLoadings<-c(TRUE) else
# if(special.fixedLoadings==FALSE)
#   fixedLoadings<-c(FALSE)
  

iLC=1
for(iLoadings in 1:length(project$cfa.loadings.EFA)){
  
  #set cutoff and rotation based on EFA method
  vRotMethod = project$cfa.loadings.EFA.rotMethod[[iLoadings]]
  vNFactors = ncol(project$cfa.loadings.EFA[[iLoadings]]$loadings)
  if(vRotMethod=="varimax") {
    vOrthogonal=TRUE
    if(vNFactors==1 || vNFactors ==2)
      vRotMethod.absCutoffs=project$cfa.absCutoff.2F.orth
    else if(vNFactors==3)
      vRotMethod.absCutoffs=project$cfa.absCutoff.3F.orth
      
  } else if (vRotMethod=="promax") {
    vOrthogonal=FALSE
    if(vNFactors==1)
      vRotMethod.absCutoffs=project$cfa.absCutoff.2F.orth
    else if(vNFactors==2)
      vRotMethod.absCutoffs=project$cfa.absCutoff.2F.oblq 
    else if(vNFactors==3)
      vRotMethod.absCutoffs=project$cfa.absCutoff.3F.oblq
  } else {
    print("NOT A VALID ROTATION METHOD!")
    return(1)
  }
  
  
  
  for(vAbsCutoff in vRotMethod.absCutoffs){
    vLogicalLoadings<-project$model.calculateLogicalLoadingsFromEFA(loadings.table.indicator_factor = project$cfa.loadings.EFA[[iLoadings]]$loadings, absCutoff = vAbsCutoff)
    #logicalLoadings<-as.data.frame(abs(loadings.EFA[[iLoadings]]) > absCutoff )
    
    vLogicalFixedLoadings.TRUE<-project$model.calculateLogicalFixedLoadingsFromEFA(loadings.table.indicator_factor = project$cfa.loadings.EFA[[iLoadings]]$loadings)
    
    for(vEstimator in project$cfa.estimator){
      #for(vOrthogonal in project$cfa.orthogonal){
        for(vFixedLoadings in project$cfa.fixedLoadings){
          
          vLogicalFixedLoadings=vLogicalFixedLoadings.FALSE
          if(vFixedLoadings)
              vLogicalFixedLoadings=vLogicalFixedLoadings.TRUE else
                vLogicalFixedLoadings=vLogicalFixedLoadings.FALSE
          
          #test
          # iLoadings=1
          # vEstimator=estimator[1]
          # vOrthogonal=orthogonal[1]
          # vFixedLoadings=fixedLoadings[1]
          
          #lc.logicalLoadings[iLC]<-list(logicalLoadings)
          #lc.logicalFixedLoadings[iLC]<-list(logicalFixedLoadings)
          
          project$cfa.lc[iLC, project$cfa.lc.initialNames]<-list(
            ncol(vLogicalLoadings),
            vEstimator,
            vOrthogonal,
            vFixedLoadings,
            list(vLogicalLoadings),
            list(vLogicalFixedLoadings),
            vRotMethod,
            vAbsCutoff
          )
            
          
          project$cfa.lc[iLC,project$cfa.lc.factorLoadingNames.F1]<-vLogicalLoadings[,1]
          if(ncol(vLogicalLoadings)>1)
            project$cfa.lc[iLC,project$cfa.lc.factorLoadingNames.F2]<-vLogicalLoadings[,2]
          if(ncol(vLogicalLoadings)>2)
            project$cfa.lc[iLC,project$cfa.lc.factorLoadingNames.F3]<-vLogicalLoadings[,3]
          
          iLC=iLC+1
          
        }
      #}
    }
  
  }
  
}

```

### Add manually curated SEM models - Table CFA (2?)

```{r mnually defined SEM models, fig.width=9, fig.height=6, out.width="1600px", out.height="1000px"}

project$cfa.lc.initialNames.manual<-c("code.manual","description","nLatentFactor","hasOrthogonalFactorCorrelations","hasFixedLoadings","definition")

project$cfa.lc.manual<-data.frame()


#ADD ONE AS AN EXAMPLE
project$cfa.lc.manual[1,project$cfa.lc.initialNames.manual]<-
  list(
  "F1.EITHER.NA",
  "",
  1,
  TRUE,
  FALSE,
  '
F1 =~ NA*ANXI + DEPR + NEUR + SUBJ + ALCD + HEAL + TIRE
F1~~1*F1
'
)
project$cfa.lc.manual[nrow(project$cfa.lc.manual),project$cfa.lc.factorLoadingNames.F1]=FALSE
project$cfa.lc.manual[nrow(project$cfa.lc.manual),c("F1.ANXI")]=TRUE
project$cfa.lc.manual[nrow(project$cfa.lc.manual),c("F1.DEPR")]=TRUE
project$cfa.lc.manual[nrow(project$cfa.lc.manual),c("F1.NEUR")]=TRUE
project$cfa.lc.manual[nrow(project$cfa.lc.manual),c("F1.SUBJ")]=TRUE
project$cfa.lc.manual[nrow(project$cfa.lc.manual),c("F1.ALCD")]=TRUE
project$cfa.lc.manual[nrow(project$cfa.lc.manual),c("F1.HEAL")]=TRUE
project$cfa.lc.manual[nrow(project$cfa.lc.manual),c("F1.TIRE")]=TRUE


#add both estimation methods
project$cfa.lc.manual<-rbind(project$cfa.lc.manual,project$cfa.lc.manual)
project$cfa.lc.manual[1:(nrow(project$cfa.lc.manual)/2),c("estimator")]<-"ML"
project$cfa.lc.manual[((nrow(project$cfa.lc.manual)/2)+1):nrow(project$cfa.lc.manual),c("estimator")]<-"DWLS"

project$cfa.lc.manual$code.manual<-paste0(project$cfa.lc.manual$code.manual,".",project$cfa.lc.manual$estimator)

#combine both datasets
project$cfa.lc.manual[setdiff(names(project$cfa.lc), names(project$cfa.lc.manual))] <- NA
project$cfa.lc[setdiff(names(project$cfa.lc.manual), names(project$cfa.lc))] <- NA
 
project$cfa.lc<-rbind(project$cfa.lc.manual,project$cfa.lc)
 
# View(project$cfa.lc)

```

### Clean loading configurations
Remove duplicate configurations
```{r Clean CFA model configurations, purl=FALSE}

project$cfa.lc<-project$cfa.lc %>%
  mutate(
    id = row_number()
  )

project$cfa.lc.selected<-project$cfa.lc[which(project$cfa.lc$nLatentFactor>1 | (project$cfa.lc$hasOrthogonalFactorCorrelations==TRUE)),] %>%
  # filter(
  #   (F1.ALCD | F2.ALCD | F3.ALCD ) & # must include all indicators - THIS IS NOT WORKING?
  #     (F1.ANXI | F2.ANXI | F2.ANXI ) &
  #       (F1.HEAL | F2.HEAL | F3.HEAL ) &
  #         (F1.NEUR | F2.NEUR | F3.NEUR ) &
  #           (F1.SUBJ | F2.SUBJ | F3.SUBJ ) &
  #             (F1.TIRE | F2.TIRE | F3.TIRE ) &
  #               (F1.DEPR | F2.DEPR | F3.DEPR )
  #     ) %>%
  distinct(code.manual,nLatentFactor,estimator,hasOrthogonalFactorCorrelations,hasFixedLoadings,
           F1.ALCD,F1.ANXI,F1.HEAL,F1.NEUR,F1.SUBJ,F1.TIRE,F1.DEPR,
           F2.ALCD,F2.ANXI,F2.HEAL,F2.NEUR,F2.SUBJ,F2.TIRE,F2.DEPR,
           F3.ALCD,F3.ANXI,F3.HEAL,F3.NEUR,F3.SUBJ,F3.TIRE,F3.DEPR,
           .keep_all = TRUE) %>%
  mutate(
    id.selected = row_number()
  ) %>%
  #select(id,id.selected,project$cfa.lc.initialNames, project$cfa.lc.factorLoadingNames)
  select(id,id.selected,project$cfa.lc.initialNames.manual,project$cfa.lc.initialNames, project$cfa.lc.factorLoadingNames)

#View(project$cfa.lc.selected)

```

### Generate model definitions (and codes) for automatically created loading configurations
Procedure to construct model definitions from previous configurations, and codes!
```{r Generate model definitions, purl=FALSE}
#iConfiguration=21
icFrom=1
icTo=nrow(project$cfa.lc.selected)
for(iConfiguration in icFrom:icTo) {
  if(!is.na(project$cfa.lc.selected[[iConfiguration,c("code.manual")]]))
    next()
  cModel<-project$cfa.lc.selected[iConfiguration,]
  
  logicalLoadings<-as.data.frame(project$cfa.lc.selected[[iConfiguration,c("logicalLoadings")]])
  hasOrthogonalFactorCorrelations<-project$cfa.lc.selected[[iConfiguration,c("hasOrthogonalFactorCorrelations")]]
  hasFixedLoadings<-project$cfa.lc.selected[[iConfiguration,c("hasFixedLoadings")]]
  logicalFixedLoadings<-project$cfa.lc.selected[[iConfiguration,c("logicalFixedLoadings")]]
  
  configurationDefinition<-project$model.define(
    code.indicator = project$sumstats.sel$code.trait,
    allow_loading.table.indicator_factor = logicalLoadings,
    fix_loading.table.indicator_factor = logicalFixedLoadings,
    special.orthogonal = hasOrthogonalFactorCorrelations
    )
  
  project$cfa.lc.selected[iConfiguration,c("definition")]<-configurationDefinition
  project$cfa.lc.selected[iConfiguration,c("code")]<-paste0(cModel$id.selected,"_F",cModel$nLatentFactor,".",cModel$estimator,".",cModel$factanalRotation,".",cModel$factanalLoadingCutoff,".",cModel$hasOrthogonalFactorCorrelations,cModel$hasFixedLoadings)
}


#View(project$cfa.lc.selected)

```


### Run model actions and update result statistics
Run the model actions on specified models
```{r CFA model actions run, purl=FALSE}
project$cfa.lc.resultColumnNames<-c("chisq","df","p_chisq","AIC","CFI","SRMR")

if (file.exists(paste0(project$folderpath.working_directory,"/","project.cfa.result.",project$setup.code,".Rds"))) {
  project$cfa.result<-readRDS(file=paste0(project$folderpath.working_directory,"/","project.cfa.result.",project$setup.code,".Rds"))
} else {
  
  print("Performing CFA - this might take a while")
  
  project$cfa.lc.selected$fittedModelResults<-NA
  
  
  iModel=1
  for (iModel in 1:nrow(project$cfa.lc.selected)) {
  #for (iModel in 1:10) {
    try(
      {
        
    cModel<-project$cfa.lc.selected[iModel,]
    codeToUse<-cModel$code
    
    print("****EVALUATING MODEL****")
    print(paste(iModel,codeToUse))
    
    uModel<-project$model.evaluate(covstruc = mvLDSC$output.traits, model = cModel$definition, estimation = cModel$estimator, code = codeToUse)
    
    #grViz(uModel$path.graph.dot)
    project$cfa.lc.selected[which(project$cfa.lc.selected$id.selected==cModel$id.selected),project$cfa.lc.resultColumnNames]<-uModel$modelfit[1,project$cfa.lc.resultColumnNames]
    project$cfa.lc.selected[[which(project$cfa.lc.selected$id.selected==cModel$id.selected),c("fittedModelResults")]]<-list(uModel)
    
      }
      # error=function(cond){
      #   message(paste0("There was an error evaluating the model with code: ",cModel$code))
      #   message(cond)
      #   next
      # },
      # warning=function(cond){
      #   message(paste0("There was a warning evaluating the model with code: ",cModel$code))
      #   message(cond)
      #   next
      # }
    )
    
  }


  project$cfa.result<-project$cfa.lc.selected
  #View(project$cfa.result)
  #View(project$cfa.lc.selected)
  
  saveRDS(object = project$cfa.result,file = paste0(project$folderpath.working_directory,"/","project.cfa.result.",project$setup.code,".Rds"))
  print("CFA is done now and the result should have been saved into a file.")
}

```


## Process selected GSEM models and CFA results
```{r process selected GSEM models and CFA results, fig.width=7, fig.height=8, out.width="1000px", out.height="1000px", purl=FALSE}

# View(project$cfa.lc.selected %>%
#   filter(
#     F1.HEAL == FALSE & nLatentFactor == 1
#   ))

#only using ML-results, non-constrained/fixed configs, and automatically generated models
project$cfa.result.filtered<-project$cfa.result[which(project$cfa.result$estimator=="ML" & is.na(project$cfa.result$code.manual) & project$cfa.result$hasFixedLoadings==FALSE),] %>%
  arrange(nLatentFactor,hasOrthogonalFactorCorrelations,hasFixedLoadings,estimator,
          F1.ALCD,F1.ANXI,F1.HEAL,F1.NEUR,F1.SUBJ,F1.TIRE,F1.DEPR,
          F2.ALCD,F2.ANXI,F2.HEAL,F2.NEUR,F2.SUBJ,F2.TIRE,F2.DEPR,
          F3.ALCD,F3.ANXI,F3.HEAL,F3.NEUR,F3.SUBJ,F3.TIRE,F3.DEPR) %>%
  select(id.selected,nLatentFactor,code.manual,code,project$cfa.lc.resultColumnNames,project$cfa.lc.factorLoadingNames, hasOrthogonalFactorCorrelations,hasFixedLoadings,estimator,definition,project$cfa.lc.initialNames,fittedModelResults)

#View(project$cfa.result.filtered)

project$cfa.result.filtered.fc<-project$cfa.result.filtered %>%
  #filter(CFI>0) %>%
  arrange(code,desc(estimator)) %>%
distinct(nLatentFactor,code.manual,hasOrthogonalFactorCorrelations,hasFixedLoadings,
           F1.ALCD,F1.ANXI,F1.HEAL,F1.NEUR,F1.SUBJ,F1.TIRE,F1.DEPR,
           F2.ALCD,F2.ANXI,F2.HEAL,F2.NEUR,F2.SUBJ,F2.TIRE,F2.DEPR,
           F3.ALCD,F3.ANXI,F3.HEAL,F3.NEUR,F3.SUBJ,F3.TIRE,F3.DEPR,
           .keep_all = TRUE) %>%
  arrange(nLatentFactor,hasOrthogonalFactorCorrelations,hasFixedLoadings,
          F1.ALCD,F1.ANXI,F1.HEAL,F1.NEUR,F1.SUBJ,F1.TIRE,F1.DEPR,
           F2.ALCD,F2.ANXI,F2.HEAL,F2.NEUR,F2.SUBJ,F2.TIRE,F2.DEPR,
           F3.ALCD,F3.ANXI,F3.HEAL,F3.NEUR,F3.SUBJ,F3.TIRE,F3.DEPR,id.selected)
#View(project$cfa.result.filtered.fc)

project$cfa.result.filtered.fc.top_overall<-project$cfa.result.filtered.fc %>%
  select(id.selected,code,nLatentFactor,hasOrthogonalFactorCorrelations,hasFixedLoadings,project$cfa.lc.resultColumnNames) %>%
  arrange(desc(CFI))
#View(project$cfa.result.filtered.fc.top_overall)

#ONLY USE MODELS WITH SET CUTOFF CRITERIA
project$cfa.result.filtered.fc.selected<-project$cfa.result.filtered.fc[which(
  project$cfa.result.filtered.fc$id.selected==4 | 
  project$cfa.result.filtered.fc$id.selected==8 |
  project$cfa.result.filtered.fc$id.selected==20 |
  project$cfa.result.filtered.fc$id.selected==32 |
  project$cfa.result.filtered.fc$id.selected==48
  ),]
#View(project$cfa.result.filtered.fc.selected)
#View(mvLDSC$output$S)

u_var<-c(0.09361389,0.15059373,0.09761900,0.08888215,0.02491597,0.06714522,0.13560103)
#project$cfa.result.filtered.fc.selected$u<-NA


tl<-project$cfa.result.filtered.fc.selected[which(project$cfa.result.filtered.fc.selected$id.selected==4),c("fittedModelResults")][[1]]
tl<-tl[[1]]
#View(tl$results)
  u_m4<-c(0.058227747,0.046528635,0.061849977,0.025328249,0.009150558,0.029181996,0.035804984)
  u_m4<-u_m4/u_var
  u_m4.tot<-1-mean(u_m4)
  u_m4
  u_m4.tot

tl<-project$cfa.result.filtered.fc.selected[which(project$cfa.result.filtered.fc.selected$id.selected==8),c("fittedModelResults")][[1]]
tl<-tl[[1]]
#View(tl$results)
  u_m8<-c(0.059688969,0.044539874,0.036770878,0.020464435,0.008940125,0.003682382,0.036231314)
  u_m8<-u_m8/u_var
  u_m8.tot<-1-mean(u_m8)
  u_m8
  u_m8.tot
  
tl<-project$cfa.result.filtered.fc.selected[which(project$cfa.result.filtered.fc.selected$id.selected==20),c("fittedModelResults")][[1]]
tl<-tl[[1]]
#View(tl$results)
u_m20<-c(0.056592354,0.043626903,-0.003416338,0.016995216,0.009535329,0.019866091,0.038672158)
#u_m20<-c(0.056592354,0.043626903,0,0.016995216,0.009535329,0.019866091,0.038672158)
u_m20.tot<-1-mean(u_m20)
u_m20
u_m20.tot

tl<-project$cfa.result.filtered.fc.selected[which(project$cfa.result.filtered.fc.selected$id.selected==48),c("fittedModelResults")][[1]]
tl<-tl[[1]]
#View(tl$results)
u_m48<-c(0.0561654726,0.0071739548,0.0007812076,0.0172482246,0.0056486089,0.0184909492,0.0415302316)
u_m48.tot<-1-mean(u_m48)
u_m48
u_m48.tot

project$plots.tableCFA.results<-project$cfa.result.filtered.fc.selected %>% 
  select(code,nLatentFactor,factanalRotation,factanalLoadingCutoff,chisq,df,p_chisq,AIC,CFI,SRMR) %>%
  gt() %>% 
  fmt_number(columns = vars(CFI,SRMR), decimals = 3) %>%
  fmt_number(columns = vars(chisq,AIC), decimals = 0) %>%
  fmt_number(columns = vars(nLatentFactor,df), decimals = 0) %>%
  fmt_scientific(columns = vars(p_chisq), decimals = 2) %>%
  tab_header(
    title = "Confirmatory factor analysis"
  ) %>% cols_label(
    code = "Model code",
    nLatentFactor = "Number of latent factors",
    factanalRotation = "EFA rotation method",
    factanalLoadingCutoff = "EFA factor loading cutoff level", 
    df = "Degrees of freedom",
    chisq = html("Chi<sup>2</sup>"),
    p_chisq = html("p Chi<sup>2</sup>")
  ) %>%
  tab_style(
    style = cell_text(size = px(12)),
    locations = cells_column_labels(everything())       
  ) %>%
  tab_style(
    style = cell_text(size = px(12),weight = "bold"),
    locations = cells_body(everything())        
  )

project$plots.tableCFA.results


gtsave(data = project$plots.tableCFA.results, filename = paste0(project$folderpath.plots,"/TableCFA.results.rtf"))
gtsave(data = project$plots.tableCFA.results, filename = paste0(project$folderpath.plots,"/TableCFA.results.png"))

# Plot model configurations

# iModel=1
# for(iModel in 1:nrow(project$cfa.result.filtered.fc.selected)) {
#   cFittedModelResults <- project$cfa.result.filtered.fc.selected[iModel,c("fittedModelResults")]
# }



```


### Quick model testing
Testing CFA models
```{r CFA test, purl=FALSE}
#testing  F3.varimax.0.3
cfa.modelTest<- '
F1 =~ NA*ALCD+ANXI+DEPR+NEUR+SUBJ+TIRE
F2 =~ NA*ALCD+DEPR+HEAL+SUBJ+TIRE
F3 =~ NA*ALCD+ANXI+DEPR+NEUR+TIRE
F1~~1*F1
F2~~1*F2
F3~~1*F3
F1~~0*F2
F1~~0*F3
F2~~0*F3


'

#ANXI~~b*ANXI
#DEPR~~b*DEPR

cfa.modelTest.usermodel<-usermodel(covstruc = mvLDSC$output.traits, estimation = "ML", model = cfa.modelTest)
cfa.modelTest.usermodel$results$Unstand_SE<-as.numeric(cfa.modelTest.usermodel$results$Unstand_SE)
cfa.modelTest.usermodel$results$STD_Genotype_SE<-as.numeric(cfa.modelTest.usermodel$results$STD_Genotype_SE)
cfa.modelTest.usermodel$modelfit
cfa.modelTest.usermodel$results

resid(cfa.modelTest.usermodel)

cfa.modelTest.usermodel.semRes<-semPlate::parseSEMResult(resultDf = cfa.modelTest.usermodel$results)
cfa.modelTest.usermodel.graph.dot<-semPlate::generateDOT(nodeDf = cfa.modelTest.usermodel.semRes$nodeDf, edgeDf = cfa.modelTest.usermodel.semRes$edgeDf)
grViz(cfa.modelTest.usermodel.graph.dot)

cfa.modelTest.usermodel$modelfit %>% 
  gt() %>% 
  tab_header(
    title = "Model fit",
  )

cfa.modelTest.usermodel$results %>% 
  gt() %>% 
  fmt_number(columns = vars(Unstand_Est,Unstand_SE,STD_Genotype,STD_Genotype_SE,STD_All), decimals = 2) %>%
  tab_header(
    title = "Loadings",
  )

```


## Prepare summary statistics for GWAS
The summary statistics is prepared for analysis by using the sumstats()-function of the GSEM package. Here reference alleles are standardised across all datasets, and SNP effects and their s.e. are scaled to match unit-variance phenotypes.
```{r prepare summary statistics}
#eval=FALSE
#use ^this to knit without running the code in the chunk

#we need to introduce checks of the summary statistics and which scale they are on
# f.ex. Leo checks my s.e. 2 * pnorm(log(1.003) / 0.021644, mean = 0, lower.tail = FALSE)

if (file.exists(paste0(project$folderpath.working_directory,"/","lfGWAS.",project$setup.code,".Rds")) | project$seting.refreshPrepareSummaryStatistics) {
  lfGWAS<-readRDS(file=paste0(project$folderpath.working_directory,"/","lfGWAS.",project$setup.code,".Rds"))
} else
{
  print("Preparing summary statistics for latent factor GWAS. This might take a while.")

  lfGWAS<-c()
for(cCode in project$sumstats.sel$code)
    lfGWAS$trait<-c(lfGWAS$trait,paste0(project$cleanedpath,"/",cCode,".gz"))

lfGWAS$sumstats.prepared<-sumstats(
  files=lfGWAS$trait,
  ref=project$sumstats.refpath,
  trait.names=project$sumstats.sel$code,
  se.logit=project$sumstats.sel$se.logit,
  OLS=project$sumstats.sel$dependent_variable.OLS,
  linprob=NULL, #THIS SHOULD BE INVESTIGATED FURTHER, IF A LINEAR OLS ESTIMATOR ON A DICHOTOMOUS DEP. VARIABLE WAS USED FOR ANY OF THE DATSETS 
  prop=NULL,
  N=project$sumstats.sel$n_total,
  info.filter=project$info.filter,
  maf.filter=project$maf.filter,
  keep.indel=FALSE,
  parallel=FALSE,
  cores=NULL
  )

  saveRDS(object = lfGWAS,file = paste0(project$folderpath.working_directory,"/","lfGWAS.",project$setup.code,".Rds"))
  print("Done summary statistics for latent factor GWAS. The result should have been saved to a file.")
}

```

## Perform latent factor GWAS
```{r latent factor GWAS, eval=FALSE}

if(is.null(lfGWAS$userGWAS.correlated) | project$setting.refreshLatentFactorGWAS) {

print("Performing latent factor GWAS. This will take a while.")
  
lfGWAS$model<-"
F1 =~ NA*DEPR05 + ANXI03 + NEUR01 + SUBJ01
F2 =~ NA*ALCD03 + HEAL01 + TIRE01
F3 =~ 1*ANXI03 + ALCD03 + NEUR01 + SUBJ01 + TIRE01 + DEPR05

F1~~1*F1
F2~~1*F2
F3~~1*F3

F1~~F2
F1~~F3
F2~~F3

F3 ~ SNP

"

nrow(lfGWAS$sumstats.prepared)

#test with only chr 1
testsnps <- lfGWAS$sumstats.prepared[which(lfGWAS$sumstats.prepared$CHR==1),]
nrow(testsnps)

lfGWAS$userGWAS.correlated<-userGWAS(covstruc = mvLDSC$output, SNPs = testsnps, estimation = "ML", model = lfGWAS$model, modelchi = TRUE, printwarn = TRUE, sub=c("F3~SNP"), cores = NULL, toler = FALSE, SNPSE = FALSE, parallel = TRUE, GC="standard", MPI=FALSE)

saveRDS(object = lfGWAS,file = paste0(project$folderpath.working_directory,"/","lfGWAS.",project$setup.code,".Rds"))

print("DONE performing latent factor GWAS. The results should have been saved to a file.")

}

```


## Show latent factor GWAS results
```{r show latent factor GWAS, fig.width=9, fig.height=6, out.width="1000px", out.height="1000px"}
# View(lfGWAS$userGWAS.correlated[[1]])
# View(lfGWAS$userGWAS.correlated[[2]])

```


